### Kubernetes 自动扩缩：基于 CPU 的扩展

在 Kubernetes 中，**自动扩缩（Autoscaling）** 是一项强大的功能，它可以根据集群负载动态调整 Pod 副本数，确保系统始终以最佳资源利用率运行。在本节课中，我们将学习如何基于 **CPU 使用率** 实现自动扩缩，并展示如何设置 **HorizontalPodAutoscaler**（水平 Pod 自动扩缩器）来根据 CPU 使用情况动态调整 Pod 数量。

---

## 自动扩缩工作原理

自动扩缩允许我们通过指定目标 CPU 百分比和最小、最大副本数来自动调整 Pod 副本的数量。自动扩缩的工作机制如下：

- **CPU 百分比**：自动扩缩基于 Pod 请求的 CPU 百分比来工作。Pod 可以设置 CPU 请求，确保 Pod 被调度到具备足够 CPU 资源的节点上。如果 Pod 没有设置 CPU 请求，自动扩缩不会生效。
- **副本数调整**：当 Pod 的实际 CPU 使用率超过目标 CPU 使用率时，Kubernetes 会增加 Pod 副本；当实际 CPU 使用率低于目标时，Kubernetes 会减少 Pod 副本。扩缩的副本数会在最小和最大副本数之间进行调整。

---

## 设置自动扩缩前的准备工作

### 安装 Metrics Server

自动扩缩依赖于集群中收集的 **CPU 和内存** 使用情况。Kubernetes 提供了 **Metrics Server** 来收集这些指标，它是 Kubernetes 自己维护的解决方案。

1. **安装 Metrics Server**：

   ```bash
   kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.5.0/components.yaml
   ```

2. **检查 Metrics Server 是否正常运行**：

   ```bash
   kubectl top pods -n deployments
   ```

   这将列出集群中每个 Pod 的 CPU 和内存使用情况。

---

## 创建部署并设置 CPU 请求

为了启用自动扩缩功能，我们需要在部署的 Pod 模板中指定 **CPU 请求**，这样 Kubernetes 才能根据实际的 CPU 使用率进行扩缩。

### 设置 CPU 请求

在应用层部署中，我们为每个 Pod 设置了 CPU 请求，确保自动扩缩能够基于 CPU 使用情况进行扩展。以下是应用层的部署文件：

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-tier
  namespace: deployments
spec:
  replicas: 5
  selector:
    matchLabels:
      tier: app
  template:
    metadata:
      labels:
        tier: app
    spec:
      containers:
        - name: server
          image: node:latest
          env:
            - name: REDIS_URL
              value: "data-tier:6379"
          ports:
            - containerPort: 8080
          resources:
            requests:
              cpu: "20m" # 设置 CPU 请求
            limits:
              cpu: "50m" # 设置 CPU 限制
```

这里，我们设置了 **CPU 请求** 为 20 milli CPU（即 0.02 核心），**CPU 限制** 为 50 milli CPU。

---

## 创建 HorizontalPodAutoscaler

我们将创建一个 **HorizontalPodAutoscaler** 资源来实现基于 CPU 的自动扩缩。**HorizontalPodAutoscaler** 是 Kubernetes 中用来根据负载动态扩展 Pod 副本数的资源。

### 创建 HorizontalPodAutoscaler 资源

```yaml
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: app-tier-autoscaler
  namespace: deployments
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: app-tier
  minReplicas: 1
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
```

- **scaleTargetRef**：指定目标资源，这里我们将其指向 `app-tier` 部署。
- **minReplicas** 和 **maxReplicas**：设置 Pod 副本的最小和最大数量。
- **targetCPUUtilizationPercentage**：设置目标 CPU 使用率，当实际 CPU 使用率超过该值时，Kubernetes 会增加 Pod 副本数。

### 创建 HorizontalPodAutoscaler

```bash
kubectl apply -f app-tier-autoscaler.yaml -n deployments
```

---

## 查看自动扩缩状态

使用以下命令查看自动扩缩的状态和当前的 CPU 使用情况：

```bash
kubectl get hpa -n deployments
kubectl describe hpa app-tier-autoscaler -n deployments
```

- `kubectl get hpa`：查看自动扩缩器的当前状态。
- `kubectl describe hpa`：查看详细信息，包括当前的 CPU 使用情况以及扩缩历史。

---

## 测试自动扩缩

在创建自动扩缩器后，我们可以通过增加或减少 Pod 的 CPU 使用负载来触发扩缩。

1. **扩展应用层的副本数**：

   ```bash
   kubectl scale deployment app-tier -n deployments --replicas=5
   ```

2. **监控扩缩效果**：

   可以使用 `kubectl get pods -n deployments` 来查看 Pod 数量是否随着 CPU 使用的变化而发生变化。

---

## 小结

在本节课中，我们学习了如何为 Kubernetes 部署启用 **自动扩缩**：

1. 使用 **Metrics Server** 收集集群的资源使用情况；
2. 在部署中设置 **CPU 请求** 和 **CPU 限制**，以便自动扩缩能够基于实际的 CPU 使用情况进行扩展；
3. 使用 **HorizontalPodAutoscaler** 来根据 CPU 使用情况自动调整 Pod 副本数。

在下一节课中，我们将继续学习如何利用 **滚动更新** 来平滑地更新应用程序，确保在不影响可用性的情况下进行代码或配置的更新。
