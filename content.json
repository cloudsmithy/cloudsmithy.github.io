{"posts":[{"title":"文章声明","text":"master 分支保存源码 Docs 分支保存 markdown 文件 gh-pages 是做静态网页托管 发表文章： 微信公众号 HEXO Blog CSDN 外部媒体： AWS 公众号 极限科技 懒猫微服","link":"/posts/7556ae54/"},{"title":"懒猫微服专栏汇总","text":"从朋友的推荐一点点变成懒猫专栏作家。 入门篇 懒猫微服入门篇（零）：开箱初探，硬件亮相 懒猫微服实战入门（一）：从开启 SSH 到免密登录，一步步教你搞定远程管理 懒猫微服实战入门（二）: 打造多人协作环境：权限控制、数据隔离一步到位 懒猫微服实战入门（三）: 懒猫智慧屏，我以为是地表最强电视盒子，结果竟然可以改装成闺蜜机？ 懒猫微服实战入门（四）：完全 DNS 访问，和本地代理冲突了怎么办？ 懒猫微服实战入门（五）：文件上传到懒猫网盘，电视盒子挂载 SMB 观影 懒猫微服实战入门（六）：使用 2fauth 共享你的 MFA 懒猫微服实战入门（七）：超越蒲公英 SD-WAN，用懒猫转发服务，Ipad 随时远程家里 window，没有带宽和设备限制哦~ 懒猫微服实战入门（八）：懒猫微服 × SSH Remote：打造随时随地的云端开发环境 懒猫微服实战入门（九）：给懒猫安装图形界面，使用 XRDP 实现远程桌面 懒猫微服实战入门（十）：使用 nmtui 设置静态 IP，接入旁路由实现科学上网 懒猫微服实战入门（十一）：一键换源指南：用 chsrc 开启丝滑体验 懒猫微服实战入门（十二）：用 iVentoy 打造你的 PXE 服务器 懒猫微服实战入门（十三）：懒猫穿透不只图形化，纯命令行服务器也可以 懒猫微服实战入门（十四）：不登录客户端，如何用 Samba 挂载懒猫微服网盘？ 懒猫微服实战入门（十五）：大疆 Pocket3 素材导入懒猫网盘 懒猫微服实战入门（十六）：把懒猫微服当作 24 × 7 在线开发机 懒猫微服实战入门（十七）： 用懒猫微服的网盘挂载功能存储 steam 游戏 进阶篇 懒猫微服进阶心得（一）M 芯片移植懒猫应用构建 Docker 镜像的常见问题排查及解决方案 懒猫微服进阶心得（二）：一台机器跑三套 Docker？深入解析懒猫容器的共存机制（上） 懒猫微服进阶心得（三）：一台机器跑三套 Docker？深入解析懒猫容器的共存机制（下） 懒猫微服进阶心得（四）：每次重启都丢配置？用 systemctl –user 自动装回环境！ 懒猫微服进阶心得（五）：使用懒猫微服做 Ventoy 启动盘 懒猫微服进阶心得（六）：以纸砚双拼为例，快速移植纯前端项目到懒猫微服 懒猫微服进阶心得（七）：懒猫的镜像仓库 懒猫微服进阶心得（八）：如何在 ARM 机器上下载并运行 X86 Docker 镜像以及在 X86 上运行 ARM 架构 Docker 懒猫微服进阶心得（九）：商店 App 如何接管 Docker 引擎？ 懒猫微服进阶心得（十）：本地开发，如何接入懒猫微服的 OpenID Connect (OIDC)？ 炫技篇 懒猫微服炫技篇（一）：使用懒猫微服的穿透服务，车机使用 DS music 远程听歌，黑群晖不用再洗白 懒猫微服炫技篇（二）：使用懒猫微服倒推停电时间 故事篇 懒猫微服故事篇（一）：服务器宕机之后，我和前端靠懒猫微服结对编程 懒猫微服故事篇（二）：西湖邂逅后，我手把手教她玩转 NAS 开发篇 懒猫微服开发篇（零）：上架应用需要哪些知识 懒猫微服开发篇（一）：懒猫微服全栈上架指南，一步打包，一键发布 番外篇 自带内网穿透,懒猫微服治好了我的 NAS 焦虑 快速检索懒猫商店 1000+应用，微服秒变 Mac 原生 APP 轻松管理 ES 集群: 我把 Infinilabs Console 上架了懒猫微服，默认支持外网访问、TLS 加密和 OIDC 登录 深度长文：NAS 大降价的年代，我为何接受溢价来购买懒猫微服（附送回本攻略） 我用 Amazon Q 写了一个 Docker 客户端，并上架了懒猫微服商店","link":"/posts/e992f34c/"},{"title":"佛•教化•屠杀","text":"东鸡冠山迷了路，误闯了田间的坟地。 以至于到了日俄监狱，那份恐惧仍旧没有消失。高高厚厚的城墙，勾起了几年前途经伪皇宫的回忆，如果说高城壁垒是为了防止犯人逃窜，那么皇宫岂不是帝王将相的牢狱？这样想着，愿生生世世莫生于帝王之家倒是一种悲哀的绝唱了。 事实上，穿过城墙，里面并没有想象中的庄严，本以为这里的冤气会压迫灵魂，让人窒息，事实上是，一路惊魂未定，却连一丝血腥气都未曾嗅到过。 监狱明显翻新过，若是复古风格，经历过枪林弹雨的山石和被抓破了的淋满殷红的墙壁才与它相称。角落里卧着的一口大钟倒是引人注意，介绍上说，这是日本帝国主义卑劣行径的体现，过去每天都有僧人到这里来超度，借以来消磨人们的反抗意志。看到这里我无意为日本开脱，若是余生充满痛苦，透过佛法来看世界倒是一个不错的选择。佛教从古印度传到中国，日本，最后成为世界三大宗教之一，自然是可以为大众消灾解祸的。这里仅仅表明立场，不做任何评价。 不过倒是想起了关于安倍的一则新闻，安倍夫妇通过初等教育渗透“爱国主义思想”，那么这些东西就像一种信仰，正在这些孩子们大脑中根深蒂固，那么与宗教，还有我们从小被培养的抗日情怀，其实都是同样一种意识形态。 整个监狱不大，猜测犯人不足一千，里面有很多过去工厂的牌坊，现在一些关闭，一些则摆放一些遗物供人们参观。大概以前犯人们就都在这里劳作。还有医务室，对于重症的病人，当然安安静静的等待他们死去。因为在这里最便宜的就是人命，人命是换取劳动果实的易耗品，当然也是供这里的人取乐的工具。把犯人双眼用黑布蒙上，让其跪在地板上，然后把脖子套进绳索，再把木板抽走，人就掉在了几米之下的木桶里，然后被几个同伴默默地抬起奔赴坟场，狱卒在后面举着短枪，准备随时扣下扳机。 复原图倒是有几具骷髅，混着朽木和尘土。当然我十年前在黑龙江省博物馆便见过真实的骨架，除了不理解为什么手心那里是凹下去的，其余并没有什么意外。小时候也埋葬过燕子，所以对骨头并不怎么畏惧，也不觉得好端端的一个人忽然变成一堆白骨有什么奇怪的地方。那个年代，人命真的是不值钱的，有些人终其一生不过吃了几颗枪子而已。 那么与那时相比，我们是否更加幸运？当然是否定的。那时的冲突是意识形态，现在则是文化断层。我们是否要缅怀先烈？那也不必，这种历史不会再重演。若是生在战争年代，那么终生梦想便是世界和平，人生安稳。现在一定与那时不一样。有人说历史一共分为三种：第一种是已经逝去的岁月，往事不可追忆；第二种写在了各类史诗典籍中，可能迫于当时时局，略加修改；那么第三种便是自己阅读各类典籍，加上自己的心得体会，认为历史应当是这个样子。那么历史是不必躺在水晶棺中任人观赏的了。与华丽相比，应该更接近于真实。 那么现在中日关系如何？我们作为小人物当然不想太清楚。国际上有一条交友准则，没有永恒的朋友，只有永恒的利益。从旅顺回到大连，写下了这样的话： 旅大是日本的情妇，被百般虐待，所有的灵感都来源于她，荣誉则是成为一份作品，而毁灭也恰好是她。","link":"/posts/b4d03554/"},{"title":"写作大纲","text":"找回二十几年失去的东西，明明过活的那么认真，到头来却被伤的遍体鳞伤。从听话的孩子逐渐转向独立人格独立思想。以古为镜。 朋友篇 恋爱篇 社会篇 职场篇 校园篇 游记篇 随感篇 历史篇 文化篇 金钱篇 律法篇 道德篇 领导篇 美食篇 文人篇 为人处事，道德，杀伐决断 希望在自己耄耋之年，看淡这样的文字，不会觉得幼稚。","link":"/posts/8f3221dd/"},{"title":"地坛游记","text":"我总会在受伤后行动不便的日子想起史铁生。第一次是拄着拐杖，第二次是十年后坐上轮椅的时候。在此期间，我曾无数次羡慕在这京城中长大的孩子，仿佛从书中描述的都是另外的一个世界，一直持续到我来到北京工作，幸运的是工作和居住都在四环附近，大多的名胜古迹只需要一小时左右的车程。市内有很多前朝的遗址，比如元大都遗址公园，甚至明清时候的九宫八庙，自然也能发现一些陈年趣事， 比如光绪帝用自来水比我早了整一百年这种半封建半现代的事情。 东直门吃过午饭后，沿着安定路旁边的河流一路骑行，慢悠悠的来到地坛的南门。马路对面就是雍和宫，经常有无数善男信女来此求取姻缘。再往南就是北京很有名的小吃簋街，这附近总是热热闹闹的，丝毫找不到小说中“这院子无人打理”，“杂草从生”的痕迹，园内也是各色人等，还在襁褓中的孩子，放假休息的学生，一边游走一边电话的成年人，还有三两成群过来散步的老人。 沿着地坛外侧砖路散步，自然是脚本慢下来不在乎时间的流逝，一方面是为了找寻小说中提到的地点，另一方面也是想要亲眼见证石门下被照的透亮的坎坷。出门时候尚未规划好行程，又临时起意来到这园子，打算看这里的日落，是否会如湖面一样拖起长长的影子。参观祭坛要额外买票，在我从前去过的许多园林之中，祭坛多被虚掩起来，虽然现在早已不再从事祭祀的活动，所幸遗迹被肉眼可见的保留了下来。 正午的方泽坛，我装做皇帝一样走向高台，穿过外墙进入内墙，然后一步步的迈过阶梯，前面有人拍照也丝毫不去避讳。登上祭祀台，已经简化了很多东西，目前的摆设是遵循1750年乾隆时代的摆设。方泽坛对面是皇祇室，大堂的中央摆放着皇地灵位，左右内侧摆放着清代卓越贡献的几代君主的灵位，从介绍得知，他们的肉身葬在我不曾听过的地方，左右外侧供奉五岳、五镇、四海、四渎、五陵山神，而皇陵大概率是龙脉所在吧，惭愧对大清历史不求甚解，也不想亵渎前人再去抄送。破旧残缺的青砖总会让人想起故宫，甚至是影视剧午门问斩血溅五步的场景。祭坛低矮墙壁的角落里，有人在练习拉伸，有人刚刚把刀从鞘中抽出来，一时无法分辨刀是真品还是高仿，加上这人的穿着，颇有反清复明吕四娘的装扮。假期里来参观的人自然不少，父亲给孩子讲解着祭祀的斋戒礼教，男人躲在角落打电话谈着生意，小夫妻在拌嘴，走马观花后觉得不该来此，还有三五成群在这野餐拍照留念。我呢，在进门之前摘下耳机，登上这祭祀的高台，甚至已经想好了焚香祷告，烹羊宰牛的画面。殿中前现存的大多是复制品，确实无法像真品那样让人怦然心动。 去年在故宫大殿参观的时候是有真迹的，我鼓足勇气与石像对视，这石像经历了战国争雄，五代十国，以及数不清楚的动乱时候仍然总算完好的保存了下来，过去的创造他的人早已深埋黄土，几百甚至几千后它还会伫立在这里，变的只是一批有一批的瞻仰者。若不是空气中弥漫的腥臭的味道和铭牌上距今几百上千年的字眼过于突兀，我会沉浸在无尽的历史长河中久久不能回神。还有在东直门某博物馆看见的函谷关的瓦当，不得不又回溯起楚汉争入关中那段荡气回肠的历史。 从祭坛出来后，继续播放《我与地坛》的有声读物，重游重温一遍内容，新鲜的风景和记忆里尘封的旧的内容交织融合。他是后天的残疾，最后也没有看透生死，只得出来生没得选死不必急于求成的结论。倘若生下来从未体会过奔跑的感觉，那么便也只能怨天尤人，要是他一蹶不振不再写作，那就是另外的故事了。这是否又是今生来体验人间苦难的下凡？不管怎么样，我从不把这种这当作励志的故事。 于是我开始去设想从前的园子，大小应该不会有很大的变化。但西北口钟的那十分破旧的那一口钟现在已经无从得见，到处的荒野杂草野路被修缮成了整齐划一的灰砖，不变的是，倒还能在路边看见近乎晒干的了蚯蚓。尽管现在重修了钟楼，封闭了马厩，同时又加上了诸多娱乐设施。只是现代的气息太浓，若来追忆经典定会觉得索然无味。还好能找见几棵400年前明代的古树，不远处还有一个妇女在教孩子聆听树的声音。上了年纪的树自然是被铁圈围起来的，让人不自觉就想起摇曳尾于涂的典故了。而古树的枝条上，总会紫藤会围着这样的老树生长，交织和抱，开出淡淡的小花，引得路人争相过来拍照。园子北侧翻修的太彻底，丝毫没有小说中的痕迹，我尝试在树的附近寻找史铁生车轮的痕迹，当前正如他所说，这园子正在被不懂它的人精心雕琢。现在每个公开场所都有所谓的商业模式，这点798为首的文艺社群中尤为突出，自然地坛也无法幸免。来地坛之前，在想象是多么幽静的环境，比人高的杂草，以及东南角那高亢嘹亮的声音，每天从北到南从南往北的女工程师。现实却是丝毫没有桃花源的感觉，似乎成为人们茶余饭后来消遣的场所了，又不由得感叹现代人肤浅的享乐简直来的太过容易，无论每个公园都会有游乐设施在大煞风景，还有不知道是哪个年代的流行歌曲一直响个不停。思绪拉回现在，老人们在吹奏手风琴还有小号，另外一旁还有正在进行的门球的赛场，倒是孩子们在无所顾及的疯跑嬉闹。 但，对于这园子的一年四季，我总是无暇来观望的，就连楼下的后花园也很少去宠幸。除了文中提到的雨燕外，还有喜鹊，乌鸦，鸽子这些鸟类，算是为数不多超出作者的笔墨吧。倒是最近每年清明都去龙潭湖散步，看鸭子高飞，鸳鸯戏水。大概是距离首都图书馆比较近的缘故吧，常常是在潘家园的二手市场中恣意寻找后骑车到方庄。但别人用过的东西从风水上讲毕竟还会残留上一个人的精气，还无法完全接受。 在我那密不透风的学生时代，总觉得许多异乡游记是和三皇五帝一样传说的故事，而我却生在一个山高皇帝远的地方，守着些不为外人道的自然风光。甚至我在工作以后才有机会到一些不算太远的旧址吊唁。比如渤海湾曾经甲午海战的地方，东鸡冠山上到处是日俄战争枪林弹雨的痕迹，就连误入的墓群主人，也分不清到底是旧时的未亡人还是几年十几年甚至几十年前疲于奔命的过劳者，甚至脚踏的这片四方黄土就是乃木宝典战死之处，还有作为标志性的建筑的弹壳，我甚至不愿想象战争年代白发人送黑发人情感被上司大如天的威严严苛所淹没，死后被历史记住已经是最大了补偿了。大连是到处都有墓碑的，在每一个所谓现代定义的景点公园，凡事对外的，总会在一不留神间瞧见墓碑或者墓群就在不远处。中日之间是有宿命的姻缘的，这点在那些发生过大规模屠杀战争的地方尤为严重。大连的每一片土地都渗着鲜血，有革命先烈的，有当代年轻人的。当地的大户说，采集百年弱冠的血，用温热的殷红把混着泥土的陈年凝块化开，喝了可以长生不老。 故宫是溥仪的家，地坛也是史铁生的后花园。至于龙潭湖附近，长眠着一位《碧血剑》中的故人，功高盖主而殁于崇禎。两次拜会，第一次因为疫情，第二次由于天色渐晚行到庙前又不忍打扰。倒不是有多喜欢古迹，除了闲逛外，多半是朋友邀约或泛读诗书自然想去凭吊一番。 十九点按时日落，大概是因为现在楼宇太多的缘故吧，守了一个下午，从中午等晚上，一直到路灯亮起，也没有在祭坛的石门前瞥见落日的余晖。索性来到簋街，在胖妹面庄的胡同前排起长长的队，再顺手把这些记录下来。 2023年4月29日于地坛","link":"/posts/bb8b63b3/"},{"title":"外滩夜游","text":"黄浦江真的很出片，无论是白天在世博中心，夜晚的外滩，都会给你一种。身处大都市的感觉，下午的黄浦江风和日丽，偶有渡轮从江面驶过，夜晚的外滩，人流拥挤，放松的人群和和东方明珠隔江相望。 同事说，没有到过外滩就等于没有到过上海，所以我特地在外滩周围订了酒店，然后在黄埔的大都市，我尽情的游玩。计划里有外滩，豫园，城隍庙，还有人民广场，大世界，然后再这一圈 xxx。 就能让我骑着小黄车悠哉悠哉的去看夜晚慢慢变黑，虽然地铁也很近，但是不喜欢那种，但是喜欢那种夜幕悄悄降临的感觉，嗯，对于上班，对上班族最。最残忍的事就是早上踏着踏着日光，或者日光没出来的时候就要出发，那晚上迎接你的就是一片黑暗，你偶尔有。街上的霓虹灯，但就不足以照亮街边的路。 要骑车，这次实实在在栽了一个跟头，在望京的时候，我经常行行在一条笔直的马路上放开了双手去骑行，靠着自然的平衡去穿过一条又一条的街道。为什么说上海栽了一个跟头呢？这是一个实实在在的跟头。平地摔了，嗯，人行斑马线的油漆太重，而且但是在单手去查的导航，所以导致。直接重心不稳，整个人飞，整个人飞了出去，不敢想象当时后面的人是怎么样一个想法。 一般来讲，这种事情都会有一个预兆，比如说后面的事情不顺，但不幸中的万幸就是也就只有膝盖擦破了皮。在行驶到外滩的中途，刚好有一家药店，我可以去买一些消毒器械，简单简单处理过之后，我就到外滩来散步。 当然这两天总会遇到一些管制，比如你世博附近演唱会散场，人流拥挤导致这一带几乎封路，对于地铁站安安检也是无能为力，直接直接放弃，崩溃，直接崩溃，放弃我今天。外滩的周边是不是不允许驶入共享单车的，驶入或者是停放共享单车的，嗯。 这就和你知道长安街相似，长安街禁止在在进故宫一带，长安街只有自行车才能使用，包括带助力的。不带，不带助力的自行车才能驶入，包括电动车都是禁止进入的，所以。在去年的深秋，我才能从百子湾一路骑到石景山，这是我觉得长安街带给我的意义。那么对于外滩呢，嗯，简单的来讲就像是一条街。你沿着黄浦江上的一条街，对面是和陆家嘴这种都市中心不太相望，嗯，在这里我们就可以看到这座城市的地标。 我不知道对于在城市的地位，这两者是否等同，但是可以肯定的是，这里人潮拥挤，确实是一个不得不来的地方。 从上北京到上海，几乎没有什么不习惯的地方，严格上来说是在北京这些方面都被磨合的很好，但不同的地方就是。这里的外国人会多一些，随处可见老外在拍照，在等，等着等着这边的红绿灯。对不对也可以。 外滩当然也不例外，嗯，有来有的外国人也有，也有一对，也有有一些情侣。嗯，可能对于外滩相当于迪士尼来说，确实不是一个适合分手的圣地。 江上的渡轮来来回回的回顾着，似乎一些是为了品牌，另一方面就是为了让为了游客去拍出更加质量，更加有质量的照片。你自拍的时候还是也试着一个人旅游去拍照，但往往总不尽如人意，比如距离感。我没有去拍照，不少，有个有个孩子要，要我帮他去拍照，然后，然后。他还很很乖巧的帮我，帮我先拍了几张。 大概是出于长期被骗的一个新人的我下意识下意识去说，或者是会不会把我的手机带走这样的，但看着对方。看着像一个没有步入社会的大学生，而且是为了演唱会来到这里，后来也就加了微信，他给我传，还顺便赠送了我刚刚出片的照片。刚刚出炉的风景照，这得再次吐槽一下，苹果的像素太难了，安卓一张 16 兆，你苹果呢？ 嗯，大概是旅游高峰，而且又是日暮，大家都会堆在入口的地方，但。等回来的时候，可能由于这一片，嗯，一个小时就逛完了，然后等等出来的时候就可以。这人是少了很多，这里看高手大山。 自从离了渤海江畔，到大城市打拼，还真的没有，今年还真没有吹过海，无论是海风还是江风，几乎都没有吹过这样。明天不会感冒，是吧？ 转了一圈，又从外滩出来啊，一波又一波的人流，我一个个企图找到一个吃饭的地方，夜晚八点。嗯 来的时候开着导航，在小小巷子里左拐右拐，回去的时候逆着人流走一条最长的街道，然后。在这夜里的八点，你在上海最正宗的小龙虾。 意外的是连接就是和平饭店，嗯，前面有一堆的小吃，今晚只是过来逛逛和平饭店，改天去吃。","link":"/posts/b4d03554/"},{"title":"房间","text":"他还是饶有兴味的看着戏剧。对他来说没有什么比戏剧更能打发这个黄昏了。他在想他的妻子在他身边该有多好。前一天他们吵了一架，她一气之下离家出走就再也没有回来。现在他只能在这个没有几个观众的看台下，痴痴地望着台上，当然心里想的还是他的结发妻。只不过他的戏剧能让他感觉稍微好些。 “先生，麻烦你跟我们走一趟”两个警察模样的人出现在他面前，冷冰冰的声音划破了这一沉寂。我们这位好好先生可是从来不问缘由的，更何况他觉得自己也没犯什错。甚至于老婆吵架时，他都是默默的承受着家庭暴力。 这次的目的地不是警察局，竟然是他的家里。屋中仿佛听见一男一女在吵架，女的似乎在咆哮：“看你昨天带回来的那个小男孩，再这么养下去我们都要穷死了！”男的成熟稳重，但也极富心机，他似乎都看不到那人的脸。那人说的每一句话都好似千斤：“我自有安排。”那个女人的声音听起来好像他的妻子，不过凭着他对她的相信，这一荒唐的想法很快就被否定了，哪怕他们只是新婚。就算新婚之夜他们刚刚吵了一架，他们也相信彼此都知道，两个人的完美主义还要慢慢磨合。世界上绝对没有任何人可以替代彼此的位置。本想等她气消了之后再和他一起游山玩水的。结果他发现现在像重物一样被人摔在地上，然后被拖进了一间黑屋子里。 清醒了一会，他发现这个屋子的布局竟然和他家一模一样，而且他也告诉自己，仅仅是相似而已。这个黑屋子很像是他的卧室，只不过没有了灯，整个屋子就好一间暗房。他瞪大眼睛似乎不敢相信这是真的。难道是谁要向他复仇吗？怎么选择了个这么相像的地方。他是个好好先生，但是也得罪过不少人。慢慢的，他发现这个屋子里还有其他人。角落里蹲着一个小男孩，目光有些呆滞，衣衫褴褛，头发也有些凌乱，而且无论他怎么喊，男孩就是不理他。男孩的周围，有一排排的月饼礼盒，上边贴满了个各种情绪的标签。走上前，他看见“智慧”和“勇气”，他曾经毫不犹豫的选择了前者，不过他觉得现在应该换个决定了。只不过男孩前面标有“自卑”与“抑郁”的盒子已经空了。“哎，今天可是中秋，看来今晚是很难见到月亮的了。”他自言自语道。 还好是中秋，月光可以透过这些黑暗，给每一间黑屋子带来光明。“喂，你看见前面那扇窗了吗？打开它，我们就可以出去了。”男孩仍然不理他，径直向前，甚至连头也不回。“终究还是孩子。”他一边叹着气，一边跟了过去。走了几步他就看见一个小女孩的骸骨横在前方，月光下显得格外阴森。而小男孩由于留恋外边的新鲜空气再也听不到他的声音了。就好像月光之下有塞壬的歌声似的。 他也不晓得为何清楚的记得过去了两周，大概是处于艰难险境的人对时间更为敏感吧。小男孩最终还是倒在了小女孩的身旁。“是我害了他。”不过这句话他没有说出口，因为他的身边已经没有其他人了。求生的欲望越来越强烈，回过头，门是虚掩这的，而且无论如何都无法反锁。他想过从这扇门中穿过去，只不过竟然有些怕那些人都聚集在门口，他一时间招架不住，于是还是选择跳窗。 不知道是已经没有退路还是求生的愿望过于强烈，拉开窗户，几个跟头，他就翻入了下一层。 虽然是高层，但是还是阴森森的像一个地下室。昏黄的灯光下边，照亮的几处蜘蛛网。他只有拼命的奔跑，只不过这里除了实验室还是实验室，难道这里住着一个和他一样的工作狂吗？他很清楚他这样很快就会被后边的人追上。“快过来这里，这里很安全！”走近细看，那人竟然是他的姑姑。他也来不及多想了。 暂时松了一口气，他瘫软在地上，余光扫过地面，一批批的黑影掠过。那她姑姑呢？为什么他可以随意走动？为什么她知道知道这里就是绝对安全的？为什么……难道？他不允许自己再这么想下去了。 “他就藏在这里。快点！”一个似曾相识的声音，十分钟之前是如何告诉自己这里是如何安全，现在有是如何把自己推向绝望的深渊的，当然这就是人性，他早就已经见惯，这次却疏忽大意。当然他终究是个理性的动物，抓紧门锁，外边向右转一圈，他就向左转一圈，累了就干脆锁死，就这样一直僵持着。 “无论如何我也要救我的孩子。”门外传来一阵叹息。 母亲受人驱使只是为了救子吗？他的心忽然颤了一下，他知道这种情况母爱是绝对不会讲道理的。他松开门锁，放弃了抵抗。 “你要用我来换你的孩子可以，但是我出去一定杀了你！”这话他是吼出去的。 “好！”对面毫不迟疑。 门开了。 里面走出了一个瞋目怒视的人 ，浑身散发着杀气，仿佛眼神都可以杀人。只有那个为了救儿子可以赔上性命的人还站在那里，似乎在等待最后的仲裁。现在两方都已经切身感受到，面对死亡本身就该无所畏惧。 随从的人早已经被吓破了胆，她还是义无反顾的站在那里，他死死的扼住她的咽喉，哪怕是他的长辈，哪怕帮助过他又马上背叛了他。这些他都不再想，因为他早已经被愤怒所淹没。他死死的攥住她的脖子，仿佛下一秒就能像向捏死一只蚂蚁一样捏死他。只不过，他突然松开了手。“带我去见他。你快点！”冷冰冰的语气，一点亲情的味道都没有了。她不回应，只是不停的咳嗽。 回到了之前的地方，之前的一男一女早已不见，地下只剩下一个破旧的书包，是他少年时期用过的，他解释不清楚。黑屋里走出个人影，正是先前日子倒下的小男孩，不同的是，他变得干净帅气又阳光。“是你救了我！”男孩嘴角上扬。 “我要去报警。你去自首？”这位好好先生第一次表现的这么富有攻击性。 去警局的路上，之前发生的一切好像都消失了，就连那件屋子也在慢慢的崩坏。路的尽头，她的妻子在等着他，她也经历了同样的事。她首先打破了这一宁静，“亲爱的我想写本书。” “嗯？” “你之前不是说过每个人走不出自己的世界吗？” “那你这本书的名字就叫做《房间》好了。” “这是一个主人格被邪恶人格囚禁的故事。” “而且主人格终将获得胜利。” 他们彼此一次笑，又是黄昏，落日的石阶前，一切坎坷都被照的透亮。","link":"/posts/e1677cc4/"},{"title":"记年初的武汉游记","text":"头一天在重庆机场过的夜，到达江汉路步行街已经快中午了。在附近的来菜吃的藕汤，在北京就很爱吃清水亭，有藕的 N 多种做法，那么来到湖北不可不吃。 主要还是特意找问当地的小伙伴要了攻略： 推荐的专门吃东西的几条街是玫瑰街、粮道街、万松园、吉庆街这些。早餐小吃比较丰富，武汉的早餐文化特别浓厚，早餐种类特别丰富，很多碳水炸弹。 正餐可以考虑 来菜，是湖北菜，藕汤是湖北菜最具特色的。文章中下面的信息还是可靠的。 午餐：这个季节湖北的藕汤已经上市，基本上随便一家都很好喝，一定要选筒子骨藕汤，9 孔粉藕炖的那种。怕踩坑可以选一些连锁的，出品有保障，如刘胖子、老村长、艳阳天，不怕排队也可以去夏氏砂锅。 武汉魅族魅友家：https://weibo.com/2709494027/4973440665388967 这是小伙伴自己总结的 武汉推崇藕汤一定要用粉藕，有炒菜的那种，也可以点干煸藕丝，那就是不同的味道了 江汉路的风景不错，虽然是老城区，住宿条件差强人意。但总归风景和视野还是不错的，可以远眺长江，夜景也很美，楼下就是江汉路步行街。 携程上酒店骂声一片，都是吐槽住宿添加太差的。如果介意的话可以选择住对面的武昌。去的时候爆满，其他地区送早餐给升级房间的桔子水晶都没有增值服务了。 早上的江汉路是没什么人的，不过晚上到 12 点都很热闹。每天都是拖着走废的腿一瘸一拐的走回去的，青城山崴的脚，再经历重庆摧残，最后在武汉彻底残了。 武汉没有真正的市中心的概念，基本都是一个片区一个片区这样的。武汉本来就是三个城市合并来的，武昌重政治、汉口重经济、汉阳重工业。所以景区或者玩的地方相对也都比较分散。 早餐可以选严老幺的三鲜豆皮和黑色麻将的热干面。那个新出的三鲜面就不要点了，毕竟不是苏州，三鲜面很难吃！！！ 现做的三鲜豆皮，很多人排队，一定要现做现吃才好，这样外壳才是脆的。 山海关路来过个不早的早，每个人拿一个小板凳，5 块钱的热干面，三块钱的藕粉汤，基本早上就吃饱了。 第二天还是骑车到山海关路继续喝了藕汤，这家叫做金三角吊子煨汤。20 块钱一碗，有排骨有莲藕，总体来说比来菜吃的爽一点吧。算是在武汉吃到的第一个拉丝的藕。 山海关路也吃了三鲜豆皮，和毛氏汽水包。不过是在吃不下了，据说这家牛肉面也不错。嗯，来自襄阳。 这个是小伙伴的旅游攻略： 1、黄鹤楼，现在应该在准备春晚分会场，闭园了2、东湖有空可以看看，东湖绿道、或者磨山风景区也可以锻炼一下，都在东湖片区，哈哈3、湖北省省博物馆离东湖也很近。越王勾践剑、曾侯乙编钟是镇馆之宝。4、武汉大学凌波门不用去了，日出日落这个季节都不太合适。武大校园里面还行，建筑风格也很不错。5、宝通寺、古德寺、归元寺是寺庙，长春观是道观。6、黎黄陂路、昙华林是文艺青年打卡地。黎黄陂路有很多近代风格的建筑，适合拍照。昙华林有一些文创小礼品吧。7、江汉路、楚河汉街、武商梦时代是商圈。江汉路建筑风格是近代租界风格，距离江滩近。楚河汉街有新开的 SKP，奢侈品应该相对多一些。武商梦时代是亚洲最大的单体商场。 武汉魅族魅友家：https://weibo.com/2709494027/4973440665388967 武汉博物馆真的很大，需要留一天的时间来看。越王勾践剑需要排队很久。 沿着东湖骑车，慢慢就天黑了，然后发现自己在湖中央凌乱。武大不让进，所以一路都在怀疑自己，一个人在外地，大晚上在人少的地方骑车干嘛。 武汉玩的地方，可以考虑下湖北省博物馆，越王勾践剑和曾侯乙编钟（有时候会有编钟表演）。 东湖也还不错，比较大，春天有樱园，也可以在那边露营。这个季节不是特别推荐，风应该会比较大 江汉路步行街是商圈，仅临武汉江滩。江滩晚上可以看对岸的楼宇和大桥上的灯光表演，比较类似上次在杭州游船的风景 从东湖离开已经是这个点了。 在楚河汉街，基本是本老武汉强行拉倒店里。说没有预制菜，藕汤保拉丝。于是大众点评 L6 送了一个价值 60+的藕汤，然后点了一个干煸藕丝。算是在武汉吃的性价比最高的一顿。果然，大众点评高等级在哪里都吃香。不过后来朋友去，据说是是不再送了。 干煸藕丝很酥脆，虽然说干炸的牛肉不多，但是味道简直无可挑剔。不过一个人吃俩大菜是在是太撑了，还是得找个女朋友一起才好。 第二天又去了梨园。下午的东湖，美的不可方物。（没坐船，来回要七八十，而且要跟着船马上回来） 美的像一幅画。 晚上去的夏氏砂锅，因为谈季加上人少，所以基本没排队。 冬天点着炉火，喝着热气腾腾的藕汤，从上暖到下，还有这个藕是真拉丝呀～ 徒步横跨长江大桥，属于又菜又还玩，危险指数 4 颗星，车在走桥在晃，小哥自行车在眼前飘过。 用 Apple Watch 记录下这个过程。 春晚彩排的原因，黄鹤楼进不去。只能在外边听见 1234567 的敲鼓声音，不过很多人也说黄鹤楼在外边看看就好了。 文人的名楼情节，大概是拜崔颢的诗词所赐了。 最后一天来参观国民政府办公厅，现在的南阳大楼被改成了酒店还是饭店一类的场所，只有三楼对外开放。电视剧里的政府办公厅和这个很像。 请看大图 VCR： 还有江汉关博物馆的讲诉曾经的故事，近代的条约，租借等等。。。。 江汉路以及黎黄坡路的租借都改成了经典或者银行，但是我们仍然可以看到过去的岁月。 那，南京得什么样啊？ 临走之前吃了，王记牛杂，生滚牛肉热干面，真心不错。 回去写了三天四藕小记： 如果用藕来比作爱情，来菜是初相识，幻想最初的美好，该是粉糯入口即化如亲吻红唇，而非迎合大众变节故作搔首，又道是重口难调。再三思虑下，你终究不是我的头牌。出来乍到幻想要轰轰烈烈的爱情，一次次的修改已不愿再等。 老武汉是路边的艳遇，你听我诉着苦， 又抚着上次的伤口，于是急切的来一场试探性的邀约，再经历试探，喧闹，繁华过后，你把新唤作老。清炖，油炸样样拉丝。本已无可挑剔，可惜你在灯红酒绿，不能常常如愿。 小吃街是日常，简单不精致，朴华粗糙，藕形状不一，大口啃着才舒服，细小的渣碎弃之不要。调侃着来往的路人以及同桌的游客，看着提高嗓门吆喝的店家。同时还能大快朵颐享受着放松而自在的瞬间，虽无钟鸣鼎食，处处诉说着平平淡淡。 夏氏的砂锅是醇厚的，就着炉火，半暗的灯光下，乘上一晚热气腾腾的汤，软糯的藕配着油花花的汤，可以散去一整天的疲惫，这家拉丝也是最多的，点着炉火，就好像无论多晚多累总归有人懂你，等你。汤一定要微烫入口，否则要重新加热到沸腾才行，锅气才是真实的人间烟火。","link":"/posts/cc35fe6/"},{"title":"深夜随笔","text":"要说从读书开始伊始到大学毕业，最大的收获是什么。大概是独立之精神，自由之思想。通俗的来讲就是官逼民反，在一直听话的过程中一直无法满足期望与要求，厌倦了君臣父子的这种病态。从那时候起，开始很多的不相信，文化，教育，以及文凭。中国人喜欢毫无意义的卷，仿佛比别人多努力一点就能多得一些，长此以往，自然而然催生了大多数精致的利己主义者，以及优秀的绵羊。 从能力或者文凭来看，中国人更加趋近于文凭，一部分是为了面子，在邻里之间吹嘘，好似现代版读书人的事叫盗而不叫偷，另一部分是为了尽可能的避免别人像被挑白菜扔来拣去。做营销的人总会有一套，先给你制造各种各样的焦虑，然后宣称自己有灵丹妙药。从当今互联网的招聘状态来看，颇有捡芝麻丢西瓜的意味。从某种程度来讲，我们所谓的快乐式教育已经荡然无存，家长一方面希望孩子能一个快乐的童年，而另一方自己有深陷漩涡，希望下一代续写昨日的故事。所以，这样的单纯，善良最后就都变成了无知与不作为残害的牺牲品。甚至不知道我们为了什么以及为什么要这么做。 喜欢看武侠，风清扬说最厉害的招式不在武功之中，而是阴谋陷阱。这句话在这里也同样适用现在的教育，资源在少数人手中，算是寒门再难出贵子的境况。暂且不论这样的教育弊端如何，但在传统儒家的观念里的尊师重道仍然被保留了下来，但是却不会有对于道德的一些标准。于是我们常常在讲，是招一个道德好但是能力一般的人还是没什么道德但是专业能力很强的人？大概是从陈平开始，从举孝廉到任人唯能，所以汉王灭楚，魏武伐仲。宋襄兵败，任侠多累。 古代的功名利禄，是和科举考试有很大关系的。至于后人妄论八股骈文，却是身在其中而不自知。又有一群人，不管心里怎么想，但是做给别人看的总要符合这个身份和当时的规则。从这点看来，现在的人没有气节，也可以称的上是某种程度的投机分子。假意逢迎不合理的制度并且为了追求自身利益最大化而劳心费力，这样的人多了，就会对这样的环境起到了正反馈的作用，从人性来讲，不反对等于隐式认同。这其实和抗战时的汉奸特务无疑，他们也只是在居无定所中安身立命，尽管这会奴役和残害自己的同胞。但，对于国素质而言，从某种程度来讲， 冷漠遗忘不作为，却更胜于杀人分尸，路边人的健康温饱甚至生死，依旧不会被关心。偏偏很大一部分人又喜欢站在道德制高点来讲述这些话。唯一不同的一点是，现在人不必被钉在耻辱柱上，因为残害杀人的定义，是由律法来决定的。 文人的圈子中从来不缺乏批判，但单多半只是自娱而已，伴随的还有求而不得。只有身居高位才能付诸忧国忧民，血染疆场才能保家卫国。而治国之策能否施展，自然有历史为证：贾生才调，武侯余生，东坡鹰犬，放翁镜湖，嵇康放荡，阮籍穷哭，守仁流放，嗣同快哉。 回到现在。纵有诸多不适，但总归会隐忍着走完这一程，随之而来的是被贴上言简意赅的标签，然后用机械化的方式来查询 SQL。似乎现在的一切都能用古代文字来解决，“世有伯乐然后有千里马，千里马常有而伯乐不常有，故虽有名马，，，。安求其能千里”。教育可以做什么，历史可以带来什么，似乎有一双看不见的手，伸出大气层，蒙在了太阳之上。我们可以不关心国际形势，因为这是政治家的事情，当然也可以不关心战争，按照俄乌的节奏，世界大战是早晚的事，那其实科技也不必关心，程序员成了码农，人机融合遥遥无期。 小人物又能做些什么呢？余华笔下的福贵是凄惨的，莫言总是在讲述村野往事，韩寒的天才少年在夕阳下凌乱。在某个不经意的瞬间，我时常想起屈原的渔夫，苏轼的洗儿，陆游的咏梅，以及闻一多的暗杀……","link":"/posts/fb8d6bf1/"},{"title":"爱情是婚姻的坟墓么","text":"婚姻是第二次投胎。 所谓爱屋及乌，经常有一种爱她就要包容她的一切的言论。那么反过来也是一样的，如果是在几经磨合之后仍然不能付诸真心，或者经历了无数次想去改变对方，再或者对现状无能为力只能默默叹气的时候。举个例子，对妹夫看不顺眼的时候，但凡在他们孩子身上看到任何相似之处，也都会有种莫名的不喜欢，甚至是把情绪转移过来。 周围的人大概有这样几种状态，单身未婚，同居未婚，已婚未育，已婚养娃。 单身未婚要么没有遇到正缘，要么是感情上面的独行者，常常被他人贴上活在自己世界，适合一个人的标签。他们也许渴望一场轰轰烈烈的爱情，但从不轻易涉足。 同居未婚，有些人打算长期维持这样的状态，彼此间相对比较独立，而且大多是丁克主义，双方也有稳定的收入，还不用在乎双方的亲戚闲言碎语以及社会舆论，那么在矛盾冷战时候也会发出是不是分手的质疑？ 还有很大一部分人，不管条件如何，总归是先住在一起，然后再慢慢磨合，他们可能是大学生，也可能才刚刚步入社会，经常说出的话是顺应自己内心的想法，而且大多讲究顺理成章顺其自然，一旦有了夫妻之实，在分开之后另寻新欢很难说不是二婚。 当然也有些是真爱，本就打算结婚，然后住在一起，互相之间总会有个照应。然后一起走过磨合，订婚，再结婚的过程，这也不失为一段佳话，既加深了羁绊，也创造了彼此间的记忆，甚至哪怕新婚燕尔，甚至也能用老夫老妻这样的话语来调侃了。 养娃的人是最累了，十月怀胎，甚至民间还有一孕傻三年的说法。前几种情况相比，只有这有母性的光辉。而且常常被不孝有三，无后为大的观念所左右。不管是出于传宗接代还是其他的目的，在这的过程中，总会不自觉得强加上去自己的想法，甚至要求他做的更好抑或是不能落后于人，抑或者彻底沦为炫耀的资本。但对于家庭和事业兼顾的人来说，这往往很难两全，总会给孩子留下一些原生家庭的不安与不适感，并且常常对此无能为力。 几十年后的养老院，还是那样大的院子，周围还是同龄的人，仍然会把人分门别类，依旧听着要那个人的发号施令，江湖依旧是那个江湖。但，最近的新闻总是看的心惊胆寒，现代文明带来的身心不适已经极大的缩短了人的寿命，谁又能保证真的能活到那一天呢？幼年时盼望有人披着晚霞，踏着黄昏带你走出这桎梏，耄耋之年为何又作茧自缚，穿过着一阵阵的喧嚣，却只能看他人天伦。 对于不婚不育的人，我们一方面要感谢他们为人口减少作出的贡献，另一方面也会出于自己小小的私心，想要伴随生命从小到大的成长，即使无法告知他人生的意义，即使在他18岁的时候会也发出安德烈一样的感慨。谁说不能效仿古人，一门七进士，父子三探花呢？","link":"/posts/5102820d/"},{"title":"雨","text":"小时候，雨是村头泥泞的路口，墙角湿滑跌在原地，不穿雨靴，不披雨衣，一把天堂伞默默撑到彼岸。 上学后，雨是城中疾驰的孩子，结队成群疾行风中前有单车，后有乌云，一盏日光灯悄悄驱散阴霾。 工作了，雨是都市湿漉的地板，半干半湿透着氤氲，昨夜雨疏，今夕风骤，一个外乡人匆匆留念海棠。 其实呢，雨该是镜湖踉跄的渔夫，驿外断桥咏叹春梅。清者濯缨，浊者濯足，一代文化人静静独留风骨。","link":"/posts/13ca4a36/"},{"title":"极限科技稿件数据","text":"6 月数据 发布时间 文章标题 文章链接 阅读量 统计时间 2025-06-25 22:00:50 · 本地 RAG 实战：用 EasySearch + Ollama SDK 半小时搭建检索增强问答系统 1156 阅读 · 2025-07-02 2025-06-24 16:39:01 · Easysearch 实战指南：修改索引主分片的三种方式（split / shrink / reindex 1251 阅读 · 2025-07-02 2025-06-24 13:45:59 · Easysearch 索引关闭与重开全攻略：open/close 操作、批量处理及防误操作配置 1001 阅读 · 2025-07-02 5 月文章 发布时间 文章标题 文章链接 阅读量（CSDN） 统计时间 备注 2025-05-09 13:19:39 · [轻松管理 ES 集群: 我把 Infinilabs Console 上架了懒猫微服，默认支持外网访问、TLS 加密和 OIDC 登录](轻松管理 ES 集群: 我把 Infinilabs Console 上架了懒猫微服，默认支持外网访问、TLS 加密和 OIDC 登录.md) CSDN:https://blog.csdn.net/weixin_38781498/article/details/147819180 2511 阅读 · 2025-06-03 2025-05-05 15:28:09 · MySQL 数据实时接入 Easysearch，零代码迁移全流程 CSDN:https://blog.csdn.net/weixin_38781498/article/details/147718262 3218 阅读 · 2025-06-03 4 月文章 发布时间 文章标题 文章链接 阅读量（CSDN） 统计时间 备注 2025-04-24 17:37:45 · [从认证到透传：用 Nginx 为 EasySearch 构建一体化认证网关](从认证到透传：用 Nginx 为 EasySearch 构建一体化认证网关.md) CSDN:https://blog.csdn.net/weixin_38781498/article/details/147484530 1728 阅读 · 2025-05-06 2025-04-25 15:54:34 · [Easysearch 基础运维扫盲指南：从 HTTP 到 HTTPS、认证与安全访问全解析](Easysearch 基础运维扫盲指南：从 HTTP 到 HTTPS、认证与安全访问全解析.md) CSDN:https://blog.csdn.net/weixin_38781498/article/details/147514771 1947 阅读 · 2025-05-06 2025-04-23 18:12:08 · [Easysearch 服务昨天还好好的，为什么今天突然访问不了了？](Easysearch 服务昨天还好好的，为什么今天突然访问不了了？.md) CSDN:https://blog.csdn.net/weixin_38781498/article/details/147460362 1446 阅读 · 2025-05-06 2025-04-17 22:05:49 · [零代码接入 Google Drive，让 Coco- AI 看懂你的资料库](零代码接入 Google Drive，让 Coco- AI 看懂你的资料库.md) CSDN:https://blog.csdn.net/weixin_38781498/article/details/147314801 2254 阅读 · 2025-05-06 2025-04-17 20:10:35 · [Coco-AI 接入自定义数据源](Coco-AI 接入自定义数据源.md) CSDN:https://blog.csdn.net/weixin_38781498/article/details/147312961 1069 阅读 · 2025-05-06 2025-04-17 19:04:29 · [Coco-AI 集成语雀作为语料库进行检索](Coco-AI 集成语雀作为语料库进行检索.md) CSDN:https://blog.csdn.net/weixin_38781498/article/details/147311955 1137 阅读 · 2025-05-06 2025-04-03 21:32:39 · [Coco-AI 支持嵌入，让你的网站拥有 AI 搜索力](Coco-AI 支持嵌入，让你的网站拥有 AI 搜索力.md) CSDN:https://blog.csdn.net/weixin_38781498/article/details/146989181 1775 阅读 · 2025-05-06 2025-03-24 18:39:29 · [Docker-Compose 部署 EasySearch 异常问题排查](Docker-Compose 部署 EasySearch 异常问题排查.md) CSDN:https://blog.csdn.net/weixin_38781498/article/details/146483037 1174 阅读 · 2025-05-06 3 月文章 发布时间 文章标题 文章链接 阅读量（CSDN） 统计时间 备注 2025-03-20 21:50:50 · [拓展 Coco AI 功能 - 智能检索 Hexo 博客](拓展 Coco AI 功能 - 智能检索 Hexo 博客.md) CSDN:https://blog.csdn.net/weixin_38781498/article/details/146407174 1485 阅读 · 2025-04-01 2025-03-18 12:36:10 · [Coco AI 智能检索 Hugo Blog 集成指南](Coco AI 智能检索 Hugo Blog 集成指南.md) CSDN:https://blog.csdn.net/weixin_38781498/article/details/146338445 1541 阅读 · 2025-04-01 2025-03-11 09:21:48 · [Coco AI 全新升级：全图形化 RAG 配置，一键开启智能知识管理！](Coco AI 全新升级：全图形化 RAG 配置，一键开启智能知识管理！.md) CSDN:https://blog.csdn.net/weixin_38781498/article/details/146170047 857 阅读 · 2025-04-01 2025-03-09 17:15:36 · [Easysearch 使用 AWS S3 进行快照备份与还原：完整指南及常见错误排查](Easysearch 使用 AWS S3 进行快照备份与还原：完整指南及常见错误排查.md) CSDN:https://blog.csdn.net/weixin_38781498/article/details/146135024 1294 阅读 · 2025-04-01 2025-03-09 11:03:08 · [Easysearch 中 PUT 和 POST 更新索引的区别及常见错误解析](Easysearch 中 PUT 和 POST 更新索引的区别及常见错误解析.md) CSDN:https://blog.csdn.net/weixin_38781498/article/details/146128940 1517 阅读 · 2025-04-01 2 月文章 发布时间 文章标题 文章链接 阅读量（CSDN） 统计时间 备注 2025-02-11 Macbook Pro 快速搭建 Easysearch 学习环境 CSDN:https://blog.csdn.net/weixin_38781498/article/details/14557411微信公众号: https://mp.weixin.qq.com/s/Q9DfNtarX7uwvrBKCoQqDA 1037 2025-03-02 2025-02-16 Coco AI APP 初体验：开启智能知识管理新篇章 CSDN:https://blog.csdn.net/weixin_38781498/article/details/145660517微信公众号: https://mp.weixin.qq.com/s/Q9DfNtarX7uwvrBKCoQqDA 1331 2025-03-02 2025-02-17 打造智能语料库：通过 Coco AI Server 实现 Notion 笔记 RAG 检索功能 CSDN:https://blog.csdn.net/weixin_38781498/article/details/145692866微信公众号: https://mp.weixin.qq.com/s/E2wMtwF_qioqb1wwp8CZfg 1170 2025-03-02 2025-02-20 推荐给 Easysearch 新用户的几个 Elasticsearch 可视化工具 CSDN:https://blog.csdn.net/weixin_38781498/article/details/145764424微信公众号: https://mp.weixin.qq.com/s/RaiDPtKJktssJpfd58Tehw 394 2025-03-02 2025-02-22 实现 INFINI Console 与 GitHub 的单点登录集成：一站式身份验证解决方案 CSDN:https://blog.csdn.net/weixin_38781498/article/details/145792720微信公众号: 1018 2025-03-02 2025-02-21 使用 INFINI Console 配置集群监控 Webhook 通知指南 CSDN:https://blog.csdn.net/weixin_38781498/article/details/145787827微信公众号: https://mp.weixin.qq.com/s/5okVri7IOfNgtG17wXgH-g 706 2025-03-02 模板 发布时间 文章标题 文章链接 阅读量 统计时间 备注 2025-12-01 xxx1 CSDN:微信公众号: 666 2025-01-01 2025-12-12 xxx2 6666 2025-01-01","link":"/posts/8e911a70/"},{"title":"代码之髓","text":"1。 从需要的地方开始阅读2。 先掌握概念再细读3。 如果以上不奏效，从头开始手抄。按照时间间隔来衡量学习效果，每隔 25 分钟看学习了多少。","link":"/posts/fc64123d/"},{"title":"关键20小时","text":"快速学习●分解步骤——把技能做最大程度的细分，分成若干小步骤。 ●充分学习——对每个小步骤进行充分学习，以便进行灵活的练习，并在练习中自我纠正。 ●克服困难——克服在练习中出现的生理、心理或者情绪上的障碍。 ●集中练习——至少用20小时集中学习最重要的小步骤。 技能习得1.早期认知。了解你即将学习的技能是什么，探索研究，想想整个过程，把技能细分为几个可以控制的小步骤。 2.中期联想。训练、注意环境反馈，根据反馈调整方法。 3.后期自主训练。不用怎么有意识地注意方法步骤就可以很自如地开展技能训练 速习得技能的10个方法1.选择方向；如果你优先学习你感兴趣的事，那么你肯定花不了多少时间就能学成。 2.集中精力；“集中精力，只学一门”对快速习得技能的重要性是不言而喻的。当然，这并不意味着你把其他技能拒之门外，只是你暂时将之搁置，等待未来重拾。 3.制定目标；你的目标制定得越轻松，掌握相关技能的速度就越快。快速习得技能的目的并不是要尽善尽美，成为世界级大师，而是要在兼顾能力和效率的同时，快速提高技能。 4.分解技能；我们学习的大部分技能都需要细化步骤。当定下想学习的技能后，就该把这项技能细化为若干步骤。学会对步骤进行筛选。把关键的步骤先找出来，再集中时间和精力去学习。 5.获得工具；对于某些技能而言，只有获得了必备工具，我们才可能最大限度地利用时间充分学习。 6.扫除障碍；●训练前的准备工作。例如，训练前找不到工具放哪儿了；训练前还没有选到合适的工具；忽略训练的必要条件。●使用临时训练工具。例如，借别人的装备，也就是说，你使用的器材是有时间限制的，随时会被要求归还。●环境干扰。例如，开着的电视；突然响起的电话；刚刚收到的电子邮件。●情绪障碍。例如，害怕；怀疑；害羞。 7.腾出时间；腾出时间,建议你下决心保证20小时的训练量。一旦训练开始，就别停下来。如果中途卡住了，一定要坚持住，直到达到20小时这个初级训练目标。如果你没有毅力投入20小时，那么请你放弃。 8.及时反馈；快速反馈有助于快速习得技能。如果反馈及时或只有一点点延迟，我们会更容易把实际操作情况和目前所获得的结果联系起来加以分析，再做出适当的调整 9.计时训练；初学一门新技能时，往往容易过分估计实际投入训练的时间。特别是当你状态不佳时，你会发现训练时间过得像蜗牛爬一样，慢慢吞吞。事实上，你实际训练的时间远没有自我感觉的时间那么长。你只需遵守一个规则：一旦计时开始，中途一定不能停下来。记住：在你练得有点泄气时，这个方法会让你更加轻松地完成更为持久的训练。持续训练的时间越长，技能习得就越快。每天腾出时间做3~5次这样的分段计时训练，短时间内就会看到明显步。 10.数量速度。刚开始习得新技能时，人们往往希望做得尽善尽美，但力求完美很容易让人产生挫败感。因为我们永远都不可能做到百分之百的完美。别去设想有完美的表现，保持良好状态的同时，保证训练量和训练速度才是最应该考虑的。练就一门技能必须用心，必须坚持。刚开始学习时，不要盲目追求质量，相反，必要的训练量和训练速度才是制胜法宝。练得多，练得快，才能学得快。 有效学习的10个方法1.收集信息；实践前，查阅一下和这门技能相关的信息是十分必要的。例如，花20分钟的时间上上网、去书店或者去住所附近的图书馆找找相关参考书和资料。总之，你应该想方设法地找到关于这门技能的参考书（至少三本）、教学DVD、教学课本或者别的学习资料。 2.克服困难；在早期研究中，参考资料里有很多让人疑惑不解的地方，有的是概念，有的是方法，有的是理念。通常情况下，你很清楚它们的重要性，可是你始终无法理解它们的意思。既无法理解为什么要这么说，也无法理解为什么要这么做。别紧张，有困惑很正常。 不愿克服困难是影响技能习得快慢的主要因素。愚蠢的感觉的确不好受，不过请你随时提醒自己：随着技能实践的不断深入，你会慢慢解决这些疑惑，最终理解这门技能 3.关联类比；不愿克服困难是影响技能习得快慢的主要因素。愚蠢的感觉的确不好受，不过请你随时提醒自己：随着技能实践的不断深入，你会慢慢解决这些疑惑，最终理解这门技能 4.逆向思维；学习新技能前，别去幻想你会学得多么完美。多设想一下最坏的结局吧！ 5.咨询交流；投入时间和精力学习新技能前，有必要和内行聊一聊。这样我们可以提前预知技能训练的每个阶段会遇到的情况，从而消除对技能学习的疑虑和误解，使我们在技能训练的过程中不但不会灰心丧气，反而会更有兴趣坚持下去。 6.排除干扰；干扰因素越少，技能习得就越有效。 7.间隔重复；“间隔重复”是一个很好的记忆方法，它可以帮助我们定期且系统地回顾所获取的知识和信息。对于那些记忆起来有难度的信息，我们更要经常复习，而对于那些记忆起来相对简单的旧知识，我们不必经常复习 推荐：Anki SuperMemo Smartr 8.创建定式；大多数技能学习都有一套固定的模式：确定项目、着手准备、坚持学习等。建立一套简单的定式可以让我们比较轻松地了解其中的关键环节。罗列清单方便我们记住学习要点，使技能训练的流程更加系统化，以便我们把精力投入到关键环节上。创建定式确保每次训练都有一套固定的模式。 9.预期测试；预期测试是指依靠已知经验，在尝试实践前假设接下来会发生的变化或者产生的结果。如果你养成了预期测试的习惯，那么你学技能会更高效。科学地讲，预期测试结果随着以下四个因素的变化而变化 ●观察——你最近在关注什么？●经历——你对这个领域了解多少？●假设——怎样做会才会更进一步？●测试——下一步你有什么新尝试？ 我建议用一个笔记本或者其他的工具记录你在训练中做出的假设。如果你不断思考这些假设，并且形成新的想法，那么你的实验成果会更加丰硕。 10.尊重生理。我们的大脑和身体都处在各自的生理系统中，因此，它们都有生理需求，比如食物、水、锻炼、休息、睡眠。我们不能把自己逼得太紧，这样会适得其反。因为大脑和身体在没有足够能量储备的情况下是不可能高效运转的 最佳学习周期是90分钟左右，在这个周期内，人的精力是最集中的。大脑和身体都需要一个自然的休息。因此，我们要瞄准时机锻炼、休息、吃饭、享用零食、打盹儿或做别的事情。 定期腾出时间练习，这就是练习的诀窍。","link":"/posts/614ff5d2/"},{"title":"吃掉那只青蛙","text":"明確目標：確定你自己究竟想要什麼。目標清晰至關重要。在每天開始工作之前，把你的目標全部寫下來。 精心計劃：把你的想法付諸筆端。你花費在準備工作上的每一分鐘時間，都將使你在工作過程中節約 5 ～ 10 分鐘的時間。 運用 80/20 法則：20%的活動能產生 80%結果。因此，盡量把你的精力集中在那 20%的活動上。 著眼未來：對你來說，最重要的、應該優先處理的事情就是那些將對你以後的生活或者工作產生最重要影響的事情，無論該影響是正面的還是負面的。首先全力以赴地處理這些事情。 學會說「不」：既然你沒有時間去做所有的事情，你必須學會推遲處理那些沒有什麼意義的工作，從而騰出時間來處理那些少數的、重要的工作。 使用 ABCDE 法：根據自己列出的工作清單開始工作之前，先花費一點兒時間，根據輕重緩急對這些事情進行安排，從而確保你先處理最重要、最有價值的事情。 抓住關鍵：要想圓滿完成自己的工作，你必須具備哪些能力和技能？找出這個問題的答案，然後通過日復一日的努力來解決上述問題。 抓大放小：找出你工作中最重要的三件事情，你對公司 90%的貢獻都來自這三件事情。無論如何，先把這些事情做好，然後，你才能騰出更多的時間來安排你的生活。 精心準備：著手工作之前，先把一切都準備就緒：所有的資料、信息、工具、辦公用品，以及你可能用得到的數據，然後，你就可以全心全意地工作了。 循序漸進：如果你下定決心一步一個腳印地前進，那你就能完成最艱巨、最複雜的工作。 精益求精：你在自己的領域內知識越淵博，技能越嫻熟，你動手就越快，任務完成得就越早。 施展才華：確定你最擅長做什麼事情，或者說你能把什麼事情做得最好，然後全身心地投入這些工作，精益求精。 突破瓶頸：確定影響你實現自己目標的瓶頸所在，或者是主要障礙，無論是來自外界還是來自自身，然後集中精力消除這些障礙。 自我施壓：假設你即將離開你所在的城市，外出一個月的時間，離開之前必須把所有重要的工作都處理完。 挖掘潛能：確定你每天什麼時候處於腦力和體力的最佳狀態，然後據此安排自己一天的工作，盡量在這段時間裡處理那些最重要、最緊迫的任務。要注意充分休息，從而保證最佳狀態。 說幹就幹：做你自己的拉拉隊隊長。在任何情況下，都尋求事情積極的一面。把精力集中在如何解決問題上，而不是問題本身。要保持樂觀向上的態度。 避開科技陷阱：你可以利用高科技來提高自己的通訊質量，但是注意不要讓自己成為科技的奴隸。要學會偶爾把所有的通訊設備都關掉，切斷自己與外界的聯繫。 化整為零：把複雜而又艱巨的大任務分割開來，變成許多部分，每次只處理一小部分。 創造大塊時間：為自己安排一份日程表，然後集中精力用那些大塊的時間來處理對你來說最重要的事情。 培養緊迫感：養成迅速處理重要工作的習慣。把自己培養成一個能迅速、圓滿完成工作的人。 全力以赴：根據事情的輕重緩急來安排優先處理的事情，然後立即著手處理最重要的、必須優先處理的事情，全心全意地去做這件事情，決不中途停止，直到百分之百地完成為止。這是工作高效、業績突出的關鍵所在。 下定決心，每天都實施這些規則，直到它們成為你的第二本性。一旦你在時間管理方面養成上述習慣，使之成為自己個性中一個不可分割的部分，你的前途將不可限量。說做就做！吃掉那只青蛙！","link":"/posts/4141dd35/"},{"title":"好叶视频笔记","text":"有明确目标，加速达成规划 目标不会不变（喜欢做的/擅长的）、 成功不需要天赋（结合自己的技能/技能优劣分类，找出 5 个） 好点子+简单策略，成就=潜能/方向（更高目标+要事优先+其他想法记录暂缓+成功健康共存），其他选择 say no 热情源自于成功，毁于挫败和标签。 创造热情的方法（创造，抢新潮流，整合自己的技能点） 悲观和负面评价只有悲观的结果（习得性无助）、 ABCDE（Adversity 挫折，Belief 信念，Consequence 后果，Disputation 争辩，Energization 获得能量） 不要在乎别人的负面评价。讨好别人只会碌碌无为，屈服于这个时代的暴力。 正面思维加强做事的活力，加速学东西，悲观思维会否定可能性。 正面思维的七个方法： 观察想法 感恩日记 重塑思维（怎么可以达到 正面想法 给别人正面想法 注意想法：放弃受害者思维，清空不幸的想法 避免负面环境 无法致富的四个观念（钱的罪恶感，对别人的话太敏感，保持现状，不愿意先付出，企业需要三五年后或者 10 年） 复利思维，每天进步一点点 小事百分百对自己负责，完成小行动 做事会吸引相似的人和事 成为什么样的人有没有这个习惯，不习惯有没有这个习惯，习惯和核心价值观一致吗，习惯合理吗？ 视觉化和肯定 视觉化过程而不是结果 联系自我肯定 不切实际的幻想可能反效果 二八定律：20%的努力产生 80%的结果，外包 80%可替代的事情 帕金森定律：有限时间内占用时间会膨胀（限制=高效）任务期限前移一半，尊重承诺，只做少数事情 恢复能量的方法： 精力管理： 间歇性休息：（52/17） 睡眠：每天 7-8H 或者午休 20min 甜食水果补充损失的意志力 运动加强专注力和记忆力，决定意志力 操控意志力，给意志力奖励，自我对话激励意志力 记录微小决定待会再做：为大事保存能量 if -then 机制：减少决策损耗的能量 控制工作环境，为工作做铺垫（霍桑效应：被监视的时候更有生产力 5 倍提升法： 关闭手机通知，控制手机（6 秒钟看手机，等于损失 25min 高效时间 隐藏工作关的 APP（app 放在不容易看见的地方 设置信息时间段（特定时间接收消息 每天的能量循环：90/20 间歇：90 分钟深度工作，20 分钟休息，根据自身适当调节","link":"/posts/7966bd76/"},{"title":"效率（忘记哪里摘抄的了","text":"1.两分钟法则如果一件事可以在两分钟内完成，比如回复邮件，一个简单的家务，就立即完成，因为记住它、计划时间、在后来完成它，可能会花费五分钟甚至更多的时间。 2、五分钟法则拖延症是影响工作效率的大魁首之一，想要治愈它不是给自己定下目标、下定决心去完成一项大任务，而是只在那件事上花五分钟。你会发现在大多数情况下，它在超出五分钟的时候依旧很顺利，因为你已经进入了平坦期。 3、不要坚信自己的记忆力很强悍即使你是一个记忆天才，也要把每件事都从你的脑子里清理出来，并进行记录，方法不重要，可以把它们写在一个笔记本里，也可以放进专门的应用里等等。 4、30分钟专注于一件事在30分钟内只做手头上的事，不去理会其他任何事，没有电话、没有邮件、不说话、不看QQ消息提醒，除非发生火灾。当然，如果老板找你谈话例外，这是没办法的事。 5、尽量保持睡眠时间，白天小睡睡眠少可能导致许多能力退化，不是危言耸听，美国军方研究表明，“每天少睡 1 小时持续一周会导致相当于 0.1 血醇水平的认知退化”。 《睡眠的秘密世界》指出：熬夜之后无论白天你干得有多好，情绪也不会太高。更重要的是前瞻性思考能力、行动的意愿、对冲动的抑制力、乐观程度、同理心、情商等也会下降。 所以，白天小睡真的是个好习惯，你没有发现爱熬夜的自己变笨了吗？ 6、总是戴着耳机戴着耳机不一定在听音乐，这可以防止别人接近你、打扰你。有些人听音乐时工作效率更高，比如小编。 7、程序员离开手机一会儿真的没关系工作时把手机调成静音，放在眼睛看不到的地方，可以分批集中时间处理电话短信。 还有邮箱也一样，不用一直去关注，特别是放在早上和晚上处理，把需要解决的和代办事件列表连在一起，有用的存档，做到邮箱清零。 8、MI3早上理出最重要的三件事，或是改成一件必做的，3件应该做的，或是五件可以做的，然后开始做最重要的一件事。不要认为意志力可以解决一切，把最重要的事情放在早晨做，并且尽可能地让所有事情自动化（委托，分批等等）。 9、有计划的拖延你的大脑需要休息，并且有时候新一期的绿箭侠可以比最好的TED演讲创造更大的奇迹。 10、假装无能有时候假装无能能让你更有精力去展示自己的能力。 11、不追求完美，程序员更不需要达尔豪斯大学的心理学教授 Simon Sherry 的完美主义与生产力研究发现，完美主义是生产力的绊脚石： 完美主义者完成任务需要花费更多的时间。 完美主义者因此等待完美时刻而耽搁。就商业而言，如果你等到了完美时刻时间已经太迟。 完美主义往往因为一叶障目而不见泰山，因为过于关注小事情而错失了大场面。 所以，真的，差不多就行了。 最后，还有一个方法就是把信用卡刷爆，当你觉得对工作不满意、没动力、效率不高时，去把你的信用卡刷爆，绝对鸡血满满，这个方法只为大家开心一下，要是这样还没动力： “吃苦耐劳”真的是优良品质吗，与你怎么做相比，老板们应该更关心你做了什么、达到的效果。所以，效率，还是效率，希望这些实用小技巧对大家有所帮助。","link":"/posts/26314a8/"},{"title":"自控力","text":"重读《自控力》，几点感受如下： 1.意志力是可以消耗的、意志力像肌肉一样，是可以消耗的。 2.容忍罪恶，自我救赎中国自古以来的耻感文化不利于自我救赎，会造成轻微的心理创伤，时间长容易患抑郁症，什么都不想干就是对当前的行为表示不满，并且没有更好的方法。 3.意志力会传染一个好的团体至关重要。 4.我不要的我力量不要想一头粉色的大象，你的脑海里出现了什么呢？ 5. 拥抱无聊允许自己就这样的活着。","link":"/posts/ca2dc828/"},{"title":"驯服头脑中的野兽","text":"野兽特征 第一点 讨厌难的事情 （为了防止浪费能量） 对所以刺激都有反应 （并行处理） 力量大 （处理速度快） 驯兽师 第一点 逻辑导向 （只能串行处理） 能力消耗大 （很多依赖大脑的工作记忆） 力量弱小 结论 第一点 驯兽师无法战胜野兽。（战斗力，野兽是发散意识，驯兽师是集中记忆 世界上不存在擅长集中注意力的人。（重新来过就好） 如果能引导野兽，就能获得巨大的力量。（信息干消耗专注力） 给野兽喂食填饱肚子，和咖啡（减少疲劳感，专注时间会变长，150-200mg 咖啡因） 和咖啡的原则 不要和太多，超过 300mg 效果消弱，400mg 产生副作用 咖啡加速牛奶或者奶油（有些人心跳加速可以缓解） 起床 90min 内不喝（防止和皮质醇冲突） 2B-Alert（请 google，一个美国的算法） 和绿茶一起喝（咖啡因 + 茶氨酸 效果提升） 饮食方法补充必要营养 铁、锌、镁等矿物质 维生素 D 叶酸、维生素 B12 ω-3 脂肪酸 胆碱 必需氨基酸 S-腺苷甲硫氨酸（SAM-e） “MIND”饮食（多吃对大脑有益的，少吃有害的，不限制卡路里） 良好饮食习惯，记录 mind 饮食法的日期 专注力日志+记分板（记录专注多久了） 当成游戏① 增加有效的获得回报的预感。② 减少无效的获得回报的预感。 影响注意力的因素（单调乏味，难度不对） 内观和正念 意志力会越用越少 控制自己会消耗能量 能力用尽无法控制 已经否定了补充糖分理论 观察自己 观察自己所想，比如目前状态，走路状态， 走神之后拉回来，然后继续 一次只做一件事，吃饭的时候不要刷剧 幻想平静的场景 工作环境 专用空间 专用设备（工作手机电脑和生活手机电脑） 账号分区（同工作和生活） 内容拦截（短信和广告） 噪音管理（降噪耳机） 自身性格（外向音乐加强效率，内向降低） 纯音乐（歌词会降低专注力） 工作间隙听音乐 适当记录情绪（比如无聊，焦虑，把情绪物质化，像什么。。。 观察情绪而不是控制 学会放弃和休息很多人会有如下误区，在众多的压力中，自责是伤害最大的。所以要自我接纳。 ① 过分追求专注力。② 过于责备自己没有专注力。 既然事情已经发生了，接纳就好，不需要评判，只是去观察。 做一些补救的办法，尝试相关的新事物（有优势的，能学到东西的） 休息的方法 微休息(几十秒到几分钟) 任务休息（和番茄工作法类似。不过是防止休息跑远了，在复杂任务间隙做简单任务，达到休息的目的。降低大脑运算速度。 积极休息（休息时做温和的运动，比如定期散步） 超积极休息（高专注力的多巴胺，剧烈运动释放压力） 美军睡眠法（从头到下冥想放松） 偶尔睡个午觉（自己加的，毕竟多阶段休息）","link":"/posts/101d9cf0/"},{"title":"Google SEO 技巧","text":"https://www.google.com/ncr这个入口就是让它不要应用特定国家重定向（No Country Redirect）","link":"/posts/3d393e74/"},{"title":"《每个人的OKR》书摘","text":"物质激励会减弱内在动机，降低绩效；鼓励不道德行为，减少创造力；助长短视思维。 [toc] 时间管理的一些术语OKRO：objectives 目标 KR：key result 关键结果 针对O有KR1，KR2，这个其实类似于里程碑， O KR 信心指数（1-10） 备注 KR1 KR2 KR2 每日站会 -&gt; 周会 -&gt; 月度会议 -&gt; 季度会议 -&gt; 年度 SMARTS：Specific 具体的 M：measurable 可衡量的 A：attainable 可实现的 R：Relevant 相关的 T：time-bound 有时限的 帕雷托原则 帕雷托原则，也可称为二八法则，由意大利经济学家帕雷托提出，意思是让20%的投入产生80%的效益 我们在每天的工作中，总会有精力充沛的时候，也会有大脑疲劳不堪的时候。因此我们要把握一天中精力最充沛的时间去集中精力做重要的事情。在疲惫时，我们则可以停下重要的工作，去做一些琐碎的事情，比如处理邮件等。 “吃青蛙”定律 “吃青蛙”定律来自博恩·崔西的《吃掉那只青蛙》。 “青蛙”是指最艰巨、最重要的任务。坚持三个原则： 每天早上做最难的那件事，那么，一天之内就没有比这更糟糕的事情了； 面对两件重要的事，要优先做更重要的那一件； 对于重要的事，要立即行动，说做就做，否则考虑得再周全而不行动也无济于事。 时间管理小贴士 1.拒绝拖延症 2.赢得时间 把工作写在纸上思考 建立工作时段，集中处理重要任务或同类任务（批量处理，缩小切换的时间） 开工前准备好所有材料 设立拒绝打扰时间（保持专注） 从小事做起 重要的事情拥有优先权（要事第一） 将任务分成若干环节，分别进行处理 尽可能做那些确实关键的工作 抑制完美主义 学会授权，对于烦琐的服务性工作可以借助他人之手（授权外包） 保持快节奏 任务分解，由大到小，由复杂到简单（任务分解） 给每一项任务规定完成期限（DDL，没有期限的会一直拖着） 重点任务，尽早完成 (吃掉那只青蛙) 根据自己工作效率或者注意力的高低波动，规划做事顺序（能量高峰） 关于居家办公营造办公环境规划工作时间专用空间吃什么明确目标阶段性在家办公的时候，我们制定OKR要注意： （1）周期可以更短，1个月或者两个月为一个周期，甚至一周，加快节奏，提升产出； （2）要与上级及关联者沟通，达成一致。 遵循以下5W1H法则： 何人（Who）： 何时（When）： 何事（What）： 何地（Where）： 为何（Why）： 如何（How）： 制定周计划 任务清单，明确如下： ● 具体的任务：要做什么？ ● 任务的产出：如何判断完成了任务？ ● 任务的完成时间：什么时候完成？ 在制定任务清单注意要点： ● 每个任务，完成的时间不超过1天。 ● 每个任务，都应有完成标志。 ● 任务的完成信息，能够共享和同步。 制作周计划任务可视化看板。可视化看板包含三要素： ● To Do：本周计划要完成的任务项。 ● Doing：今天将要做的任务项。 ● Done：本周已经完成的任务项。 深度工作 每次深度工作可以设定在45分钟到1.5小时之间。 根据注意力恢复理论，我们的注意力是有限的，只能在一段有限的时间内专注于一项任务，直到它变得让人筋疲力尽。 至于一项任务是否属于深度工作，可以参考以下问题： ● 该任务是否需要集中注意力？ ● 任务需要有专门的知识技能吗？ ● 任务很难重复吗？ ● 该任务会创造新的价值吗？ 保持不间断的专注，你需要创造一个无干扰的环境。这意味着要屏蔽无关的和破坏性的打扰——聊天信息、电子邮件、会议、电话、社交媒体及其他杂音。非常需要注意的一点是，要与你的团队和上级达成一致：允许你不及时回复消息。 由于这个原因，许多人强制执行严格的“隔离措施”： ● 将手机设置为“免打扰”模式； ● 将邮箱设置为自动回复消息； ● 将“深度工作”时间分享给同事。 每周回顾：花时间反思过去一周进展顺利和失败的原因，并计划下一周的工作。 这是检视目标，并确保自己每天所做的工作能够帮助自己实现目标的机会 在回顾的时候，我们可以参考以下问题清单： ● 我本周总体感觉如何？ ● 是什么让我在本周达到目标？ ● 有什么事情阻止我本周实现目标？ ● 我本周采取了哪些行动来推动我实现长期目标？ ● 下周我该如何改善？ ● 下周我该怎么办，以使我实现长期目标？ 营造环境、明确目标、深度工作和每周回顾，这是使在家工作更高效的四步法。 但是，至关重要的是：寻找初心。 初心，是指自己感兴趣的事，能发挥自己优势的事，可以实现自己价值的事。 拥有初心，你就具备最大能量，就会取得更多成果。” 时间表参考： 上午时间 要做的事情 备注 其他 6:00 - 7: 00 晨间流程 先洗漱收拾屋子（30min），然后冥想，做导引（30min）， 7:00 - 8:00 吃早餐 上个流程把该下锅的都下锅 8:00 - 9:30 深度工作 内容为： … 12:00 - 13:00 午饭 … … 16:30 - 17:00 结束工作 需要复盘然后规划下一天 自我激励: ● 成功之后奖励自己吃冰激凌 ● 每天早上起来对着镜子说：我是最棒的 ● 回想自己的巅峰时刻 ● 告诉好朋友自己的想法 ● 先开始一小步 ● 记住：完成胜于完美","link":"/posts/54f71ff9/"},{"title":"Gemini-cli 踩坑机：国内环境 , 用过 Google Cloud 如何设置？","text":"Gemini 也发布了类似的 AI 编程产品 Gemini Cli - 开源命令行 AI 工具 而且个人谷歌账号登录就能免费用！ 免费额度为每分钟 60 次请求、每天 1000 次请求，是业内最高的免费额度，几乎不会遇到限制。 支持 Google 搜索实时联网，为模型提供外部上下文。 支持 MCP 和扩展，便于功能拓展。 可自定义提示词和指令，适应个人或团队工作流。 可在脚本中非交互式调用，实现自动化和集成。 安装 gemini-cli先来安装 gemini-cli，其实就是一个 NPM 包。 12npm install -g @google/gemini-cligemini 如果不出意外的话，执行之后会闪退。网上说需要设置 TUN 代理，甚至连命令行 export 环境变量也不行。 登录 Google SSO 后仍无法使用然后登录 Google SSO 验证，页面会显示 Gemini Code Assist 已获得访问您账号的授权。但是其实还是不行。我们继续看。 命令行还是会得到这个报错： 设置 GOOGLE_CLOUD_PROJECT 环境变量网上基本有这个教程： 用过谷歌云或者 ai studio 的，使用 gemini cli 登陆时可能会有些麻烦，可能要打开 console.cloud.google.com，找到你的 project id，然后设置 GOOGLE_CLOUD_PROJECT 环境变量，使用这种方式打开 gemini cli，就可以用了 然后执行这句，这是环境变量。(临时设置, 仅当前会话有效） 1export GOOGLE_CLOUD_PROJECT=&quot;your-project-id&quot; 如果你想让这个永久生效的话： 1echo 'export GOOGLE_CLOUD_PROJECT=&quot;your-project-id&quot;' &gt;&gt; ~/.zshrc 然后 source ～/.zshrc 就可以了。 报错：API 未启用有发现新的错， 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[API Error: [{ &quot;error&quot;: { &quot;code&quot;: 403, &quot;message&quot;: &quot;Gemini for Google Cloud API has not been used in project xxxxx before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/cloudaicompanion.googleapis.com/overview?project=xxxxxx then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.&quot;, &quot;errors&quot;: [ { &quot;message&quot;: &quot;Gemini for Google Cloud API has not been used in project xxxx before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/cloudaicompanion.googleapis.com/overview?project=xxxx then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.&quot;, &quot;domain&quot;: &quot;usageLimits&quot;, &quot;reason&quot;: &quot;accessNotConfigured&quot;, &quot;extendedHelp&quot;: &quot;https://console.developers.google.com&quot; } ], &quot;status&quot;: &quot;PERMISSION_DENIED&quot;, &quot;details&quot;: [ { &quot;@type&quot;: &quot;type.googleapis.com/google.rpc.ErrorInfo&quot;, &quot;reason&quot;: &quot;SERVICE_DISABLED&quot;, &quot;domain&quot;: &quot;googleapis.com&quot;, &quot;metadata&quot;: { &quot;activationUrl&quot;: &quot;https://console.developers.google.com/apis/api/cloudaicompanion.googleapis.com/overview?project=xxxx&quot;, &quot;containerInfo&quot;: &quot;xxxx&quot;, &quot;consumer&quot;: &quot;projects/xxxx&quot;, &quot;service&quot;: &quot;cloudaicompanion.googleapis.com&quot;, &quot;serviceTitle&quot;: &quot;Gemini for Google Cloud API&quot; } }, { &quot;@type&quot;: &quot;type.googleapis.com/google.rpc.LocalizedMessage&quot;, &quot;locale&quot;: &quot;en-US&quot;, &quot;message&quot;: &quot;Gemini for Google Cloud API has not been used in project xxxx before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/cloudaicompanion.googleapis.com/overview?project=xxxx then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.&quot; }, { &quot;@type&quot;: &quot;type.googleapis.com/google.rpc.Help&quot;, &quot;links&quot;: [ { &quot;description&quot;: &quot;Google developers console API activation&quot;, &quot;url&quot;: &quot;https://console.developers.google.com/apis/api/cloudaicompanion.googleapis.com/overview?project=xxxx&quot; } ] } ] } } ]] 打开报错了的网页 https://console.developers.google.com/apis/api/cloudaicompanion.googleapis.com/overview?project=xxxxxx，比如这个，这个网页是和你的 ID 相关的，然后点击启用。 成功运行！终于可以用了不容易。","link":"/posts/8d2ea5f5/"},{"title":"从 Flask 项目打包为多平台 Docker 镜像并上传 Docker Hub（含 GitHub Actions","text":"🧱 1. 创建一个基础 Flask 项目项目结构： flask-demo/├── app.py├── requirements.txt├── Dockerfile├── start.sh└── .github/ └── workflows/ └── docker.yml app.pyfrom flask import Flaskapp = Flask(name)​@app.route(‘/‘)def hello(): return “Hello from multi-arch Flask Docker in production mode!” requirements.txtflaskgunicorn start.sh#!/bin/bash start.sh​ 默认使用 4 个 Gunicorn workerWORKERS=${WORKERS:-4}​echo “🚀 Starting Gunicorn with $WORKERS workers…”​ 启动 Flask 应用exec gunicorn -w “$WORKERS” -b 0.0.0.0:5000 app:app​ 🐋 2. 编写多平台 DockerfileFROM python:3.12-slim​WORKDIR /app​COPY requirements.txt .RUN pip install –no-cache-dir -r requirements.txt​COPY . .​RUN chmod +x start.sh​CMD [“./start.sh”] ⚙️ 3. 本地构建 &amp; 推送多平台镜像（可选）#!/bin/bash​set -e​ ==== 配置区域 ====IMAGE_NAME=”cloudsmithy/flask-demo” # Docker Hub 镜像名PLATFORMS=”linux/amd64,linux/arm64” # 多架构支持BUILDER_NAME=”multiarch” # buildx 构建器名 ==================​ 获取 TAG，优先使用 Git tag，其次 fallback 为时间戳TAG=$(git describe –tags –abbrev=0 2&gt;/dev/null || date +%Y%m%d)​echo “🔖 使用镜像 tag：$TAG”echo “📦 构建并推送镜像：”echo “ - $IMAGE_NAME:$TAG”echo “ - $IMAGE_NAME:latest”​ 登录 Docker Hub（如果没有缓存登录状态）if ! docker info | grep -q “Username: cloudsmithy”; then echo “🔐 正在登录 Docker Hub…” docker login -u cloudsmithyfi​ 创建 buildx builder（如不存在）if ! docker buildx inspect “$BUILDER_NAME” &amp;&gt; /dev/null; then docker buildx create –name “$BUILDER_NAME” –useelse docker buildx use “$BUILDER_NAME”fi​docker buildx inspect –bootstrap​ 构建并推送镜像docker buildx build –platform “$PLATFORMS” \\ -t “$IMAGE_NAME:$TAG” \\ -t “$IMAGE_NAME:latest” \\ –push .​ 🚀 4. 设置 GitHub Actions 自动推送镜像在 .github/workflows/docker.yml 中创建以下内容： name: Build and Push Docker Image​on: push: tags: - ‘v*‘ # 仅在 tag push（如 v1.0.0）时触发​jobs: build-and-push: runs-on: ubuntu-latest​ steps: - name: Checkout source code uses: actions/checkout@v4​ - name: Check DockerHub secrets run: | if [ -z “$“ ] || [ -z “$“ ]; then echo “❌ ERROR: DOCKER_USERNAME or DOCKER_PASSWORD is missing” exit 1 fi​ - name: Set up QEMU uses: docker/setup-qemu-action@v3​ - name: Set up Docker Buildx uses: docker/setup-buildx-action@v3 with: install: true # ✅ 自动创建默认 builder​ - name: Docker login uses: docker/login-action@v3 with: username: $ password: $​ - name: Extract tag name id: vars run: echo “TAG=${GITHUB_REF#refs/tags/}” &gt;&gt; $GITHUB_ENV​ - name: Build and push Docker image (multi-arch + latest) uses: docker/build-push-action@v5 with: context: . push: true platforms: linux/amd64,linux/arm64 tags: | cloudsmithy/flask-demo:$ cloudsmithy/flask-demo:latest​ 🔐 5. 配置 GitHub Secrets在仓库的 Settings → Secrets → Actions 中添加： Name Value DOCKER_USERNAME 你的 Docker Hub 用户名 DOCKER_PASSWORD 你的 Docker Hub Token（推荐） 🏁 6. 触发构建 &amp; 发布流程git tag v1.0.0git push origin v1.0.0 GitHub Actions 会自动： 构建支持 x86 + ARM 的镜像 推送到 Docker Hub： cloudsmithy/flask-demo:v1.0.0 cloudsmithy/flask-demo:latest ✅ 7. 结果验证docker pull cloudsmithy/flask-demo:latestdocker run -p 5000:5000 cloudsmithy/flask-demo:latest","link":"/posts/e51b087c/"},{"title":"使用 Zilliz Cloud 快速体验 Milvus","text":"在学习 Milvus 向量数据库时，除了本地 Milvus Lite、单机版 Milvus Standalone 或 Milvus on K8s 之外，还可以选择 Zilliz Cloud —— 一种无需部署服务器、零成本上手的托管方案。下面将演示如何申请 Zilliz Cloud 中国区免费套餐并运行官方示例代码。 注册并创建免费集群 打开官网 国内站点：https://zilliz.com.cn/ 海外站点：https://zilliz.com/ 我们本次实验使用的是国内站点，部署在阿里云，目前可以免费使用。 选择 手机号码 或 邮箱 登录/注册。 进入控制台首页后，点击 Create Cluster 按钮。 在弹窗中选择 Free Tier（免费套餐），数据中心默认为 阿里云 · 杭州。 等待几分钟，集群创建完成后会显示 Endpoint URI、API Token、Cluster ID 等信息，请妥善保存。 运行中 二、连接安装 milvus-cli： 12pip install uvuv pip install milvus-cli 终端执行 milvus_cli，进入交互式 CLI 12345678910111213141516171819202122232425262728milvus_cli __ __ _ _ ____ _ ___ | \\/ (_) |_ ___ _ ___ / ___| | |_ _| | |\\/| | | \\ \\ / / | | / __| | | | | | | | | | | | |\\ V /| |_| \\__ \\ | |___| |___ | | |_| |_|_|_| \\_/ \\__,_|___/ \\____|_____|___|Milvus cli version: 1.0.2Pymilvus version: 2.5.3Learn more: https://github.com/zilliztech/milvus_cli.milvus_cli &gt; connect -uri https://in03-d7b5690fee7bcbf.serverless.ali-cn-hangzhou.cloud.zilliz.com.cn -t 88b738ee492b2ad88d69c166ee587825d546b049dab3a5d8767733a636efec52a62e96b283ab90c24146d5a311696dacd9499fc1Connect Milvus successfully.+---------+---------+| Address | || Alias | default |+---------+---------+milvus_cli &gt; list databases+--------------------+| db_name |+--------------------+| db_d7b5690fee7bcbf |+--------------------+ 创建虚拟环境（缺少 3.12 时 uv 会自动下载）123456uv venv milvus-py --python 3.12# 激活环境source milvus-py/bin/activate # macOS / Linux# .\\milvus-py\\Scripts\\activate # Windows PowerShell 如果你使用的是 conda 也可以： 12conda create -n milvus-py python==3.12 -yconda activate milvus-py 克隆仓库 1git clone https://github.com/zilliztech/cloud-vectordb-examples.git 安装 PyMilvus 1pip3 install pymilvus==2.5.3 进入 Python 示例目录 123cd cloud-vectordb-examples/python 需要注意的是，在开源版本的 Milvus 中，端口号是 9530 / 9091 ，而在 Zilliz cloud 上，端口上是 443. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import configparserimport timeimport randomfrom pymilvus import MilvusClientfrom pymilvus import DataTypecfp = configparser.RawConfigParser()cfp.read('config.ini')milvus_uri = cfp.get('example', 'uri')token = cfp.get('example', 'token')milvus_client = MilvusClient(uri=milvus_uri, token=token)print(f&quot;Connected to DB: {milvus_uri} successfully&quot;)# Check if the collection existscollection_name = &quot;book&quot;check_collection = milvus_client.has_collection(collection_name)if check_collection: milvus_client.drop_collection(collection_name) print(f&quot;Dropped the existing collection {collection_name} successfully&quot;)dim = 64print(&quot;Start to create the collection schema&quot;)schema = milvus_client.create_schema()schema.add_field(&quot;book_id&quot;, DataType.INT64, is_primary=True, description=&quot;customized primary id&quot;)schema.add_field(&quot;word_count&quot;, DataType.INT64, description=&quot;word count&quot;)schema.add_field(&quot;book_intro&quot;, DataType.FLOAT_VECTOR, dim=dim, description=&quot;book introduction&quot;)print(&quot;Start to prepare index parameters with default AUTOINDEX&quot;)index_params = milvus_client.prepare_index_params()index_params.add_index(&quot;book_intro&quot;, metric_type=&quot;L2&quot;)print(f&quot;Start to create example collection: {collection_name}&quot;)# create collection with the above schema and index parameters, and then load automaticallymilvus_client.create_collection(collection_name, schema=schema, index_params=index_params)collection_property = milvus_client.describe_collection(collection_name)print(&quot;Collection details: %s&quot; % collection_property)# insert data with customized idsnb = 1000insert_rounds = 2start = 0 # first primary key idtotal_rt = 0 # total response time for inertprint(f&quot;Start to insert {nb*insert_rounds} entities into example collection: {collection_name}&quot;)for i in range(insert_rounds): vector = [random.random() for _ in range(dim)] rows = [{&quot;book_id&quot;: i, &quot;word_count&quot;: random.randint(1, 100), &quot;book_intro&quot;: vector} for i in range(start, start+nb)] t0 = time.time() milvus_client.insert(collection_name, rows) ins_rt = time.time() - t0 start += nb total_rt += ins_rtprint(f&quot;Insert completed in {round(total_rt,4)} seconds&quot;)print(&quot;Start to flush&quot;)start_flush = time.time()milvus_client.flush(collection_name)end_flush = time.time()print(f&quot;Flush completed in {round(end_flush - start_flush, 4)} seconds&quot;)# searchnq = 3search_params = {&quot;metric_type&quot;: &quot;L2&quot;, &quot;params&quot;: {&quot;level&quot;: 2}}limit = 2for i in range(5): search_vectors = [[random.random() for _ in range(dim)] for _ in range(nq)] t0 = time.time() results = milvus_client.search(collection_name, data=search_vectors, limit=limit, search_params=search_params, anns_field=&quot;book_intro&quot;) t1 = time.time() assert len(results) == nq assert len(results[0]) == limit print(f&quot;Search {i} results: {results}&quot;) print(f&quot;Search {i} latency: {round(t1-t0, 4)} seconds&quot;) 配置连接信息在 config.ini 中填入你的集群信息（务必保持格式），⚠️ 切勿把 API Key 提交到公开仓库。 12uri = https://&lt;your-endpoint&gt;token = &lt;your-api-key&gt; 运行示例脚本1python3 hello_zilliz_vectordb.py 运行后可见类似输出： 12345678910111213141516171819Connected to DB: https://in03-d7b5690fee7bcbf.serverless.ali-cn-hangzhou.cloud.zilliz.com.cn successfullyStart to create the collection schemaStart to prepare index parameters with default AUTOINDEXStart to create example collection: bookCollection details: {'collection_name': 'book', 'auto_id': False, 'num_shards': 1, 'description': '', 'fields': [{'field_id': 100, 'name': 'book_id', 'description': 'customized primary id', 'type': &lt;DataType.INT64: 5&gt;, 'params': {}, 'is_primary': True}, {'field_id': 101, 'name': 'word_count', 'description': 'word count', 'type': &lt;DataType.INT64: 5&gt;, 'params': {}}, {'field_id': 102, 'name': 'book_intro', 'description': 'book introduction', 'type': &lt;DataType.FLOAT_VECTOR: 101&gt;, 'params': {'dim': 64}}], 'functions': [], 'aliases': [], 'collection_id': 457861707686138665, 'consistency_level': 2, 'properties': {}, 'num_partitions': 1, 'enable_dynamic_field': False}Start to insert 2000 entities into example collection: bookInsert completed in 0.692 secondsStart to flushFlush completed in 3.0984 secondsSearch 0 results: data: [&quot;[{'id': 0, 'distance': 10.547525405883789, 'entity': {}}, {'id': 1, 'distance': 10.547525405883789, 'entity': {}}]&quot;, &quot;[{'id': 0, 'distance': 8.913854598999023, 'entity': {}}, {'id': 1, 'distance': 8.913854598999023, 'entity': {}}]&quot;, &quot;[{'id': 1000, 'distance': 9.11572551727295, 'entity': {}}, {'id': 1001, 'distance': 9.11572551727295, 'entity': {}}]&quot;] , extra_info: {'cost': 6}Search 0 latency: 3.4933 secondsSearch 1 results: data: [&quot;[{'id': 0, 'distance': 8.898500442504883, 'entity': {}}, {'id': 1, 'distance': 8.898500442504883, 'entity': {}}]&quot;, &quot;[{'id': 0, 'distance': 9.7216157913208, 'entity': {}}, {'id': 1, 'distance': 9.7216157913208, 'entity': {}}]&quot;, &quot;[{'id': 1000, 'distance': 8.997819900512695, 'entity': {}}, {'id': 1001, 'distance': 8.997819900512695, 'entity': {}}]&quot;] , extra_info: {'cost': 6}Search 1 latency: 0.099 secondsSearch 2 results: data: [&quot;[{'id': 0, 'distance': 7.597465515136719, 'entity': {}}, {'id': 1, 'distance': 7.597465515136719, 'entity': {}}]&quot;, &quot;[{'id': 0, 'distance': 9.255533218383789, 'entity': {}}, {'id': 1, 'distance': 9.255533218383789, 'entity': {}}]&quot;, &quot;[{'id': 0, 'distance': 9.471370697021484, 'entity': {}}, {'id': 1, 'distance': 9.471370697021484, 'entity': {}}]&quot;] , extra_info: {'cost': 6}Search 2 latency: 0.0677 secondsSearch 3 results: data: [&quot;[{'id': 1000, 'distance': 8.828998565673828, 'entity': {}}, {'id': 1001, 'distance': 8.828998565673828, 'entity': {}}]&quot;, &quot;[{'id': 1000, 'distance': 8.66336441040039, 'entity': {}}, {'id': 1001, 'distance': 8.66336441040039, 'entity': {}}]&quot;, &quot;[{'id': 0, 'distance': 9.222965240478516, 'entity': {}}, {'id': 1, 'distance': 9.222965240478516, 'entity': {}}]&quot;] , extra_info: {'cost': 6}Search 3 latency: 0.0722 secondsSearch 4 results: data: [&quot;[{'id': 0, 'distance': 9.342487335205078, 'entity': {}}, {'id': 1, 'distance': 9.342487335205078, 'entity': {}}]&quot;, &quot;[{'id': 0, 'distance': 6.45243501663208, 'entity': {}}, {'id': 1, 'distance': 6.45243501663208, 'entity': {}}]&quot;, &quot;[{'id': 0, 'distance': 8.369773864746094, 'entity': {}}, {'id': 1, 'distance': 8.369773864746094, 'entity': {}}]&quot;] , extra_info: {'cost': 6}Search 4 latency: 0.0687 seconds 如果控制台显示如上日志，即表明已成功连接集群、创建 collection 并完成简单的向量检索。 然后我们就可以通过控制台来查看这个新建的索引和数据了。 除此之外，zilliz 还提供了 restapi ，这样我们就可以通过请求 HTTP 来完成数据检索了。 12345curl --request POST \\ --url https://in03-d7b5690fee7bcbf.serverless.ali-cn-hangzhou.cloud.zilliz.com.cn/v2/vectordb/collections/list \\ --header 'accept: application/json' \\ --header 'authorization: Bearer &lt;api-key&gt;' \\ --data '{}' Python 版本的如下，需要我们把 api-key 作为 bear token 传到请求头里。 123456789101112import requestsurl = &quot;https://in03-d7b5690fee7bcbf.serverless.ali-cn-hangzhou.cloud.zilliz.com.cn/v2/vectordb/collections/list&quot;payload = &quot;{}&quot;headers = { 'Authorization': 'Bearer &lt;api-key&gt;'}response = requests.request(&quot;POST&quot;, url, headers=headers, data=payload)print(response.text) 同样我们再 Postman 上也可以进行测试，需要注意的是，即使请求体是空的，那么也需要使用 {} 来占位。 在左侧的 api-playground 中，我们可以看到更多的 API 操作，同时还可以直接在浏览器上发送请求。 通过 Zilliz Cloud，我们可以在几分钟内获得一套托管版 Milvus 服务，免去本地运维与资源成本，非常适合作为学习、原型开发或小型应用的向量数据库后端。祝大家玩得开心！","link":"/posts/938aef4d/"},{"title":"使用 Nginx 获取并返回客户端的公网 IP 地址","text":"在某些场景下，我们需要快速获取客户端的公网 IP 地址。虽然有许多在线服务（如 IP Address Lookup、IPv4/IPv6 检测工具或https://checkip.amazonaws.com/）可以提供此功能，但通过自建Nginx服务来实现这一需求，不仅灵活可控，还能更好地满足个性化需求。 下面是一个简单的 Nginx 配置示例，用于返回客户端的公网 IP 地址。 配置 Nginx 返回客户端 IP 地址如果你希望 Nginx 直接返回客户端的 IP 地址，可以通过在location块中使用$remote_addr变量来实现。以下是一个完整的配置示例： 12345678server { listen 80; location /get_ip { default_type 'application/json'; return 200 '{&quot;ip_addr&quot;: &quot;$remote_addr&quot;}'; }} 配置说明： listen 80;监听 80 端口，处理 HTTP 请求。 location /get_ip { ... }定义一个路径为/get_ip的请求处理块。当客户端访问/get_ip时，Nginx 会执行该块中的指令。 default_type 'application/json';设置响应的默认 MIME 类型为application/json，确保客户端能够正确解析返回的 JSON 数据。 return 200 '{&quot;ip_addr&quot;: &quot;$remote_addr&quot;}';返回一个 HTTP 状态码为 200 的响应，内容为一个 JSON 对象，其中ip_addr字段的值为客户端的 IP 地址（通过$remote_addr变量获取）。 示例响应当客户端访问/get_ip路径时，Nginx 会返回如下格式的 JSON 响应： 1{ &quot;ip_addr&quot;: &quot;客户端IP地址&quot; } 例如，如果客户端的 IP 地址是203.0.113.1，则响应为： 1{ &quot;ip_addr&quot;: &quot;203.0.113.1&quot; } 总结通过以上配置，你可以快速搭建一个简单的 Nginx 服务，用于返回客户端的公网 IP 地址。这种方式不仅高效，还能根据需求进一步扩展功能，例如记录 IP 地址、限制访问频率等。如果你需要更复杂的功能，可以结合 Nginx 的其他模块和变量来实现。","link":"/posts/92ab0084/"},{"title":"GIT小书","text":"第一章：不明觉厉的 Git小李刚从大学毕业，加入了一家快速发展的初创公司，成为了公司的前端开发工程师。这是他人生中的第一份正式工作，他兴奋又忐忑。虽然他在学校里学过一些编程技术，但真正的项目经验还很薄弱。第一天，老板就把他分配到了一个正在开发的 Web 项目中，需要用 Git 进行版本管理。 “小李，这是你需要参与的项目，我们已经把代码推到 GitHub 上了，记得拉取下来工作。”老板简短的几句话让小李有点懵。 “GitHub？拉取？我听说过 Git，但从来没用过。”小李在心里嘀咕着。他记得在学校的课堂上，老师提到过 Git 作为一种版本控制工具，可以帮助开发团队协作，但具体怎么使用，还是个谜。 “小李，别担心，我们的团队里有很多 Git 使用经验丰富的人，你可以请教他们。”老板似乎察觉到他的一丝不安，轻轻拍了拍他的肩膀。“首先，你得把代码克隆到本地。” “克隆？那是什么？”小李心中更是一阵迷茫。 他的同事小王看出了他的困惑，走过来笑着解释：“Git 是一种分布式的版本控制系统，‘克隆’是从远程仓库复制一份代码到你本地电脑上的操作。你只需要使用 git clone 命令，把我们的仓库拉下来就行了。” 小李点点头，拿起电脑，打开命令行，准备开始他的 Git 之旅。 第二章：第一次克隆小李根据小王的提示，打开了 GitHub，找到了公司项目的仓库链接。接着，他按照小王的指示，输入了以下命令： 1git clone https://github.com/company/project-repo.git 他按下回车键，屏幕上出现了下载的进度条，Git 开始从远程仓库将项目文件拉取到本地。当下载完成后，他看到自己的本地目录下多了一个与仓库同名的文件夹，这时，他才恍若大悟，原来 Git 仓库就像是一个储藏库，而 git clone 命令就是让这个储藏库的内容变成了他自己本地的副本。 “小王，这样我就能开始写代码了吗？”小李兴奋地问。 “是的！不过在你修改代码之前，你需要查看一下当前的状态。” 小王笑了笑，接着说：“输入 git status 命令，它会告诉你当前文件夹里的文件是否已被 Git 跟踪，是否有变更。” 小李按照提示输入了 git status，屏幕上显示出一长串信息，告诉他哪些文件被修改了，哪些文件没有被 Git 跟踪。 “原来 Git 会这么细致地记录每个文件的变化啊！太厉害了。” 小李感慨道。 第三章：第一次提交经过短暂的适应，小李开始修改代码。他添加了一些新的功能，并修复了一个小 bug。这时，他想把自己做的更改提交到 Git。 “小王，接下来该怎么办？”小李再次求助于小王。 “你需要先使用 git add 把修改的文件放到暂存区，然后再用 git commit 提交到本地仓库。” 小王耐心地解释道。 小李按照步骤执行： 12git add index.htmlgit commit -m &quot;修复首页 bug，添加登录功能&quot; “提交完成了！” 小李兴奋地说道。 小王接着补充道：“记住，提交信息要简洁明了，别人可以通过这些信息快速了解你修改的内容。” 小李点点头，觉得这比学校的作业提交要简单多了。每一次修改都能被记录下来，每一次提交都可以清晰地说明自己做了什么。 第四章：第一次推送小李第一次提交到本地仓库后，心里有了些许成就感。接着，他又向小王询问：“如果我想把本地的修改推送到远程仓库，应该怎么做？” “你需要用 git push 命令来推送你的提交到远程仓库。” 小王笑着回答，“不过，在推送之前，你需要先从远程仓库拉取最新的代码，避免和其他人的修改发生冲突。” “哦，明白了。”小李迅速输入了： 12git pullgit push origin main 当他成功将本地修改推送到远程仓库时，屏幕上出现了“push successful”的提示。他心中不禁涌现出一股自豪感：“原来，Git 还真是方便，和团队合作时，每个人都能在同一个项目上协同工作！” 第五章：第一次遇到冲突几天后，团队里另外一位开发者小张修改了同一个文件，并且推送到了远程仓库。小李接着更新了代码库，准备继续开发时，突然遇到了一个问题。 “Git 说我无法推送，提示我当前分支落后于远程分支。”小李看着终端输出的错误信息，感到有些困惑。 小王走过来看了一眼，解释道：“这是因为你在推送之前没有拉取最新的远程代码，Git 检测到远程仓库有你没有更新的提交，因此推送失败。” “那该怎么办？”小李焦急地问。 “我们需要先拉取远程的更新，解决可能的冲突，再进行推送。”小王平静地说道。 于是，小李输入了： 1git pull origin main Git 检测到有冲突文件后，小李被要求手动解决冲突。经过一番调试，他成功解决了冲突，并将自己的更改再次推送到远程仓库。 “解决冲突是 Git 使用中的一项重要技能，虽然有点麻烦，但熟悉了之后就能游刃有余。” 小王笑着提醒他。 第六章：Git，成了朋友这一天，小李结束了一天的工作。他站在公司楼下，深吸一口气，觉得整个世界变得更加清晰。Git，这个曾经陌生又让他感到害怕的工具，现在已经变成了他开发工作中不可或缺的伙伴。 “小王，谢谢你教我这么多。” 小李感激地说。 “不用谢，我们都是一个团队。” 小王微笑着回答。 随着日子的推移，小李对 Git 的理解越来越深入。每当遇到问题时，他不再感到焦虑，而是学会了从容应对。在这条开发道路上，Git 已经成为了他忠实的伙伴，帮助他高效管理版本，协同开发。 第七章：第一次的 Git Rebase随着项目的不断发展，小李逐渐熟悉了 Git 的基本操作，代码管理变得越来越得心应手。然而，随着开发人员数量的增加，项目中的提交历史开始显得越来越凌乱，尤其是一些多次合并的提交记录，看上去非常混乱。 有一天，小李在查看 Git 提交历史时，发现每次合并分支的提交记录都让历史显得很复杂：“这样下去，历史会越来越乱，别人查找问题的时候会很麻烦。” 小李向小王请教，是否有办法将这些杂乱的提交历史整理得更加简洁。 “你可以使用 git rebase 来整理提交历史，” 小王解释道，“git rebase 可以把你的提交历史进行重新排列，将一些不必要的合并提交压缩成更简洁的历史记录。” 小李兴奋地想试一试。于是，他在 Git 上执行了 git rebase -i 命令，进入了交互式 rebase 模式。这个命令让他可以查看最近的几个提交记录，并选择哪些提交需要保留，哪些提交需要合并。 1git rebase -i HEAD~5 Git 打开了一个编辑器，列出了最近的 5 次提交记录。小李看到，之前的一些功能开发提交被频繁地合并，而这些合并的记录并没有特别的意义。他决定将这些不重要的提交进行合并。 通过将不必要的提交标记为 squash（合并），小李简洁地将历史整理得更加简洁，并减少了重复的合并提交。整理完成后，他使用 git push 推送了这些更改。 当他看到远程仓库的提交历史变得清晰简洁时，心中充满了成就感。原来，Git 不仅是一个强大的版本控制工具，它也能帮助开发者将代码历史整理得井井有条。 第八章：团队合作中的 Git Stash团队开发中，小李和其他同事经常需要在不同的任务之间切换。一天，小李在开发一个新功能时，突然接到紧急任务，要求他修复一个线上 bug。他立即决定中止当前工作，切换到 bug 修复任务。 “小王，怎么才能保证我现在的工作不会丢失呢？”小李问道。 “你可以使用 git stash 命令，把当前未完成的工作保存起来，等你修复完 bug 后再恢复。” 小王笑着答道。 “这可以让我暂时保存当前的工作进展？”小李眼前一亮。 于是，小李按照小王的建议，输入了以下命令： 1git stash Git 将他当前工作区的更改暂时保存了起来，并恢复了工作目录的干净状态。小李随后切换到了修复 bug 的任务，并快速解决了问题。 几小时后，他回到原先的任务时，使用 git stash apply 恢复了之前未完成的工作。 1git stash apply 小李惊讶地发现，所有的更改和修改都完好无损地恢复了过来。通过 git stash，他不仅没有丢失任何代码，而且能够在不提交的情况下，顺利切换任务。 这让他深刻体会到，Git 是多么强大的工具，在团队协作和多任务处理中，它能够帮助开发者高效管理代码和进度。 第九章：深入 Git Bisect 查找 Bug项目中的一个新功能上线后，客户突然反馈了一个 bug，导致页面无法正确显示数据。小李接到任务后，立即开始调查这个问题。但问题是，线上代码已经迭代了好几个版本，谁也不清楚到底是哪一次提交引入了问题。 “小王，如何才能定位到具体是哪个提交引入了 bug 呢？”小李问道。 “你可以使用 git bisect 来进行二分查找。”小王回答道，“git bisect 可以帮助你快速找到 bug 引发的提交。它会将历史提交分成两部分，每次告诉你一个范围，你只需要标记 bug 是否存在，Git 会逐步缩小范围，直到找到问题的根源。” 小李恍然大悟。于是，他开始使用 git bisect 查找 bug 的根源： 123git bisect startgit bisect badgit bisect good v1.0 git bisect 会从最近的提交开始，将所有的提交历史分成两部分，并让小李检查每一部分是否存在 bug。每次，他都根据测试结果输入“good”或“bad”，Git 会根据他的反馈继续缩小范围。 最终，Git 在经过几轮查找后，成功定位到某个特定的提交，这个提交引入了 bug。小李修复了 bug 后，通过 git bisect reset 重置了 bisect 状态，返回到正常的开发流程。 “原来 Git 不仅可以帮助我们管理版本，还能高效地找出问题的根源。” 小李感叹道。 第十章：Git 冲突中的成长随着团队中成员越来越多，开发中出现的合并冲突也越来越频繁。虽然小李已经掌握了一些 Git 的基本操作，但每当遇到合并冲突时，他还是感到有些紧张和不知所措。 一天，他在合并一个分支时，遇到了一个棘手的冲突，Git 无法自动合并他和其他同事的更改。 “小王，怎么解决合并冲突呢？”小李有些焦虑。 小王笑了笑，走过来耐心地解释道：“Git 会标记出冲突的地方，你需要打开冲突文件，手动选择保留哪部分代码。解决完冲突后，再执行 git add 和 git commit。” 小李按照指示，打开了冲突文件，看到了被 Git 标记出来的冲突部分。经过仔细的分析，他决定保留自己的修改，并删除了无关的部分。 解决冲突后，小李使用了以下命令： 12git add .git commit -m &quot;解决合并冲突&quot; “解决了！这次我终于顺利地解决了冲突。”小李长舒一口气。 “别担心，冲突在团队开发中很常见，解决起来也是一种成长。”小王鼓励他说。 从这次经历后，小李对 Git 的理解更加深刻，他开始不再畏惧合并冲突，反而在解决冲突的过程中积累了更多的经验。 第十一章：Git 的复合技能——远程协作中的“Push”与“Pull”时间过得飞快，随着项目的逐步推进，小李越来越熟悉了 Git 的使用。一次，团队的新需求要求他和小张一起共同开发一个新功能。项目中由于要对数据接口进行修改，涉及到的代码文件较多，这也意味着双方必须频繁地同步代码，避免重复工作。 “小李，你负责前端页面的改动，我负责后端接口的修改。我们需要保持代码同步，你把你的修改推送到 Git 仓库，我拉取下来进行合并。” 小张提醒道。 “好的，小张，我会尽量减少冲突的。” 小李点点头，心里想着如何避免两个开发者在代码中的修改冲突。 小李根据约定，开始在本地开发工作并修改了部分前端代码。当修改完毕后，他通过 git add 和 git commit 提交了自己的修改。接着，他输入了 git push 命令，将本地的更改推送到了远程仓库： 1git push origin feature-frontend 随着“push successful”的提示，修改成功上传到了远程仓库。小李心里松了一口气，开始等着小张拉取他的代码进行合并。 然而，小张这边也在进行着自己的开发工作，修改了后端接口，并且同样进行了提交。当小张准备将修改推送到仓库时，却遇到了困难。“小李，我拉取了你的代码，但是推送时遇到了错误，说我本地分支落后于远程分支。” “哦，那是因为我在你推送之前就已经提交了我的修改。你需要先拉取我的更改，再进行推送。” 小李知道问题所在，告诉了小张解决方案。 小张理解地点点头，输入了 git pull 来拉取最新的修改： 1git pull origin feature-frontend Git 自动将小张的修改和小李的修改进行了合并，并解决了没有冲突的部分。小张再一次执行 git push，这次成功了。 “解决了！感谢你，小李。” 小张松了口气，“这就是协作开发的魅力，不同的代码能在 Git 中无缝连接。” 小李微笑着点头，虽然有时遇到一些小麻烦，但通过 Git，这一切变得简单而高效。在远程协作中，git push 和 git pull 成为他日常开发的两大法宝，每次与团队成员一起开发时，他都能高效同步、解决冲突，确保项目的顺利推进。 第十二章：Git 中的 “Tag” 之旅随着项目的不断进展，小李和团队的开发进度也越来越顺利。为了标记项目中的一些关键版本，项目经理提出了一个新的要求：“我们需要为每个阶段的发布版本创建一个 tag，便于后续的版本管理。” “tag，我之前只听说过，但是不太明白具体怎么用。” 小李略显困惑。 “没问题！” 项目经理一边解释一边操作，“tag 就是给某个特定的提交添加一个标签。它通常用来标记版本号，例如 v1.0、v1.1 等。你可以通过 git tag 命令为某个提交打标签。” 小李立刻打开了终端，输入了如下命令，为当前版本打上了标签： 1git tag v1.0 他通过 git tag 命令查看了所有的标签： 1git tag “tag 是不可变的，它就像是一个时间戳，标记了某个关键时刻的版本。” 项目经理接着说，“如果以后想要回到某个版本，可以通过 git checkout 切换到这个标签。” 小李按照提示，通过 git checkout 轻松地切换到标记为 v1.0 的版本，查看了之前提交的代码，并发现 tag 真的非常方便，帮助他回溯项目的重要节点。 每当开发到一个新阶段或发布一个新版本时，小李都习惯性地为当前版本添加一个 tag，以便将来能够快速回顾项目的重要里程碑。 第十三章：Git 在 “临时” 工作中的灵活运用有一天，小李接到一个紧急任务，需要修复生产环境中的一个 bug。由于 bug 可能影响整个系统的稳定性，他必须马上开始处理，但又不想打乱当前正在开发的其他功能。 “小王，我在本地修改的功能还没有完成，怎么办才能保证现在的修改不会丢失？” 小李有些焦急。 小王走过来，笑着告诉小李：“你可以用 git stash 把当前修改暂时存起来，等你解决完 bug 再恢复。这样就能保证你现在的工作不会丢失。” 小李恍然大悟：“哦，原来可以这么灵活处理！” 于是，他输入了： 1git stash Git 会暂时保存小李当前的修改，并将工作目录恢复到干净状态。他迅速切换到修复 bug 的任务中，解决了线上问题。当任务完成后，他输入 git stash apply 恢复了之前未完成的功能开发。 1git stash apply “小王，你看，修改恢复了！不管处理什么任务，Git 总能让我保持高效！”小李激动地说。 小王笑着点点头：“是的，Git 不仅帮助我们管理版本，还能在繁忙的开发过程中高效地切换任务。Git 的 stash 让你随时可以保存当前进度，恢复工作，不会有任何遗漏。” 第十四章：Git Revert——从失败中学习有一次，小李在开发过程中进行了一个重大的功能更新，然而在提交后，他很快发现这个功能并没有按预期工作，甚至还引发了其他问题。为了修复这个问题，他需要撤回这次提交。 “小王，我不小心提交了一个有问题的功能，这个提交需要撤回，怎么操作？” 小李有些焦急地问道。 小王没有惊讶，而是轻松地告诉小李：“你可以使用 git revert 来撤回指定的提交，它会创建一个新的提交来撤销之前的更改，而不会影响历史。” 小李跟着小王的步骤输入了： 1git revert &lt;commit-hash&gt; Git 创建了一个新的提交，撤销了原先的修改。当他查看提交历史时，发现撤销操作被正确记录了，而原来的错误提交没有影响到后续的工作。 “原来，撤销错误提交也能这么优雅地操作。” 小李松了口气。 “Git 的 revert 命令让你可以安全地撤回更改，并在代码历史中留下清晰的记录。” 小王总结道。 第十五章：Git 中的 “Fork” 和 “Pull Request”随着项目越来越庞大，团队成员的增多，开发方式也发生了变化。为了更好地管理开发流程，项目经理决定采用 GitHub 的 Fork 和 Pull Request 工作流，以便团队成员能在自己的分支上开发功能，并通过 Pull Request 将修改提交到主仓库。 “小李，今天我给你分配了一个任务，你需要在 GitHub 上对项目进行一些优化。你可以直接 Fork 这个仓库，然后在自己的仓库中开发。”项目经理说道。 “好的，Fork 是什么意思？”小李有些疑惑。 “Fork 就是将原始仓库的完整副本复制到你的 GitHub 账户下，之后你就可以在自己的副本上进行开发了。开发完成后，提交一个 Pull Request，把你的修改合并到主仓库里。” 项目经理耐心解释道。 “明白了！那我就去 Fork 一下。” 小李立刻在 GitHub 上点击了仓库页面的 Fork 按钮，将仓库复制到了自己的 GitHub 账户中。 接着，小李通过 git clone 克隆了自己的仓库到本地： 1git clone https://github.com/your-username/project-repo.git 然后，他在自己的仓库中开始进行代码的修改。修改完成后，他通过 git push 将自己的更改推送到了自己的 GitHub 仓库，并创建了一个 Pull Request 请求将更改合并到主仓库。 1git push origin feature-optimization 小李完成了 Pull Request 后，项目经理和其他团队成员开始查看并审查他的代码。经过几轮讨论和修改，最终小李的优化功能被成功合并到主仓库。 通过这种工作流，小李意识到，Fork 和 Pull Request 提供了一种高效的协作模式，开发者可以在独立的仓库中进行开发，不会影响主仓库的稳定性，同时也能保持代码的清晰和有序。 第十六章：Git 的持久化——“GitHub Actions” 帮我自动化部署随着项目的需求变得越来越复杂，小李和团队开始考虑如何将代码部署过程自动化。为了减少人工操作，提高效率，小李提议使用 GitHub 的 CI/CD 功能——GitHub Actions。 “小王，我们可以用 GitHub Actions 来实现自动化部署吗？” 小李询问道。 “当然可以！GitHub Actions 是 GitHub 提供的 CI/CD 服务，能够在你每次推送代码时自动触发一系列动作，比如编译、测试、部署等。” 小王一边讲解，一边打开了 GitHub 仓库的设置页面。 小李兴奋地学习着如何配置 GitHub Actions。他创建了一个新的 .yml 配置文件，定义了自动化的流程。每次有新的代码推送到主分支时，GitHub Actions 会自动执行一系列操作，首先进行单元测试，然后编译代码，最后自动将更新部署到生产环境。 小李的配置文件如下： 12345678910111213141516171819202122232425262728name: CI/CD Pipelineon: push: branches: - mainjobs: build: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v2 - name: Set up Node.js uses: actions/setup-node@v2 with: node-version: &quot;14&quot; - name: Install dependencies run: npm install - name: Run tests run: npm test - name: Deploy to production run: npm run deploy 这个配置文件定义了当代码推送到 main 分支时，GitHub Actions 会自动进行代码的检查、依赖安装、测试和部署过程。小李将这个文件推送到 GitHub 仓库中后，团队中的每个成员都能在代码推送后享受到自动化部署的便利。 不久之后，当小李提交代码并推送到 GitHub 上时，他看到 GitHub Actions 自动触发了部署流程，并成功将代码部署到生产环境。每次提交后，他不再需要手动执行部署操作，GitHub Actions 自动为他完成了这一切。 “真是太棒了！这下我们可以更专注于开发，不用再浪费时间在部署上了。” 小李高兴地对小王说。 小王点头道：“是的，自动化部署让我们可以更快速、更高效地推送代码，也减少了人为错误。” 第十七章：Git Submodule——为项目添加依赖库随着项目的扩展，团队决定将一些通用的库或模块独立出来，作为子模块来进行管理。这些子模块将在多个项目中复用，减少了重复代码的编写。 “小李，我需要你帮助把我们当前的公共库添加为 Git 子模块，这样其他项目也可以引用这个库。” 项目经理安排了一个新任务。 “好的，git submodule 是怎么操作的？” 小李询问。 “git submodule 是 Git 提供的一个工具，它允许你将一个 Git 仓库嵌套在另一个 Git 仓库中。你可以在主项目中添加其他的 Git 仓库作为子模块，通过子模块来管理依赖。” 项目经理解释道。 小李按照项目经理的要求，输入了以下命令，将公共库添加为子模块： 1git submodule add https://github.com/example/public-library.git libs/public-library 通过这个命令，Git 将公共库克隆到主项目中的 libs/public-library 目录，并将其添加为子模块。小李继续执行了： 1git submodule update --init --recursive 这样，子模块的所有内容都成功同步到本地。当其他团队成员需要使用这个公共库时，他们只需要在主仓库中执行相同的 git submodule 命令来同步子模块。 “小李，感谢你的帮助！以后其他项目也能通过这个子模块共享公共库了，极大减少了重复开发的时间。” 项目经理赞扬道。 小李点点头，意识到 Git 的 submodule 功能极大地提升了团队的开发效率，让依赖库的管理变得更简单、更灵活。 第十八章：Git 的高效工具——“Git Cherry-pick”小李在团队开发的过程中，逐渐接触到了更多的 Git 高级操作。随着项目逐渐向前推进，他发现有时需要从一个分支中挑选特定的提交，而不是直接合并整个分支。比如，有时他只想把某个特定的功能或者修复应用到当前工作中，而不希望将整个分支的其他修改都合并过来。 “小王，有没有什么方法能让我只选取某个提交而不是合并整个分支？”小李问道。 “当然有，”小王笑着说道，“Git 有一个非常有用的命令，叫做 git cherry-pick，它可以让你从另一个分支上挑选特定的提交，并将该提交应用到当前分支。” 小李顿时豁然开朗：“那如果我想把某个功能从 feature 分支中拿到当前的 main 分支上，该怎么操作？” “你只需要找到那个提交的哈希值，然后用 git cherry-pick 命令把它应用到你的当前分支。”小王答道。 于是，小李开始操作： 首先，他通过 git log 查找 feature 分支中的那个提交的哈希值。 1git log feature 然后，他切换到 main 分支，准备将提交引入当前分支： 1git checkout main 接着，使用 git cherry-pick 来选择并应用那个提交： 1git cherry-pick &lt;commit-hash&gt; 当命令执行后，Git 自动将那个提交的更改应用到了 main 分支上，而不需要合并整个 feature 分支。小李检查了代码，确认应用成功后，顺利地将新功能整合到当前分支。 “小王，真是太棒了！这个命令太实用了，以后再也不用为合并多余的代码而烦恼了！”小李高兴地说道。 小王点头笑道：“对，git cherry-pick 就是为了解决这个问题，它让你可以选择性地引入更改，避免不必要的合并。” 小李开始在日常开发中频繁使用 git cherry-pick，每当他需要从其他分支挑选特定提交时，这个命令都成为了他的得力助手。 第十九章：Git 与团队协作中的高效沟通在一次代码审查的过程中，小李和团队成员遇到了一些小小的矛盾。由于对某个功能实现的理解不同，大家对如何修改代码意见不合。虽然问题本身并不大，但由于缺乏清晰的沟通，导致开发的进展有些停滞。 “小李，你能给我们解释一下你这次修改的思路吗？”项目经理耐心地询问。 小李站在桌前，深吸一口气，决定用更清晰的方式来表达自己的想法。他打开了 Git 提交记录，逐一展示了自己的修改和思路。 “我在这里用 git commit --amend 修改了之前的提交，因为在初始提交时，我没有充分考虑到性能问题。通过这次修改，我优化了这一部分。”小李一边说，一边展示了代码改动的细节。 项目经理点点头：“明白了，这样修改的确能够提升性能。但是，我们最好在团队中进行一些小范围的讨论，再决定如何优化。” 小李决定更加注重团队的沟通，他理解到 Git 提交的详细记录和清晰的提交信息可以极大地帮助团队成员理解每个开发者的修改意图。在随后的开发过程中，他在每次提交时，都更加注重编写简洁且易懂的提交信息。 “小李，你这次提交信息写得很好，大家都能清楚知道你的修改意图。”项目经理称赞道。 这次经验让小李意识到，Git 不仅是一个版本控制工具，它还成为了团队成员之间沟通的桥梁。通过清晰的提交记录和及时的 Pull Request，每个开发者都能了解其他人的工作，从而更好地进行协作。 第二十章：Git Tag 的应用——版本管理的好帮手随着项目开发的深入，版本发布的节奏也逐渐加快。小李开始频繁接触到版本管理的任务。每当团队开发出一个新功能并完成测试时，他们就会创建一个版本发布，并用 Git 的 tag 来标记发布的版本。 “小李，接下来我们需要为即将发布的版本打上标签。” 项目经理走过来，指着屏幕说道，“你可以使用 git tag 来为我们当前的版本创建一个标签，并标记一个明确的版本号。” “我明白了，标签就像是一个历史的快照，可以帮助我们标记每一个发布版本。” 小李回答道。 于是，小李在完成最后的代码修改后，为当前的提交打上了一个标签： 1git tag v1.0 然后，他通过 git push 推送了标签到远程仓库： 1git push origin v1.0 项目经理看到远程仓库成功更新了标签后，表示满意：“很好，tag 可以让我们轻松标记每次发布的版本，方便后续的维护和版本回溯。” 小李意识到，Git 的 tag 功能不仅能够帮助团队在版本发布时更加清晰地管理项目，还能在遇到回滚或版本回退时快速恢复到特定的版本。随着团队开发的推进，tag 成为了团队工作中不可缺少的工具之一。 第二十一章：Git 工作流中的“Branch”与“Merge”随着小李逐渐掌握了 Git 的基础和高级操作，团队中的工作流程也开始更加成熟。在一次团队会议上，项目经理提议引入一种新的 Git 工作流，以便更高效地管理开发和部署过程。 “小李，团队正在采用 Git 的 feature branch 工作流，我们建议每个开发者在开发新功能时，都创建一个新的分支，开发完成后再合并回主分支。”项目经理说道。 “这样可以避免多人同时修改同一代码文件时产生冲突吗？”小李问道。 “没错，”项目经理解释道，“通过使用 feature branch，每个开发者都可以在独立的分支上进行开发，确保主分支保持稳定。只有在开发完成后，才能通过 git merge 或者 git pull request 合并回主分支。” 小李听后对这种工作流产生了浓厚兴趣。他立刻实践了这个流程。在开发新功能时，他从 main 分支创建了一个新的分支，并在分支上进行修改。当功能开发完成后，他执行了： 123git checkout maingit pull origin maingit merge feature-new-feature 通过这种方式，小李能够确保每个功能都能在独立的环境中开发，不会影响其他团队成员的工作。而且，git merge 能够帮助他将所有更改平滑地合并到主分支，确保代码的稳定性。 Git，开发者的最佳伙伴**随着时间的推移，小李不断地在实践中熟练掌握 Git 的各种技巧和工作流，他不仅能够高效地管理代码和版本，还能帮助团队提高开发效率。Git 成为了他工作中不可或缺的伙伴，见证了他从初学者到专业开发者的成长。 每当遇到问题或新的挑战时，小李总能依赖 Git 解决问题。他逐渐明白，Git 不仅仅是一个工具，它更像是一位教练，帮助开发者从错误中学习，从实践中进步。 未来的路还很长，而 Git 将继续陪伴小李，助力他在开发的世界中越走越远。在这个信息化飞速发展的时代，Git 让团队协作变得更加高效，代码管理变得更加清晰，开发者的每一步成长，都将在 Git 的世界中留下深深的印记。 第二十二章：Git 进阶——掌握 git reset 和 git reflog随着开发项目的不断发展，小李逐渐遇到了一些复杂的情况。有时候，他在提交后发现代码存在问题，或者做了不必要的操作，想要撤回。对于这种情况，git reset 命令成为了他解决问题的利器。 一天，小李正在开发一个新功能，突然意识到自己在提交时选择了错误的文件进行修改，造成了不必要的代码变动。他想要撤回这次提交，怎么做呢？ “小王，我不小心提交了错误的代码，能不能撤回？” 小李焦急地问道。 小王走过来，微笑着解释道：“你可以使用 git reset 来撤回最近的提交。git reset 允许你恢复到某个特定的提交状态，你可以选择是保留本地修改，还是完全丢弃。” “那如何使用呢？”小李问道。 “你可以通过 git reset --soft HEAD~1 撤销最近一次提交，但保留你的工作区更改；或者使用 git reset --hard HEAD~1 完全撤销提交，并且丢弃所有更改。” 小王继续说道。 小李决定使用 git reset --soft 来撤回错误的提交并保留工作目录中的修改： 1git reset --soft HEAD~1 执行完命令后，Git 将最近一次提交撤销，并把修改恢复到暂存区。这时，小李可以继续修改代码并重新提交。 “小王，真是太方便了！git reset 让我能够灵活控制我的代码，避免了不必要的错误提交。” “是的，git reset 是一个非常强大的命令，但要小心使用，尤其是 --hard 参数，使用不当可能会丢失数据。” 小王提醒道。 不仅如此，小李还学会了使用 git reflog 查看历史操作的记录。当他不小心做错操作时，git reflog 成为了解决问题的救命稻草。 “git reflog 是一个很有用的工具，它记录了你所有的 HEAD 操作历史，即便你执行了 git reset 或者其他改变了历史的操作，它也能帮你找回丢失的记录。” 小王向小李展示了 git reflog 的使用。 1git reflog 小李通过 git reflog 快速找到了丢失的提交，并通过 git reset 恢复了之前的状态。这让他更加有信心在复杂的开发任务中使用 Git 来管理版本和操作历史。 第二十三章：Git 在代码审查中的优势随着项目的逐渐深入，团队的代码审查变得尤为重要。小李不再是唯一负责提交和修改代码的人，团队中的每个成员都在贡献自己的力量。而 Git 在代码审查中的作用，也变得愈发突出。 “小李，今天我们来做代码审查，你的这段代码有一些地方需要调整。” 项目经理提醒道。 “好的，项目经理，能不能给我一些反馈？”小李走到项目经理的办公桌旁。 项目经理通过 Git 提交记录查看了小李的代码，指出了其中的一些问题。通过 git diff 命令，他能清楚地看到小李在提交时修改了哪些部分。 “小李，你在提交时改变了这个函数的实现逻辑。我们能不能保留原有逻辑并优化一下性能？”项目经理问道。 小李立刻打开终端，执行 git diff 查看具体的代码差异，确认了项目经理的建议： 1git diff HEAD~1 “确实是这样。谢谢你指出这个问题，我会按照建议进行修改。”小李认真地说道。 通过 git diff，小李能够迅速查看每次提交所带来的代码差异，确保每次修改都能符合团队的要求。而且，Git 也让代码审查变得更加高效，团队成员可以轻松查看每个提交的改动内容，避免了沟通上的误解。 项目经理总结道：“Git 在团队协作中的优势非常明显，代码审查时，我们能直接通过提交记录看到每个开发者的修改，而且能随时回溯历史，查看每个修改的细节。” 小李深刻认识到，Git 提供的强大工具不仅能帮助他高效管理代码，还能在团队合作中提升代码审查的效率，确保每个成员的代码质量。 第二十四章：Git 和持续集成（CI）结合随着项目的规模不断扩大，团队决定引入持续集成（CI）工具，以便更好地自动化测试和部署流程。小李负责配置 Git 和 CI 工具的集成，让团队的代码自动化构建、测试和部署。 “小李，我们要使用 Jenkins 来进行自动化构建和测试，能帮我把 Git 和 Jenkins 集成起来吗？”项目经理问道。 “没问题，项目经理，我来配置。” 小李点头答应。 首先，他在 GitHub 仓库中配置了 Webhook，当代码推送到 GitHub 仓库时，Webhook 会自动触发 Jenkins 构建任务。接着，小李在 Jenkins 中配置了一个构建任务，并在构建脚本中加入了自动拉取 Git 仓库代码的命令： 1git clone https://github.com/your-username/project-repo.git 此外，Jenkins 还配置了自动化测试步骤，每当代码推送到 Git 仓库时，Jenkins 会自动拉取代码，执行单元测试，确保没有新的 bug 被引入。 通过这种方式，小李实现了 Git 与 Jenkins 的无缝集成，让每次代码推送后都能自动触发构建和测试流程，极大提高了开发效率。 “小李，你的配置太棒了！现在我们每次推送代码后，Jenkins 会自动进行构建和测试，这样就能第一时间发现问题，避免了手动操作的麻烦。”项目经理感慨道。 小李也深刻感受到，Git 不仅是团队协作的工具，还能与 CI 工具结合，提升整个开发流程的自动化和高效性。 第二十五章：Git 的深层次运用——多仓库管理随着小李在项目中不断积累经验，他开始接触到更加复杂的 Git 使用场景。例如，团队中的多个子项目之间需要进行协调开发，这就需要管理多个仓库。为了有效管理这些子项目，小李学习了如何使用 Git 管理多个仓库的代码。 “小李，我们有多个子项目需要同步更新，能不能管理多个 Git 仓库？”项目经理问道。 小李思索了一下，答道：“我们可以使用 Git 的 submodule 功能来管理这些子项目，或者通过 git remote 将多个远程仓库关联到一个本地仓库。” 他通过 git remote 添加了其他项目的远程仓库，使得多个仓库能够通过一个 Git 仓库进行管理。这种方法让小李能够方便地同步多个子项目的代码，并确保所有仓库的代码始终保持一致。 “小李，这种管理方式非常有效，能让我们轻松地同步多个仓库的代码。”项目经理满意地说道。 第二十六章：Git 在应对大规模项目中的应用随着团队逐渐发展，项目的规模也在不断扩大，甚至开始涉及多个跨团队的合作。小李渐渐意识到，在这样的大规模项目中，Git 不再是一个单纯的版本控制工具，而是整个开发流程的核心之一。为了解决不同团队成员之间的协作问题，团队决定采用 Git 作为核心工具来协调各项工作。 “小李，我们的项目越来越复杂，多个团队的协作需求也越来越高，如何更好地协调和管理多个模块之间的关系呢？” 项目经理问道。 “我建议我们将每个模块或子系统作为独立的 Git 仓库，采用 Git 的 Submodule 或者 Subtree 功能来管理不同模块之间的依赖。” 小李回答道，“这样可以让每个团队独立工作，同时通过 Git 的功能保持各个模块之间的同步。” “Submodule 和 Subtree？能不能再详细说一下？” 项目经理有些疑惑。 “好的，” 小李微笑着解释，“git submodule 用于将一个 Git 仓库嵌套到另一个仓库中，适合在一个大的项目中引用一些公共的库或者子项目。它能够让我们独立管理每个模块，并通过主仓库来同步这些模块。git subtree 则是一个更强大的工具，允许我们将一个项目的子目录作为另一个仓库的历史部分来管理，方便合并和共享代码。” 项目经理点点头，表示理解：“那我们可以先尝试使用 git submodule，看看能不能有效管理各个子模块。” 于是，小李开始在主项目中引入了 Git 子模块，将各个子模块独立管理，每个团队都可以独立开发自己的部分，通过 Git Submodule 来同步。每当有更新时，团队成员只需使用 git submodule update 命令来同步各自的子模块。 “小李，这样的做法确实很有效。每个团队都可以专注于自己负责的模块，且能通过 Git 保证模块间的同步。” 项目经理满意地说道。 随着项目的不断发展，团队的协作也变得更加高效。Git Submodule 成为了管理大规模项目中多个模块之间关系的关键工具，使得每个团队能够更加高效地独立开发，避免了冲突和重复工作。 第二十七章：Git 和 DevOps 的融合随着团队在多个项目中的逐渐积累，团队的开发模式也逐渐从传统的开发方式向 DevOps 转型。持续集成（CI）、持续交付（CD）和自动化测试成为了团队开发的核心需求，而 Git 作为版本控制工具在 DevOps 中的作用变得尤为重要。 “小李，接下来我们要将开发流程进行 DevOps 化，我们需要一个自动化的 CI/CD 流程来提高开发效率。” 项目经理指示道，“你能帮忙把 Git 与我们的 CI 工具结合起来吗？” “没问题，我来配置。” 小李迅速答应道。 小李首先配置了 Git 与 Jenkins 的集成。每当团队成员向 Git 仓库推送代码时，Jenkins 会自动检测到提交，触发自动化构建流程，执行单元测试，确保每次提交的代码都能够通过测试。接着，他配置了持续交付流程，每当通过测试后，Jenkins 会将代码自动部署到开发环境进行进一步的验证。 为了进一步优化流程，小李还在 GitHub 上配置了 Webhooks，将每次 Git 提交推送事件通知给 Jenkins，确保流程的自动化和即时性。 “通过这种方式，我们的代码每次提交后都会自动构建和测试，减少了手动操作的时间和错误。” 小李解释道，“这种 DevOps 思维方式不仅提升了开发效率，也保证了代码的质量。” 项目经理看着自动化部署流程的顺利运行，表示满意：“非常好，Git 与 DevOps 结合，自动化构建和测试提高了我们的交付效率，减少了人工操作的错误。” 第二十八章：Git 在开源项目中的协作模式随着小李在公司中积累的经验越来越丰富，他开始参加一些开源项目的开发。开源项目通常有很多开发者参与，其中涉及到不同的工作流和版本管理方式。在参与开源项目时，Git 的使用成为了开发中的一个重要部分，尤其是如何高效地与其他开发者协作。 “小李，最近我在 GitHub 上看到一个非常有意思的开源项目，我们也可以参与其中贡献代码。” 小王激动地说。 “开源项目？那我们要如何参与其中呢？”小李问道。 “我们可以通过 Fork 该项目，并在我们的个人 GitHub 仓库中进行开发。当我们完成自己的功能后，通过 Pull Request 向原项目提交我们的更改。” 小王解释道。 小李立刻开始了解开源项目的工作流程。首先，他在 GitHub 上 Fork 了项目，然后将其克隆到本地。接着，他在本地进行了修改，并在完成之后推送到个人仓库。 然后，他创建了一个 Pull Request，请求将自己的更改合并到原项目中。通过这种方式，原项目的维护者可以查看他的修改并决定是否接受他的更改。 “小李，Fork 和 Pull Request 真是开源项目的核心工作流。它能让我们独立开发，并通过 PR 与原项目进行贡献。”小王感慨道。 通过参与开源项目，小李不仅进一步提升了自己的开发技能，还学会了如何在全球范围内与其他开发者协作。Git 的强大功能使得开源项目的开发变得有序而高效，团队成员之间能够通过清晰的提交记录和 PR 进行有效沟通，确保了代码质量和开发进度。 第二十九章：Git 与 Agile 开发的结合随着团队的进一步发展，团队决定采用敏捷开发（Agile）方法来提高开发效率和灵活性。敏捷开发要求团队快速响应需求变化，并在较短的时间内交付高质量的代码。而 Git 成为了实现这一目标的关键工具之一。 “小李，我们决定引入敏捷开发，采用迭代的方式进行功能开发。每个 Sprint 结束后，我们需要提交一个可交付的版本。” 项目经理说道，“你认为我们如何利用 Git 来支持敏捷开发？” “我认为，Git 能够非常好地支持敏捷开发。” 小李答道，“通过创建 feature 分支，我们能够快速开发出独立的功能。在每个 Sprint 结束时，我们可以通过 git merge 或者 git pull request 将功能合并到主分支，从而保证代码的稳定性。” “那我们如何处理版本发布呢？” 项目经理问道。 “Git 的 tag 功能非常适合版本管理。在每次功能开发完成后，我们可以通过 git tag 打上版本标签，标记每个发布的里程碑。” 小李解释道。 通过使用 Git 支持敏捷开发，团队能够更快速地进行功能开发和迭代交付，同时保持代码的清晰和可维护性。每次迭代结束后，Git 的分支管理和版本标签都确保了每个功能都能够按时交付，且不会影响其他功能的开发。 项目经理表示赞赏：“Git 的分支管理和 tag 功能完美支持了我们敏捷开发的需求，让我们能够更加高效地进行迭代和发布。” Git —— 开发者的长久伙伴**随着时间的推移，小李不仅在公司中积累了丰富的 Git 使用经验，也在开源项目和敏捷开发中不断提升自己。Git 成为了他日常开发工作中不可或缺的工具，帮助他在团队中与其他成员高效协作，推动项目顺利进行。 Git 不再只是一个简单的版本控制工具，它已经深入到整个开发流程中，成为小李的长久伙伴。无论是日常的功能开发，还是复杂的多团队协作，Git 都能够帮助开发者高效管理代码，提升开发效率。 未来的道路依然充满挑战，但小李相信，只要有 Git 作为工具，他将能够不断突破自己，迎接更大的成功。在这个快速发展的技术时代，Git 将继续陪伴小李，在他编程的旅程中不断迈向新的高度。 第三十章：Git 在大规模团队中的管理实践随着公司项目的规模日益壮大，团队成员也越来越多。小李和其他团队成员发现，Git 在大规模团队中的协作变得更加复杂。在一个多团队、跨部门的项目中，如何有效地管理和合并不同的代码变得尤为重要。 “小李，团队的规模扩大后，我们发现管理多个开发分支变得越来越困难，很多人都在不同的分支上并行开发，合并冲突也变得更频繁了。你觉得我们怎么做才能更高效地管理代码？” 项目经理问道。 小李开始思考，发现随着团队规模的扩大，代码管理面临的挑战确实在增加。他想到了一些改进方法：“我们可以采用 Git Flow 工作流来更好地管理分支。Git Flow 是一个标准化的分支管理模式，它通过规定各个分支的功能来减少冲突，确保每个分支的职责明确。” “Git Flow？听起来很有用。你能详细解释一下吗？” 项目经理有些好奇。 小李耐心地讲解道：“Git Flow 是由 Vincent Driessen 提出的分支模型，它定义了几个主要的分支角色： master：主分支，保存着所有已经发布过的代码，始终保持稳定。 develop：开发分支，所有新的功能都在这个分支上开发，只有当功能开发完成并经过测试后，才会合并到 master 分支。 feature：特性分支，用来开发独立的功能模块。每个功能都会在一个单独的 feature 分支上开发，开发完成后合并回 develop 分支。 release：发布分支，主要用于准备新版本的发布。当 develop 分支上的功能基本完成时，我们会创建一个 release 分支来进行最终测试和 bug 修复。 hotfix：修复分支，快速修复主分支上的紧急 bug，修复完成后合并到 master 和 develop。 这种工作流的优势在于，每个团队成员可以在自己的特性分支上独立开发，减少冲突。而且，release 和 hotfix 分支帮助我们在发布和修复过程中保持主分支的稳定。” 项目经理听后点点头：“这个工作流确实很有意义，它能够帮助我们更有条理地管理代码，避免过多的冲突和合并问题。” 小李随后帮助团队将 Git Flow 工作流应用到团队项目中，确保每个开发人员按照规范创建分支、提交代码，并使用 git merge 或 git pull request 合并分支。通过这种方法，团队成员之间的协作变得更加高效，而 Git Flow 也为团队提供了清晰的分支管理结构。 第三十一章：Git 在多平台开发中的角色随着团队的技术栈不断扩展，项目开始涉及多个平台的开发需求：前端使用 React，后端使用 Node.js 和 Express，移动端使用 React Native，甚至还有一些用于数据处理的 Python 脚本。每个平台的代码和环境不同，但如何确保这些平台的代码都能同步更新、管理起来却不产生冲突，成为了小李的一个新挑战。 “小李，考虑到我们开发的多个平台，如何更好地管理这些不同代码的依赖呢？” 项目经理询问道。 小李回忆起自己在过去的项目中遇到过类似的需求，顿时有了主意：“我们可以利用 Git 子模块（git submodule）来管理跨平台的代码库。通过将每个平台的代码作为独立的 Git 仓库，使用主仓库来统一管理这些代码，就能有效地将不同的代码库集中在一个地方，方便我们管理。” “你是说，不同的代码库可以独立管理，然后通过主仓库来同步吗？” 项目经理问。 “是的，git submodule 允许我们将其他 Git 仓库嵌套在主仓库中，作为子模块来管理。每个子模块有自己的版本号，主仓库负责对子模块进行版本控制和更新。当我们需要更新子模块的代码时，只需在主仓库中同步子模块即可。” 小李解释道。 他接着为项目配置了 Git 子模块，每个平台的代码库都作为一个子模块被添加进主仓库中，使用 git submodule 命令来同步更新各平台的代码： 123git submodule add https://github.com/example/frontend-repo.git frontendgit submodule add https://github.com/example/backend-repo.git backendgit submodule add https://github.com/example/mobile-repo.git mobile 每当更新子模块的代码时，团队成员只需要在主仓库中执行： 1git submodule update --recursive --remote 通过这种方式，团队能够有效管理不同平台的代码，并确保每个平台的版本都能保持同步，减少了版本冲突的发生。 “通过子模块管理多个平台的代码，团队成员可以独立开发，不同平台之间不会相互干扰。” 项目经理表示赞赏。 第三十二章：Git 与 Code Review 流程随着项目的不断发展，代码质量和团队合作变得尤为重要。小李意识到，除了版本控制和代码同步，如何高效地进行代码审查（Code Review）也是团队合作中的一个关键环节。 “小李，最近我们在团队中遇到了一些代码质量问题。为了提高代码质量，我们决定加强代码审查流程。” 项目经理说。 “我明白，代码审查能帮助团队发现问题并保持一致的编码风格。我觉得 Git 可以在这方面发挥很大作用。” 小李答道。 小李向项目经理提议，通过 Git 提交记录和 GitHub 的 Pull Request 功能，团队成员可以高效地进行代码审查。每次提交新的功能或修改时，开发者都通过 git push 将代码推送到远程仓库，并创建一个 Pull Request，请求团队成员进行审查。 在代码审查过程中，团队成员可以在 GitHub 上查看具体的改动（git diff），留下评论，提出修改意见。每次修改完毕，开发者会更新 Pull Request，直到所有问题得到解决。最终，项目经理或负责人会合并代码并批准最终的提交。 “小李，这个流程非常有帮助，Git 的 Pull Request 功能能让我们更高效地进行代码审查，确保每个功能都经过了充分的讨论和审核。” 项目经理说道。 通过 Git 提供的强大功能，团队能够在代码审查中更好地协作，不仅提升了代码质量，还加强了团队之间的沟通。 第三十三章：Git 在自动化和脚本化中的应用随着团队项目越来越复杂，小李开始接触到一个新的需求——自动化。项目中有很多重复性、繁琐的操作，比如同步子模块、打标签、发布新版本等。小李发现，手动执行这些操作既耗时又容易出错，因此他决定通过编写脚本来自动化这些任务。 “小李，我们希望能简化每次发布的过程，能不能帮忙写个自动化脚本，避免每次都要手动执行 Git 命令？” 项目经理提出了一个需求。 小李非常兴奋，因为他一直对自动化非常感兴趣。他思考了一下，决定用 Bash 脚本来实现这一功能。脚本的目标是每次新版本发布时，自动更新子模块、切换到主分支、打标签，并将代码推送到远程仓库。 他编写了如下脚本： 1234567891011121314151617181920#!/bin/bash# 1. 更新所有子模块git submodule update --init --recursive# 2. 切换到主分支git checkout main# 3. 拉取最新的代码git pull origin main# 4. 打上新的版本标签VERSION=$(date +&quot;%Y%m%d%H%M%S&quot;)git tag -a &quot;v$VERSION&quot; -m &quot;Release version $VERSION&quot;# 5. 推送主分支和标签到远程git push origin maingit push origin &quot;v$VERSION&quot;echo &quot;Release $VERSION successfully created and pushed!&quot; 这个脚本首先更新了所有子模块，确保每个模块都是最新的。然后，它会切换到 main 分支，拉取远程仓库的最新代码，接着生成一个基于当前时间戳的版本号，并使用 git tag 打上标签。最后，脚本会将 main 分支和新标签都推送到远程仓库。 “小李，这个自动化脚本简直太棒了！以后发布新版本时，直接执行这个脚本就行了，避免了手动操作的错误。” 项目经理大加赞赏。 小李也对这个自动化过程非常满意。通过自动化脚本，他不仅减少了繁琐的操作，还降低了人为错误的风险。这次经历让小李更加深刻地认识到，Git 不仅是版本控制工具，它也能够与自动化流程紧密结合，提升整个开发流程的效率。 第三十四章：Git 与团队沟通的桥梁随着团队规模和项目复杂度的增加，沟通变得尤为重要。团队成员之间不仅要讨论功能需求，还需要清楚地了解其他成员的工作进展。小李发现，Git 提供的提交记录、分支管理、合并过程和 Pull Request，实际上都为团队沟通提供了强有力的支持。 一天，小李在查看项目的 Git 提交记录时，注意到某些提交信息比较模糊，无法准确反映开发的进度和内容。他认为，这是团队在使用 Git 时未能充分利用其沟通能力。 “小王，你觉得 Git 提交信息的重要性有多大？”小李向同事请教。 “其实提交信息是团队沟通的一个重要桥梁，它可以帮助我们了解每个功能的开发进度和思路。如果提交信息不清晰，团队成员很难理解开发者的意图。” 小王认真回答道。 “那我们能不能有一个规范，确保每个人在提交时都写清楚相关信息？”小李提议。 小王点点头：“是的，我们可以制定一些提交信息规范，比如每次提交时都写清楚这次提交的目的、所修复的 bug、改进的功能等。这样可以帮助团队成员快速理解代码的变动，提升沟通效率。” 于是，小李和团队一起讨论并制定了一份 Git 提交信息规范，要求每次提交时都必须包括以下内容： 简短的标题：描述这次提交的主要目的（如“修复登录功能”、“优化数据处理逻辑”）。 详细的描述：具体说明这次提交修改了什么，为什么要修改，以及如何修改的。 关联的 issue 或 bug：如果是修复 bug 或实现某个需求，提交信息中需要提及关联的 issue 或 bug 编号。 从那以后，团队的 Git 提交记录变得更加清晰和规范，每个人在查看提交记录时都能迅速理解变更内容。Git 不再只是一个简单的工具，它成为了团队沟通的桥梁，帮助开发者更好地协作。 第三十五章：Git 与远程协作的无缝结合在小李所在的公司，随着项目的扩展，团队成员开始分布在不同的地方，甚至有了远程工作模式。如何保持远程团队的协作效率，成了一个关键问题。小李深知，Git 的强大远程协作能力将在这里发挥巨大的作用。 “小李，考虑到我们团队已经是远程工作，我们需要有一个标准化的流程来管理远程仓库和分支，确保每个人都能高效协作。”项目经理提出了新的挑战。 “我们可以利用 GitHub、GitLab 或 Bitbucket 等平台的功能来实现这一点，配合 git fetch、git pull、git push，保证每个人的工作始终与远程仓库同步。” 小李回答道，“我们可以设置清晰的分支管理规则，例如每个功能使用独立的 feature 分支，合并时使用 Pull Request，并且严格要求审查代码。” “那这样的话，团队成员都可以在自己的分支上独立工作，最后通过 Pull Request 来进行合并和代码审查，对吗？” 项目经理进一步确认。 “是的，完全正确。每个人都可以在自己的分支上工作，提交并推送到远程仓库后，其他成员可以随时拉取更新。通过 Pull Request 和代码审查，我们可以确保代码质量，避免直接推送到 main 分支。” 小李解释道。 为了更好地管理远程协作，小李还建议团队使用 GitHub 的团队管理功能，将每个项目的成员分成不同的权限组，确保项目代码的安全性。 通过这些措施，团队的远程协作变得越来越顺畅，开发进度也大大加快。Git 成为他们跨时区、跨地域协作的桥梁，保证了远程工作模式下的高效沟通与协作。 第三十六章：Git 与知识管理的结合在一次团队会议上，项目经理提到：“我们团队已经积累了大量的知识和技术文档，如何能够更好地管理这些知识，让每个新加入的成员都能快速了解项目和技术栈？” 小李听后立即想到了 Git 的优势：“我们可以将这些文档和知识管理工作与 Git 结合起来，创建一个专门的 Git 仓库，来管理项目的技术文档、架构设计以及解决方案等。” 项目经理表示认可：“这样一来，新成员可以通过 Git 仓库查看我们的文档，也能通过 Git 提交的历史记录了解每个问题的解决过程。” 小李和团队决定创建一个专门的 Git 仓库，专门用来存储项目文档、设计文档、代码规范和技术文章等。在这个仓库中，所有文档都将与代码一样进行版本控制，每个文档的更新和修改都会记录在 Git 提交历史中，方便后续查看和追溯。 通过这种方式，团队的知识管理变得更加高效，每个成员都可以随时查看、更新和修改文档，而 Git 则确保了文档的版本控制和更新记录。 第三十七章：Git 在复杂环境中的应用——跨平台开发与持续集成随着项目变得越来越复杂，小李发现开发环境的多样化带来了新的挑战。在一个典型的跨平台开发环境中，团队同时在开发前端、后端、移动应用、甚至机器学习模型等多个部分，而每个部分都有不同的技术栈和依赖。 “小李，我们的项目现在涉及多个平台，前端是 React，后端是 Node.js，移动端是 React Native，机器学习模型是用 Python 实现的。如何在这些平台之间保持一致，并且高效协作呢？” 项目经理问。 “这个问题确实不小，”小李思考了一下，“不过我想到了一种方式。我们可以利用 Git 和 Docker 来帮助管理这些平台的环境，确保每个开发者的环境一致。同时，我们可以通过 CI 工具进行自动化测试和构建，确保每个平台的代码都能顺利运行。” 他继续讲解：“首先，我们可以为每个平台创建独立的 Git 子模块，分别管理每个平台的代码库。然后，我们可以通过 Docker 为每个平台创建独立的开发环境，确保每个开发者都能在本地轻松搭建相同的开发环境。” 项目经理表示理解并表示认可：“这个思路不错，Git 的子模块能帮助我们管理各个项目，而 Docker 则能保证每个开发者的环境一致。接下来，你可以为我们实现这一方案吗？” 小李开始实施方案。他为每个平台创建了独立的 Git 子模块，将不同平台的代码库分开管理，确保每个平台的代码能独立开发且相互不干扰。接着，他为每个平台编写了 Dockerfile 文件，确保每个开发者都能通过 Docker 快速搭建一致的开发环境。 例如，前端的开发环境通过 Docker 配置了 Node.js 和相关的构建工具，而后端则使用了 Express 和数据库连接，机器学习的环境则配置了 Python 和 TensorFlow。通过 Docker 容器，开发者只需要拉取相应的容器镜像，就可以快速搭建起完全一致的开发环境。 “小李，这个方案非常棒！通过 Docker，我们能够在不同平台之间确保开发环境的一致性，Git 子模块则让我们能更好地管理不同平台的代码。” 项目经理感慨道。 小李也对这一方案非常满意。通过 Git 和 Docker 的结合，团队能够有效地管理和协作多个平台的开发，避免了环境不一致的问题。同时，自动化测试和持续集成的引入也让开发进度更加高效。 第三十八章：Git 在数据库版本控制中的重要性随着项目的功能越来越丰富，数据库的管理也变得尤为重要。数据库结构、存储过程和数据迁移等方面的变动需要进行详细的记录和管理。小李发现，传统的数据库管理方式往往不够透明，难以追溯数据库的变动历史。于是，他提出了一个新方案：使用 Git 来管理数据库的版本控制。 “小李，我看到你最近在研究数据库版本控制的方案。你能给我们讲讲怎么将 Git 应用到数据库管理中吗？” 项目经理问。 “我想到了一个方法，就是通过将数据库的结构和迁移脚本也放入 Git 仓库中，和应用代码一起管理。” 小李回答道。 他接着解释：“我们可以把每次数据库的变动（例如表结构变更、索引创建、存储过程更新等）写成迁移脚本，并将这些脚本放入 Git 仓库中进行版本控制。每当需要修改数据库结构时，开发者只需编写迁移脚本，并将其提交到 Git 仓库。然后，通过自动化工具或者手动方式运行这些迁移脚本，数据库就能与应用代码同步更新。” 项目经理觉得这个方案非常有价值，毕竟数据库的变更往往难以管理，Git 的引入能够帮助团队更好地追踪和管理这些变动。 “小李，你可以为我们建立一个数据库迁移管理流程吗？” 项目经理问道。 小李开始构建这个方案。他创建了一个新的 Git 仓库，用于存储所有数据库的迁移脚本。每次数据库结构有变化时，开发者会编写相应的迁移脚本，提交到 Git 仓库中。迁移脚本的命名规则也被统一，以便于后续的管理和回滚。 当需要更新数据库时，开发者会使用一个数据库迁移工具（例如 Flyway 或 Liquibase）来自动应用这些脚本，确保数据库与应用代码保持一致。如果数据库出现问题，可以通过 Git 历史记录查看之前的变更，并回滚到某个历史版本。 “小李，你的这个方案太好了！数据库变更再也不需要手动记录和更新了，所有的变动都可以通过 Git 来追溯。” 项目经理激动地说道。 通过将数据库版本控制与 Git 集成，团队不仅提高了管理效率，还增加了开发过程中的透明度和可追溯性。 第三十九章：Git 与团队文化的融合随着项目逐渐走向成熟，小李逐渐意识到，Git 不仅仅是一个技术工具，它也在潜移默化地影响着团队的文化。在团队的协作中，Git 强调了透明度、代码的可追溯性和团队成员之间的高效沟通。 “小李，最近我注意到，团队成员在协作时越来越注重代码的清晰度和规范性，大家的合作也越来越顺畅。” 项目经理感慨道，“你觉得这与 Git 的使用有关系吗？” 小李点点头：“有很大关系。Git 强调了每个人对代码的责任和透明度。每次提交都可以清晰地查看修改内容，团队成员通过 git diff 和 git log 能够清楚地看到彼此的工作。这不仅提升了代码质量，也促进了团队成员之间的有效沟通。” 项目经理继续说：“我还发现，团队成员越来越注重提交信息的规范，大家在写提交信息时，会写得很清晰，标明修复的 bug、优化的功能以及其他细节。这种良好的习惯促进了团队的协作和项目的高效推进。” 小李微笑着回答：“是的，Git 的提交信息规范性确实对团队合作有很大影响。当每个开发者都知道自己提交的每一行代码都需要经过审查并且能被追溯时，大家会更自觉地保证代码的质量和清晰度。Git 让我们在开发过程中养成了良好的编码习惯，也提升了团队协作的效率。” 项目经理点头赞同：“Git 作为我们的核心工具，不仅帮助我们管理版本、协作开发，还帮助我们树立了良好的团队文化。我们现在的开发过程更加高效，团队也更加和谐。” 第四十章：Git 与 DevSecOps 的结合随着公司项目和团队规模的扩大，小李逐渐意识到，除了版本控制和协作，Git 在保障代码安全性方面也能发挥重要作用。在项目中，团队开始引入 DevSecOps（开发、运维和安全一体化）的概念，确保代码在整个开发周期中都能遵循最佳的安全实践。 “小李，我们最近决定加强项目的安全性，将安全控制纳入到开发流程中，你觉得 Git 在这个过程中能扮演什么角色？” 项目经理问道。 小李思索了一下，回答道：“Git 在 DevSecOps 中的作用主要体现在两个方面。一方面，它能够帮助我们确保代码的安全性，通过代码审查和历史提交记录，让我们清晰地了解代码变动，确保没有恶意或不安全的代码被引入；另一方面，Git 还能够与安全工具集成，通过 CI/CD 管道自动化地检测漏洞，保证每次代码提交都经过安全审查。” “能举个例子吗？” 项目经理感兴趣地问道。 小李接着解释道：“举个例子，我们可以在 Git 提交时，集成一些静态代码分析工具，例如 SonarQube 或 Checkmarx，这些工具会扫描每次提交的代码，检测潜在的漏洞或安全隐患。如果发现问题，Git 会阻止代码的合并，直到问题被修复。通过这种方式，我们能够确保每个提交都符合安全标准。” 项目经理点头称赞：“这个思路很好，Git 不仅能管理版本，还能与安全工具紧密结合，自动化检查代码中的安全问题。这将大大提高我们的安全性，避免漏洞进入生产环境。” 小李开始为团队配置了与 Git 集成的安全工具。他设置了 SonarQube，确保每次代码提交时，都会自动进行静态代码分析，并通过 Git 的 hook 阻止潜在的漏洞进入主分支。通过这种方式，团队确保每次提交的代码都能符合安全标准，而不需要人工介入。 第四十一章：Git 在微服务架构中的管理随着项目架构的复杂性增加，团队决定将项目的开发模式转向微服务架构。微服务架构将应用拆分成多个独立的服务，每个服务都负责一个特定的功能模块，能够独立部署、独立开发，并且通过 API 进行互联。 “小李，随着我们逐渐采用微服务架构，如何高效地管理每个微服务的代码和依赖呢？” 项目经理问道。 “我们可以使用 Git 来管理每个微服务的代码库，确保每个微服务都能独立开发和部署。” 小李回答道，“每个微服务都可以作为一个独立的 Git 仓库来管理，这样能够保证服务之间的独立性，并且可以通过 Git 的 Submodule 或者 Subtree 来管理微服务之间的依赖。” “小李，那微服务间如何进行版本控制和依赖管理呢？” 项目经理继续问。 “我们可以在每个微服务的 Git 仓库中使用标签（tag）来标记每个版本，确保我们可以回溯历史版本。” 小李进一步解释道，“此外，通过在 Git 仓库中配置 CI/CD 流程，每个微服务都能独立构建、测试和部署，确保每个服务的更新不会影响其他服务的运行。” 项目经理表示赞同：“这样的话，每个微服务就能独立管理，同时保持与其他服务的同步，减少了系统的耦合性。” 小李帮助团队将 Git 应用于微服务架构的管理中，为每个微服务创建了独立的 Git 仓库，并通过 Git 子模块来管理服务之间的依赖。通过这种方式，每个微服务的代码都能独立更新和发布，而 Git 确保了服务之间的同步和版本控制。 第四十二章：Git 与团队协作工具的集成随着团队逐渐壮大，协作工具的使用也变得越来越重要。小李发现，除了 Git，本地的代码管理，团队还需要借助 Slack、Jira、Trello 等工具进行任务管理、沟通和协作。为了提高工作效率，如何将 Git 与这些工具集成，成为了小李的新挑战。 “小李，我们希望在每次代码提交时，能够自动通知团队成员并更新任务进度，你觉得 Git 能和这些工具集成吗？” 项目经理问道。 “完全可以，” 小李答道，“我们可以利用 Git 提供的 webhook 功能，将 Git 与 Slack、Jira 等工具集成。当我们提交代码时，可以自动通过 webhook 发送消息到 Slack，通知团队成员代码的更新；同时，我们也可以自动更新 Jira 上的任务状态，让团队成员更清晰地知道当前任务的进度。” 项目经理听后非常赞同：“这能大大提高我们的沟通效率，让每个团队成员都能第一时间知道任务进展。” 小李立即开始为团队配置 Git 与 Slack 和 Jira 的集成。他设置了 GitHub 的 webhook，在每次提交时，自动发送消息到团队的 Slack 频道，告知大家新的功能开发进度或 bug 修复的状态。同时，他也将 Jira 与 GitHub 集成，每次提交代码时，相关的任务会自动更新状态，确保任务进展清晰可见。 “小李，太棒了！通过这种集成，我们的沟通效率大大提高，团队成员能够第一时间看到任务的进展和代码更新。” 项目经理感慨道。 第四十三章：Git 的未来——AI 与自动化的结合随着技术的不断进步，小李看到 Git 的发展趋势将不仅仅停留在传统的版本控制和协作管理上。人工智能（AI）和自动化工具的结合，将使 Git 变得更加智能化，能够自动分析代码质量，提供代码优化建议，甚至自动修复常见的代码问题。 “小李，你认为 Git 在未来的发展会是怎样的？” 项目经理问道。 “我认为，未来 Git 会与 AI 更紧密地结合，自动化和智能化的特性将进一步增强。” 小李回答道，“例如，Git 将能够通过 AI 自动分析代码的质量、风格和结构，自动生成优化建议，并通过机器学习模型来预测代码的潜在问题。未来的 Git 可能不仅仅是一个代码管理工具，它也可以作为开发中的智能助手，帮助开发者更高效地编写和管理代码。” 项目经理笑了笑：“这个思路非常前瞻，的确，AI 与 Git 的结合将为开发者带来更多的便利。也许在不久的将来，Git 就不再是一个仅仅执行命令的工具，而是一个智能的合作伙伴，主动为开发者提供帮助。” 小李对未来的 Git 充满期待。他相信，随着 AI 和自动化技术的发展，Git 将继续进化，成为开发者不可或缺的智能伙伴，不仅帮助管理版本和代码，更会成为整个开发过程中的决策支持系统。 第四十四章：Git 与版本控制系统的进化随着技术的不断发展和项目需求的不断增加，小李渐渐意识到，Git 的功能已远远超出了传统的版本控制工具的范畴。越来越多的团队开始探索如何利用 Git 在更高层次的工作流和管理中发挥作用。小李对 Git 的深度掌握也逐渐使他开始考虑，未来是否有可能会出现新的版本控制系统，或者 Git 会如何进化以适应未来的需求。 “小李，你觉得 Git 在未来会如何发展？是否会有其他版本控制工具取代 Git 的地位？” 项目经理在一次会议中向小李提出了这个问题。 小李思索了一下，回答道：“我认为 Git 目前仍然是最强大的版本控制系统，它已经深深扎根于开发者的工作流中。不过，随着大数据、分布式计算和人工智能的快速发展，Git 可能会在未来进行一些技术性进化，特别是在性能优化、协作和自动化方面。可能我们会看到更多与 Git 集成的工具，或是智能化的 Git 提示系统，甚至 Git 会在管理大规模分布式系统中变得更加高效。” 他继续说道：“目前的 Git 是为开发者和小型团队设计的，但随着大型开源项目和企业级开发的需求增加，Git 在性能和复杂工作流方面仍然存在一定的局限性。未来可能会出现一种更加适应大规模并行开发、全球分布式协作和高度自动化的版本控制系统。” 项目经理点头表示认可：“你说得对，随着开发需求的多样化，Git 也必须不断进化，才能保持其在开发中的核心地位。” 小李也意识到，尽管 Git 强大且灵活，但未来开发模式的变化无疑将推动版本控制系统的发展。基于人工智能和机器学习的自动化工具，可能会为 Git 提供更加智能的版本分析和优化建议，同时帮助开发者快速发现潜在问题，甚至自动修复常见的代码错误。未来的 Git，可能不仅仅是一个代码管理工具，它可能变成一个主动帮助开发者的智能平台。 第四十五章：Git 与云原生技术的结合随着 Kubernetes、Docker 等云原生技术的普及，团队的工作流程和开发环境也发生了巨大的变化。尤其是在微服务架构、容器化和云部署方面，Git 被赋予了新的角色。小李看到了 Git 与云原生技术结合的巨大潜力，开始思考如何将 Git 更好地融入到云原生的开发和部署流程中。 “小李，考虑到我们现在使用的 Kubernetes 和 Docker，如何将 Git 与这些工具结合，以便更好地支持我们在云环境中的开发和部署？” 项目经理提出了新的挑战。 小李微笑着回答：“Git 在云原生开发中的作用将变得越来越重要。它不仅可以用于代码管理和版本控制，还能与 CI/CD 工具和容器化管理平台如 Docker 和 Kubernetes 紧密集成。通过 Git，我们可以管理云原生应用的代码、配置和容器镜像的版本，并通过 Git 的工作流管理持续集成和交付。” “能不能更具体地说说 Git 如何与这些工具集成？” 项目经理继续问。 “当然。我们可以通过 Git 来管理 Kubernetes 的 YAML 配置文件和 Dockerfile，每次提交都会自动更新这些文件并生成新的容器镜像。然后，我们可以将 Git 与 CI/CD 工具（如 Jenkins、GitLab CI 或 CircleCI）集成，让每次代码提交都触发自动化构建、测试和部署流程。当新的容器镜像构建完成后，Kubernetes 可以自动更新集群中的服务，确保所有服务运行的是最新版本的容器。” 小李解释道。 小李随后展示了如何将 Git、Docker 和 Kubernetes 融合在一起。他为团队配置了 GitLab CI，通过 GitLab 的 CI 管道，自动化地将每次提交的代码构建成 Docker 镜像，并将其推送到容器镜像仓库。然后，GitLab CI 会触发 Kubernetes 的滚动更新，将最新的容器镜像部署到集群中。 “这样一来，团队可以通过 Git 统一管理应用代码、容器镜像和配置文件，所有的操作都可以自动化完成，大大提升了开发和部署效率。” 小李补充道。 项目经理非常满意：“通过 Git、Docker 和 Kubernetes 的结合，我们能够实现更高效的开发和部署流程，这样我们的云原生应用管理会变得更加灵活和自动化。” 第四十六章：Git 与人工智能的融合——自动化代码审查小李对 Git 的理解越来越深，他意识到，随着人工智能（AI）的发展，Git 与 AI 的结合将带来革命性的变化，尤其是在代码审查和质量保障方面。人工智能的智能化算法可以帮助自动化审查每次提交的代码，检测潜在的 bug、代码风格问题、甚至安全漏洞，从而进一步提高开发效率和代码质量。 “小李，你提到过 Git 可以与人工智能结合，我非常感兴趣。你认为 Git 和 AI 会如何结合呢？” 项目经理问道。 小李兴奋地回答：“未来 Git 可以与 AI 技术结合，自动化地分析每次提交的代码并提供反馈。比如，AI 可以通过机器学习算法分析代码的历史版本，识别出常见的代码问题、低效的代码结构和潜在的安全漏洞。每当开发者提交代码时，AI 会自动进行审查，甚至给出优化建议，帮助开发者提高代码质量。” 他继续解释：“AI 还可以根据项目的代码库和历史记录学习最佳实践，为每次提交提供个性化的建议。此外，AI 还可以通过分析大量的开源项目，帮助开发者学习其他项目的代码风格和技术实现，优化自己的代码。” 小李展示了如何将 Git 与 AI 集成，利用 GitHub Actions 和第三方 AI 插件，自动对每次提交的代码进行静态分析，检测潜在的 bug 和性能瓶颈。通过这种方式，开发者可以在代码提交之前获得实时的反馈，大大减少了错误的发生，并提高了代码的质量。 项目经理听后非常赞赏：“这个方案非常前沿，未来的 Git 不仅仅是一个版本控制工具，它还能成为智能的代码审查助手，主动帮助开发者提升代码质量。” 第四十七章：Git 与团队文化的深度融合随着时间的推移，Git 不仅仅作为一个技术工具融入了团队的开发流程，也深刻影响了团队的文化。通过 Git，团队逐渐形成了一种透明、开放、协作的文化，所有的代码变更都能被追溯，团队成员之间的沟通变得更加顺畅。 “小李，最近我发现团队成员之间的沟通和协作变得更加高效了，大家在提交代码时，都在 commit message 中写得很清楚，代码审查时也能快速理解每个提交的目的和实现。” 项目经理总结道。 小李点头表示同意：“是的，Git 让我们的团队更透明。每个提交记录不仅仅是对代码的记录，也是对开发过程的记录。通过清晰的提交信息和 Pull Request，我们能够看到每个开发者的工作进展和思路，及时发现并解决问题。” 项目经理继续说道：“而且，Git 让我们保持了高效的协作，每个人都能在自己的分支上独立开发，只有经过审查和确认后，才会合并到主分支。这样我们不仅能保证代码质量，也避免了直接推送到主分支可能带来的风险。” 小李感慨道：“Git 让我们建立了一个高效、透明的开发文化，不仅提高了工作效率，还增强了团队之间的信任和合作。” 第四十八章：Git 与创新的结合——开源贡献与全球合作随着团队项目的不断发展，小李的思维也逐渐扩展到全球开源社区的协作。在一次技术分享会上，项目经理提到了一个新的发展方向：“小李，我们是否可以将我们的部分技术栈或工具开源，贡献给全球开发者社区，获得更多的反馈和贡献？” 小李顿时眼前一亮：“开源是一个很好的方式，可以通过全球社区的力量推动项目进步。同时，Git 本身就是开源的，已经深深融入了全球开发者的工作流。我们可以通过 GitHub 或 GitLab 等平台将我们的项目开源，让更多的人参与进来。” “你说得对，开源不仅能促进技术创新，还能让我们获得来自全球的反馈。” 项目经理笑道，“那我们开始考虑如何将我们的项目开源吧。” 小李开始探索如何将团队开发的工具和库开源，并通过 Git 管理开源项目。首先，他为项目创建了一个 GitHub 仓库，并在仓库中提供了详细的文档、安装指南、功能说明等内容。接着，他将项目代码整理好，确保它能与其他开发者无缝集成。 在开源项目的管理过程中，小李使用 Git 的 Pull Request 工作流来管理外部贡献。当其他开发者提出修改或优化时，团队通过审查 Pull Request 来评估贡献质量，最终合并到主仓库中。这种流程帮助团队高效管理外部的贡献，同时确保代码质量和稳定性。 “小李，看到这些来自全球开发者的贡献，我们不仅提高了工具的质量，也扩大了团队的影响力。” 项目经理感叹道，“通过 Git 和开源，我们实现了全球范围的技术合作。” 小李也感到无比兴奋，他知道开源不仅是对技术的贡献，更是一种全球化的合作方式。通过 Git 管理的开源项目，他与全球开发者共同推动了技术的进步。 第四十九章：Git 与 DevOps 2.0——智能化运维与持续交付在一次团队会议中，随着 DevOps 实践的深入，小李意识到，随着自动化、人工智能和机器学习的引入，DevOps 也逐渐进入了智能化的新阶段。团队在原有的 CI/CD 管道上进一步优化，加入了智能化运维和持续交付（Continuous Delivery，CD）的理念。 “小李，现在我们已经将 CI/CD 集成到项目中，但如何进一步优化并提高运维的智能化水平呢？” 项目经理问道。 小李思索了一下，回答道：“我认为，我们可以通过将 AI 和机器学习引入到 DevOps 流程中，提升运维和发布的智能化水平。Git 可以与这些新技术结合，通过持续监控、数据分析和预测算法，帮助团队提前发现潜在的问题，甚至自动执行修复。” 他继续解释：“例如，我们可以通过 Git 与机器学习模型的结合，分析每次提交的代码，预测可能的性能瓶颈或代码错误。根据这些预测，CI/CD 管道可以提前生成优化建议，甚至自动修复代码中的常见问题。” 项目经理对这个思路非常感兴趣：“这个方向非常有前景。Git 不仅仅是管理版本的工具，未来它还可能成为我们 DevOps 2.0 中智能化运维的一部分。” 小李开始着手实现这一方案。他集成了 Git、Jenkins 和 AI 模型，通过分析每次提交的代码，预测潜在的性能问题和安全漏洞，并将预测结果通过 Git 提交记录反馈给开发者。当 Git 检测到潜在问题时，自动发出警告，并触发自动化修复任务。 “通过 Git 与 AI 的结合，我们的 DevOps 2.0 管道变得更加智能化，能够自动监控、分析和修复代码中的问题，减少了人工干预。” 小李兴奋地说道。 项目经理也非常满意：“这不仅能提高开发效率，还能让我们更早地发现并解决问题，减少了运维的负担。” 第五十章：Git 与自动化测试的无缝对接随着团队对自动化的需求增加，团队决定将自动化测试与 Git 完全集成，确保每次提交和部署都能通过自动化测试来保障代码质量。在过去的项目中，虽然有一些自动化测试，但由于没有与 Git 紧密结合，很多时候测试结果无法及时反馈给开发者，导致修复过程缓慢。 “小李，我们希望能够将自动化测试与 Git 完美集成，实现每次提交后自动执行单元测试，并将测试结果即时反馈给开发者。” 项目经理提出了新的需求。 “这个方案完全可以实现。” 小李回答道，“通过 Git 与 CI 工具的结合，我们可以在每次代码提交后自动触发测试脚本，确保代码的质量不受影响。同时，我们还可以将测试结果实时显示在 GitHub 或 GitLab 上，开发者可以第一时间看到自己的提交是否通过了测试。” 于是，小李开始配置 Git 与 Jenkins 和 Selenium 的集成。每次团队成员向 Git 提交代码时，Jenkins 会自动拉取代码并执行自动化测试，确保每个功能模块都经过严格的测试。测试结果会通过邮件或 Git 的通知功能反馈给开发者，确保开发者能及时修复问题。 “小李，这样一来，我们就能确保每次提交的代码都经过了自动化测试，不仅提高了代码质量，还能加快开发进程。” 项目经理满意地说道。 小李也意识到，Git 与自动化测试的结合将使开发流程更加高效和安全，减少了因人为错误或疏忽导致的问题。 第五十一章：Git 与云平台的深度集成随着公司逐渐迁移到云平台进行开发和部署，云平台成为了小李和团队工作流程中的重要部分。如何将 Git 与云平台无缝结合，成为了小李在这一阶段的新挑战。 “小李，我们已经在使用 AWS 和 Azure 进行开发和部署，但如何将 Git 与云平台更好地结合，形成一个高效的开发和部署流程？” 项目经理问道。 “我们可以通过 Git 与云平台的 DevOps 工具集成，来实现自动化构建、部署和监控。” 小李回答道，“例如，通过将 Git 与 AWS CodePipeline 或 Azure DevOps 集成，每次代码提交后，Git 会自动触发云平台的构建和部署流程。我们还可以通过云平台的监控工具实时获取应用的运行状态，确保代码始终在稳定的环境中运行。” 小李帮助团队配置了 AWS CodePipeline，并通过 GitHub 集成了自动构建和部署流程。每当团队成员提交代码时，AWS CodePipeline 会自动拉取代码、构建应用并部署到 AWS 上进行运行。通过云平台的监控工具，团队可以实时查看应用的健康状态，确保应用的稳定性。 “通过 Git 与云平台的集成，我们能够将开发和部署完全自动化，不仅减少了人工操作，还能实时监控应用的状态。” 小李总结道。 项目经理对这个集成方案表示高度满意：“这大大提高了我们团队的开发和部署效率，也让我们在云平台上的管理更加便捷。” 第五十二章：：Git——开发者永不止步的伙伴回顾这些年，小李的 Git 旅程不仅仅是一个技术学习的过程，它已经深刻地影响了团队的工作方式，推动了团队从传统开发模式走向 DevOps、AI 和云原生的未来。Git 不仅仅是一个版本控制工具，它已经演化为开发流程的核心，融入了团队的文化和协作方式。 “小李，你的努力让我们的团队在技术上不断创新，从自动化测试到云平台集成，Git 在我们的开发流程中扮演了越来越重要的角色。” 项目经理感慨道。 “Git 是我职业生涯中最重要的伙伴，它让我从一个新手开发者成长为今天的技术专家。未来我会继续学习，继续进步。” 小李自信地回答。 无论技术如何进化，Git 都将继续成为开发者的重要工具，帮助他们管理代码、提升协作效率、自动化工作流程。随着时代的变化，Git 也将继续为开发者提供强大的支持，成为他们永不止步的伙伴。","link":"/posts/fa9f211a/"},{"title":"快速启动 http 站点","text":"以下是 Python 内置 HTTP 服务器的几种常用启动方式： 默认端口启动（8000）： 1python -m http.server 指定端口启动（示例使用 1378 端口）： 1python -m http.server 1378 支持 IPv6 的启动方式： 1python -m http.server 1378 --bind :: 这些命令会在当前目录启动一个简单的 HTTP 文件服务器，方便快速共享文件或测试网页。","link":"/posts/572b7187/"},{"title":"通过 SMTP 使用 163 邮箱发送邮件","text":"这里的 授权码（Authorization Code） 是 163 邮箱（以及 QQ 邮箱等国内常见邮箱服务商）专门为 SMTP/POP3/IMAP 等邮件协议提供的独立密码，与邮箱的登录密码不同。 作用：用于通过第三方客户端（如 Python 的 smtplib）发送邮件，避免直接暴露邮箱登录密码。 获取方式（以 163 邮箱为例）： 登录 163 邮箱。 进入 设置 → POP3/SMTP/IMAP。 开启 SMTP 服务，系统会提示你设置授权码（类似 ABCDEFG123456，不是你的登录密码）。 复制这个授权码，替换代码中的 your_authorization_code。 123456789101112131415161718192021222324252627282930313233343536373839import smtplibfrom email.mime.multipart import MIMEMultipartfrom email.mime.text import MIMETextfrom email.mime.application import MIMEApplicationdef send_163_email(): # 163邮箱SMTP配置 smtp_server = &quot;smtp.163.com&quot; smtp_port = 465 # SSL加密端口 sender = &quot;your_username@163.com&quot; # 你的163邮箱 password = &quot;ABCDEFG123456&quot; # 替换为你的SMTP授权码（不是登录密码！） receiver = &quot;recipient@example.com&quot; # 收件人邮箱 # 创建邮件 msg = MIMEMultipart() msg['From'] = sender msg['To'] = receiver msg['Subject'] = &quot;测试邮件（带Markdown附件）&quot; # 邮件正文 msg.attach(MIMEText(&quot;这是邮件正文，附件是Markdown文件。&quot;, 'plain', 'utf-8')) # 添加Markdown附件 markdown_content = &quot;# CSDN文章汇总\\n| 标题 | 链接 |\\n|------|------|\\n| [Python教程] | https://example.com |&quot; attachment = MIMEApplication(markdown_content.encode('utf-8'), Name=&quot;articles.md&quot;) attachment['Content-Disposition'] = 'attachment; filename=&quot;articles.md&quot;' msg.attach(attachment) # 发送邮件 try: with smtplib.SMTP_SSL(smtp_server, smtp_port) as server: server.login(sender, password) server.sendmail(sender, receiver, msg.as_string()) print(&quot;邮件发送成功！&quot;) except Exception as e: print(f&quot;发送失败: {e}&quot;)if __name__ == &quot;__main__&quot;: send_163_email()","link":"/posts/5dfd4b8a/"},{"title":"Home Assistant 实现米家设备接入 HomeKit，圆梦苹果全家桶","text":"最近终于把软路由搞定，群晖上也顺利安装好了 Docker，于是立马安排上迟到了好几年的 Home Assistant（简称 HA）。这篇文章就分享一下如何用 HA 把米家设备接入 Apple 的 HomeKit，真正实现“苹果家庭全自动”的梦想！ Step 1：用 Docker 部署 Home Assistant先直接上命令。建议使用 host 网络模式，不然后面 iPhone 添加 HomeKit 的时候经常找不到设备。 1sudo docker run -d --name=&quot;home-assistants&quot; --net=host homeassistant/home-assistant 小提示：我图省事没做目录映射，但大家正式部署还是建议把 config 映射出来，便于备份和迁移。 启动完成后，默认监听在 8123 端口。浏览器访问 http://群晖IP:8123 即可进入 HA 初始界面。 Step 2：初次配置 Home Assistant第一次访问会提示你创建账户。 接着可以选择你的地理位置，后面用于推送天气等信息。 Step 3：安装米家插件，让 HA 支持 Xiaomi 生态参考的是小米官方的 Home Assistant 插件项目： 🔗 项目地址：https://github.com/XiaoMi/ha_xiaomi_home 先进入 HA 容器内部，然后安装插件。 1234cd configgit clone https://github.com/XiaoMi/ha_xiaomi_home.gitcd ha_xiaomi_home./install.sh /config 完成后重启 HA 容器，重新登录到 UI 界面。 点击左下角“设置” → “设备与服务”，进入集成页面： 点击“添加集成”，选择 Xiaomi Home： 会先看到免责声明，点继续。 Step 4：通过 OAuth 登录小米账号插件采用 OAuth 登录小米账号，这一步会打开小米官方的登录授权页面。 登录成功后返回回调地址： ⚠️ 注意：默认回调地址是 http://homeassistant.local，很多时候解析不了。可以手动把浏览器地址栏改成 http://你的HA局域网IP:8123，再回车，就能完成回调流程。 成功登录后会同步你米家账号下所有的设备： 数量感人！ Step 5：添加 HomeKit 支持进入“设置” → “设备与服务”，右下角点击“添加集成”，选择 HomeKit： 接着选择 HomeKit Bridge： 添加完成后左侧会出现一个 HomeKit 的二维码，使用 iPhone 上的“家庭”App 扫码配对即可。 添加过程中，如果出现以下提示，说明网络设置有问题，大概率是 HomeKit 无法找到设备。 Step 6：排查 HomeKit 配对失败的问题如果 iPhone 迟迟找不到 Home Assistant 设备，务必检查网络配置： 进入“设置” → “系统” → “网络”，找到 HA 的网络适配器； 确保它和你手机所在的 Wi-Fi 是在同一个网段； 如果是 Docker + 群晖用户，确保容器是 host 网络模式； 没看到网卡配置？记得开启高级选项！ 左下角点击头像，开启高级： 没开高级的话是这样的： Step 7：设备全部导入 HomeKit！终于圆梦！所有米家设备都顺利接入了 HomeKit，iPhone 上可以直接语音控制开灯、调温度，真正体验到苹果生态下的丝滑体验。 尾巴从部署 HA 到米家设备接入，再到 HomeKit 配对，中间有点小坑，但整体体验还是很不错的。如果你也想让米家秒变 HomeKit 原生设备，不妨试试这个方法。让智能家居真正融入 iOS 生态，丝滑又稳定！","link":"/posts/aec4a8fe/"},{"title":"NFC复制卡写手机手环","text":"手机无法复制加密的 IC 卡,所以需要需要额外的方法来进行写入 读原来的卡 仅复制卡号 创建空白卡 仅复制卡片卡号 写入数据接下来就是把手机/手环放在机器进行写入 添加成功 参考资料NFC-PRO 至尊双频版操作说明读写卡操作视频:https://cloud.video.taobao.com/play/u/null/p/1/e/6/t/1/409421501065.mp4加密卡手机手环模拟操作视频:https://cloud.video.taobao.com/play/u/null/p/1/e/6/t/1/409017352153.mp4","link":"/posts/5ce15c7a/"},{"title":"“智能”家居相伴的日子","text":"你是程序员吧，我家电脑有点慢，网络有点卡，帮我看一下吧。” 尽管网上关于程序员修电脑的段子已经层出不穷了，似乎大多数人也不再吐槽程序员修电脑这个事情。事实上，不管走到哪里都总会有人找我修电器，从广告 LED 屏幕，电子秤，再到手机电脑，电视盒子，最后到路由器。所以当别人问我大学读的什么专业，我干脆回答修家电的。 我似乎已经形成了习惯，不管走到哪里都要准备一套趁手的设备：螺丝刀套装，钳子，万用表和绝缘胶带，准备了这些电工和网工必备的工具来提升维修的效率，至于网线钳实在是太累手，已经抛弃不用了。 这几年 NAS 的成品百花齐放，有对爱好者入门很友好的群晖，有适合更加专业一些的威联通，甚至于联想和绿联这样的商家也纷纷推出成品来降低使用者的门槛。其实驱动着自建 NAS 的爱好者不断折腾不过以下几个原因，网盘限速，限制文件大小，还有各种网盘的不定时监控。在我自从被用百度网盘被莫名限制文件下载之后，便开始了在家里自建数据中心的想法，这样就可以不受拘束自由的下载和分享文件。实施下来除了晚上各种网线灯和电源灯的光污染之外，其他方面提升了很高的幸福指数，上传下载可以跑满家里的千兆内网，也可以分享体积大于 5GB 的单个文件，至于存储空间就取决于钞能力了，也希望早日能够实现家庭百 T 存储的梦想。 一开始由于资金的原因，我打算在 Centos7 上自己部署一些开源服务，但是鸟哥私房菜实在太厚啃不动，加之后期的维护成本巨大，每个服务维护起来都要敲指令。后来我索性花重金买了 QNAP 当红机器，同时也不定时和同学柜子里的黑群晖在做着异地同步。在这一切准备完毕后，我找到了联通公司要了动态公网 IP 地址，结束了与内网穿透的相爱相杀的艰难的日子，同时利用闲置域名设置了一套动态域名解析，用手机随时随地连回家里的服务。唯一遗憾的是回老家是用树莓派做的网页监控也经常被运营商封掉，后来从群友处得知 80/8080/443 这几个端口不能使用，联通客服只能从后台看见网络状态，其他的超出了支持范围，同时也驳回了我想去找网警咨询的要求。 后来了我解到，如果是在家里建站好像是要和公安部门申请的，走一个类似备案的流程。而联通的上传带宽只有 30MBPS，似乎满足不了随时连回家观影 4K 电影的需求。在极客心的驱使下我走上了单宽带叠加的路程，使用家里 200M 的宽带同时拨号三次可以达到 550M 的网速，再后来趁着活动免费提升到了 500M，单线多播这才告一段落。但是搬家到北京之后，出租房的网络太差并且带宽只有 100M，在因为网络不稳和在经历了无数次和运营商以及二级运营商的扯皮后，只能选择额外加上一个其他运营商的线路，京东下单了小米 AX5400 路由器，在上边设置了一个双宽带叠加。相对而言没有软路由那么自由，硬路由的叠加只能是不同的运营商的宽带，比如移动和联通。而且运算速度也不如 X86 架构的软路由，优点是 NAT 性能很好。所以还是推荐软路由加上个普通路由做个 AP。 经过群友不完全统计，有些地区的运行商很大方会直接给公网 IP，有些地方运营商政策不一，需要等一定的时间，然后手动更改为路由器拨号。还有一些运营商甚至明码标价，公网 IP 每月固定收费，这个典型的代表就是北京移动。 解决了存储问题后，下一个面对的问题是网络。我想到很多国外的设备仍然需要连接海外的服务器进行激活，比如 Oculus 的 VR 眼镜，包括 Google Pixel 在内的原生安卓，这些都需要在连接海外服务器的情况下激活，这样的功能默认在国内是无法使用的。所以我想玩的痛快游一些，于是便在路由器的上挂一层代理，这样电脑手机都不用安装专门的客户端了，甚至连 kindle 都可以愉快的科学上网了。我折腾了下面三种： X86 平台的工控机 这种产品现在已经成为产业链了，主要供货渠道来是各个平台短视频平台的科技 UP 主，基本上是一次购买终身答疑的制度，还有对应售后的微信群以及用于下载资料和固件的博客网站。对于小白用户，大概要熟悉一周左右，需要安装 EXSI 和两个路由器系统虚拟机，其中一个是国产路由器操作系统 IKUAI，另一个是大名鼎鼎的 Openwrt。再把网卡直通（类似 EC2 的增强联网）。IKUAI 的系统是免费的，也可以在这里安装虚拟机安装 openwrt，当然禁止套娃。Openwrt 在 Github 上有源代码和 release 文件，也有开源的编译方法。这里有个小插曲： a) 我装系统一直用的 ventory，出现安装之后无法启动的错误，给技术支持打电话之后，的工程师表示镜像没有问题，换了刻录镜像的方式之后可以安装。后来调查应该是 ventory 的支持不好。 b) 用自己的四核笔记本电脑编译 OP 源码，几个小时 CPU 一直满载，风扇噪音比冰箱制冷的声音还要大。（我的冰箱因为压缩机问题本身噪音就很大，妥妥的人工噪音） 普通路由器降级再刷官改固件 实习的时候部门老大过来跟我闲聊，他说把家里的 AC86U 刷了梅林固件，后来因为信号问题影响孩子写作业又刷回原厂固件了。梅林固件我是用的斐讯 K3 刷的，江湖人称漏油机，好像是因为散热的硅脂不太行，只要加热就会有油析出，拆开之后散热器上是油和灰尘的混合体（画面太美就不放了，想看可以移步朋友圈）。而且斐讯的其他产品也可以随便刷机，我把两个 K2 分别刷了 openwrt 和Padavan的系统，N1 和 T1 都刷成了安卓电视盒子，其中个人觉得 T1 作为影音系统的效果更好一些。不过 N1 还可以刷成 openwrt 制作旁路由。 旁路由 我的网络理论知识不太行，虽然不懂原理，但是按照提示把主旁路由设置为相互的网关之后，屋内的设备就能愉快的上网了。这样流量每次都会在旁路由上转一圈，然后能做的事情就更多了。 当然言归正传，折腾完之后还是有一定的维护的成本，这一套部署下来家里感觉变成了一个 KTV，24 小时的噪音和灯光污染，软路由的网线口已经基本插满，家里每晚都闪烁着黄绿交替的灯。当然是黄灯闪烁，绿灯常亮。在一次在通电的情况下拔掉系统盘导致了磁盘坏块，如下图，数据丢失，虚拟化需要手动操作，然后上面的流程又需要重新开始。 虽然大多数折腾的产品都很耗费时间精力，不过还是极大的方便了我的生活。在有了外网环境之后，下一个要折腾的就是原生安卓系统了。 我是四年的米粉换了 Iphone，还要从小米 8 刷原生安卓开始，来叙述这一段爱恨情愁。。。。。。 我在换了苹果全家桶之后，有种整个世界都安静的感觉，不用经常清理内存，也不必忍受普铺天盖地的广告。相信对于大多数爱好者来说，折腾安卓刷机的那个年代还是还留下了很多美好的回忆。对我来说，一切都是从高一那阵给同学手机刷机救砖开始，同学在手机 root 之后删除了系统关键文件导致无法开机。于是我一直花费整个晚上去找适配 Android2.3.5 的 ROM 包，到后来也会尝试用一些软件破解手机锁屏密码，比如爱思助手，奇兔刷机之类的。直到最近几年，国内各大安卓厂商技术已经相对成熟，刷机精灵也早已倒闭，在安卓系统开始变得封闭的那段时间里，我渐渐忘记了安卓刷机的事情。直到有一天，我手里的小米 8 在过保后经常屏幕反复黑屏，系统变卡之后，我终于忍无可忍重操旧业。正巧了解到有个关于原生安卓的开源项目” MoKee“，这个刷机步骤和以前大同小异。如果是品牌手机需要把系统降级到开发版，然后刷入 TWRP（也就是以前的Recovery），最后双清卡刷 ROM 包。由于我在家里已经安装好了软路由，激活时候完全不用担心连接国外服务器延迟卡顿的问题。终于在刷机完成后，我的小米 8 好似复活了一般，清爽的没有广告，和三星相似的 UI，再装上 Google 三件套，我仿佛嗅到了自由的味道。 然而好景不长，大概半年以后，原生安卓的系统出现了和国内硬件水土不服的问题，经常发生内存爆满，应用卡顿，需要多次手动释放内存才能正常使用，而且还有很多本地化的功能无法使用，比如 NFC 门禁，小米公交钱包。而我在因为手机卡顿无法刷码差点被赶下公交车后，便开始尝试其他社区的官改包了，所谓官改包就是在官方的包上剔除广告和预装应用，然后再加上一些提升效率的小工具。我找了一个人气还行的 ROM，不过在刷机期间发生了一点点误操作，安卓不小心被刷成变砖头了，还是出现了熟悉的兔子界面，玩笑一语成谶。而对于小米来说，官方从根源上解决了用户自己救砖的问题，用户使用自己的设备刷机还需要官方的授权密码，而维修店的刷机设备则不需要。我在和小米官方售后交涉了小半年之后，终于在用 9008 免密刷机的方式刷回了最新版的小米安卓系统。还真是应了群友的话，愿你刷机半生，最后 MIUI 养老。 在分享过这个经历之后，便有朋友过来向我请教把手机刷成砖头的”秘诀”了。 除此之外，闲来无事翻出来一个闲置的 36W 的三色 LED 灯，我起初想本着废物利用的原则，然后又买了一段 220V 的开关延长线，淘宝了买羊皮纸做了个简单的照明灯壳子，也用了闲置的米家智能插座。 对于 IOS 设备来说还可以和 Siri 进行联动，只需要在快捷方式里加上一个唤醒米家设备的设置，最后用 HomePodMini 唤醒智能设备，唯一美中不足的是京东海淘的音响的是英版的插座，需要买额外的转换插头，如果用多口氮化镓的话会还重新分配工功率影响使用。此外 HomePod 还可以作为屋子里所有 Apple 设备的音响，无论你是 MacOS, Ipad 还是 iphone 都可以无缝连接，HomePodMini 是名副其实的 WIFI 音响，你值得拥有。 除了电子设备之外，生活总会有些突如其来的小插曲，比如洗衣机坏了，面板报错 E3，朋友在电话里告诉我盖子传感器有问题，开微信视频指导我修，怎么拆盖子和电路板。我在和厂家确认过维修价格之后，便驳回了房东给的报销，还是自己拆更放心些，洗衣机报错盖子盖不严，拆机后发现传感器生锈了，最后使用了 320 目砂纸打磨搞定。一段时间过后，在某读书群认识一个同样修过洗衣机的姑娘，跟我讲如何给家里更换洗衣机电路板。顺便还晒了一波男朋友给的全家桶 – R2S，Pixel 加上 Google 三件套。她也给男朋友订阅了 Jetbrains 全家桶。 我甚至有个大胆的想法，希望以后传统家电的厂家可以暴露给用户一些接口，让用户写代码或者使用图形拖拽的方式来对品牌家电进行互联，等以后有了房子后搞一套 HomeKit 智能家居，下图是我现在用到的智能家居的 app，给各大厂商定一个小目标，就希望有一天可以互相整合开放 SDK 吧。","link":"/posts/49e53210/"},{"title":"便携显示器","text":"宣传是这样的： 到手是这样的 画质确实很清晰","link":"/posts/3badab23/"},{"title":"大上墨水屏测评","text":"更新 ing… 最早接触墨水屏显示器，是前年在北京的 SKP。最早用过 kindle，那时候去看文石的产品。正巧看到了墨水屏显示器，在店里试用了下很喜欢。相对于很古早的 kindle 而言，我们更需要本地化的东西。比如彩色版，或者看视频，起码在大上的墨水屏上都能够使用了。 对于墨水屏来说，我是买账的。在店里也能用他们的样机看一些 demo 视频，虽然没有 LCD 流畅，但是已经是能看的水准了。毕竟很早以前的 kindle，连翻页都觉得卡。这些日子挺喜欢用墨水屏来看游戏王的，虽然是日漫，但是开了视频模式，感觉像是漫画一样。 我拿到的机器是 Mac 版本，所以需要先做特殊的配置。革命者系列自带了一个 HDMI，TYEPC 的线，还有一根 USB-A 转 USB-B 的线。USB 的线是用和驱动软件通讯的。 这里有两个槽点: Typec 只用用来传输数据，并不能给 Macbook 供电。 Macbook 或者 Macmini 都没用 USB-A 的接口了，所以这个线还要转接一下。 言归正传，介绍外观。25.3 寸的屏幕使用起来没有比我的 28 寸显示器体感少太多。机身十分简洁，只有左下角有六个按键，分别对应： C: 刷新《》 M：调整模式 剩下就是对比度调节和亮度调节，以及开关机按钮。 大大的按键，按压起来软软的。使用起来十分方便。没有花里胡哨的功能菜单，更像是大人的玩具。 熄屏的时候，会显示以前的电视没信号那种图标。如果晚上在昏暗的灯光下的话，还真有点吓人。 屏幕有背光灯，所以晚上使用的时候不用担心光源的问题。如果不连接电脑的话，晚上就不会触发这个。 然后再说说这几种模式， 我最喜欢的时候文本模式，其次是视频模式。文本模式用来看电子书，就是最古早的 Kindle 那种看电子书的感觉，白纸黑字的感觉最好了。这个模式也能用来刷网课，比如一些理论公式什么的，效果竟然比视频模式要好的多。 视频模式主要用来刷剧，比如前面提到的看游戏王。竟然有漫画的感觉 ， 在不同模式之间切换需要调节合适的亮度和对比度。比如黑色的场景就把对比度调亮一些。 刷新率能够达到宣传的33HZ，尽管和LCD显示器相比在窗口拖拽方面还是有较大的拖影，但是在文字阅读和日常上网方面已经几乎可以当作主力设备来使用了，比如买一个Macmini，然后外接这样一个显示器。（前提是得解决Paperlike客户端开机自启动的问题） 在拓展屏的模式下ufotest有这个报错，在把墨水屏设置为主显示器之后可以正常显示了。 12ufotest SYNC FAILURE:Move all apps and browser windows to primary monitor #1. 背景尽量纯色。 再来说残影 我想到一个场景 Macmini + 墨水屏。老人看小说或者，。 墨水屏用着用着就会困。 HiDPI 虽然不能开满分辨率，但是比带鱼屏效果好很多。之前三星 3.5K 带鱼屏外接简直不能看，720P 的 HIDPI，网页都会被截掉半截。 因为这个事，我还特意调查了分辨率以及 PPI 对 MacOS 外接的影响。大上外接几乎没啥违和的地方，屏幕分辨率也不是 4K。PPI 需要算一下。 墨水屏写作，多了一份静心。让我们远离蓝光的辐射。 不管是作为博主输出文字，还是","link":"/posts/2fca5ee8/"},{"title":"出远门带的电子产品","text":"MacBook/ipad/iphone/nuc12/鼠标/耳机 Gan/移动电源/type C 电源 NFC 复制器+空白卡","link":"/posts/3205bf5/"},{"title":"家居常用软件","text":"中兴路由器测速的软件 speedtest 和中科大测速有时候抽风，中兴自带的还不错 手机也可以使用全球网测， 安卓使用花瓣测速","link":"/posts/73f93987/"},{"title":"工作台改造","text":"办公无线打印扫描一体机 照片打印机实木电动升降号桌4K 显示器要带菊花链 墨水屏显示器移动固态人体工学椅降噪耳机现在有 airpod pro2， qc45，华强北 airpod Mesh 路由屏幕挂灯随身 WIFI娱乐4K 投影仪吊椅地投幕布 生活即热饮吧自动烘干机全自动扫地机器人可以自己换水自己换垃圾那种 自动拉窗帘家庭中枢 HomePod * 3全屋智能家居定制智能门锁智能猫眼家里要布置的电子设备电脑设备4415U 缝缝补补还能再战三年 网络10G 内网24 口交换机机柜现在的设备 乐歌自动升降桌 E6—HD 双 4K 显示器(philip，samsung) NUC8 黑苹果(双系统，内存 64G) Ipad air5(apple pencil2 + magic board) 无线打印机(Lenovo M7400 Pro 改) 键鼠(Ikbc，logtech) 耳机(Bose QC 45，Airpod pro 2) 小米路由器 AX3000 山特 UPS NAS(QNAP 453Dmini， 内存 64G) EXSI 双软路由(ikuai + openwrt) 小米台灯 PRO 公牛插座 6 排 * 2 绿联 Gan 100W 8K typec 视频线 apple magsafe","link":"/posts/baed0386/"},{"title":"TrackWeight, 把 Macbook 的触控板当作电子秤","text":"大数据推送的，地址在这里 https://github.com/KrishKrosh/TrackWeight/ 最新的 release 打开一开始是这样， 然后给作者留言，修复了 MacOS13 上不能运行的问题。（不到 10 分钟作者就改好了 release） 这个程序需要手指始终触摸板，然后一开始需要校准。 校准之后就可以放置物品了。 除了手有点抖之外，总体还不错。 这个页面也很好看，","link":"/posts/10473fce/"},{"title":"普通人需要哪些电脑知识？","text":"作为一个 N 多年的电脑社畜，日常使用 window/Linux/MacOS 三系统，写点最近被问到的问题。 请问您觉得有什么我们普通人可以尝试的一些电脑软件方面的操作呢，这些前沿的知识蛮重要，一般人很难知道 🌹 装机，如果追求不多，弄个装系统的 U 盘就行，Windows 安装有手就行。不折腾就用微 PE 工具箱，需要 Linux 共存就用 Ventoy。然后再能换个内存和硬盘就更好了。我习惯于买小配置然后自己升级，当然土豪随意。手不残党还可以上网搜一搜自己换个笔记本屏幕。 安装软件。远离 360 全家桶，xx 大师，xx 精灵，这些不止流氓，还会带一堆的捆绑软件。杀毒软件就用火绒，或者干脆不装大多数情况也没啥事。还有就是再垃圾软件篡改主页之后再改回来，以及更换浏览器的搜索引擎。 分清楚快捷方式和安装软件的区别。很多人把快捷方式一删除就不管了，很多年前遇到过一个妹子倒腾半天最后发过来一个快捷方式给我。请掌握正确的卸载方法（比如 windows 的控制面板）。还要分清楚安装版和绿色版区别。大家都是这么过来的，windows 虽然不好用，但是会强迫你看到一堆的技术字眼，比如 DLL 链接库， .net 框架等等。 分清无线和有线，以及怎么查看动态 IP 地址和配置静态地址。这能够解决大部分电脑不能上网的情况。如果能自己接网线就更好了。 分清楚电脑接口，比如视频线的 VGA，HDMI，DP， Typec。数据线的 USB2.0 和 3.0，不管 3.X 后面多少后缀，他也是当年的 USB3.0。手边常备一个数据线转接头，转 HDMI 或者 USB。 买电脑买新不买旧，不要为了省钱而受罪。配置太低的可能刷网页，写文档都卡。不需要频繁更新系统。 U 盘不要买金士顿。 不要找程序员修电脑。很多人不会，会的也懒得修。","link":"/posts/87d5ac58/"},{"title":"工具集锦","text":"工欲善其事必先利其器，所以干活之前要先准备好工具，也就是基础设施一类的东西，对于电工网工而言，就是电气设备网线一类的东西了。 电工必备大概是从自制插排开始，一把 10 元螺丝刀螺丝刀开始，自制插排，换插座吗，就把线接一起就行，没啥难的，注意接的时候断电。 如果你想自己做插排，你可以使用以下步骤：准备材料：你需要一个电缆，一个插头盒，一些电线和电缆接头。切线：按照需要的长度将电缆切为若干段，并分别给每一段线剥去绝缘层，留下裸露的电线。做接头：将裸露的电线与电缆接头相连，并给接头做好绝缘。安装插头：在插头盒中安装电缆接头，并确保每个接头的接触良好。测试：插上插头，确认每个插口都能正常工作。注意：请确保使用适当的工具和安全设备，避免造成危险。如果你不熟悉电器装置，建议请专业人员帮助。 电烙铁手残党哎，一言难尽。忘记留图。以后争取买一把好的电烙铁。 网工以前是因为路由器和电脑网卡不行导致延迟太大，所以需要自己做一段网线，需要买网线钳，水晶头一类的东西。另外顺便把光猫和 NAS 的网线也给换了。 蓝色是自己做的。 如果你想要做网线，你可以使用以下步骤：准备工具：你需要一把剪刀、一台网线剥线器和网线插头（RJ45 插头）。剥线：使用网线剥线器将网线剥去外层的绝缘层，留下八条裸露的线芯。分类：根据网线插头的颜色代码将线芯分为五组，分别是白色、橙色、绿色、蓝色和棕色。排列：排列五组线芯，按照颜色代码将线芯排成一条直线，从左到右依次是白、橙、绿、蓝和棕。对接：将网线插头与网线相连，把排列好的线芯插入网线插头中，直到线芯完全插入插头。测试：使用网络测试仪测试网线的连通性。注意：网线插头的颜色代码有不同的标准，在选择网线插头时请确认使用的是适合你的网线标准。 水晶头剥线钳其实现在的网线都是 B 类的直通线，网线线序 xxx，不够据说现在的交换机都能智能识别线序，从二层这里兼容了双绞线和直通线，当然本人偶尔也有把线序弄错的时候，但是竟然还可以正常传输，这点不得而知。 螺丝刀学生时代买的 10 元螺丝刀用了很多年，遇到其他尺寸也要单买不同的规格，况且买东西经常赠送小螺丝刀什么的，每次换一个地方都要买一个螺丝刀套装，miniso 的 15 元套装也用了很多年。不过入手了电动螺丝刀之后兼职不要太幸福，拆电脑，门锁窗户把手都是分分钟的事。按左边拆螺丝，按右边拧螺丝。","link":"/posts/cf8e3176/"},{"title":"硬件常见的坑","text":"苹果外设 秒控键盘和笔没有平替 有了 homepod 还需要一台手机转发，手机关机指令无效 苹果建议不低于 4K，不然屏幕发糊 键盘 ikbc 有时候锁定 win 按键 [^1] 锁定 Fn+左 win 解锁 Fn+ 右 win(ikbc w200 实测) 电容键盘没电要使用软件给电容充电 NIZ plum 静电容键盘的 alt 和 win 键互换位置: 按住 Fn 和侧面标注有 Win/Mac 的按键 3 秒以上，看到指示灯闪烁就代表成功切换。 typec 一线通 便携显示器可以使用笔记本给屏幕供电，此时显示器作为 hub 大型显示器可以使用显示器给屏幕供电，此时显示器作为 hub c 口 ipad 也可以一线通，此时显示器作为 hub 部分安卓手机可以一线通，此时显示器作为 hub 部分小米手机能充电，能做 hub，不支持视频 显示器不支持给充电 c 宝供电 三星客服说 vesa 壁挂和支架分开的显示器不能升降旋转 大于 65W/90W 以上的机箱不建议 typec 一线通，功率跟不上会关机 typec 用了 Dock 就不能一线通了，因为已经不是全功率了 4K 视频线和屏幕线一般可以混着用 充电线一般是 2.0，4K 线可以 3.0 满速 100W 充电宝和氮化镓 加个设备会重新分配功率 2Wmah 充电宝给电脑只能支持俩小时 不用 apple 自家的充电头，magsafe 最多 10W PC typec 无法充电，MacOS 开机无显示器不进系统 NUC 维奇说白苹果也是没显示器不进系统 typec 无法充电试试退出运输模式 电脑的坑 有些笔记本没有主板电池，内置电池用完了 bios 会恢复出厂设置 标称最大支持 16G/32G 还可以插更多内存 [^1]: IKBC 键盘 Win 键失效的解决办法_NXGG 的博客-CSDN 博客_ikbc windows 键","link":"/posts/6f08b777/"},{"title":"假装南方小土豆,哈尔滨一日游,再也不去了","text":"昨晚开会到 11 点，然后起个大早坐车去哈尔滨，预计的一个半小时实际有了两个小时，换乘地铁到市里再加上吃饭的时间就用了三小时。 在附近找了一个门店挺大的兰州牛肉面，面中规中矩，就是再来到这片区域，距离上一次，已过廿余年。 除了逛商场,还要写吐槽。 餐饮篇性价比很高 早餐兰州牛肉面(美团找的),煮好的时候大叔手抓的香菜,牛肉,配菜,萝卜. 当场跟表示注意卫生问题,只恨自己忘记带 pocket3 午饭特意小红书搜的,刘氏知音酒楼.网上评价很高.差不多锅包肉天花板的感觉.电话预约几乎没怎么排队(高德没找到预约的按钮) 点餐服务员完全听不到,最后连着叫了三次,慢吞吞的回我,点的第一个菜就对不起没有.也没说明白原因.在我点餐过程中倒是很原因和别人聊天,有被冒犯…(菜品还行吧,性价比很不错,锅包肉带着 120 分期待来了,最后只能给到 95 吧,上来的时候外壳发软,不脆,觉得是锅包肉大忌,然后就是调的汁没有挂匀,萝卜啥的少的可怜,有的感觉在吃炸酥肉)。优点是量大味道纯,肉也多,不是靠面糊的技巧来少放肉的那种.对于餐饮的平时,大家都讲当地及格线是北京的天花板. 吐槽篇感觉不缺游客,几乎没什么好态度 Part1:大疆 (商场) 我:pocket3 现在还断货么 对方:没货 我;是不是今年就不会出 pocket4 了 对方:我不知道 我:这个无人机是新品吗 对方:不是 我:这个支持编程么 对方:不支持 不看无人机了,看相机 问:5pro 和 pocket3,拍 vlog 哪个好一点 答:看你场景 我:我知道我还问你??????? 而且在店里走到哪里被跟在哪里,很不舒服 Part2:小米店(商场) 不推销手里哪里好,就说买吧买吧 换个手机 我:我是 Apple 全家桶,有些功能没发用安卓 对方:airdrop 能,只有小米原生支持 我:还有随航和接力呢 对方:airdrop 能,只有小米原生支持 用他自己手机演示,当场翻车,一个文件都过不去 然后看到 iphone 上装了一个小米生态的助手… 问:这不是还需要额外安装软件么,也有很多三方软件能办到啊 答:三方如何如何… (内心 OS):给你讲开源你也不懂啊…. 拿起一台小米手机,解锁屏幕两行 ssl 的 Exception 报错 对方:这个是商场的网不好导致的 ……… Part3:秋林-里道斯总店 由于刚去了秋林感觉可能被忽悠了,然后问一下这个是不是总店 只得到对方的一句,这不写着呢么 又问鲜酿的格瓦斯的规格,又被没好气的,指了个小牌子这写着呢 然后给接饮品的时候,把我这个暂停了跟别人聊天,然后聊完继续接,大姐你这单片机中断学的真好… 挺好喝的,打算邮寄点,但是现场接的没有塑封不确定会不会撒,然后问了一句,得到一句含糊不清的话,人走了 再也没见到过她….. 另一个展柜, 问 :秋林和秋林里道斯什么区别呢? 答:两家公司…. 我知道人多你们忙,没有态度全是质量…… **Part4:**新一百楼下中央大街 问:怎么买马迭尔冰棍 对方手一指,答:那(nei)边 问:都有啥口味的呢? 对方手换个方向一指,答:那(nei)边.自己看 Part5:中央大街 秋林-里道斯分店 鲜酿的格瓦斯没喝够(18 块的饮料,17.5 的冰镇和气) 到中央大街终于看到分店,到档口准备再卖一瓶,又不确定分店品质 大哥自顾自的把白桦树饮料摆在我面前的台子上,正当我以为他要说,喝点啥的话术的时候,然后他走了….. 我赶紧盯着他的店内包邮的牌子问多少钱包邮啊,,,没好气的回答 100 多…. 大哥你这么做有生意么? 想起了之前在北京吃的日料被怼够呛的经历(回去美团找了下评论 倒闭了哈哈哈) 我:帮忙拿双筷子 服务员:等会 我:xxx 菜还没上 服务员:我知(二声)道(拉长音~) 我:有没有哪个位置不吵的 服务员:没有不吵的(斩钉截铁) 差点喷国粹,大哥你东北的吧. 红肠篇高德导航到秋林食品总店,一个小屋子,还没客厅加上厨房大感觉,屋子里就我一个买货的,询问后不提供试吃,遂买了一根感觉味道不对..发干,而且还有黑点点(以前吃的咋没有),一直在 diss 商委 抓了路人(纯路人,交警,司机) 差不多都是当地人 有的推荐秋林总店,秋林商城,商委 路边的广告大屏幕啥的都是秋林里道斯,跟湖北宣传来菜似的. 秋林商城:地下一层,感觉各种小商贩的聚集地,小超市的感觉吧,毕竟挂着秋林的名头,但是红场看着就发红,经验感觉不靠谱…(自己标了伊雅红场)看介绍是创始人的名字 里道斯国际大厦(秋林里道斯):看人数这下应该对了,排的长队都去买散装然后自付两元打包装,说是流动快新鲜些,正常商品包装的几乎没啥人买,两者价格一样的…. 两家都是自己始于 1900.百年老店:口径都是和对方是两家店 商委:炒的太火了,都有肠贩子了,据说需要排队.距离也挺远的,以后有机会再探吧, 交通篇上车的时候用 apple watch 记录地图,下车消耗 290 卡… 地铁也很没素质哎,我去哪里排队然后就有人去哪里插到我前面或者是,占用下车区域..换了两三回 还碎碎念 回去的时候在路边等车，不是什么时候看到小情侣在亲亲我我，啊，这不就是现代的雨霖铃吗，总会升起一种莫名的反感，祝天下有情人终将分手吧。自古以来就没有什么非谁不可，饮食男女，人之大欲。在我这里，竟升起从未有过的陌生感。我会在旁边脑补他们吵架到分手，出轨，以及在原生家庭的冲突下意见不合，然后产生冷漠，偏见，以及厌恶。于是失去理智的歇斯底里，但是又不得不为了下一代继续苟延残喘。又仿佛这一切从未发生过。 客车上写到这昏昏睡去, 梦醒来满脑子都是“刘彰暗弱无能.星夜奇袭成都,庞统百拜”, ”主公,张松是我出卖的.刘彰背信弃义,在主公退军路上设伏杀了你军师,主公这下师出有名了吧“ 回去复盘这一天的糟糕经历, 再也不想去了.都是说来东北东北虎,我今天甚至都不用买门票. 啊,东北虎果然是形容词 不写了……省城都这样,那其他地方得啥样啊….","link":"/posts/32308110/"},{"title":"关于速食我想说的话","text":"Soylent最早接触的速食是 Soylent，准确的说应该是代餐，据说是一个程序员为了节约时间发明创造的产品，他那个时候没有 AIGC 时间都浪费在 debug 上了，所以从吃上来节省时间。无论是学生时代还是在帝都上班的时光里，这款产品的定位始终透露着吃不起的风格，而且国内一直没正规渠道卖过，只能海淘遂放弃。 若饭海外的东西国内总有平替，这个叫做“若饭”，也曾疯狂追捧过，除了是为了腾出时间让老板过上更好的生活，要么就是外边的饭太难吃了。这个花样很多，固体的粉末的，还有其他口味以及能量棒什么的。总结下来就是真的吃不饱，起码两瓶才能保证没有饥饿感（好像也没有饱腹感），号称科学的添加了各种人体所需的营养，可以满足人体的需求。尽管这样，官方对他的定义仍然是建议每周保持几顿正常餐饮。不过在帝都，不吃几条街的馆子那就可惜了，遂放弃。 接下来是几款速食产品，单品不超过一顿饭的成本，按照时间顺序有蔡林记，阿宽，拉面说，牛肉河粉。至于速热米饭和自热锅，本来印象就不好，就不在这里再踩一遍了。 蔡林记京东购入，打折的时候不到 10 元一包，当初也是被公司附近的小馆子逼到只能网上买吃的，公司的饮水机的热水永远也泡不完两碗热干面，个人也不是很喜欢酸豆角，即使每顿两碗，这个能量还是供应不上学习时候的用脑过度。连着吃几天还是会感觉身体营养不良。 阿宽小面味道不错，单价实惠，面皮吃了很上瘾，但是真的没啥能量，肚子饱了但是脑袋反应不过来，不能常吃，后来还是去同学家一口气吃了两三大碗米饭（排骨玉米汤）。 拉面说拉面说似乎是这里最高档的面了，这个是半干半鲜面，一半都需要煮上 6-8 分钟，再用开水冲开里面的料包，所以这个不适合在办公室吃，汤面多一些，拌面少一些。配料应该是速食界的天花板了，但是也抵不住疫情期间每天吃过的厌倦，真的不会再买了。另外狠狠的吐槽下和府捞面，除了宣传的书房里的拉面，其他都是严重掉粉，量上价格贵又难吃系列，貌似现在店里也是这种预知的餐盘，但是卫生问题仍然不能保证，工作人员素质问题有待提高。 五谷道场本来方便面是不应该放在这里的，毕竟非油炸国产之光 个人心中的国产方便面排名： 五谷道场 &gt; 汤达人 &gt; 康师傅 &gt; 其他 五谷道场兰州牛肉面和线下兰州牛肉面味道一模一样，辣子的味道能品尝出大西北的粗犷 牛肉河粉线下 58 一碗的河粉尽管可以免费续面，但是单价还是很贵，于是超市购入一箱火车头河粉，还是面饼+汤料的搭配，只是这个价格赶超拉面说还是让人觉得没有下次了。味道嘛，以后还是去吃线下吧，大不了再多续几碗嘛～ 羊肉泡馍女同事推荐的，山姆超市高档货，味道很浓郁，料包需要开水煮，我这砂锅煮了五六分钟打开看羊肉还有部分红血丝。不过味道不错，比上边同价位越南河粉好上不少。 日清拉面Youtube 刷到了日清拉面创始人的故事，所以直接上网买了一堆，不过都没有青菜包，图片的肉片也是没有的，感觉还是拉王比较好吃，泡开了之后看起来很像日式拉面而是方便面，其他的泡开的和方便面没差。鸡汤拉面也很惊艳，用开水冲泡开就能直接收获一碗鸡汤面，生的面渣还能当作干脆面吃。出前一丁是日清的子品牌，其他都是杯面（基本上都是合味道），因为吃不饱就没有买。 这个就是日清拉王泡开的效果了，基本上看不出是方便面，再加上空气炸锅烤的鸡蛋简直完美～ 总结价格上真的不值得，营养也不见得跟得上，还是好好吃饭吧～","link":"/posts/404bc04b/"},{"title":"几个获取公网IP的网站","text":"如果你固定了公网IP，那么这几个结果都是一样的，如果你是二级运营商，那么可能出口IP不一样，需要向运营商索要动态公网IP。 speedtest： https://api-v3.speedtest.cn/ip 12345678910111213141516{&quot;code&quot;: 0,&quot;data&quot;: {&quot;country&quot;: &quot;中国&quot;,&quot;province&quot;: &quot;北京&quot;,&quot;city&quot;: &quot;北京&quot;,&quot;district&quot;: &quot;朝阳区&quot;,&quot;isp&quot;: &quot;中国联通&quot;,&quot;lon&quot;: &quot;120.333&quot;,&quot;lat&quot;: &quot;45.34&quot;,&quot;countryCode&quot;: &quot;CN&quot;,&quot;ip&quot;: &quot;123.113.111.178&quot;,&quot;operator&quot;: &quot;中国联通&quot;},&quot;msg&quot;: &quot;ok&quot;} IP.cn: https://ip.cn/api/index?type=0 1234567{&quot;rs&quot;: 1,&quot;code&quot;: 0,&quot;address&quot;: &quot;中国 北京 北京市 联通&quot;,&quot;ip&quot;: &quot;123.113.111.178&quot;,&quot;isDomain&quot;: 0} IP API: http://ip-api.com/json/ 1234567891011121314151617{&quot;status&quot;: &quot;success&quot;,&quot;country&quot;: &quot;China&quot;,&quot;countryCode&quot;: &quot;CN&quot;,&quot;region&quot;: &quot;BJ&quot;,&quot;regionName&quot;: &quot;Beijing&quot;,&quot;city&quot;: &quot;Beijing&quot;,&quot;zip&quot;: &quot;&quot;,&quot;lat&quot;: 23.22,&quot;lon&quot;: 21.222,&quot;timezone&quot;: &quot;Asia/Shanghai&quot;,&quot;isp&quot;: &quot;China Unicom Beijing Province Network&quot;,&quot;org&quot;: &quot;&quot;,&quot;as&quot;: &quot;AS4808 China Unicom Beijing Province Network&quot;,&quot;query&quot;: &quot;xxxx&quot;} https://checkip.amazonaws.com/123.113.111.178","link":"/posts/b893f77b/"},{"title":"消毒药水","text":"紅藥水又稱紅汞，汞會讓蛋白質凝固沉澱，所以有抑菌的作用，因為對人體組織的傷害較小，曾經廣泛使用於局部皮膚創傷，是預防細菌感染最常用的表皮消毒藥水。 為何當初會拿來作為傷口處理用？大家小時候做生物實驗為了要看清楚細胞或是某些組織，會用染色劑把它們染色方便觀察。紅藥水就是這種作用，紅色顏料嘛！只不過對於細胞來說，染色劑會把細胞毒殺，所以被染過色的細胞，就等於是死了，同樣的道理，細菌本身也是細胞，所以當細菌被染色劑碰到時，也同樣會死亡。古時候醫療沒有很發達，就會使用比較容易取得的染色劑作為傷口殺菌之用。 使用紅藥水除了要擔心會有汞殘留人體外，還會看到很明顯的紅色，造成傷口色素沈澱，會留下疤痕，另外蠶豆症的患者不可以使用。其實紅藥水抑菌作用微弱，治療效果差，現在幾乎沒有在使用了！ 紫藥水主要成分是龍膽紫稀釋溶液，也可以叫結晶紫，聽到結晶紫是不是也勾起大家小時候做實驗的回憶？ 用來分辨細菌的革蘭氏染色法裡面有個步驟就是使用結晶紫。因爲它的陽離子能和細菌蛋白質的羧基結合，影響代謝而產生抑菌作用。它能抑制革蘭氏陽性菌，特別是葡萄球菌，對白色念珠菌也有較好的抗菌作用。外用可治療皮膚與粘膜的創傷感染及潰瘍、小面積的燙傷、鵝口瘡等。 不過傷口感染化膿時，不適合使用紫藥水，因爲它有收斂作用，會在傷口表面形成一層痂膜，讓壞死組織中的膿難以排出而向深部擴散，加重感染。紫藥水會使皮膚殘留紫色痕跡，脫色不易，所以對較大面積的傷口，盡量避免使用。而且跟紅藥水一樣，蠶豆症的患者也是不可以使用，否則會引發急性溶血反應。 值得一提的是，因為紫藥水擁有潛在的致癌性，所以現在醫療機構已不用紫藥水來消毒傷口。 黃藥水成分為Acrinol，也是常見的外用消毒劑。它跟紫藥水一樣，陽離子能和細菌蛋白質的羧基結合，影響代謝而產生抑菌作用。 黃藥水同樣也會染色，不過因為亞洲人皮膚是黃色，加上黃藥水的著色力不比剛剛講的紅藥水和紫藥水強，所以比較容易清除。它的特點是，抗菌效力不受膿血蛋白質影響，所以可以用來治療化膿性傷口。 要注意的是，黃藥水不適用在大於兩手掌面積的傷口或是深部感染傷口。不過因為他的抗菌效果沒有很好，現在也很少使用了。 白藥水雖然叫白藥水，但其實不是白色，而是一種透明液體，主要成份是陽離子殺菌劑benzakonium加上局部麻醉劑(Dibucaine Hydrochloride)、血管收縮劑(Naphazoline Hydrochloride)、抗組織胺(Chlorpheniramine Maleate)。應用原理為破壞微生物的細胞膜，除了對抗細菌之外，對真菌也有效。白藥水的特色是它沒有顏色，所以對於擔心傷口被染色劑染色或是衣服被優碘染到顏色的人來說，白藥水算是一個很好的選擇。 白藥水因為添加了局部麻醉劑，所以有止痛的效果，跟擦優碘或是雙氧水比起來，舒服多了。裡面添加的抗組織胺對於減輕局部組織的腫脹及組織液的滲出有不錯的功效，也有止癢的效果。但是在這邊要提醒各位，如果你的傷口已經傷到了真皮或是皮下組織，建議不要使用白藥水作為傷口處理之用，因為血管收縮劑有傷口收斂的效果，會讓你的傷口更容易產生包覆作用，會讓傷勢惡化在裡面，所以白藥水還是只適合表淺的傷口護理。 雙氧水又叫過氧化氫水溶液。小時候我賽跑跌倒，手肘磨破皮，傷口看起來髒髒的，回家媽媽拿醫藥箱的雙氧水幫我消毒。真的很痛！我邊看傷口冒泡泡邊哭！媽媽還會說『哭什麼？誰叫你要不小心跌倒？！』這種狠話也只有家人才說得出口。 為什麼我的傷口會冒泡泡？其實雙氧水可以殺菌，是利用它接觸傷口發生氧化反應釋放出氧氣的原理。 雙氧水可以分解血液中的酵素，除去血漬，但其穿透力差，殺菌時效短暫，用在深的傷口，容易造成蛋白質變性，組織壞死，傷口反而不易復原。一般只適合在出血凝塊的表淺傷口處理。目前也不建議將雙氧水直接用作傷口清理之用，因為對皮膚過於刺激，容易傷害到表皮細胞。 優碘優碘呈深褐色，殺菌效果強，可以在20~30秒內殺死病毒、細菌、黴菌、結核菌、原蟲等，為廣效型的殺菌劑，更有預防傷口化膿的功效，而且容易清洗、溫和不刺激，不過塗在傷口在還是會痛啦！優碘是目前使用最廣泛的消毒藥水。優碘會留下黃褐色顏色，容易使皮膚在日曬後形成色斑，頸部以上部分傷口使用時要多加考慮。 不過大家不要誤會，其實優碘並不會造成傷口的色素沉澱，剛剛提到了曬太陽之後會產生色斑，主要是因為陽光照射之後，容易形成紫黑色的固態碘，外觀上會很像色素沉澱所以會引起誤會。 當優碘與傷口組織接觸時，會形成薄膜，然後慢慢釋出碘來達到殺菌效果。但值得注意的一點是，此薄膜通常有點黏黏的，如果傷口較大，大多數人會再覆蓋一層紗布，結果優碘形成的薄膜加上組織液與紗布黏在一起，下次換藥時拆紗布的時候相信很多人都有經驗，絕對痛到你嘴歪眼斜！所以建議塗完優碘後，可以在傷口上蓋上石蠟紗布(如下圖)來降低傷口的沾黏。 今天跟大家分享這麼多消毒藥水，簡單來說，紅、紫、黃藥水目前已經不建議使用，雙氧水如果要用的話，也只適用在第一次消毒傷口，不適合持續使用 ; 頭頸部的表淺傷口可以使用白藥水避免色素沈澱 ; 身體跟四肢的傷口可以考慮使用優碘。 ![[Pasted image 20230702120450.png]] 當然要告訴大家很重要的一點，就是雖然居家常備這些藥水，可以處理小型的傷口，非常方便，但如果過了幾天，傷口都沒好轉的跡象，甚至愈來愈紅，愈來愈痛，就要趕快去看皮膚科，畢竟傷口的照顧是一門很大的學問，它還牽涉到用什麼去覆蓋，要不要擦抗生素藥膏，又要擦哪一種抗生慌藥膏，幾天換藥一次，需不要縫合，要不要貼人工皮……等等很多問題，來防止疤痕的形成，這些都不光是擦個藥水就能解決這麼簡單。","link":"/posts/ff4866a6/"},{"title":"自制辣椒油","text":"起锅烧油,放入香料(八角,花椒,桂皮,香叶),葱姜,蒜,香菜,洋葱炸至金黄捞出弃用 碗内辣椒切碎,有条件可以自己研磨五香粉和芝麻混合,用白酒拌匀(激发香味防止炸糊),我放的化花雕酒味道也很不错 热油泼到辣椒上,然后滴几滴醋增香.","link":"/posts/eae9c1f1/"},{"title":"小白零基础线上配镜，拔草蔡司。","text":"购买理由网络越来越发达了，很多事情都可以在网上完成，学习外卖快递什么的比以前方便多了，甚至配眼镜也可以了。希望有一天可以在线吃饭吧。 流程先谈一下线上配眼镜的优缺点吧: 优点： 便宜，线下普通眼睛的钱就能配到蔡司的镜片 可以熟悉配眼镜的流程，防止日后被坑 缺点： 需要线下验光，线下有些家不提供验光或者验光度数不准确 眼睛框可能带着不舒服 需要 3-7 天才能拿到成品，没有备用眼镜的话很难受 几个月前被种草蔡司镜片，在蔡司睛选小程序上询问最普通的莲花膜也要上千，更何况我每天超过 10 小时面对电子屏幕，必须要蓝光膜，姑且不说是不是智商税，起码图个心里安慰，不要以为有蓝光膜就可以随便作了，眼睛病了也是病啊，就跟不好好吃饭等于慢性自杀一样。 找了几篇帖子，最终在 1688 上选择了一家深圳的眼镜店，我配的是钻立方的蓝光膜，应该是比较入门的一款镜片，毕竟第一次尝试，打算成功了后下一个眼镜直接上顶配。实测一周后发现，除了选镜框的时候没注意到尺寸有点小之外，其他的都算不错。基本流程就是，选镜框-验光-下单镜片-邮寄镜框-镜框加工。 镜框镜框由于经费原因没有选择蔡司原厂，在京东上选了个商务风格纯钛材质了。品牌是精工，日本的老牌子了，眼镜店里的品牌在网上都搜不到，索性买了大品牌风格类似的。 京东下单，不过还需要调货，精工店比宝岛店还便宜一些。对这镜子试了试觉得风格挺好看就联系顺丰邮寄走 了，邮费 18 大洋。 后期收到货的是时候才发现同样的镜框，近视镜和平镜的感觉是不一样的，也可能是第一次用半框，总会看见边框。 验光验光是在宝岛眼镜，搜索公众号选择验光师就可以了(不要选配镜师)，之后的数据会同步到小程序上，验光的费用是 50,个人觉得还是挺划算的，毕竟一堆参数，验光师操作一堆设备操作起码半个小时，再加上我问了一堆问题。当然也不排除有些店嫌麻烦不提供验光服务的，去之前要电话沟通好。当然电话里说 50 一次然后去店里不给验光的也有。 如果想货比三家防止度数不准确的话，那么就不要去同一个连锁店了。毕竟他们都可以查到数据…… 总之，宝岛还是挺靠谱的。 镜片镜片根据需要下单就可以了，上边的加个是一片的，记得数量要选 2,然后还有加工费，算上这些差不多是线下的三分之一。加工之前卖家会确定下镜框和度数，剩下的就是加工时间和物流的时间了，顺丰发出。顺便吐槽下顺丰没有之前快了。 收货收到的第一感觉是轻，毕竟配眼镜成功的标准就是感觉不到它的存在。后来觉得我的树脂镜框就像一块石头压在了脑袋上。 除了天没亮剩下的都亮了的感觉。 如何保养保养的话，买了美的超声波清洗仪，190 入手。当然也可以洗假牙手表珠宝什么的。没有精力每天去洗，家里又多了一个长期吃灰的设备。 总结总体来看的话，还算挺成功的一次配镜。毕竟有句话叫做能用钱搞定的不要花是时间。懒人不止一次的为这个社会带来变革，希望有一天穷人也可以吧。","link":"/posts/b97d7b57/"},{"title":"记一次消防演练","text":"写字楼物业组织了消防演练，也是第一次使用真实的灭火器，当然还是希望永远都不要再用到的好。 这次使用的是干粉灭火器，也只能覆盖火苗降低温度，然后还需要使用水来彻底灭火，使用起来很简单。需要提醒的是，使用的时候不要距离太近。 消防人员交了四字口诀“提拔握压” 提：单手提起灭火器，手提提把，保持水平垂直 拔：拔出保险销，注意另外一只手不要按到压把，否则无法拔出 握：握住喷管的最前端，控制好方向 压：压住灭火器的开关，喷出干粉灭火 体验了一次火灾模拟，每人分发了湿毛巾捂住口鼻（还是很呛），出来的时候感觉空气都是甜的。只能说烟熏比较火情更为恐怖。 除此之外，还有消防车的喷水演示，从图片中可以看到，这个射程还是很远的。 其实大多数人对火灾没啥概念，无非是偶尔看到哪里哪里又着火了之类的，还是防患于未然吧。","link":"/posts/cd8d8984/"},{"title":"血型","text":"血型是一种遗传特性，主要由 ABO 系统和 Rh 系统两个主要系统决定。 ABO 血型系统：这是最重要的血型系统，包括 A型、B型、AB型和O型四种血型。A型血液具有A型抗原，B型血液具有B型抗原，AB型血液具有A型和B型抗原，而O型血液则没有这两种抗原。 Rh 血型系统：Rh 血型系统是在 ABO 血型系统之后最重要的血型系统。最主要的是 Rh(D)抗原，它决定了一个人是 Rh阳性（Rh+）还是 Rh阴性（Rh-）。因此，我们常常会听到血型被描述为 A+ 或 O- 这样的形式，其中的 “+” 或 “-“ 就是指的 Rh 血型。 所以，总共有八种血型：A+、A-、B+、B-、AB+、AB-、O+ 和 O-。 ABO 血型系统是一种基于人体红细胞上存在的抗原类型的分类系统。在 ABO 系统中，主要有 A 型抗原、B 型抗原和没有这两种抗原的 O 类型。 以下是具体的细节： A型血：有 A 型抗原，体内产生抗 B 抗体B型血：有 B 型抗原，体内产生抗 A 抗体AB型血：有 A 型和 B 型抗原，体内不产生抗 A 或抗 B 抗体O型血：没有 A 型或 B 型抗原，体内产生抗 A 和抗 B 抗体关于父母血型和孩子血型的关系，因为 ABO 血型是由两个等位基因决定的，一个从母亲那里继承，一个从父亲那里继承。A 和 B 两个等位基因是显性的，而 O 等位基因是隐性的。所以： 如果父母的血型都是 A 型，那么孩子可能是 A 型或 O 型（假设其中一个或两个父母携带了 O 基因）。如果父母的血型都是 B 型，那么孩子可能是 B 型或 O 型（假设其中一个或两个父母携带了 O 基因）。如果父母的血型都是 O 型，那么孩子只能是 O 型。如果父母的血型是 A 型和 B 型，那么孩子可能是 A 型、B 型、AB 型或 O 型（假设其中一个或两个父母携带了 O 基因）。如果父母的血型是 A 型和 O 型，那么孩子可能是 A 型或 O 型。如果父母的血型是 B 型和 O 型，那么孩子可能是 B 型或 O 型。如果父母的血型是 AB 型和 O 型，那么孩子可能是 A 型或 B 型。如果父母的血型是 AB 型和 A 型，那么孩子可能是 A 型或 AB 型。如果父母的血型是 AB 型和 B 型，那么孩子可能是 B 型或 AB 型。如果父母的血型是 AB 型，那么孩子可能是 A 型、B 型或 AB 型。 不同血型的人接受输血时，必须确保血型相容，否则可能产生严重甚至致命的免疫反应。例如，B型血的人如果接受A型血的输血，他们体内的抗-A抗体会攻击输血中的A抗原，导致血液凝块、器官损伤等问题。 理解 ABO 血型遗传关系的关键是知道 A 和 B 基因是显性的，而 O 基因是隐性的。这意味着如果一个人从父母那里获得了 A 或 B 基因和 O 基因，那么 A 或 B 基因将显性表达，而 O 基因将隐性表达。 用这个理念，我们可以对血型遗传关系进行一些简化： 如果两个 O 型血的父母（OO 和 OO），他们的孩子只能是 O 型血。 如果两个 A 型血的父母（可能是 AA 或 AO），他们的孩子可能是 A 型或 O 型血。 如果两个 B 型血的父母（可能是 BB 或 BO），他们的孩子可能是 B 型或 O 型血。 如果两个 AB 型血的父母（AB 和 AB），他们的孩子可能是 A 型、B 型或 AB 型血。 如果一个 A 型血的父母和一个 B 型血的父母（可能是 AA, AO, BB 或 BO），他们的孩子可能是任何血型。 如果一个 AB 型血的父母和一个 O 型血的父母（AB 和 OO），他们的孩子可能是 A 型或 B 型血。 以上简化可能没有涵盖所有的情况，但基本上可以解释大多数情况的遗传模式。请注意，这个遗传模式是理想的，现实中可能存在一些偏差。 如果你想更详细地理解每种可能的遗传模式，我推荐你使用 Punnett 方格。Punnett 方格是一种在生物学中用于理解和预测遗传模式的工具。在这个方格中，你可以表示每个父母的基因型（例如，A 型血的父母可能是 AA 或 AO），然后看看每种可能的组合。 此外，血型也在妊娠中起着重要的角色，特别是母亲是Rh-而胎儿是Rh+时，可能会发生Rh不兼容，导致新生儿溶血性疾病。这种情况可以通过在怀孕期间给予母亲抗-Rh(D)免疫球蛋白（Rho(D) immune globulin）预防。 血型在医学、法医学和人类遗传学研究中都很重要。不过，关于血型和性格、饮食偏好等的关联的说法，尚无科学依据。","link":"/posts/d14ad726/"},{"title":"写给懒猫微服玩家的容器小书 Docker篇（一）：《无法部署的诅咒》","text":"一直想写一本容器小书，真好懒猫基本都做了容器化，所以把这部分分享出来。不同的是，懒猫微服中使用 pg-docker 来替代 docker 命令，使用 dockge 来执行 docker-compose。以下讲解以标准 docker 为主，这样子既学会了 docker 知识，也能够在懒猫微服上启动 Docker 服务。 《无法部署的诅咒》讲的是 Docker 的起源与作用、镜像与容器概念、安装入门🏙️ 开篇：代码在电脑上运行良好，部署却频频翻车小李是一名后端工程师，刚完成一个用 Flask 编写的内部管理系统。他信心满满地将代码提交，交给测试工程师老赵部署。 可没想到—— “报错了！你是不是少传文件了？” “我这边 Python 是 3.6，怎么你这代码用了 match case？” “你数据库呢？你 Redis 配了？环境变量在哪？” 这一刻，小李陷入了一个叫「部署地狱」的世界。 这个世界里，每一台服务器都是独一无二的“宠物”，需要手动配置、手动部署、手动踩坑，稍有不慎就会陷入版本冲突、依赖缺失、环境不一致的深渊。 小李心里想：有没有一种办法，能让我把代码和环境一起打包起来，无论在哪运行都能保持一致？ 🌀 变故：神秘的程序员大叔与魔法容器在公司茶水间，小李邂逅了一个带着黑框眼镜的大叔，大家都叫他老周。 老周是个技术老炮，在各种部署大灾难中杀出血路。他听完小李的吐槽后，轻轻地推了一份文档过来，只写了五个字母： Docker “这是个魔法容器，”老周说，“把你代码和环境都打包进去，哪怕放在火星，也能跑。” “以后别再‘它在我电脑上可以跑’了，Docker 能让所有环境变得一致。” 小李的眼睛亮了。 🔧 技术讲解 Part 1：什么是 Docker？Docker 是一个开源的容器化平台，它允许开发者将应用及其所有依赖打包成一个“容器”，保证在任何平台上都可以一致运行。 你可以把 Docker 想象成： 程序员的打包箱子：把你写的程序、环境、库、配置都放进去，打包成一个“镜像”； 程序员的快递服务：运行镜像就像打开快递，内容和你寄出时一模一样。 🚀 为什么要用 Docker？ ✅ 跨平台运行：一次构建，到处运行（Run anywhere） ✅ 快速部署：秒级启动，适合 CI/CD ✅ 环境一致性：不再“你电脑能跑我电脑不行” ✅ 轻量隔离：不像虚拟机那么重，不需要整个操作系统 ✅ 资源占用少：用起来更像一个进程，而不是一台虚拟机 ☑️ 一句话总结：Docker 解决了“在我电脑上能跑”的问题。 🛠️ 技术讲解 Part 2：如何安装 Docker？老周拍了拍小李的肩膀，说：“先装起来，动手最重要。” 🧑‍💻 在 Mac / Windows 上： 访问官网：https://www.docker.com/products/docker-desktop 下载并安装 Docker Desktop 安装后打开终端（Terminal），输入： 1docker --version 如果看到 Docker 的版本信息，说明安装成功。 🧑‍💻 在 Linux（Ubuntu）上：1234sudo apt updatesudo apt install docker.iosudo systemctl start dockersudo systemctl enable docker 🔐 建议将当前用户加入 docker 组，以免每次都要用 sudo： 1sudo usermod -aG docker $USER 🧠 技术讲解 Part 3：Docker 的核心概念 概念 说明 镜像（Image） 应用和其依赖的静态快照模板（如：打包好的 Python 环境 + Flask 项目） 容器（Container） 镜像运行出来的实例，是真正“活着”的程序 Dockerfile 编写镜像的“配方”，定义如何构建镜像 Docker Hub 类似 GitHub 的公共镜像仓库，可上传/下载别人做好的镜像 docker 命令 Docker 的主命令工具，用于操作镜像、容器、网络、卷等 📌 镜像 vs 容器 镜像是“模具”，容器是“实物” 镜像不可变，容器是可运行的环境 一个镜像可以运行多个容器 🧪 技术实践：Hello Docker 世界老周指导小李敲下第一行命令： 1docker run hello-world 如果 docker run/pull 有问题，那么可以通过lzc-cli appstore copy-image your-images来使用懒猫的镜像仓库。 这个命令会做三件事： 自动从 Docker Hub 拉取一个 hello-world 镜像（如果本地没有） 基于镜像运行容器 容器运行后输出信息，然后自动退出 这是验证 Docker 是否正常运行的“点灯测试”。 🧱 小李的第一个真实容器：Flask Web 项目打包实战老周笑着说：“现在，把你那个 Flask 管理系统也丢进 Docker 试试。” 小李在项目根目录下写了一个 Dockerfile： 1234567891011121314# 使用 Python 官方基础镜像FROM python:3.11-slim# 设置工作目录WORKDIR /app# 复制项目文件COPY . /app# 安装依赖RUN pip install -r requirements.txt# 设置启动命令CMD [&quot;python&quot;, &quot;main.py&quot;] 构建镜像：1docker build -t my-flask-app . 启动容器：1docker run -p 5000:5000 my-flask-app 现在访问浏览器 http://localhost:5000，你的项目上线了！ 💡 小知识快闪 Docker 容器内部不包含完整操作系统，只包含必要的运行库； Dockerfile 的每一行都是一层（Layer），构建时会缓存复用； docker ps 查看运行中容器，docker images 查看已有镜像； 可以通过 .dockerignore 文件忽略不想加入镜像的文件，比如 .git 和日志。 ⚔️ 章节尾声：打破部署诅咒这次，小李把打好的镜像发给了测试老赵： 1docker run -p 5000:5000 my-flask-app 老赵只运行了一行命令，项目便神奇地跑了起来。 “不改配置？不用装 Python？数据库也连上了？”“你这是什么魔法！” 小李笑了笑，第一次感觉部署是件简单的事。 🧭 第一章总结知识点： 技术点 命令 安装 Docker Mac/Win 下载 Docker Desktop / Ubuntu 安装 docker.io 查看版本 docker --version 运行测试容器 docker run hello-world 编写 Dockerfile FROM / COPY / RUN / CMD 构建镜像 docker build -t name . 运行容器 docker run -p 宿主:容器 镜像名","link":"/posts/effe7a9a/"},{"title":"写给懒猫微服玩家的容器小书 Docker篇（二）：《镜像旅馆的秘密》","text":"一直想写一本容器小书，真好懒猫基本都做了容器化，所以把这部分分享出来。不同的是，懒猫微服中使用 pg-docker 来替代 docker 命令，使用 dockge 来执行 docker-compose。以下讲解以标准 docker 为主，这样子既学会了 docker 知识，也能够在懒猫微服上启动 Docker 服务。 《镜像旅馆的秘密》讲的是 Docker 镜像的原理、分层结构、生命周期、Docker Hub 上传与下载、常见镜像命令详解🏰 开篇：进入镜像旅馆自从小李用 Docker 成功打包并运行了自己的 Flask 项目，他的开发效率飞快提高。 某天，老周带他来到一座巨大的数字建筑——Docker 镜像旅馆。 “这是你所有镜像的家，”老周说，“也是全球程序员共享旅程资源的中转站。” 镜像旅馆里，层层叠叠地存放着成千上万个镜像，就像一栋模块化的高楼大厦。 🧱 镜像的本质：一层一层搭起来的文件系统老周告诉小李： “镜像（Image）其实是一个只读的分层文件系统。你写的每一条 Dockerfile 指令，都会构成一层 Layer。” 比如这个简单的 Dockerfile： 12345FROM python:3.11-slimWORKDIR /appCOPY . /appRUN pip install -r requirements.txtCMD [&quot;python&quot;, &quot;main.py&quot;] 对应的镜像层如下： FROM → 拉了一个基础镜像层（Python 3.11） WORKDIR → 添加一个设置工作目录的 Layer COPY → 拷贝代码文件的 Layer RUN → 安装依赖的新 Layer CMD → 容器入口（不是 Layer，但存配置） 💡 小知识：Docker 会尽量缓存和复用前面的 Layer，节省时间和存储。 🧪 镜像命令全攻略小李打开终端，开始探索这些镜像的日常操作。 1. 查看本地镜像：1docker images 输出示例： 123REPOSITORY TAG IMAGE ID CREATED SIZEmy-flask-app latest 123abc456def 2 minutes ago 125MBpython 3.11-slim 789xyz654hij 3 days ago 40MB 解释： REPOSITORY：镜像名 TAG：标签（版本号） IMAGE ID：镜像唯一标识符 SIZE：镜像大小 2. 查看镜像历史构建过程（看每层）：1docker history my-flask-app 3. 删除镜像：1docker rmi my-flask-app （⚠️ 若有容器在运行该镜像，需先停止并删除容器） 🗂 镜像仓库：Docker Hub老周指了指旅馆大堂里的一个巨大电梯： “这是 Docker Hub，全球最大的镜像共享仓库。” 在这里，小李能下载成千上万的开源镜像，也能上传自己的。 登录 Docker Hub：1docker login （需要先注册账号） 下载镜像：1docker pull nginx 这会从 Docker Hub 拉取最新版本的 nginx 镜像 指定版本拉取：1docker pull redis:6.2 如果 docker run/pull 有问题，那么可以通过lzc-cli appstore copy-image your-images来使用懒猫的镜像仓库。 （相当于拉取 redis 仓库中 tag 为 6.2 的镜像） 上传镜像（先打标签）：12docker tag my-flask-app yourdockerhubname/my-flask-app:1.0docker push yourdockerhubname/my-flask-app:1.0 📦 镜像 Tag 与版本控制老周问：“小李，你知道为什么镜像都有个 :latest 吗？” 小李说：“这是默认版本号吧？” “对，但我们不能依赖它。开发、测试、生产应使用明确版本号，比如 1.0、20240321 等。” Docker 镜像是通过 tag 来区分版本的： 12docker build -t myapp:1.0 .docker build -t myapp:latest . 你可以为同一个镜像打多个标签，对应不同场景使用。 🔍 镜像体积优化技巧小李注意到镜像越来越大了，占了很多硬盘空间。 老周给了他几点建议： 使用轻量级基础镜像： 比如 python:3.11-slim 代替 python:3.11 合并 1RUN 命令，减少层数： 1RUN apt update &amp;&amp; apt install -y git &amp;&amp; rm -rf /var/lib/apt/lists/* 删除临时文件： 安装后清理缓存，避免垃圾文件残留 多阶段构建（进阶）： 构建和运行使用不同的镜像阶段 📂 镜像保存与迁移后来小李想把自己的镜像传给另一位没有 Docker Hub 的同事。 他用到了镜像导出与导入： 导出镜像为 .tar 文件：1docker save my-flask-app &gt; myapp.tar 导入镜像：1docker load &lt; myapp.tar 镜像打包成离线文件，便于携带与备份。 🔍 深入 Layer 实战：查看镜像内容小李很好奇，镜像到底长什么样？ 老周教他运行容器并进到里面： 1docker run -it --rm my-flask-app /bin/bash 这样他就能直接进入容器的 Linux 环境，像在服务器上一样查看文件结构： 123ls /cd /appcat requirements.txt 他终于明白，每个镜像就像是一个“静态快照”，而容器才是“它的动态运行副本”。 📊 镜像生命周期总结表 操作 命令 查看本地镜像 docker images 构建新镜像 docker build -t name . 删除镜像 docker rmi 镜像名 下载镜像 docker pull 镜像名[:tag] 上传镜像 docker push 镜像名[:tag] 镜像打包导出 docker save &gt; xxx.tar 镜像导入还原 docker load &lt; xxx.tar 镜像历史层查看 docker history 镜像名 🎬 尾声：镜像旅馆的门票小李现在拥有了多个镜像，搭配不同的版本、依赖、语言，像积木一样可以快速组合各种环境。 “这就像 Minecraft 的世界地图，每张都是一个镜像。”小李说。 老周点点头：“没错，镜像只是开始，真正的冒险——是容器运行起来后的世界。” 🧭 第二章小结 镜像是构建环境的基础模板，支持版本控制、缓存加速、快速构建 可以上传到 Docker Hub 或导出 .tar 进行离线传输 管理命令要熟练掌握：build、pull、push、rmi、tag、history 优化镜像大小要用 slim 基础镜像、合并命令、清理缓存 ✨ 增补内容：镜像的高级技能与实战应用 🧪 多阶段构建：精致分工，极限瘦身有一次，小李需要构建一个使用 npm 打包前端、Python 启动后端的项目。打包工具很多、依赖也重，他担心镜像太大。 老周说：“你要学会多阶段构建（multi-stage build），把构建阶段和运行阶段分开。” 多阶段构建的目标是：编译用谁都行，最终镜像要最小。 示例：Node 构建 + nginx 托管123456789# 第一阶段：使用 node 构建前端FROM node:18 AS builderWORKDIR /appCOPY . .RUN npm install &amp;&amp; npm run build# 第二阶段：用 nginx 托管打包后的静态文件FROM nginx:alpineCOPY --from=builder /app/dist /usr/share/nginx/html 第一阶段装依赖、打包代码 第二阶段只取编译结果，不用带上 node/npm 等工具 小李一测试，镜像体积从 300MB 降到 25MB，部署速度快了 10 倍！ 🧩 使用 .dockerignore：镜像防垃圾机制构建时，小李发现镜像中夹杂了 .git、node_modules、__pycache__…… 老周摇头道：“你忘了 .dockerignore 文件。” 就像 .gitignore 一样，.dockerignore 告诉 Docker 哪些文件在构建镜像时要排除。 示例：12345__pycache__/.git/node_modules/.env*.log 这个文件放在 Dockerfile 同目录下，能显著加快构建速度和减小镜像大小。 📦 自建私有镜像仓库（Registry）当公司禁止使用 Docker Hub 时，小李开始尝试搭建自己的镜像库。 老周带他部署了一个本地私有镜像仓库（基于 Docker 官方镜像）： 1docker run -d -p 5000:5000 --restart=always --name registry registry:2 现在他可以： 推送到私库： 12docker tag myapp localhost:5000/myappdocker push localhost:5000/myapp 拉取镜像： 1docker pull localhost:5000/myapp 适合公司内部使用，搭配 Nexus、Harbor 可实现更完善的权限、审计、镜像管理等功能。（比如懒猫的 copy-image） 🧠 镜像调试技巧：如何从镜像中探查问题？如果小李的镜像出错了，他可以通过两种方式“探测”镜像内部： 方法 1：运行一个交互式 shell 容器1docker run -it myapp /bin/bash （如果 bash 不存在，可以用 /bin/sh） 方法 2：打开已有容器的终端1docker exec -it container_id /bin/bash 通过 ls、cat、which、env 命令，可以检查： 文件有没有 COPY 进去？ pip install 是否安装成功？ 环境变量是否丢失？ 🔐 镜像安全：不要把密码打包进镜像！小李曾在 Dockerfile 里写了： 1ENV DB_PASSWORD=123456 老周当场拍桌：“你这是把钥匙写死进容器了！” 最佳做法： 在容器运行时注入环境变量（例如使用 .env 文件 + --env 参数） 使用 docker secret 或 KMS 管理 使用 BuildKit 的 --secret 机制加密构建时参数（高级用法） 🧾 镜像标签管理规范建议小李准备上线，他开始给镜像打各种 tag： 12docker build -t myapp:1.0.0 .docker tag myapp:1.0.0 myapp:latest 老周说： “tag 是镜像的版本名，不要用 latest 作为生产环境唯一标识。” 推荐命名规范： 标签 含义 myapp:1.0.0 语义化版本控制 myapp:20240324 构建时间戳 myapp:prod 环境标识 myapp:feature-login 功能分支测试 🔁 镜像缓存失效调试技巧有时候构建镜像时，小李发现修改了某个文件，Docker 却好像没更新。 老周点拨他：“那是缓存搞的鬼。” 方法一：强制跳过缓存1docker build --no-cache -t myapp . 方法二：注意 COPY 顺序影响缓存命中Docker 会从上到下按顺序缓存。如果把变化频繁的文件 COPY 太早，就会导致缓存失效： 1234COPY requirements.txt . # OK，变动少，适合先复制RUN pip install -r requirements.txtCOPY . . # 后复制代码，避免频繁无效重建 ✨ 技巧：越是稳定的文件，越早 COPY，利于缓存复用。 📘 第二章 · 补充总结更新版 技术点 命令 / 说明 多阶段构建 FROM ... AS builder + COPY --from=builder 忽略文件 .dockerignore 文件 镜像上传私库 docker push localhost:5000/myapp 开启 BuildKit DOCKER_BUILDKIT=1 docker build ... 进入镜像内调试 docker run -it 镜像 /bin/bash 镜像版本管理建议 避免乱用 latest，使用语义化 tag 跳过缓存构建 docker build --no-cache ... 小李站在镜像旅馆的屋顶，看着一层层高楼像乐高积木一样堆叠而起。 他感到激动——他已经不再为“部署”苦恼，而是拥有了一个随时可打包、可还原的开发宇宙。 老周说：“你的旅程才刚刚开始，容器的世界比镜像更复杂。”","link":"/posts/e0565a55/"},{"title":"写给懒猫微服玩家的容器小书 Docker篇（三）：《容器部落生活》","text":"《容器部落生活》讲的是 容器生命周期管理，包括容器的启动、停止、查看、交互、日志、后台运行、重启策略等操作 一直想写一本容器小书，真好懒猫基本都做了容器化，所以把这部分分享出来。不同的是，懒猫微服中使用 pg-docker 来替代 docker 命令，使用 dockge 来执行 docker-compose。以下讲解以标准 docker 为主，这样子既学会了 docker 知识，也能够在懒猫微服上启动 Docker 服务。 镜像旅馆的旅途告一段落，小李的下一站是容器部落。 老周牵着他走过一条闪烁着数字光芒的通道，一排排运行中的应用像帐篷一样排列着。有人在调试日志，有人在重启服务，还有人用 bash 正在某个容器里“打补丁”。 老周说： “镜像只是静态的模板，容器才是它们的生命。容器是镜像运行出来的真实世界。” 🧠 技术基础：容器 vs 镜像 项目 镜像（Image） 容器（Container） 类比 模板、配方 实际的运行实例 特性 只读 可读写 作用 用来创建容器 实际运行中的程序环境 状态 不运行 可运行、停止、销毁 🛫 第一节：容器的启动方式小李想运行他的 Flask 应用镜像。 老周告诉他： “运行镜像的命令是 docker run，容器就像是用镜像盖起来的一顶帐篷。” 1. 最常见方式（临时 + 前台）：1docker run my-flask-app 但程序一执行完就退出了。小李困惑。 老周解释： “容器会在主进程结束后自动退出，比如 CMD [&quot;python&quot;, &quot;main.py&quot;] 一旦结束，容器就结束了。” 2. 保持后台运行（常用）1docker run -d --name flask-app -p 5000:5000 my-flask-app 解释： -d：detached 模式，后台运行 --name：给容器取个名字，方便管理 -p 宿主端口:容器端口：端口映射，把容器内部 5000 暴露到外部 小李可以在浏览器里访问 http://localhost:5000，服务在跑！ 3. 设置环境变量1docker run -d -e ENV=production my-flask-app 在容器内可通过 os.environ['ENV'] 访问。 4. 设置自动重启策略（生产强烈建议）1docker run -d --restart=always my-flask-app 可选策略： 策略名 说明 no 不自动重启（默认） on-failure 出错时重启 always 永远重启 unless-stopped 除非人为停止 🧭 第二节：查看容器状态老周说：“运行中的容器就像是火堆，你得学会看它们是否还在烧。” 查看运行中容器：1docker ps 如果想看所有容器（包括已退出的）： 1docker ps -a 输出示例： 12CONTAINER ID IMAGE STATUS NAMESf123abc456 my-flask-app Up 3 minutes flask-app 🔄 第三节：容器的停止与重启停止容器：1docker stop flask-app 启动容器：1docker start flask-app 重启容器：1docker restart flask-app ⚠️ 容器停止后并不会删除，除非显式用 docker rm 🧰 第四节：进入容器内“远程调试”有一次小李发现容器里缺了个配置文件，他想进去看看。 使用 exec 进入运行中的容器：1docker exec -it flask-app /bin/bash -i：保持输入 -t：分配终端 /bin/bash：使用 bash shell（Alpine 镜像可能要用 /bin/sh） 现在他能像 SSH 进服务器一样，在容器里操作文件、日志、环境变量。 📜 第五节：查看容器日志某天应用崩溃了，小李要调日志。 老周提醒他：“容器日志直接走标准输出和错误输出。” 1docker logs flask-app 可以加参数看最近内容： 1docker logs --tail 100 flask-app 实时滚动输出（调试很有用）： 1docker logs -f flask-app 🧽 第六节：删除容器小李尝试重建容器时，系统提示名字重复。 老周告诉他要先删除原来的： 1docker rm flask-app 如果容器还在运行，先 stop 再 rm，或直接强制： 1docker rm -f flask-app 🔄 第七节：容器生命周期一览表 操作 命令 创建 + 运行容器 docker run 后台运行 docker run -d 设置名字 docker run --name name 设置端口映射 -p 外:内 查看容器 docker ps [-a] 停止容器 docker stop name 启动容器 docker start name 重启容器 docker restart name 删除容器 docker rm [-f] name 查看日志 docker logs [-f] name 进入容器 docker exec -it name /bin/bash 🧪 小李的实战练习任务老周布置了一个练习： “请你写一个脚本，构建镜像，运行容器，设置环境变量和端口，再用日志确认 Flask 成功启动。” 小李完成如下步骤： 1234docker build -t flask-test .docker run -d --name flask-run -p 8080:5000 -e MODE=debug flask-testdocker logs -f flask-rundocker exec -it flask-run /bin/bash 🧬 衍生补充：容器的状态码解释容器退出时，可以用 docker ps -a 查看 STATUS 栏： Exited (0)：正常退出 Exited (1)：出错退出 Up：正在运行 调试时很有用。 🎬 尾声：容器部落里的秩序小李现在已经能够用容器完成： 应用部署 环境隔离 日志查看 重启容错 在线修复问题 他看着容器部落中灯火通明的帐篷，知道自己终于从一个“只会打包镜像”的新人，成长为能驾驭容器生命周期的工程师。 老周拍拍他肩膀说： “你已经能掌控容器的生死了，下一步——掌控它们的数据。” 好嘞，我们来拓展第三章《容器部落生活》，新增三大实战内容： 🚀 Nginx 容器部署🔗 多个容器配合运行（应用 + 数据库）🩺 容器的服务探针（健康检查） 这部分会继续以故事+实战命令+讲解的方式展开，帮助你更贴近真实工作中的容器部署流程。 🧱 实战一：Nginx 容器部署小站点小李想搭个静态站点测试，老周给他出了一个练习： “用 Nginx 容器部署一个 HTML 网站，只通过 Docker 完成。” 1. 准备文件结构：123nginx-site/├── index.html└── Dockerfile index.html 示例： 123456789&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Hello from Nginx&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Hello Docker + Nginx!&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt; 2. Dockerfile 内容（基于官方 Nginx）：12FROM nginx:alpineCOPY index.html /usr/share/nginx/html/index.html ✅ 把自己的网页文件覆盖掉默认首页。 3. 构建 + 运行：12docker build -t nginx-site .docker run -d --name my-nginx -p 8080:80 nginx-site 打开浏览器访问 http://localhost:8080，小李看到页面显示成功，笑得像个孩子。 🔗 实战二：应用容器 + 数据库容器组合运行接着老周出了第二个任务： “把你的 Flask 应用和一个 MySQL 数据库用两个容器跑起来，实现数据连接。” 方法一：手动网络 + 多容器连接1. 创建网络（容器间通信）：1docker network create flask-net 2. 启动 MySQL 容器：12345docker run -d --name my-mysql \\ --network flask-net \\ -e MYSQL_ROOT_PASSWORD=root123 \\ -e MYSQL_DATABASE=mydb \\ mysql:5.7 3. 启动 Flask 应用容器（连接到 MySQL）：假设 Flask 连接数据库时使用： 1host = 'my-mysql' # 容器名就是主机名 启动命令： 12345docker run -d --name flask-app \\ --network flask-net \\ -e DB_HOST=my-mysql \\ -p 5000:5000 \\ my-flask-app 🔗 容器间在同一个网络中，通过名字直接通信，像局域网一样！ 方法二：使用 docker-compose（下一章会详细讲） 🩺 实战三：为容器添加“健康探针”老周问小李：“如果你的服务挂了，但容器还在运行，你怎么知道？” 小李摇头：这不就是“僵尸容器”吗？ 老周笑了： “那就给它加一个健康探针（HEALTHCHECK），定期检测服务状态。” 为 Flask 容器加健康检查：修改 Dockerfile： 12HEALTHCHECK --interval=30s --timeout=5s --start-period=5s --retries=3 \\ CMD curl -f http://localhost:5000/health || exit 1 在 Flask 代码中添加一个健康检查路由： 123@app.route('/health')def health(): return &quot;OK&quot;, 200 构建镜像，运行容器后，通过命令查看健康状态： 1docker inspect flask-app | grep -i health 输出示例： 1234&quot;Health&quot;: { &quot;Status&quot;: &quot;healthy&quot;, ...} 如果 /health 接口返回失败状态码，容器会标记为 &quot;unhealthy&quot;，可配合自动重启策略联动修复。 🧭 实战拓展总结表 场景 命令 / 技术 部署静态站点 Nginx + COPY index.html 容器间通信 docker network create + --network 参数 多容器组合 应用容器连接数据库容器 服务探针 Dockerfile 添加 HEALTHCHECK，应用实现 /health 探针状态查看 `docker inspect 容器名 🎬 尾声 · 容器集群的微光小李站在容器部落的山丘上，看着成百上千个容器像城市灯火一样运转。 Nginx 做前端代理，Flask 作为后端逻辑，MySQL 管理数据，每个服务都是一块积木，有秩序、有协作。 老周淡淡说： “这只是单机的容器调度，真正的战场——在云上。” 小李的眼里闪起光芒：“那我下次要学的就是——Compose，K8s，还有 CI/CD，对吧？” 老周点头：“没错，下一站——数据卷与共享、Compose 编排，再之后……你就要去打云原生的战了。”","link":"/posts/5517bd46/"},{"title":"写给懒猫微服玩家的容器小书 Docker篇（四）：《数据之岛与持久化卷》","text":"一直想写一本容器小书，真好懒猫基本都做了容器化，所以把这部分分享出来。不同的是，懒猫微服中使用 pg-docker 来替代 docker 命令，使用 dockge 来执行 docker-compose。以下讲解以标准 docker 为主，这样子既学会了 docker 知识，也能够在懒猫微服上启动 Docker 服务。 《数据之岛与持久化卷》讲的是 Docker Volume 持久化数据方案、挂载宿主机目录、多个容器共享数据、自动创建卷、数据备份与恢复等🏝️ 开篇：数据会随浪消失有一天，小李运行了一个容器，里面的 Flask 项目能正常写入用户信息到 SQLite 数据库。可当容器一停止，再启动——所有数据消失了！ 老周说：“你的数据，被潮水带走了。” “Docker 容器默认的文件系统是临时的，只要容器删除，数据也就没了。想让数据真正存活，就要登上‘数据之岛’。” 🧠 基础概念：数据卷（Volume）Docker 提供了三种数据持久化方案： 方案 用法 场景 Volume Docker 管理的专属数据区 最推荐、安全、可多容器共享 Bind Mount 映射宿主机目录 更灵活，适合本地调试 tmpfs 临时存储在内存 适合敏感数据，重启即丢弃 本章重点讲解：Volume（数据卷） 与 Bind Mount（绑定挂载） 📦 第一节：使用 Volume 保存数据小李重新部署了 MySQL 容器，他决定为数据提供一个“保命空间”。 1docker volume create mysql-data 然后运行 MySQL 时挂载： 1234docker run -d --name my-mysql \\ -e MYSQL_ROOT_PASSWORD=123456 \\ -v mysql-data:/var/lib/mysql \\ mysql:5.7 -v 卷名:容器内目录：将卷挂载到容器内数据库文件存储位置。 容器即使删除，数据卷依然保留！ 查看所有卷：1docker volume ls 查看卷详细信息：1docker volume inspect mysql-data 输出中可以看到 Mountpoint，即数据在宿主机上的物理位置。 🧪 第二节：自动创建匿名/具名卷小李写了个简单的服务： 1VOLUME /app/data 每次 docker run 时，Docker 会自动生成匿名卷挂载到 /app/data。 但这类匿名卷难以追踪、管理，老周建议： “生产环境请用具名卷，并在运行时用 -v 显式指定。” 🔗 第三节：绑定挂载宿主机目录（本地调试神器）开发中，小李想把宿主机的项目代码直接挂进容器，不必每次重建镜像。 1234docker run -d --name dev-nginx \\ -p 8080:80 \\ -v /Users/xiaoli/site:/usr/share/nginx/html \\ nginx 本地 /Users/xiaoli/site 的代码实时反映在容器内网站目录，修改立刻生效！ 使用 Bind Mount 的场景： 本地开发热更新 日志文件落盘 配置文件映射 IDE + 容器联调 🤝 第四节：多个容器共享数据卷老周给小李展示了另一个高级玩法： “多个容器可以挂载同一个卷，共享数据，就像一块公共磁盘。” 小李准备两个容器： 一个容器写入日志 一个容器实时读取日志 123456789# 写入容器docker run -d --name logger \\ -v shared-logs:/logs \\ busybox sh -c &quot;while true; do date &gt;&gt; /logs/t.log; sleep 2; done&quot;# 读取容器docker run -it --name reader \\ -v shared-logs:/logs \\ busybox tail -f /logs/t.log 这两个容器在不联网的情况下，通过挂载卷实现了数据同步，让小李直呼神奇。 🔄 第五节：备份与恢复数据卷老周说： “你现在的数据安全了，但还不够。万一服务器挂了怎么办？你得学会备份。” 备份数据卷为 .tar：12345docker run --rm \\ -v mysql-data:/data \\ -v $(pwd):/backup \\ busybox \\ tar czf /backup/mysql-backup.tar.gz -C /data . ⛴️ 第一个挂载是数据卷，第二个挂载是宿主机当前目录，输出备份包。 恢复数据卷：12345docker run --rm \\ -v mysql-data:/data \\ -v $(pwd):/backup \\ busybox \\ tar xzf /backup/mysql-backup.tar.gz -C /data 只需备份 .tar.gz 文件即可，适合迁移数据、升级、容灾。 🧹 第六节：清理无用卷（慎用）随着实验多了，小李电脑堆满了无主卷。 查看： 1docker volume ls 清理： 1docker volume rm 卷名 清除所有未被挂载的孤立卷（慎用）： 1docker volume prune 清理命令要慎重，别误删生产卷！ 📋 Volume 挂载选项速查表 类型 命令 特点 匿名卷 -v /path 难追踪，系统自动命名 具名卷 -v myvol:/path 推荐用法，可管理 Bind 挂载 -v /host:/container 与宿主机文件交互，适合本地调试 tmpfs --tmpfs /path 内存存储，重启即消失 权限控制 -v myvol:/path:ro 只读挂载 SELinux/AppArmor :z、:Z（高级安全挂载） 安全增强场景 🧠 小李的应用持久化策略建议 类型 内容 数据库 必须挂载 Volume 保持数据持久 日志 推荐落盘到宿主机或集中采集 配置文件 可用 Bind Mount 从本地同步配置 静态资源 静态目录挂载 + CDN 临时缓存 tmpfs 或容器内路径，无需持久化 🎬 尾声：构建自己的数据之岛小李站在一个小岛码头，身后是一个个挂载卷，他的应用和数据终于脱离容器生命周期的束缚。 老周说： “真正的服务，要能容器随时销毁，数据却永存。” 小李点头，轻轻拍了拍他那卷 MySQL 的备份包，知道自己已经拥有了构建“数据之岛”的能力。 继续拓展高级内容，围绕： 🧪 数据卷在 CI/CD 中的作用和实战应用 ☸️ 数据卷在 Kubernetes 中的延伸 —— PVC（PersistentVolumeClaim）挂载 以小李的旅程为主线，继续带你掌握更强大的容器化数据策略。 🔧 拓展一：数据卷在 CI/CD 中的角色与实践在一次项目发布中，小李加入了公司的 DevOps 流水线。他发现 GitLab CI 跑测试时，每次都重新构建环境，速度太慢，还会出现缓存丢失的问题。 老周告诉他： “在 CI/CD 环境中，合理使用数据卷可以极大加快构建速度、保留缓存和数据状态。” ✅ 使用场景 1：缓存 pip/npm 依赖，加速构建小李把 pip install 改成挂载缓存目录： GitLab Runner 示例：.gitlab-ci.yml： 123456789101112131415cache: key: pip-cache paths: - .cache/pipbuild: script: - docker run --rm -v $CI_PROJECT_DIR:/app -v $CI_PROJECT_DIR/.cache/pip:/root/.cache/pip my-builder-image bash -c &quot; cd /app &amp;&amp; pip install -r requirements.txt &amp;&amp; pytest &quot; 🔁 依赖安装过程可被缓存，构建速度提升 50%！ ✅ 使用场景 2：测试数据隔离小李部署端到端自动化测试容器： 123docker run --rm \\ -v test-volume:/app/test-results \\ e2e-runner:latest 测试结果可从宿主机挂载目录或卷中提取，用于后续报告生成或持久存档。 ✅ 使用场景 3：构建产物跨阶段传递CI/CD 有多阶段：构建 → 测试 → 部署小李通过挂载共享卷，将编译好的前端包从构建容器传给部署容器： 12docker run --name builder -v build-volume:/output frontend-builderdocker run --rm -v build-volume:/usr/share/nginx/html nginx ☸️ 拓展二：Kubernetes 中的数据卷演进 —— PVC 实战进入云原生世界，小李不再直接使用 docker run，而是通过 Kubernetes 来编排容器。 在 K8s 中，数据卷概念变得更专业： Volume（临时存储，随 Pod 生命周期） PersistentVolume（PV：管理员创建的存储资源） PersistentVolumeClaim（PVC：用户申请的存储） StorageClass（存储策略模板） 🔐 场景一：部署 Stateful 服务（如 MySQL）小李写了以下 YAML： 123456789101112131415161718192021222324252627282930313233343536373839apiVersion: v1kind: PersistentVolumeClaimmetadata: name: mysql-pvcspec: accessModes: - ReadWriteOnce resources: requests: storage: 5Gi storageClassName: standard---apiVersion: apps/v1kind: Deploymentmetadata: name: mysqlspec: replicas: 1 selector: matchLabels: app: mysql template: metadata: labels: app: mysql spec: containers: - name: mysql image: mysql:5.7 env: - name: MYSQL_ROOT_PASSWORD value: &quot;123456&quot; volumeMounts: - mountPath: /var/lib/mysql name: data volumes: - name: data persistentVolumeClaim: claimName: mysql-pvc 💡 PVC 是 “我要一个 5Gi 的盘”，PV 是“管理员给你一个”，Pod 中挂上它即可持久保存数据。 🧠 小知识点：K8s 中 Volume 的对比 类型 生命周期 是否持久 典型用途 emptyDir Pod 生命周期 ❌ 临时缓存、构建产物传递 hostPath 节点目录挂载 ⚠️ 有风险 本地开发测试 PVC（推荐） 与集群存储绑定 ✅ 数据库存储、日志、持久缓存 📦 StorageClass：自动动态分配 PVC在云环境（如 EKS、GKE）中，PVC 可以自动创建对应的 PV（EBS、Ceph、NFS 等），只要指定 StorageClass 即可： 1storageClassName: gp2 这种方式可以实现跨节点迁移不丢数据、按需付费扩容、快照备份等高级功能。 ✅ 拓展总结：Docker 到 CI/CD，再到 Kubernetes 的数据策略演进 场景 技术 推荐做法 本地开发 Bind Mount 映射目录，实时更新 本地持久化 Volume 隔离性好，便于管理 CI/CD 中间数据 卷 / 缓存目录 挂载 .cache、build 等路径 K8s 中数据存储 PVC + StorageClass 可扩展、可备份、可跨节点持久化 🎬 尾声：从数据孤岛到分布式星图在 DevOps 流水线中，小李用数据卷构建了无缝衔接的构建流程； 在 Kubernetes 集群中，他用 PVC 实现了跨集群节点的 MySQL 数据持久化部署； 他站在云端存储的星图前，知道自己已经掌握了从 Docker 到 DevOps 再到 Kubernetes 的数据生命周期。 老周拍拍他： “你已经造好了船，也撑起了帆。下一步，是用 Compose 编排你的舰队。”","link":"/posts/8b5626cb/"},{"title":"写给懒猫微服玩家的容器小书Docker篇（五）：《多容器交响曲：Docker Compose 上场》","text":"一直想写一本容器小书，真好懒猫基本都做了容器化，所以把这部分分享出来。不同的是，懒猫微服中使用 pg-docker 来替代 docker 命令，使用 dockge 来执行 docker-compose。以下讲解以标准 docker 为主，这样子既学会了 docker 知识，也能够在懒猫微服上启动 Docker 服务。 《多容器交响曲：Docker Compose 上场》讲的是使用 Docker Compose 统一编排多容器服务，理解 YAML 配置结构、服务依赖、网络、挂载、构建策略、变量管理、Compose vs K8s 初探等 🎼 开篇：服务之间的管弦乐团随着项目日益复杂，小李的服务已经不再是一个容器就能承载的了。 前端、后端、数据库、缓存、日志系统……像一个交响乐团，需要统一调度、和谐配合。 老周递给他一个新的工具：“Docker Compose——它是你的指挥棒。” 🎻 第一节：什么是 Docker Compose？老周解释： “Docker Compose 是 Docker 的多容器编排工具，用一份 docker-compose.yml 文件，就能同时启动、停止、构建多个服务。” Compose 帮你解决： 多个服务启动顺序 多容器共享网络 统一管理环境变量 配置简洁、开发者友好 跨平台部署一致 📄 第二节：写出你的第一个 docker-compose.yml小李的项目结构如下： 12345678myapp/├── backend/ # Flask 应用│ ├── app.py│ └── Dockerfile├── frontend/ # 静态页面│ ├── index.html│ └── Dockerfile└── docker-compose.yml docker-compose.yml 示例：1234567891011121314151617181920212223242526272829version: &quot;3.9&quot;services: backend: build: ./backend ports: - &quot;5000:5000&quot; volumes: - ./backend:/app environment: - DB_HOST=db depends_on: - db frontend: build: ./frontend ports: - &quot;3000:80&quot; db: image: mysql:5.7 environment: - MYSQL_ROOT_PASSWORD=123456 - MYSQL_DATABASE=mydb volumes: - dbdata:/var/lib/mysqlvolumes: dbdata: 🔧 每个 service 就是一个容器定义，Compose 会为它们创建默认网络，自动 DNS 互通。 🧪 第三节：Compose 命令实战速查小李在项目目录下运行： 1docker-compose up -d 后台启动所有服务！ 其他常用命令： 操作 命令 构建镜像 docker-compose build 后台启动 docker-compose up -d 前台启动 + 日志输出 docker-compose up 停止服务 docker-compose down 查看容器日志 docker-compose logs [服务名] 重启某个服务 docker-compose restart 服务名 进入某个容器 docker-compose exec 服务名 bash 📦 第四节：Compose 的网络与数据共享机制老周介绍： “Compose 默认创建一个网络，所有服务能通过服务名互相访问。” 在上面的例子中： backend 容器可以用 db:3306 连接 MySQL frontend 可通过 backend:5000 访问后端 API 小李不再需要手动 docker network create 和 --network 参数，Compose 一切自动打通。 Volume 的挂载：Compose 中的 volume 显式声明（如 dbdata:）会自动创建、管理。 支持： 1234volumes: - ./data:/data # Bind mount - myvolume:/data # Named volume - /custom/path:/data:ro # 带权限控制 🌐 第五节：使用 .env 管理配置变量Compose 支持使用 .env 文件集中管理变量： .env 文件： 12DB_PASSWORD=123456DB_NAME=mydb Compose 文件中使用方式： 123environment: - MYSQL_ROOT_PASSWORD=${DB_PASSWORD} - MYSQL_DATABASE=${DB_NAME} 🚀 配合 CI/CD 时 .env 可由流水线动态生成，便于多环境切换（dev/stage/prod）。 🧬 第六节：高级配置技巧1. 统一重启策略：1restart: unless-stopped 确保服务宕机时能自动重启。 2. 多阶段构建支持：123build: context: ./backend dockerfile: Dockerfile.prod 可指定构建路径、Dockerfile 文件、构建参数等。 3. Healthcheck 健康检查：12345healthcheck: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:5000/health&quot;] interval: 30s timeout: 10s retries: 3 🆚 第七节：Docker Compose vs Kubernetes 简析 特性 Compose Kubernetes 启动容器 简单 标准化 配置语言 YAML YAML 网络 自动共享 需显式配置 存储 Volume PVC + SC 服务发现 服务名互通 DNS/ClusterIP 用途 本地开发 / CI 集群部署 / 云原生 高可用 / 伸缩 ❌ ✅ 内建 社区生态 中小项目广泛使用 大型平台标准方案 小李理解了：Compose 是“轻量乐队指挥”，K8s 是“交响级 AI 指挥系统”。 🔁 第八节：Compose + CI/CD 集成发布小李将 Compose 整合进 GitLab CI 流程： .gitlab-ci.yml 示例： 12345678910111213141516services: - docker:dindstages: - build - deploybuild: stage: build script: - docker-compose builddeploy: stage: deploy script: - docker-compose up -d CI 构建完镜像后，直接用 Compose 部署，既省事又稳定。 🧠 小李 Compose 使用技巧总结 目标 技巧 服务隔离 每个项目单独一个 Compose 文件 共享网络 不用写 network，服务名即 DNS 跨环境配置 使用 .env 动态切换变量 状态排查 docker-compose logs / ps / exec 多环境文件 使用 docker-compose.override.yml CI/CD 联动 编排命令嵌入流水线任务中 🎬 尾声：指挥容器交响曲的时刻当小李敲下 docker-compose up 的回车键，前端、后端、数据库同时启动，日志齐鸣，服务稳定运行。 “这就是我梦想的微服务协奏曲啊。” 老周拍了拍他肩膀： “你已经能用 Compose 驾驭服务之海，下一步，是把它们部署上云、扩展弹性、自动滚动升级。” 小李点头，望向远方的集群编排系统——Kubernetes，眼中闪着新的渴望。 好！那我们就在第五章《多容器交响曲》中，继续深入补充这四大实战技能： 🧩 补充一：Compose 的多环境部署实践（开发、测试、生产）小李希望同一套服务，在开发、测试、生产环境下分别使用不同的配置，比如： 数据库密码不同 是否挂载本地代码 是否启用调试模式 老周教他使用 Compose 的多文件配置机制： ✅ 方案一：使用 docker-compose.override.ymlDocker Compose 默认会自动加载 docker-compose.override.yml 并与主文件合并。 文件结构：1234docker-compose.ymldocker-compose.override.yml.env.dev.env.prod 主配置（docker-compose.yml）：1234567services: web: build: . ports: - &quot;8000:8000&quot; environment: - ENV_MODE=${MODE} 开发环境覆盖文件（docker-compose.override.yml）：123456services: web: volumes: - ./src:/app/src environment: - DEBUG=true 运行： 1MODE=development docker-compose up ✅ 方案二：按环境拆分多个 Compose 文件适合 CI/CD 或部署多个 stage。 示例： docker-compose.dev.yml docker-compose.prod.yml 运行： 1docker-compose -f docker-compose.yml -f docker-compose.dev.yml up -d 多个 -f 会按顺序合并，后面覆盖前面。 📦 建议主文件写“公共配置”，子文件按环境细化。 🎯 补充二：优化服务依赖启动顺序小李发现，即使写了 depends_on，后端有时候也连不上数据库。 老周摇头说： “depends_on 只是控制启动顺序，不是等服务就绪。数据库可能还没监听端口就已被标记为 ‘up’。” ✅ 正确姿势：服务内设置“等待就绪”比如 Flask 等数据库： 1234567#!/bin/bashuntil nc -z db 3306; do echo &quot;Waiting for db...&quot; sleep 1donepython app.py 或者使用工具包如 wait-for-it.sh： 12COPY wait-for-it.sh /wait-for-it.shENTRYPOINT [&quot;/wait-for-it.sh&quot;, &quot;db:3306&quot;, &quot;--&quot;, &quot;python&quot;, &quot;app.py&quot;] 🩺 推荐结合容器健康检查，判断服务是否真正 ready。 🛠 补充三：Docker Compose V1 ➜ V2 迁移技巧小李的 CI 工具用的是 Compose v1，项目准备升级。 老周提醒： “Docker Compose v2 使用的是 docker compose（空格），而非 docker-compose（短横线）。” ✅ 主要变化： 项目 v1 (docker-compose) v2 (docker compose) 命令格式 docker-compose up docker compose up 安装方式 独立二进制 集成于 Docker CLI 文件格式 v2, v3 推荐统一 v3.9 ✅ 迁移建议： 删除旧的 docker-compose 二进制 使用 docker compose CLI 更新脚本、CI 工具调用方式 移除 legacy 字段（如 links） 检查 .env 是否兼容（v2 更严格） ☸️ 补充四：Compose 与 Helm 的映射关系对照当小李进入 Kubernetes 世界，他问老周： “Compose 文件和 K8s 的 YAML 有啥对应关系？” 老周说：“很好理解，Compose 是开发者的 K8s 简化版本。” 对照表： Compose Kubernetes services: Deployment + Pod volumes: PersistentVolumeClaim ports: Service（NodePort / ClusterIP） depends_on: initContainers 或 readinessProbe .env ConfigMap / Secret docker-compose.yml Helm Chart (values.yaml + templates) 示例：Compose 转 Helm 构思Compose 配置：1234567services: web: image: myapp:latest ports: - &quot;8080:80&quot; environment: - DEBUG=true Helm values.yaml：1234567891011image: repository: myapp tag: latestenv: - name: DEBUG value: &quot;true&quot;service: port: 8080 targetPort: 80 Helm deployment.yaml（模板）：12345678containers: - name: web image: {{ .Values.image.repository }}:{{ .Values.image.tag }} env: {{- range .Values.env }} - name: {{ .name }} value: {{ .value }} {{- end }} ✅ 小李意识到，Helm 是“模板化 + 分层管理”的 Compose 超集，是云原生部署的标准组件管理器。 🎬 尾声：Compose 是微服务上云的跳板小李已经用 Docker Compose 实现了： 开发环境热更新 测试环境集成数据库 生产环境独立配置 CI/CD 自动部署服务 为 Kubernetes 迁移打下基础 他明白了： “Compose 就像舞台排练，Kubernetes 才是真正的大型音乐厅。但有了排练，登台才不会慌。”","link":"/posts/61cfcd24/"},{"title":"懒猫微服入门篇（零）：开箱初探，硬件亮相","text":"用了一个半月的懒猫微服，来写一个伪开箱。机甲风格外壳也得值个几百块，这个外壳还支持拆机之后全身水洗。在桌面上确实颜值很高，在各个小主机都是塑料外壳的时代，属于用心良苦了。 这张图是创始人在用户群里发的实拍图： 据群友们聊天说，这台机器已经经过了多个版本迭代，最后定型为现在这个样子。以后不要再用鞋盒了。 系统与配置通过 neofetch 可以看到，这台机器预装的是 Debian 12，实际系统也做了不少魔改优化。核心配置如下： CPU：Intel Core i5-1155G7 @ 4.5GHz（4 核心 8 线程），相当于现在主流的 N305 强了很多。 内存：笔记本内存 DDR4，最大可扩展至 32GB，3200MHZ （买的时候可以谈从 16G 升级到 32G） 显卡：Intel Iris Xe Graphics，英特尔最强核显，核显频率最高 1.35GHz，支持 4K 高清输出与 H.265 视频硬解 存储： 系统盘：512GB PCIe 4.0 NVMe，用于运行系统组件和保存根目录文件。 数据盘：两个 2.5 寸 SATA 盘位，可以组 RAID0 或者 RAID1。SSD 或者 HDD 不限。 主板：看上是自己做的，叫做 YENTEK LC2580，启动热键是 F11，进入 BIOS 的按键是 &lt;DEL&gt; 。 没有锁 BIOS，也支持刷成其他的系统。 运行 dmidecode 可见内存状态如下： 12345678910sudo dmidecode -t memory | grep -e &quot;Size&quot; -e &quot;Form Factor&quot; -e &quot;Locator&quot; Size: No Module Installed Form Factor: Unknown Locator: Controller1-ChannelA-DIMM0 Bank Locator: BANK 0 Size: 32 GB Form Factor: SODIMM Locator: Controller0-ChannelA-DIMM0 Bank Locator: BANK 0 ... 网络性能网络配置方面也比较主流： 有线：2.5G 单网口，可惜我的路由器还是千兆不能完全发挥其能力 无线：Intel AX210，支持 WiFi 6 可以跑满千兆。 12345(base) lzcbox-029c588e ~ # dmesg | grep -i ethernet[ 2.946824] Intel(R) 2.5G Ethernet Linux Driver[ 9.157839] Bluetooth: BNEP (Ethernet Emulation) ver 1.3(base) lzcbox-029c588e ~ # lspci | grep -i network04:00.0 Network controller: Intel Corporation Wi-Fi 6 AX210/AX211/AX411 160MHz (rev 1a) 于 WIFI6 来说协商速率一般是 2402Mbps，所以就算达到协商速率的一般的话，也就是差不多千兆，加上很多家用路由也仅仅是千兆，我为了 POE 供电所以牺牲了部分内网带宽，所以没有跑满。如果你有 2.5G 的机器和交换机，那么一定可以跑的很舒服，基本就到机械硬盘的上限了。 CPU 性跑分跑了几次 geekbench6，能够看到单核心的性能有 1700+，由于测速的同时还在运行很多系统应用，所以实际的数值比这个还要大一些。 后面用了 EndeavourOS KDE 的随身碟，能够看到单核心分数还能再提升。这个 CPU 跑 docker，K8S 甚至虚拟机都没啥问题了。 外部接口机器背部接口一览，我这边插了一张采集卡，非常实用： 接口方面也非常丰富： USB：USB 3.0 x3 Type-C：USB 3.2 Type-C x2，支持反冲保护 视频输出：HDMI 2.1 x1，支持 4K 输出、多声道音频 音频接口：3.5mm 耳机口，支持高阻抗耳机 电源接口：DC 5525 整机搭载一枚 17mm 涡轮静音风扇，结合滚珠轴承与自研调速算法，实际体验确实安静，确实没有 3.5 寸硬盘那种炒豆子的声音了。 可以看到 Deepin 的 团队出来做产品的能力还是挺强的，从主板到 OS 的深度定制，技术功底可见一斑。 下面是群友的发的效果图，实物质感确实很棒，欢迎找我下单体验！","link":"/posts/4022bac/"},{"title":"懒猫微服实战入门（一）： 从开启SSH到免密登录，一步步教你搞定远程管理","text":"对于很多资深的 NAS 玩家来说，拿到一台机器首先要配置远程登录和环境依赖。懒猫上其实可以实现云计算讲的 Iass - Pass -Sass 这三个层级，不过对于资深玩家而言，肯定是要从 Infra 这个级别入手的。 官方文档如下：https://developer.lazycat.cloud/ssh.html 安装懒猫开发者工具，然后再右上角能够看到 sshd 服务的状态。然后点击开启，之后我们才可以使用 ssh 登录，在写这篇文章测试的时候，我关闭了这个按钮，再去 ssh 直接就报错了。 默认是 root 身份登录，密码在开发者工具里启动的时候设置： 1ssh root@&lt;your-service-name&gt;.heiyu.space 如果觉得密码麻烦，也可以导入密钥，更加安全： 1ssh-copy-id -i ~/.ssh/id_ed25519 root@xxxxx.heiyu.space 输出如下： 1234567891011/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/Users/xu/.ssh/id_ed25519.pub&quot;/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysroot@micro.heiyu.space's password:Number of key(s) added: 1Now try logging into the machine, with: &quot;ssh -i /.ssh/id_ed25519 'root@xxxx.heiyu.space'&quot;and check to make sure that only the key(s) you wanted were added. 如果觉得 root 用户不安全的话，可以新建一个日常用户，然后加到 docker 组里面，也能正常使用 docker 123456sudo useradd -m -s /bin/bash user1usermod -aG docker user1usermod -aG sudo user1 如果遇到到 root 组会有无法使用 sudo 的问题，请独立安装，sudo 是单独的软件包,需要安装才有.并不是所有 Linux 都有 sudo 1apt update &amp;&amp; apt install sudo 注意：要开着懒猫微服 APP ，否则无法使用 heiyu.space 提供的穿透服务。","link":"/posts/56f9b737/"},{"title":"懒猫微服实战入门（十）：通过 nmtui 设置静态 IP，接入旁路由实现科学上网","text":"日常开发中，我主要使用的是 MacBook 作为主力机。但有些软件、驱动或容器服务必须在 X86 架构环境下测试，这时懒猫微服就是一个很好的辅助平台。然而在一些网络场景下，为了访问特定服务，还需要将这台设备接入旁路由中。 不然我访问 Dockerhub 是这样的，经常会超时，只能用不是很全的镜像站。 群晖等设备提供的图形化网络面板，懒猫微服这类轻量系统没有 GUI，只能使用命令行工具。NetworkManager 提供了一个非常好用的文本界面工具：nmtui。 什么是 nmtuinmtui 是 NetworkManager 的 TUI（Text-based User Interface）组件，界面类似简化版 GUI，操作简单，功能却很强大。通过它，我们可以方便地完成以下配置： 选择并连接网络设备（有线或无线） 设置 手动 IP 地址 指定 网关、DNS 服务器 管理 路由策略 开启或关闭 DHCP 自动获取功能 命令如下： 1nmtui 设置静态 IP 接入旁路由打开 nmtui 后，进入“Edit a connection”，编辑你连接的网卡（如 enp2s0），手动设置 IP 地址、网关和 DNS。如下图所示，我将所有网络解析都指向了旁路由（比如是 OpenWrt 或其他带翻墙能力的设备）： 确保设置完成后，运行以下命令重新应用配置： 1nmcli device reapply enp2s0 如果配置无误，网络将立即切换到静态 IP 并走旁路由的网关。 验证效果这样子终端就能下载 Docker image 了，其实到这一步已经完成了。 接下来，可以通过懒猫微服中安装的浏览器测试网络是否生效。 继续打开 YouTube 首页，也能顺利访问并加载视频页面： 你没看错，这是 浏览器里的浏览器，实现了一个“浏览器套娃”的效果。😂 最终，我播放了银临的《牵丝戏》，人美歌也好听～","link":"/posts/b704f5f8/"},{"title":"懒猫微服实战入门（十一）：一键换源指南：用 chsrc 开启丝滑体验","text":"最近懒猫微服的系统固件进行了更新，默认的软件源重新指向了国际源。估计是为了方便海外用户，但对于国内开发者来说，访问速度顿时大打折扣，软件安装和更新频繁卡在连接阶段，着实是一个问题。 正巧群友推荐了一个神器 —— chsrc。这个工具支持一键切换系统、Python、conda 等多个主流组件的源，简洁高效，非常适合懒猫微服这样的轻量环境使用。 下载并安装 chsrcchsrc 项目在 Gitee 上提供了预编译的可执行文件，适用于不同架构的 Linux 设备。我当前使用的是 x86_64 架构，因此只需运行以下命令： 12curl -L https://gitee.com/RubyMetric/chsrc/releases/download/pre/chsrc-x64-linux -o chsrcchmod +x ./chsrc 下载后，为了方便使用，我们通常会把它加入环境变量。但懒猫微服的一个特殊机制是：除了 /root 目录，其他目录在每次重启后都会被重置。这意味着如果你将 chsrc 放在 /home 或 /usr/local/bin 之类的目录，它在下次重启后可能就不见了。 所以我将 chsrc 的二进制文件移动到了 /root/app 下（可以新建这个目录），并在 ~/.bashrc 中手动追加了环境变量： 1export PATH=/root/app:$PATH 这样每次打开 shell 时，系统就会自动把 chsrc 所在路径加入 $PATH，确保我们可以直接使用 chsrc 命令。 一键更换 Debian 软件源懒猫微服是基于 Debian 的发行版，因此可以直接运行： 1chsrc set debian 运行后，工具会先检测系统当前源格式（支持新版 deb822），然后测速多个国内镜像源（如清华、中科大、阿里等），自动选择最快的源进行替换，整个过程完全自动化，再也不用去网上搜帖子找各种源了。 更换 Python 镜像源除了操作系统本身的源之外，也能更换 Python，node 这样的源。 我制作了一个 Miniconda 的一键安装脚本，用来替代系统自带的 Python3.11，用 conda 虚拟环境管理起来很方便。 12345678910111213141516171819202122232425#!/usr/bin/env bashset -e# 1. 下载最新 Miniconda 安装脚本echo &quot;📥 正在下载 Miniconda 安装器...&quot;MINICONDA=Miniconda3-latest-Linux-x86_64.shwget https://repo.anaconda.com/miniconda/$MINICONDA -O /tmp/$MINICONDA# 2. 静默安装到 ~/miniconda3echo &quot;⚙️ 正在静默安装到 ~/miniconda3...&quot;bash /tmp/$MINICONDA -b -p $HOME/miniconda3# 3. 添加到 PATH（写入 .bashrc）echo &quot;🔧 正在将 Miniconda 添加到 PATH...&quot;CONDA_INIT='export PATH=&quot;$HOME/miniconda3/bin:$PATH&quot;'if ! grep -q &quot;$CONDA_INIT&quot; ~/.bashrc; then echo &quot;$CONDA_INIT&quot; &gt;&gt; ~/.bashrcfi# 4. 初始化 conda（非交互式）$HOME/miniconda3/bin/conda init bash# 5. 提示用户刷新 shellecho &quot;✅ 安装完成！请运行以下命令以立即生效：&quot;echo &quot; source ~/.bashrc&quot; 这个脚本的好处是全程自动化，不需要你动手点选目录，也不必一步步设置环境变量，适合懒猫开发者在新设备或系统还原后快速恢复工作环境。 安装好 Miniconda 之后，就可以利用 chsrc 来更换 pip 源了： 1chsrc set python 此命令会将 pip 的默认源改为清华源或豆瓣源等国内镜像，提高模块下载速度，彻底告别“卡在安装 xx 模块”的窘境。 最后一步，把 conda 的源也换成国内的。直接执行： 1chsrc set conda 然后需要手动更新 .condarc 配置文件。 小结这次我体验了 chsrc 在懒猫微服上的完整使用链路，感受可以总结为三句话： 能跑就行？不，要跑得快。 别用默认源，懒人换源有奇效。 系统、Python、Conda，一条龙解决卡顿。 如果你也在用懒猫微服、或者在其他 Debian 系的轻量服务器上摸索开发环境，强烈推荐你试试这个工具和脚本组合。毕竟，“懒得配置”不应该成为“卡在配置”的理由。","link":"/posts/eef881d4/"},{"title":"懒猫微服实战入门（十二）：用 iVentoy 打造你的 PXE 服务器","text":"很多介绍 Linux 的书籍都会在结尾推荐 PXE 装机方式，尤其是经典的 TFTP + Kickstart 自动部署方案。但在普通家庭或轻量办公环境中，这种方式显得有些繁琐。在 U 盘装机的环境中，我一般使用的 Ventoy多合一 。不过 Ventoy 团队又推出了一个支持 PXE 的装机版本，名为 iVentoy，和 WDS 类似，不过更加省心，这个应用已经上架懒猫微服的应用商店，非常适合内网多机装系统的场景。终于不用再琢磨 WDS 了。还有就是之前不小心用店家带的 U 盘把主机的所有数据都格式化了，这种手残也一去不复返了。 什么是 PXE 无盘装机？PXE，全称 Preboot eXecution Environment，是一种允许电脑在没有本地操作系统、光盘或 U 盘的情况下，通过网络从服务器下载引导程序并完成系统安装的机制。 PXE 装机简化流程如下： 1234567891. 开机 → BIOS/UEFI 设置为从网卡启动（PXE Boot） ↓2. 客户端通过网卡发出 DHCP 请求 → 获取 IP 和引导文件地址 ↓3. 通过 TFTP 下载启动文件（如 pxelinux.0 或 iPXE） ↓4. 加载内核（vmlinuz）和安装器（initrd.img） ↓5. 进入图形界面或执行自动化系统安装 PXE 装机适用场景 大量办公电脑或服务器的系统部署 设备没有 USB 接口或启动盘时 多系统测试、系统重装、快速恢复环境 各类 PE 工具、Linux Live 系统启动 懒猫微服 上 iVentoy 装机体验以下是我在懒猫微服环境中使用 iVentoy 的全过程： 1. 上传系统镜像进入懒猫的应用数据目录：应用数据 - Iventoy - ISO将你准备好的 Windows / Linux ISO 文件上传到此路径。 2. 启动 iVentoy，配置网络确保机器在内网下有一个 有效的 IPv4 地址，然后启动 iVentoy。 3. BIOS 设置启用 PXE进入待装机设备的 BIOS，确保启用 PXE Boot / 网络启动功能。 4. 插网线，选择 PXE 启动启动设备，确保插入网线（无线网卡 PXE 启动通常不被支持），从网卡启动。 5. 自动进入 iVentoy 引导菜单如果网络配置无误，设备会自动弹出引导菜单，可以看到之前上传的 ISO 镜像。 选择一个系统镜像，回车进入即可，相当于将 ISO 当成 LiveCD 使用。 6. 成功进入桌面系统以 Pop!_OS 为例，系统已经顺利启动，无需任何 U 盘！ 小结这个办法还是适合炫技，把电脑接上网线，然后不用 U 盘，凭空装好系统，不过还是没有 U 盘那么丝滑，有时候不能打满千兆带宽。不过假如手头 U 盘不够用，或者要在多个系统反复装机测试就很方便了。","link":"/posts/9d1544e0/"},{"title":"懒猫微服实战入门（十三）：懒猫穿透不只图形化，纯命令行服务器也可以","text":"需要解析 heiyu.space 这个域名就得安装客户端，突然发现懒猫微服的客户端都是图形化界面。对于服务器环境，特别是没有图形界面的服务器，我们需要纯命令行解决方案。 随着公网 IPv4 地址即将枯竭，许多云厂商的学生机也不再提供公网 IP，这迫使开发者寻找异地组网方案。虽然 Tailscale 是一个可选方案，但作为懒猫微服用户，我更希望利用懒猫自带的组网功能实现这一需求。 在 VIP 群咨询后，获得了服务端组网工具：https://gitee.com/lazycatcloud/hclient-cli 和花生壳的 CLI 类似，但是比花生壳省心多了。（这里不再过多吐槽花生壳系列了） 安装与配置1. 下载与初始运行12chmod +x ./hclient-cli-$arch # 首次启动需要添加可执行权限./hclient-cli-$arch 初始运行会提示：当前为非 tun 模式,仅支持通过 http 代理访问微服或其他设备资源 然后就会提示当前为非 tun 模式,仅支持通过 http 代理访问微服或其他设备资源，也就是说现在是单项的组网，这肯定不是我的要求，然后 GPT O3 给了我一个答案。 2. 启用 TUN 模式1sudo ./hclient-cli-$arch -tun true 再启动之后，就没有那个 TUN 模式的提示了。如下 3. 常用命令然后需要使用命令添加，bname 是机器的名字，uid 和 password 是用户名和密码，这样就保证了全球唯一性质，执行完第一步的时候已有的客户端会弹出验证码，执行完第二步就会消失。 1234567891011121314# 添加微服curl -X POST 'http://127.0.0.1:7777/add_box?bname=%s&amp;uid=%s&amp;password=%s'# 设置TFA Code（两步验证码）curl -X POST 'http://127.0.0.1:7777/add_tfa?bname=%s&amp;tfa=%s'# 列举微服curl 'http://127.0.0.1:7777/box_list'# 删除微服curl -X DELETE 'http://127.0.0.1:7777/del_box?bname=%s'# 查看当前客户端信息curl 'http://127.0.0.1:7777/client_info' 在懒猫微服设备监控中可以看到加入的设备。 2. 访问验证一开始去访问我写的面食比例计算机，发现了重定向了，才想到懒猫默认给所有的应用加了一个认证。 1234&lt;a href=&quot;https://micro.heiyu.space/sys/login?redirect=https%3A%2F%2Fflour-calc.name.heiyu.space%2F&quot; &gt;Temporary Redirect&lt;/a&gt;. 3. 双向访问测试商店里的 elasticsearch 放行了所有路由，这样我们在终端和 SDK 就不再需要走那个 web 的验证了，不然只能在请求头里面硬塞 cookie，但是如果是多层认证就非常的难搞。从图片中可以看到，我们从云服务器可以成功访问到家里的懒猫微服了。这个代表从云服务回到家里时没有问题的。 4. SSH 访问测试其实更多的时候我们的异地组网是为了能够在没有公网 IP 的情况下访问节点，查一下监控设备中的域名，然后 ssh 访问进去，发现基本没什么问题。所以就能够双向访问了，这样我们组网的目的就达到了。 总结通过懒猫微服的 CLI 工具，我们成功实现了： 无图形界面服务器的穿透接入 双向网络访问","link":"/posts/3d7a2d17/"},{"title":"懒猫微服实战入门（十四）：不登录客户端，如何用 Samba 挂载懒猫微服网盘？","text":"懒猫微服网盘自带自动挂载 Samba 功能，但如果不登录客户端，也可以手动通过微服的私有地址来挂载，实现访问和高速传输。 由于懒猫网盘采用多租户架构，每位用户的数据是隔离的。因此，访问路径通常为： 1smb://&lt;ip&gt;/&lt;用户名&gt; 🧩 步骤一：开启内网访问服务在开始挂载前，请确保你已在懒猫微服后台开启了“内网访问服务”，否则 SMB 连接会被拒绝。 💡 回忆一波上机考试的方式以前在上机考试时，老师会将题目放在服务器共享目录中，我们用 Win + R 输入 \\\\IP地址 来下载资料，当时还觉得这操作很高端。 解释：这是通过 Win + R 快捷键打开“运行”窗口，输入 \\\\&lt;IP&gt; 快速访问局域网 SMB 共享目录。通常用于临时打开文件夹，不做映射。 🐧 macOS/Linux 挂载方式（CLI）在 Linux 或 macOS 上，可以直接用以下地址挂载： 1smb://&lt;ip&gt;/Download 或者通过 mount.cifs： 1sudo mount -t cifs //192.168.1.100/your-username /mnt/share -o user=your-username,password=your-password 🪟 Windows 上手动挂载 SMB 网盘在 Windows 中，需要通过图形界面手动挂载为本地磁盘，操作如下： 第一步：右键“此电脑” → 映射网络驱动器 解释：在这里你可以： 选择盘符（建议使用末尾的 Z:, Y:, X: 等）； 输入共享路径（例如 \\\\192.168.1.100\\your-username）； 可勾选“使用其他凭据连接”等选项。 第二步：确认挂载路径并验证身份系统将提示输入用户名和密码： 第三步：挂载成功，查看 Z 盘内容成功后，可以在“此电脑”中看到挂载好的 SMB 网络盘： 你可以像操作本地硬盘一样打开、拖拽、复制文件。 打开挂载目录后的界面如下： 🚀 实测传输速度：约 500MB/s我测试了一下，将文件从 SMB 网盘拖入 PVE 虚拟机，传输速度稳定在 500MB/s，表现不错。","link":"/posts/86ecba8b/"},{"title":"懒猫微服实战入门（十五）：大疆Pocket3 素材导入懒猫网盘","text":"日常使用 Pocket3 拍摄视频，就是共享比较麻烦，不然就得每个手机安装一个 app，然后再导出。突发奇想可以把素材传到懒猫网盘中，这样就解决了这个痛点。 大疆的机器每次连接都要走这个流程，不得不说真的很麻烦。这个 Wi-Fi 的记忆功能比较鸡肋。 连接之后需要右上角先把视频下载到手机本地，然后点击分享。 这里可以选各种软件，比如 airdrop，微信，邮件。我这里选懒猫微服，点击之后就会跳转到懒猫网盘。 第一次传输我发现速度慢的离谱。询问了售后才发现 ios 会默认在 wifi 网络不好时走流量的。 因为大疆的 pocket3 传输需要连接相机的 Wi-Fi。所以手机是整个一断网额的状态。这流量也不快。 偷偷跑流量是手机和运行商的传统了，那么在蜂窝网络里给他关掉。关掉无线局域网助理。 关了之后，再重复上边的操作，就发现懒猫网盘打不开了，嗯 这就是预期的行为了，不会偷偷的用网了。 于是询问大疆额售后能不能让机器连接家里的网，得到的回答是不行。只能手动切换 Wi-Fi。 换了网之后再传输，这个速度就舒服多了，虽然没跑满千兆，但是也能够看了。 然后把上一步的视频文件夹共享出来，以后把素材都发到这个文件夹里。再共享给其他的懒猫用户，就很方便了。 两个很想吐槽的地方 大疆 pocket3 不能直接连家里 Wi-Fi，传文件到网盘必须换网 Apple 的 lighting 原生不支持 OTG，需要买转接头。","link":"/posts/50f8f5d2/"},{"title":"懒猫微服实战入门（十六）：把懒猫微服当作 24 × 7 在线开发机","text":"最近和极限科技沟通，将 INFINI Console 上架到懒猫微服。可以当作随时可用、不关机的 远程开发机。比如连接自己部署的 ES，中间件，数据库什么的。 1. 应用商店一键安装 INFINI Console从懒猫微服应用商店搜索 Console，点击“安装”即可： 2. 初始化与登录初始化之后登录： 首次登录后台，左侧侧边栏包含 Dashboard、Agents、Settings 等模块： Dashboard 默认展示 CPU / 内存 / 磁盘实时曲线。 顶栏可切换“明暗主题”并显示当前工作区 ID。 右下角有“检查更新”按钮，提示有新版时可一键升级。 3. 用 Dockge 安装 EasysearchES 的话，我是直接用 Dockge 安装的，如果你需要啥中间价，数据库都可以用这个安装。 前提需要用 lzc-cli appstore copy-image 来获取国内的镜像源： 12# 将官方镜像复制到懒猫内网仓库lzc-cli appstore copy-image infinilabs/easysearch:1.13.0-2159 然后把 docker run 或 docker-compose.yml 中的镜像地址替换成上一步生成的私有 registry 地址即可。全部容器由 Dockge 图形化管理：（截图信息要点） Dockge 左侧列出所有 Stack，右侧显示 Easysearch 服务状态为 Running。 端口 9200 已自动映射，重启、查看日志，都能一键完成。 4. 为什么说它适合做开发机？ 需求 懒猫微服能力 体验亮点 24 × 7 在线 独立云主机，自动重启、监控告警 关掉本地电脑，服务仍在运行 x86 架构 后端统一使用 x86 节点 对 Mac M 系列（ARM）用户，可避免本地编译兼容性问题 多端远程开发 内置 Web Shell、端口映射、域名分配 VS Code Remote / JetBrains Gateway 秒连接 镜像同步 lzc-cli appstore copy-image 国内网络下拉镜像不超时 中间件生态 Dockge + Compose RabbitMQ、Redis、Postgres 都能一键启动 环境变量管理 UI + .env 托管 私密信息集中维护，避免泄漏 总结下来，把懒猫微服当作一个可远程访问的轻量开发机还是挺合适的： 不用担心公网 IP 和端口映射 应用商店部署方便快捷 支持命令行部署、私有镜像同步 用 Dockge 管理一套中间件生态完全没问题 适合：👉 想要随时随地调试项目的开发者👉 不想在本地装一堆环境的轻量用户👉 有多端共享、协作需求的远程开发场景 整套流程走下来，你只需一台浏览器，就能获得 24 × 7 不关机的云端开发环境。如果你也是 Mac M-芯片用户、经常出差或需要多端协作，不妨试试用懒猫微服托管自己的 DevBox。","link":"/posts/25ccd3a3/"},{"title":"懒猫微服实战入门（十七）：把 Steam 游戏存到懒猫网盘","text":"懒猫微服的网盘基本可以替代一些公有的网盘，还有一个好处是可以自动挂载，只要打开懒猫微服的客户端，然后自动把网盘就能自动挂载到 Finder，十分方便。 网盘的挂载是支持了 WebDAV 和 Sambda。这是常见的两种远程访问的协议。 WebDAV（Web Distributed Authoring and Versioning）主要用于 HTTP/HTTPS 协议 的文件共享，适合 远程访问、云存储。基于 HTTP/HTTPS，可在浏览器中直接访问（如 http://server/webdav）。 SMB（Server Message Block）/ Samba 主要用于 局域网文件共享（如 Windows 共享文件夹、NAS、企业内网存储）。 通过 mount 命令可以看到，懒猫微服客户端默认使用的是 SMB 协议挂载： 12//xu-automount@file.micro.heiyu.space/xu-automount on /Users/xu/lazycat_automount/micro (smbfs, nodev, nosuid, mounted by xu)//xu-automount@file.micro.heiyu.space/xu on /Volumes/xu (smbfs, nodev, nosuid, mounted by xu) 默认有两个文件夹，其实都是指向网盘根目录的软连接。两者内容完全一样。 &lt;用户名&gt;-automount：这个应该不是自动挂载到文件管理器的目录 &lt;用户名&gt;: 这个是网盘多租户的目录 所以在 Steam 里我们直接添加驱动器就好： 然后可以选择这两个文件目录，就像前面介绍的，这两个选择哪个都行： 然后这个时候会弹出来这个提示。我们选择允许。这样 Steam 才能有写入懒猫网盘的权限。 然后选择下载之后，我们发现网盘里多了一个 SteamLibrary 的目录。所有的游戏都存在这里。 如果你比较习惯网盘的页面，也可以在网盘里找到 SteamLibrary 的目录 如果哪天不再需要写入懒猫网盘，用这个办法删除。网上吐槽挺多的。","link":"/posts/ffc71b6/"},{"title":"懒猫微服实战入门（十八）：用 planka 做项目管理","text":"工作里用 Jira 管理项目进度。家里也是想找个类似的软件来管理一些长期的事情，如果能带一多人合作的功能就更好了。在网上找了很久也没有太好用的，直到在懒猫微服中找到 planka，在对比了几个同类型的软件之后，决定使用这个软件来管理自己的一些事情。 其他的软件体验不佳的点主要是： 付费：还都是订阅制，没有找到终身制的软件 界面太丑，操作太复杂 Saas 免费版本延迟太高 移动端访问体验不佳 Planka 算是解决了大部分的问题： 虽然这个页面不是很现代化风格，但是也不丑，页面响应速度很快。而其他软件大多臃肿体验不佳，要么就是延迟的很高耽误体验。 简介的 UI 和快速的响应很好的诠释了 less is more 的原则。 进入主页之后可以新建多个项目，算是一个隔离吧，虽然我目前也只是用到了一个。 每一个 Project 都能开好几个 board，这样就把不同类别的事情跟区分开了。 然后每个 board 上标注 Todo，Doing，Pending，Done，Deprecated 来确认事情的进度。有点白版卡片的那个味道了，不用自己像线下那种写贴纸来回移动，也不用再花费软件的订阅的费用。 这个是我和前端协作开发时候一起做的 Dashboard，当时在一起开发一个前后端分离的大语言模型的 APP。 只要给他新建一个用户就可以了，然后分给他某个面板的权限，然后就可以可以一起愉快的协作了。（前提给他安装了懒猫微服的客户端，分了 app 权限） 这个是面板的详细参数，可以把 task 分配给某个成员，然后也可以添加 task 描述，task 子任务拆解以及成员评论，拿来记录一些 change log 还是不错的，起码测试的一些过程可以随手记录在这里了。 Dashboard 功能还需要继续探索，比如计时，打标签一些的功能。 不过我目前用到的功能就这么多，也算能基本覆盖全部的场景了。 这个是我用 planka 来追踪关于懒猫微服的写作和上架应用的一些事情，真的帮助了我很多很多。","link":"/posts/51800531/"},{"title":"懒猫微服实战入门（十九）：我最喜欢的 RSS 阅读器-FreshRSS","text":"自建的博客都可以接入 RSS 订阅，我之很喜欢的一款 FreshRSS 在懒猫微服的商店上架了，可以联动一下了。 我的博客 RSS 订阅是：https://cloudsmithy.github.io/atom.xml 然后点击左上角的订阅管理，先新建一个分类，然后是输入 RSS 订阅地址即可。 我也添加了懒猫微服王总的博客订阅：https://manateelazycat.github.io/feed.xml 这个是我博客的订阅效果，这样在 PC 和移动端都可以访问了： 那如果想让用其他的软件订阅这个 FreshRSS 呢，在右上角点击设置，然后选择认证，点击允许 API 访问。然后就可以通过抓数据的方式进行访问。 然后回到账户管理，这个时候下面就出来了 API 管理这个选项，设置 token 然后就可以使用了。 然后我们访问 API 端点：https://freshrss.&lt;机器名字&gt;.heiyu.space/api/ 这里可以看到 Google Reader compatible API 和 Fever compatible API。 1234567891011FreshRSS API endpointsGoogle Reader compatible APIYour API address:https://freshrss.&lt;机器名字&gt;.heiyu.space/api/greader.phpGoogle Reader API configuration test:✔️ PASSFever compatible APIYour API address:https://freshrss.micro.&lt;机器名字&gt;.space/api/fever.phpFever API configuration test:✔️ PASS 那接下来使用 fluent-reader 订阅微服里的 FreshRSS。选择 Fever API，输入上边 RSS API 返回的 URL。 用户名和密码是登录 FreshRSS 的用户密码，然后端点是 Fever compatible API。（这里没有用到 token） 这个就是订阅的效果了。（FreshRSS 夹带私货自动订阅 release） 在 APP 里还挺好看的。（除了 fluent-reader 不支持检索） 用懒猫微服当作一个 RSS 存储的后端，同时也提供了一个 FreshRSS 的部署版本，很多记忆再也不会丢了。","link":"/posts/9fd148d9/"},{"title":"懒猫微服实战入门（二）：打造多人协作环境,权限控制+数据隔离一步到位.md","text":"最近在懒猫微服上架了一些应用，正好分享给家里人用。这个实现起来很简单，在懒猫微服上开一个新的用户，然后控制这个用户是否可以安装软件，可以使用什么软件，这样不同用户之间的数据就隔离开了，比如每个人的懒猫网盘和懒猫清单是独立的，互相不会产生干扰。 下面就以实际操作为例，教大家新建用户，并且了解这些自带的安全机制。 新建用户设置 - 用户管理，这里可以看到现存的账户，第一次激活的时候会提示注册一个管理员账户，后面可以右上角点击邀请成员，然后会得到弹出一个二维码，新的客户端需要下载懒猫客户端，然后客户端扫码添加输入信息即可。 扫码后可以为新用户设置用户名和密码。客户端下载地址：👉 https://lazycat.cloud/download 注册完成后，新成员就可以使用自己的账号登录懒猫微服啦。默认是“非管理员权限”，更安全。 用户权限控制新建之后，我对这个新用户的画像是用户而不是管理者，所以只需要登录之后看到应用白名单就可以了。 点击新建用户的头像，可以设置用户可以看见应用的白名单。 比如，我只授权了家庭成员使用懒猫网盘、懒猫清单等基础工具。于是使用手机端登录新的账户，可以看到在我的应用中只有刚刚选中那些，这对于日常使用来说刚刚好，这个页面相对于安装了几十个 app 的管理页面来说，实在是清爽。 登录的二次验证在此之前我们先来介绍多因子验证（MFA），通俗来讲我们在使用用户名密码登录的时候有时候还要接收一个验证码，有时候是发到邮箱的，有的是手机短信，还有个需要安装特定的 APP 来查看，比如 Authy，Google Authenticator。 而懒猫微服在 APP 中内置了 MFA 接收验证码的功能，新设备登录的时候会有如下提示： 在一台新的设备登录懒猫账户的时候，已经登录这个账户的设备就会弹出这个提示，这个时候我一般是提前打开懒猫微服 APP。 当然如果没有提前打开或者登录呢，也可以在「微服管理 - 安全码」来查看，比如这样，这个方式很 Apple 但是用着比 Apple 的提示舒服多了。 那么什么时候才会触发这个 MFA 呢？经过不完全测试，主要还是在这里设备管理这里有一个云端白名单，在这里的设备可以就可以免去 MFA 的验证，如果删除某个设备之后，这个设备会马上注销登录，并且在此登录的时候还需要 MFA 验证。这个操作，极大了降低了被黑客攻击的可能性。 当然如果你觉得 MFA 比较麻烦，那么也可以使用手机号码的方式进行登录，绑定手机号，然后用收验证码的方式进行登录,比如这样： 1【懒猫微服】验证码：0000，5分钟内有效！请勿转发或泄漏。 写在最后以前用过很多 NAS，一直苦于怕黑客攻击而没有监管 NAS 放在互联网，而一套完整的登录机制也要花费很大的精力去维护，拓展。期间也选择过蒲公英这样的异地组网设备，虽然可以达到目的，但是过程不尽如人意，对于很多国产生态来说，售后一直是缺失的很重要的一环。而懒猫微服恰好弥补了这样的短板，让懂技术的人从繁杂的维护设备中解放出来，像使用公有云一样的使用 NAS。","link":"/posts/4d17c8d/"},{"title":"懒猫微服实战入门（二十）：如何使用 Time Machine 将 Mac 备份到懒猫微服","text":"看了 Apple 的文档，时间机器备份到 SMB 或者外接设备（APFS）。正好懒猫微服带了 SMB 的共享。然后我们可以把时间机器备份到网盘里。虽然默认连接的是懒猫网盘根目录，但是我们也可以映射一个子文件夹 TimeMachine。如下： 一、 在 Mac 上连接到 SMB 共享 在 Finder 中，点击菜单栏的 “前往” (Go) &gt; **“连接服务器…” (Connect to Server…)**。 在弹出的窗口中，输入 SMB 共享的地址，格式通常是 smb://[懒猫微服的IP地址或主机名]/[共享文件夹名称]。 例如：1smb://192.168.1.100/用户名/timemachine （域名也可以） 点击“连接”。系统会提示你输入用户名和密码。（懒猫微服的用户密码）成功连接后，你会在 Finder 中看到这个网络共享。 二、 设置 Time Machine 进行备份 打开 **“系统设置” (System Settings)**（或旧版 macOS 中的“系统偏好设置”）。 点击 “通用” (General) &gt; **“时间机器” (Time Machine)**。 点击 **“添加备份磁盘…” (Add Backup Disk…)**。 在弹出的列表中，你应该能看到你刚刚连接的 SMB 共享文件夹。 如果再次提示输入凭据，请再次输入你在懒猫微服上设置的用户名和密码。 Time Machine 会在共享中创建一个特殊的 .sparsebundle 文件，然后开始首次备份。 三、 解决 Time Machine 备份变慢的问题在某些情况下，macOS 的默认设置或某些第三方应用程序可能会导致 Time Machine 备份变慢。 1. 暂时禁用磁盘节流（Disk Throttling） macOS 默认会对后台进程（包括 Time Machine）进行磁盘 I/O 节流，以确保系统响应速度。在首次备份或需要快速完成备份时，可以暂时禁用此节流。 操作方法： 打开“终端”应用程序（位于“应用程序”&gt;“实用工具”），输入以下命令并按回车键：bash sudo sysctl debug.lowpri_throttle_enabled=0 输入管理员密码后，该设置会立即生效。请注意，这会使 Time Machine 占用更多系统资源，可能影响 Mac 在备份期间的流畅性。备份完成后，建议通过以下命令重新启用节流：bash sudo sysctl debug.lowpri_throttle_enabled=1 2. 检查和禁用干扰备份的应用程序 某些应用程序，特别是防病毒软件、系统清理工具或文件同步工具，可能会频繁访问磁盘，从而干扰 Time Machine 的正常运行。 操作方法： 尝试在 Time Machine 备份期间暂时禁用这些应用程序，或者检查它们的设置，看是否可以将 Time Machine 备份盘从其扫描范围中排除。 3. 确保 Mac 保持唤醒状态 对于大型备份，如果 Mac 进入睡眠状态，可能会中断或减慢备份进程。 操作方法： 在备份期间，你可以前往“系统设置”&gt;“显示器”（或“节能”）调整显示器关闭时间和电脑睡眠设置，或使用 caffeinate 命令让 Mac 保持唤醒：1caffeinate -s -m -i -t 36000 &amp; 此命令将使 Mac 在 10 小时内（36000 秒）保持唤醒，&amp; 符号表示在后台运行。 四、 查看备份情况可以按到我目前磁盘使用了 90 个 G，在时间机器中看到占用 50G。 在懒猫网盘中也可以看到这个数据。 通过以上步骤，你就可以成功地将你的 Mac 通过 Time Machine 备份到懒猫微服提供的 SMB 共享了。","link":"/posts/c5298d72/"},{"title":"懒猫微服实战入门（二十一）：使用 Memos 替代 Flomo","text":"曾经用过 Flomo，一度觉得体验不错，但后来因不想续费会员而中止使用。最近在懒猫微服的商店中发现了 Memos，完全开源、支持自托管，是个很不错的替代方案。 什么是 Memos？Memos 是一款开源、极简、现代化的笔记系统，主打「快速记录、随时检索」。适合捕捉灵感、日常备忘、碎片想法、读书笔记等多种用途。 它具有以下特点： 🧩 极简 Markdown 编辑器，写作无干扰 🔍 支持标签与多条件过滤，查找便捷 📱 原生适配移动端界面，自动响应式布局 🌐 内置开放 API，可接入自动化工具或客户端 🗂 支持归档、置顶、图像插入、链接跳转等实用功能 🔐 数据完全自托管，掌控在自己手中 目前 GitHub star 数已超 6k，开发活跃，文档完善，社区生态也在不断壮大。 页面结构与使用方式Memos 主页面分为两栏： ✅ 左侧侧边栏： 创建 Memo：点击加号即可撰写新内容 标签筛选：点击任意标签快速过滤 快捷菜单：查看所有 Memo、归档 Memo、置顶 Memo、搜索功能等 ✅ 右侧内容区： 展示所有 Memo 内容，以时间倒序排列 每条 Memo 支持： 编辑、置顶、归档 标签添加（支持 #标签名 快捷方式） Markdown 格式（支持标题、代码块、列表、引用等） 拖拽上传图片或截图粘贴 自动识别链接并可点击跳转 📷 示例页面如下： 开启 API 支持在设置中可以启用 API 功能，系统会生成一个唯一的 API KEY，用于连接第三方客户端或自动化工具（如 Moe Memos）。 📷 API 开关和密钥生成页面如下： Moe Memos 客户端App Store 上的 Moe Memos 是一款第三方移动端客户端，原生适配 Memos 的 API 接口，界面极简，使用流畅。 📷 图标预览： 如何登录 Moe Memos 安装 Moe Memos 后，打开 App 输入你的自托管域名，如 https://memos.name.heiyu.space 填写 API KEY 即可登录（需在系统中开启单租户模式） 📷 登录后界面展示： 简单对比 Flomo 功能 Flomo Memos（自托管） 微信同步 ✅（原生） ❌（可接 webhook 实现） 多端支持 ✅ ✅ Moe Memos 数据隐私 ❌ 云端托管 ✅ 完全自持 开放 API ❌ 限制较多 ✅ 支持 API KEY 成本 收费会员制 免费开源（除托管成本） Markdown ❌ ✅ 原生支持 图片粘贴上传 ❌ ✅ 虽然 Memos 不支持微信原生同步，但凭借开放架构和高度可定制性，能实现更强的私有笔记体验。 总结Memos 是一款功能恰到好处、设计极简、部署门槛低的笔记系统，非常适合替代 Flomo 这类灵感记录工具。配合懒猫微服提供的部署方案，可以做到： 一键上线，无需服务器运维知识 API 集成快捷，客户端体验佳 数据可备份、可迁移、可掌控 适合用来做「知识碎片记录」、「阅读随想」、「灵感管理」、「工程笔记」等场景。欢迎大家一起探索更多玩法！","link":"/posts/6f97c31a/"},{"title":"懒猫微服实战入门（二十二）：使用 DDNS-GO 给 Cloudflare 做动态域名解析","text":"我的域名最初是在 AWS 的 Route53 上购买的，然而在使用过程中发现 Host Zone 的费用并不低，除了每月的托管费用，还包括 TTL 更新等开销。在朋友建议下，我决定将域名解析的任务从 AWS 迁移到 Cloudflare，一方面可以节省成本，另一方面配置也更为灵活。我家里的公网 IPV4 经常变动，所以我使用懒猫微服商店里的 DDNS-GO 和 Cloudflare 做动态域名解析。 第一步：更改 NS 记录准确地说，需要在原域名注册商（我的是 AWS Route53）处修改 Name Server，将默认的 AWS NS 记录改为 Cloudflare 提供的 NS 地址。这样，域名解析权就转移到了 Cloudflare。Cloudflare 可以从懒猫微服的商店进入，也可以使用网页。而 DDNS-GO 使用商店快捷下载就非常方便。 Route53 中的 NS 修改界面 如下， 替换成 Cloudflare 的 NS 后，域名正式托管在 Cloudflare 第二步：创建 API Token前往 Cloudflare 的 API Token 页面，为 DDNS-GO 创建一个具备修改 DNS 权限的 Token。 建议选择 “Edit zone DNS” 模板，只赋予必要权限，并可以限制在特定域名范围内使用。 第三步：配置 DDNS-GODDNS-GO 是一个开源的动态域名更新工具，支持多个域名服务商（不包括 AWS 的 Route53）。看来不仅迁移出来省钱，还省心。我们把上一步申请的 token 添加到这里，TTL 设置成自动就行。 TTL 建议设置为“自动” IP 获取方式推荐使用外网 API（如 ipip.net） 此外，DDNS-GO 支持 webhook 通知，可选用如 Slack、Server 酱等方式实时通知 IP 变动情况。 第四步：查看效果我将 DDNS 记录绑定到家用公网 IP（IPv4），未启用 IPv6。保存配置后，前往 Cloudflare 后台查看 DNS 记录，已成功同步更新。 ⚠️ 小提示：如果你绑定的 IP 是中国大陆的，建议不要开启 Cloudflare 的代理功能（小云朵），否则可能出现连接问题。 Bonus：免费 TLS 证书使用 Cloudflare 托管 DNS，访问你的网站时会根据规则加上 TLS 证书，实现 HTTPS 加密，非常方便省心。 小结通过将域名解析迁移到 Cloudflare，并配合 DDNS-GO 工具进行动态更新，既省钱又省事，还顺带获得了免费证书加持。相比 AWS Route53 的托管费用和配置复杂度，Cloudflare 无疑是个人用户和轻量级应用的更优选择。","link":"/posts/6031f818/"},{"title":"懒猫微服实战入门（二十三）：使用 GitHub 单点登录到 Memos","text":"之前我们介绍了如何使用 Memos 替代 Github，那这次我们来进阶一下，给 Memos 添加 Github 单点登录，如果你开发的应用后续想接入 Github 也可以采取这种办法。 一、创建 GitHub OAuth 应用1. 打开 GitHub OAuth 应用配置入口 登录 GitHub，点击右上角头像，选择 Settings（设置） 在左侧栏选择 Developer settings 点击 OAuth Apps，然后点击右侧的 New OAuth App 创建新的应用 📷 页面示意： 2. 填写应用基本信息在创建页面中填写如下字段： Application Name：如 Console SSO Homepage URL：建议填写系统主页，例如 https://memos.name.heiyu.space Authorization callback URL：授权成功后的回调地址，格式如下： 1https://memos.name.heiyu.space/auth/callback 📷 示例填写界面： 3. 获取 Client ID 和 Client Secret提交后，GitHub 将生成： Client ID：用于标识该 OAuth 应用 Client Secret：用于身份验证，请妥善保存，不要泄露！ 📷 凭证界面如下： 二、查看和管理 OAuth 应用创建完成后，返回 OAuth 应用列表，即可看到刚创建的应用。 点击应用名可查看授权信息和应用详情： 📷 应用列表和详情视图： 应用列表页面 然后邮件会收到 Github 绑定 Oauth 的通知。 4. 在 Memos 中配置 GitHub 登录进入系统设置页面： 点击左下角齿轮图标（设置） 选择 单点登录（SSO） 选择 GitHub 作为登录方式，填写刚获取的 Client ID 和 Client Secret 📷 Memos 配置页面示例： 配置保存后，注销当前账号，登录页面会显示 GitHub 登录按钮。 📷 登录页面展示效果： 通过以上步骤，我们完成了 GitHub 登录的接入流程： ✅ 创建并配置 GitHub OAuth 应用✅ 获取并填入凭证✅ 在 Memos 中启用 OAuth 登录 最后成员列表一览：","link":"/posts/b10cd1f4/"},{"title":"懒猫微服实战入门（二十四）：在懒猫微服中使用群晖","text":"各种 OS in docker 的操作很多，包括 debian，arch，windows，Macos，安卓，这次甚至带来了黑群晖 in docker，基本上都是基于 QUME 的虚拟化来做的。也希望哪天有也有 docker 版本的 QNAP 吧。NAS 一家人就要整整齐齐。（unraid 估计没戏 哈哈哈哈哈） https://appstore.lazycat.cloud/#/shop/detail/chestnut.app.vdsm 从懒猫微服商店就可以直接下载了，群友上传了 release。 开源地址在这里：https://github.com/vdsm/virtual-dsm 也不需要再搞群晖引导啥的，直接一件安装很方便，最后设置下用户名和密码就可以了。 版本是目前最新的 DSM7.22，相信群晖应该是很多爱好者的第一个 NAS 系统。这些年我一路从 DSM6 走过来，群晖的系统 UI 是越来越好看了。第一件是必须是安装套件，激活文件管理器。 美中不足的是，没有找到群晖的虚拟机管理器。也罢，反正是虚拟机，VM in VM 性能损耗很大，倒是 Docker in Docker 还能接受。 虽然这个存储空间只有 16G，不过嘛，感觉这个大小其实适合尝鲜或者做已有群晖的 backup。不过机械硬盘倒是没有明显的卡顿。 去应用查看器翻了一下，磁盘大小竟然是在环境变量写死的，那么在 V1.38+的 OS 也能通过修改环境变量来换成更大的空间，毕竟数据盘都是 HDD 不差这点空间。 因为我已经有了一个物理机的群晖，上面也跑着虚拟机和打印机驱动的一些软件，所以这个群晖更多是尝鲜，或者说组成一个集群双活。磁盘太小的话，那么我就添加外部的 SMB，其实就是懒猫网盘。 在群晖的文件管理器中 - 工具 - 装载远程文件夹 - CIFS 共享文件夹。 然后输入 SMB 的信息。需要事先选中一个空文件夹。 这个时候发挥 Linux 的 mount 哲学了 hhhhh 然后把群晖自己 SMB 映射出去，还能做一个 SMB 的存储网关。 懒猫网盘和 share 都是 SMB 挂载的其他设备。也能通过这个虚拟群晖的 SMB 一起访问。 怎么洗白？都有懒猫微服穿透和相册了？不用洗了吧！","link":"/posts/815f771a/"},{"title":"懒猫微服实战入门（四）：完全DNS访问，和本地代理冲突了怎么办？","text":"刚拿到懒猫微服的时候，了解到这个机器完全使用 DNS 来访问是很吃惊的。拒不完全使用经验，大概是机器里部署了一套私有的 DNS server，然后广播到整个局域网。而公网上的则是 heiyu.space，通过 whois 查看，公网的 domain 是在腾讯云购买的。 所以应该是两套的解析结构，局域网访问的时候，就先用机器部署的私有 domain 进行解析，如果使用流量或者在外边，就是走互联网上 DNSPod 的解析记录。这个结论属于猜测，因为很多公有云也确实四这么做的，一个公开托管的 domain 用来互联网解析，一个 VPC 内的 private domain 用来解析 VPC 内部的地址。 懒猫微服和传统的 NAS 又很大的不同，如果作为小白玩家可以很快上手，当做 Sass 服务来用。但对于专业玩家，总有一种技术的强迫症，总用抽丝剥茧，从 Saas 一点点解析到 Iass，然后一点把懒猫编程能够公开访问的私有云。 比如网络。可以通过 dig 或者 nslookup 来解析 12dig xxx.heiyu.space +shortdig xxx.heiyu.space AAAA +short 但是，DNS 解析这里慢慢就出现问题了。在某次上传文件到懒猫网盘的时候，我发现速度慢的可怜，几乎是走了公网。在 VIP 答疑群里得知，流量应该是从代理转了一圈，然后回来的，所以慢，剩下的就是解决这个问题了。 那么办法就是放行白名单，不让他走代理，由于是 DNS 访问，而很多代理的规则是根据域名匹配的，所以要去改这个匹配规则。当然如果你用 nmtui 配置静态 IP 地址的话，那么内网访问也是没有问题了，直接走上级路由的默认路由表即可。 而白名单主要是放行， _.heiyu.space 和 _.lazycat.cloud 这两个域名，heiyu.space 是穿透服务，lazycat.cloud 是官网和论坛。 不同的软件有不同的设置办法，比如说用 DOMAIN-SUFFIX 来替代域名的泛解析，所以放行的时候 heiyu.space 这这样子就好。我在修改配置文件的时候用 DOMAIN-SUFFIX 匹配*.heiyu.space 不生效，花了不少的时间。实际不需要再写一次 * 号。 而最终落到配置文件上就是这样的。（之前写 DOMAIN-SUFFIX,*.lazycat.cloud,DIRECT）一直不生效。 1234rules:- DOMAIN-SUFFIX,lazycat.cloud,DIRECT- DOMAIN-SUFFIX,heiyu.space,DIRECT- DOMAIN-SUFFIX,deepseek.com,DIRECT 也总结一下其他规则吧，最常见的类型有这些： 1）DOMAIN 只匹配某个域名本身。 举例：gs.apple.com → 只有访问 gs.apple.com 才会命中。 2）DOMAIN-SUFFIX 匹配所有以这个后缀结尾的域名。 举例：apple.com → gs.apple.com、itunes.apple.com 都会命中。 3）DOMAIN-KEYWORD 匹配包含某个关键词的所有域名。 举例：apple → apple.com、gs.apple.com、appleabc.xyz 都会命中。 4）IP-CIDR 匹配某个 IP 地址段。 举例：192.168.0.0/16 → 匹配 192.168 开头的所有 IP。 这些是规则写法里最基本的几种，掌握了就能应对绝大多数情况。","link":"/posts/36782d5f/"},{"title":"懒猫微服实战入门（三）:懒猫智慧屏，以为是地表最强电视盒子，结果是闺蜜机","text":"过年那阵子，为了看春晚不卡顿，打算换一个当贝盒子，尽管这些年刷过矿机当盒子或者 Armbian，但是仍然对当贝系列情有独钟，而时过境迁，最后发现在当年风靡市场的网红盒子，不过 RK3566 而已，根据不同的 RAM+ROM 的组合来卖到更高的价格，实在是没有什么性价比。 于是想到 X86 能性能会更加好一些，比如 Android TV 这种固件，不过这种基本都是海外版本，纯净的基本什么都要自己捣鼓，而 B 站评论的第三方链接又很担心安全问题。 这问题一直持续到我购买了懒猫微服，高性能的 X86 主机，还带 HDMI（目前 Typec 不支持供电和视频传输），和飞牛的原生 Gnome 输出不同的是懒猫智慧屏其实是商店里面一个独立的 APP，本质上相当于客户端，需要手机扫码授权才能使用 登录之后是这样的，其实就是在原来 APP 的基础上加了一个 Chrome 浏览器，然后其他的应用也能在显示器上打开。右上角依次是搜索栏，软件商店和登出按钮。接下来就是可以愉快的观影了，个人体验新开一个账户，然后设置应用白名单体验会更加的好～（但是用手机遥控的时候会提示，智慧屏正在被其他用户使用是否停止 hhhh） 我尝试的观影流程如下： 把视频传输到懒猫网盘（拖拽上传或者 Samba） 打开视频播放器（其他播放器也可） 然后选中网盘文件就可以播放啦 目前支持手机端遥控，类似市面上的盒子助手， 我连接了 Action III ，能够愉快的观影了。 由于是内置的应用，所以不存在电视盒子广告乱象的问题，11 代 I5 拿来观看 4K 也是轻松秒杀，需要什么就往网盘传什么。高端的需求只需要简单的办法。感觉不用买 Apple TV 了，如果需要其他软件比如 jellyfin 啥的也可以自己部署～。 机器有 USB 还能插键鼠，接好外设的时候记得重启一下，应该是容器部署的原因，让容器在启动的时候再读一遍/dev/bus/usb 下的设备。除了观影，接会议室的演示大屏幕也不错～ 毕竟这个页面，连 debian 虚拟机都能使用，其他的应用也不在话下。想用 X86 安卓的话，直接安装到虚拟机里～ 为啥说可以成为闺蜜机呢？ 为啥说可以成为闺蜜机呢？ 某天在商场的时候看到一个大大的带支架的还可以随时移动的平板叫做闺蜜机。 那么懒猫微服 + HDMI 投屏器/毫米波投屏器 + 可移动支架，是不是很像？ 某宝上还有这样的改装套餐，解决显示器供电看来就 OK。 市面上没有好用的电视盒子？选懒猫！ 市面上没有良心的在线网盘？选懒猫！ 市面上没有便宜的闺蜜专机？选懒猫！ 市面上的闺蜜机动辄大几千，配置又差强人意，还不如买懒猫微服，还有专业的售后陪玩，探索无限可能！ 什么？你说闺蜜机还得有语音助手， AI 美颜，娱乐互动？快登懒猫微服用 Docker 来部署吧，还有机会上架懒猫商店哦～","link":"/posts/5a9099c0/"},{"title":"懒猫微服实战入门（五）：文件上传到懒猫网盘，SMB 电视盒子观影","text":"作为一个合格的 NAS，肯定要有文件共享的功能，一般我们常用的是 SMB，NFS 和 WebDav 这三种，然后需要设置共享目录和用户权限。 懒猫网盘提供了一个开箱即用的方案，直接通过 APP 把网盘的文件夹映射自动挂载到本地，不需要像 Linux 那样 mount，也不需像 window 一样新建磁盘映射： 我们看看以前要挂载一个盘有多麻烦: 12345# Debian/Ubuntusudo apt install cifs-utilssudo mkdir /mnt/smb_sharesudo mount -t cifs //SERVER_IP_OR_NAME/SHARE_NAME /mnt/smb_share -o username=SMB_USER,password=SMB_PASSWORD,domain=WORKGROUP 如果需要开机自动挂载，还得改/etc/fstab 里面的条目。但是，懒猫网盘可以开箱即用，不管你是用浏览器，APP，还是用访达挂载 SMB 都访问都可以。属实是解放了 Mac 党的电脑空间。 在网盘中点击自己的头像，然后设置 - 网络服务这里，可以看到设置。甚至点击起开内网服务，还会给一个 IP 地址的 SMB 地址： smb://ip/user-name，电视盒子不能安装懒猫 app，但是有了 IP 地址之后就可以连接 SMB 了～ 然后就是当贝盒子这里啦，如果你是小米盒子或者其他的盒子，只要文件管理器支持 SMB 就 OK 进入文件管理器，选择 局域网共享连接。 然后输入懒猫微服的 IP 地址，用户名密码就是微服 APP 的， 这一套有点 AD 域的感觉了。 如果你的文件管理器默认没有 SMB 也没有关系，还可以使用第三方应用进行 SMB 连接，比如这个 Github 项目，可以从 release 中下载 APK 进行安装。 连接成功后，可对文件进行扫描和管理。 通过以上配置，就可以在电视盒子上通过 SMB 连接 NAS，开心的观看的 4K 电影了。","link":"/posts/b62d86a5/"},{"title":"懒猫微服实战入门（六）：使用2fauth共享你的MFA","text":"标题有点绕口，甚至听起来有点反直觉。 故事的背景是这样的，去参加了 AWS 的活动给的账户强制开 MFA，但是我们还想团队内部 share 使用，于是产生了这个需求。 登录到 AWS 的控制台强制开了 MFA，而且在第一次注册的时候强制绑定多因子验证。这也就意味着，其他人如果想登录这个账户就得随时 call 我，然后我去发给他数据验证码，这实在很不方便，所以想到了共享的 MFA 的需求。 头几天逛商店看到的，觉得项目有点意思就下载了，没想到这么快用到了。懒猫商店，一键部署很方便，当成 Saas 服务来用，完全不考虑部署运维的事情。 之前给小伙伴开了懒猫微服的账户，共享了 planka 来看项目进度，这次把 2fauth 的权限也添加给他。 首先我这边先注册管理员的账户，默认是登录页面，需要切换一下。 登录之后会提示绑定一下这个账户的 MFA，我就是为了不在手机上安装 MFA 软件才用这个的，就不要套娃了。反正外面还有懒猫的验证系统，那个还有 TLS 加密，安全码验证。 选择不绑定设备之后，在这里导入需要设置的 MFA，这可以用摄像头或者导入二维码文件。我用的电脑端，所以直接在应用处截图，然后导入到这里了。 点击最下面的导入，然后选择二维码 - 上传 就可以了。 导入之后是这样的，可以二次确认签发机构。 然后把生成的 6 位数字填写到 aws 控制台上，就可以成功验证了。 在 2fauth 控制台上是这样的，点开就可以查看 6 位数字验证码。 那么回到一开始的话题，怎么共享给其他账户呢？点击下方 - 管理员 - 用户 ，然后我们来新建一个普通用户。步骤基本和前面的一致。 本来以为有用户组一类的概念，把两个用户和 MFA 放在一个组里达到 share 的目的，结果发现这个分组完全是用来区分的 TAG。也没有找到把用户加到组里的操作。那就从管理员导出，再从下一个用户导入吧。 首先试了二维码，但是导入的时候就提示 server error。于是查了了 wiki，都是其他 MFA 软件导入 2fauth 的。无奈只能只能导出配置文件。名字叫做 2fauth_export.json 登录新用户的时候新建，然后选择文本文件。导入刚才的配置文件就可以了。 配置文件基本长这样： 123456789101112131415161718192021{ &quot;app&quot;: &quot;2fauth_v5.3.2&quot;, &quot;schema&quot;: 1, &quot;datetime&quot;: &quot;2025-05-16T08:35:07.676665Z&quot;, &quot;data&quot;: [ { &quot;otp_type&quot;: &quot;totp&quot;, &quot;account&quot;: &quot;Q&quot;, &quot;service&quot;: &quot;AWS SSO&quot;, &quot;icon&quot;: null, &quot;icon_mime&quot;: null, &quot;icon_file&quot;: null, &quot;secret&quot;: &quot;secretsss&quot;, &quot;digits&quot;: 6, &quot;algorithm&quot;: &quot;sha1&quot;, &quot;period&quot;: 30, &quot;counter&quot;: null, &quot;legacy_uri&quot;: &quot;otpauth://totp/&quot; } ]} 整个过程有点绕，有人说每个人手机安装 google authenticator 扫一下不就好了吗？ 为什么采取这个方案？ 之前用手机安装类似软件，每次去三里屯维修的时候都说返厂要把数据抹掉，下次还得重新绑定，还有一些软件只认 MFA 不认人。 这过程不光折腾的够呛，而且 Apple 本身的问题还要 MFA 来买单。 起初是想做一个类似于团队共享 MFA 的场景的，类似于 RBAC，控制起来很灵活，但是实际体验下来是没有达到的。 把最早的 MFA 二维码截图 share 出去也能扫，但是不确定有效时间。","link":"/posts/b6b74923/"},{"title":"懒猫微服实战入门（七）：超越蒲公英SD-WAN，用懒猫转发服务，Ipad随时远程家里window","text":"最近懒猫用懒猫的穿透服务突然有一些想法，既然每个客户端都可以用域名连接到微服，那么有没有可能从客户端之间可以互相访问呢？于是抱着这个目的试了一下，确实可以。异地组网的原因主要有几个，没有公网 IP，传输链路容易被截获以及不同办公室需要逻辑上的组网。 说干就干。 在懒猫论坛上看玄兴梦影的文章，《懒猫微服无缝连接你所有的设备》和《懒猫微服助我生活工作穿梭无忧》这两篇让我受益颇丰。主要是借用懒猫微服的中继服务，用来自建 Rust Desk，还有 RDP 到局域网的其他设备上。 先说 Rust Desk，这是一度被推举为 Todesk 的替代的软件，在懒猫上安装服务端拿到域名和密钥，然后在客户端上填入就可以了,具体操作可以看前面推荐的文章，里面有细致的讲解。 我的需求就是，在外边除了能够访问家里的微服之外，还访问其他的设备，比如群晖，威联通，甚至 windows。这样子以后带个 Ipad 出门就可以了，MacbookPro 的受害者表示笔记本太沉了。 所以这本质上是一个异地组网的问题，在上一个版本的 HomeLab 中是使用的蒲公英的 P5 盒子，这东西卖点是旁路由，直接 POE 接入局域网就好了，还能共享打印机。但是吧，商业产品还有很多限制，比如组网只能三个设备，带宽有限制，在多次的和售后拉扯而且案例没有在规定时间内回复也没有按照服务水平协议赔偿之后，索性退坑。 还有一次很玄学的事情，蒲公英盒子升级固件和家里跳闸的时间高度重合，开案例询问之后，传了日志，客服也只是贴了文档表示绝对不会有电流突增的问题，再问就再也没有回复了。然后会自动结单给五星好评，还不能重新打开继续问问题。 蒲公英在国内是没有什么竞品的，论企业服务远远不及思科之类的产品，而个人用户又一种丝毫不在意的态度。而且会一直推荐买最新的 X5 PRO，而卖完之后改完静态路由不能组网，客服又一副到底你懂不懂的样子。哎，蒲公英是彻底疯转黑了。那不买他们硬件用 OrayOS 呢？请先看免责声明： 所以一直想找其他 SD-WAN 或者异地组网的方案。主要需求嘛，就是既能从外面访问，也能转发其他的设备的流量，能做权限控制就更好了。 懒猫微服目前没有自己的虚拟机系统，所以是用的 webvirtcloud，但是商店里也有很多上架的系统，比如直接点点鼠标就可以开 windows 虚拟机了，这个有点云计算的味道了。不过就是我用的机械硬盘，开 windows 实在是有点差强人意。所以后面弄了一个局域网的机器专门拿来跑 windows，就是后面要提到的局域网转发。 从商店下载的 app 都有一个特定的域名。 1&lt;应用名&gt;.&lt;设备名&gt;.heiyu.space 以商店里的虚拟机为例，直接在 RDP 里输入这个机器的 URL 就就行，以前的 Windows remote desktop 现在改名叫做了 Win APP，同时也能在国内的 app store 上搜索到了。（前提登录懒猫 APP） 首先设置密码，虽然没有密码能够打开远程登录，但是实际怎么都连不上。 然后在系统设置打开远程桌面，在上面那个搜索栏的中直接搜就好。 然后我们就可以连接了。 那两台登录微服的设备如何互联呢？这里有个很赞的工具，可以获取客户端的信息。商店搜索：懒猫微服在线设备获取 在 APP 中我们能够看到每个设备的域名：（隐私保护，我这里已经隐去） 那在脑洞一下，是不是可以做到之前说的旁路由的效果呢？ 这里有个局域网转发工具。 猜测可能是 iptables 一类转发的吧。可以把局域网的设备映射出去（不需要安装懒猫客户端），还要什么旁路由。 现在远程连接的是我这台局域网一台刚刚装好的 windows，不需要在被控端安装安装任何软件（包括懒猫 APP），看到也能通过懒猫的域名组网了，开心～ 内网穿透有了！ 旁路路模式转发有了！ 出门带 ipad 不用带笔记本了～","link":"/posts/59f4c56d/"},{"title":"懒猫微服实战入门（八）：懒猫微服 × SSH Remote：打造随时随地的云端开发环境","text":"Apple 开始换了 ARM 芯片之后，我们还处于 X86 和 ARM 交叉的阶段。所以有时候还得有一台 X86 的开发环境来测试一些兼容性问题。一开始手里面只有低配置的软路由，后来入手了懒猫微服，这个 11 代 i5 的 CPU 终于能够编译一些重型的任务了。 下面演示如何把懒猫微服配置成一台云端开发机，并分别用 VS Code 与 PyCharm 进行远程开发。 虽然懒猫微服的商店已经上架了 code-sever 可以开箱即用，除此之外我们也来探索下其他的方案。 1 · 准备 SSH 免密登录修改 ~/.ssh/config（若无自行创建）： 123456789Host lzc HostName server.heiyu.space # 服务器域名 / IP User root # 默认用户名 IdentityFile ~/.ssh/id_ed25519 # 私钥路径 Port 22 # 默认端口 ServerAliveInterval 60 # 60 秒保活 TCPKeepAlive yes # TCP 保持连接 ForwardAgent yes # 允许代理转发 IdentitiesOnly yes # 只尝试显式钥匙 终端测试： 1ssh lzc # 应直接登录而不再提示密码 2 · VS Code ：一键 Remote 需要 Remote Development 三件套插件（SSH / WSL / Containers）。 安装完成后，点击左下角 棕黄色的 Remote 图标。 VS Code 自动读取 ~/.ssh/config，显示刚才的 lzc 主机。 选择需要打开的文件夹，我们是 root 登录，所以基本上所有的路径都有访问权限，由于懒猫微服的设置，除了 root 目录外，其他的目标可能会被清空，所以我们尽量把代码留在 root 目录下就好。 打开之后我们就可以看到代码了，剩下的就和本地差不多了，这也就是偷懒不学 VIM 的原因吧。 3 · PyCharm ：Gateway 秒连我们再来看 Pycharm，默认提供了远程开发的功能。记得最早 Jetbrains 的是这么实现的，把本地代码推送到远端的/tmp 文件夹然后调用远端编译器执行。现在用了 Gateway 基本可以达到实时的效果了。 依次点击 New SSH Configuration → Add，填入主机、端口、用户名，并选择 私钥 或 密码。 连接成功后，选择需要打开的服务器目录（同样建议用 /root/...）。 首次连接时 PyCharm 会在服务器端安装一个 IDE Agent。 安装完毕即可像本地一样运行、调试、补全。 写在最后apple 的 M 芯片用来开发，而懒微服就作为上线环境之前的测试环境，当需要 X86 环境的时候，随时切换过去。","link":"/posts/778337f4/"},{"title":"懒猫微服实战入门（九）：给懒猫安装图形界面，使用 XRDP 实现远程桌面","text":"虽然我们日常使用 Linux 系统时，大多数操作都是通过终端完成的，比如运行服务、查看日志、编辑配置文件等。但在某些场景下，图形界面仍然是非常有用的：例如需要打开浏览器进行调试、运行带 GUI 的应用程序，或者想给不太熟悉命令行的同事一个更友好的访问方式。 因此，这一篇教程就来介绍如何在懒猫微服上安装图形桌面环境，并通过 XRDP 实现远程桌面连接。我们选择的是轻量级的 XFCE4 桌面环境，它资源占用小，运行稳定，界面风格有点像老版本 Windows，非常适合资源有限的 VPS 或微型容器环境。当然，你也可以选择 KDE Plasma、GNOME 等更现代的桌面环境，但安装包体积和资源占用会更高。 一键安装脚本经过多次测试，我总结了一份实用的一键安装脚本，适用于基于 Debian 的系统（如 Ubuntu 或懒猫微服）： 123456789101112131415161718192021222324252627#!/usr/bin/env bashset -eecho &quot;==&gt; 设置 keyboard-configuration 为无交互模式&quot;echo 'keyboard-configuration keyboard-configuration/layoutcode select us' | debconf-set-selectionsecho 'keyboard-configuration keyboard-configuration/modelcode select pc105' | debconf-set-selectionsexport DEBIAN_FRONTEND=noninteractiveecho &quot;==&gt; 更新系统包索引&quot;apt updateecho &quot;==&gt; 安装桌面和远程桌面组件&quot;apt install -y xfce4 xfce4-goodies xorg dbus-x11 x11-xserver-utils \\ xrdp xorgxrdp keyboard-configurationecho &quot;==&gt; 配置 .xsession 启动 XFCE&quot;echo &quot;startxfce4&quot; &gt; ~/.xsessionchmod +x ~/.xsessionecho &quot;==&gt; 添加 xrdp 到 ssl-cert 用户组（避免黑屏）&quot;adduser xrdp ssl-certecho &quot;==&gt; 启动并启用 xrdp 服务&quot;systemctl enable xrdpsystemctl restart xrdpecho &quot;✅ 安装完成！现在可以使用 Windows 远程桌面（mstsc）登录本机 IP，使用系统用户名登录 XFCE 桌面。&quot; 你只需要将这段脚本保存为 install-xrdp-xfce.sh 文件，赋予执行权限并运行即可： 12chmod +x install-xrdp-xfce.sh./install-xrdp-xfce.sh 需要注意的是, 重启之后这个配置仍然会消失.所以还需要使用 systemd –user 拉起来这个脚本. 远程桌面使用说明 安装完成后，在 Windows 系统中打开“远程桌面连接（mstsc）”。 输入你的懒猫主机 IP 地址。 使用系统中的用户名密码进行登录 如果一切正常，应该可以看到一个 XFCE 图形桌面。 如果你连接后出现黑屏问题，通常是 .xsession 配置不正确或者权限不足，上述脚本中已经处理好了这个问题。 补充：如果你还想让它能本地显示图形界面如果你希望在物理机或有显卡输出的虚拟机中直接打开图形界面（不是远程连接），可以额外添加如下配置： 123echo &quot;exec startxfce4&quot; &gt; ~/.xinitrcchmod +x ~/.xinitrcstartx 这样你在本地终端执行 startx 就能启动 XFCE 桌面。 通过上述脚本，我们可以非常快速地为懒猫微服安装一个可用的图形桌面环境，并通过 XRDP 实现远程访问。这在需要图形界面支持的场景下尤其方便，例如： 使用浏览器调试网页； 可视化工具如 Wireshark、GParted； 为不熟悉命令行的用户开放访问权限。 如果你希望安装 KDE、GNOME 等更复杂的桌面，可以将 apt install 中的包名替换为 kde-standard、gnome 等，并注意资源占用问题。","link":"/posts/8e360f7e/"},{"title":"懒猫微服开发篇（零）：上架应用需要哪些知识","text":"懒猫微服的可玩性在于可以让开发人员放开手脚来做一些事情，等于是提供了一个可靠的基础设施。那么理所当然我们可以把开源的知识应用到上面，比如开发或者移植应用，或者干脆部署一些好玩的东西。这在传统 NAS 上实现起来很困难，甚至都没有包管理工具。 我们看一看开发懒猫应用，需要什么样的知识？ 那么，开发懒猫微服的应用需要掌握哪些技能呢？ NPM懒猫微服的 CLI 本质上是一个通过 NPM 全局安装的工具包，因此掌握一些基本的 NPM 使用方法是必要的。 1npm install -g @lazycatcloud/lzc-cli 这个工具是用 JavaScript 编写的，但如果你只是为了使用而非开发，那么并不需要掌握这门语言。当然，你也可以选择使用 pnpm 或 yarn 作为包管理工具，或者通过 NVM 来创建 Node.js 虚拟环境。 如果在 macOS/Linux 上遇到了权限不足的问题，其实不一定要使用 sudo。默认情况下，npm 的全局目录是 /usr/local，普通用户对其没有写权限。比如我们可以看到： 1234567891011 ll /usr/total 0drwxr-xr-x 918 root wheel 29K 6 5 14:05 bin/drwxr-xr-x 32 root wheel 1.0K 6 5 14:05 lib/drwxr-xr-x 417 root wheel 13K 6 5 14:05 libexec/drwxr-xr-x 8 root wheel 256B 6 10 09:31 local/drwxr-xr-x 230 root wheel 7.2K 6 5 14:05 sbin/drwxr-xr-x 43 root wheel 1.3K 6 5 14:05 share/drwxr-xr-x 5 root wheel 160B 6 5 14:05 standalone/lrwxr-xr-x 1 root wheel 25B 6 5 14:05 X11@ -&gt; ../private/var/select/X11lrwxr-xr-x 1 root wheel 25B 6 5 14:05 X11R6@ -&gt; ../private/var/select/X11 因此我们可以通过设置 npm 的全局安装目录，规避权限问题。在当前用户目录中创建一个文件夹并添加到环境变量中即可： 12345678 npm config get prefix/usr/localmkdir ~/.npm_packagesnpm config set prefix ~/.npm_packages/npm config get prefix/Users/home/.npm_packagesexport PATH=~/.npm-global/bin:$PATH 开发的技能是可选的，如果你只是移植现有的应用的话，那么具备一些 Docker Compose 的知识就足够了，这个我们后面再说。 如果是开发原创 APP 的话，那么无论是 Vue，React，Go，Python 都有用武之地，只要是 Web 的应用能够本地运行或者打包成 Docker 就能上架商店。相信很多开发的小伙伴也会做一些 Devops 的事情，这部分的技能是可以完全迁移过来的。 Linux很多 NAS 是基于 FreeBSD 或者 Linux 改的，懒猫微服是基于 debian12， 虽然在设计之初是针对非专业玩家。但是后来也开放了 SSH，可以做和其他 Linux 一样的事情，给了 root 用户，所以可以底层操作文件，网络，查看分区，监控，以及系统负载。 所以不是只有树莓派或者自己笔电装机才能学 Linux，懒猫微服的系统重启之后会复原（除了 root 目录和网络设置），所以请随便折腾。 虽然有了一套很完善的图形客户端，但是相信很多专业的玩家还是更加喜欢用传统 Linux 的方式来看待这个微服，我管他叫做拆解系统设计。 举个例子：用 htop 查看负载、用 nmtui 配置网络、用 lsblk 查看磁盘分区、用 systemctl 设置服务自启。深度定制的系统，让我们可以完全无视内核，以及 grub 的这些东西。甚至连 sambda，webdav 这些 server 都不用自己安装。 DockerDocker 好像对 NAS 玩家是必须的，无论是群晖，威联通。与传统 NAS 不一样的是，懒猫微服集成了三套 docker，分别是系统组件，playground 和应用商店。 playground 就是我们刻板印象的 Docker， 这里叫做pg-docker，所以需要懂一些 Docker 的知识，比如下载，打包，上传，还有数据卷的贡献。甚至包括 Docker- compose 的使用。 应用商店也是基于 Docker 运行的， 上架软件时有两种方式： 直接打包：这个一般用于原创应用或者移植开源无 docker 版本的应用。调试的时候可以使用懒猫内置的 Docker Registry 的 image 进行测试，颇有 VS code remote 的风格。这个调试模式叫做 devshell。 Docker 镜像迁移：一般用于已有的 docker image 的迁移，由于国内出海宽带不足，访问 Docker 经常失败。所以需要使用懒猫提供的 Docker Registry 来做一个国内版本的镜像。然后再做目录的映射。 OIDC这个稍稍有点跑题，前面的都是传统 Devops 需要的东西。这里的 OIDC 叫做 OpenID Connect，是单点登录实现的一种。传统的认证有基于 cookie 的，或者基于 JWT 的。OIDC 是后者，也是单点登录中最优雅的实现。除了 OIDC 之外，你可能听说过 SAML，Oauth，其实也都是 Single Sign-On 的不同实现，而 Oauth 是和 OpenID Connect 源同一脉，Oauth 的各家实现千差万别，而 OpenID Connect 既统一了规范，解决用户态的问题。换句话说 OAuth 2.0 只是用来授权，颁发的是Access Token，而对于访问者是谁还需要开发人员自己存数据库。OIDC 则是引入了ID Token，这通常是通常是 JWT，所以认证直接请求 IDP 解码就好了。大致是这个流程： 下图是 OIDC 的基本流程： 能够学到哪些知识： 微服内部的官网看起来是根据 OpenResty 改的（个人推断），所以可以来复习一下 nginx 或者 OpenResty 相关的知识 Docker 的使用，容器这几年还是挺火的，移植应用必备，甚至还支持 web VNC。 HTTP 知识：有些情况需要对 http 的请求做特殊的处理，比如加一些自定义 header 或者 cookies 单点登录：微服内置了 OIDC 的认证，应用能够自动帮助我们申请 CLIENT_ID 和 CLIENT_SECRET，简化了和 IDP 打交道的环节。 总结如果你熟悉 Web 开发、Docker 和基本的 Linux 操作，那么你已经可以快速上手懒猫微服的应用开发。无论是移植开源项目，还是开发原创 App，只要能够在本地运行或打包为 Docker 镜像，就可以顺利上架到应用商店。 懒猫微服不仅仅是一个面向普通用户的 NAS 系统，更是一块为开发者打造的自由试验田 —— 它就是一台稳定可靠的 Debian 云主机，你可以在上面尽情发挥创意与技术。","link":"/posts/c7acbc13/"},{"title":"懒猫微服开发篇（一）：懒猫微服全栈上架指南，一步打包，一键发布","text":"懒猫应用离不开社区的力量，有了各位社区贡献者的支持让懒猫商店的应用越来越丰富。下面示范如何把自己的全栈应用上架到懒猫微服。 官网给出的示例里只有 3 个必备文件：lzc-build.yml、lzc-icon.png、lzc-manifest.yml。 **lzc-icon.png**：应用图标，必须为 PNG。 **lzc-build.yml**：定义打包脚本、输出路径与图标路径。 **lzc-manifest.yml**：应用清单，描述路由规则等。 lzc-build.yml 示例1234567891011121314151617181920212223242526272829303132333435363738# 打包预处理，例子里是复制目录，打包前端文件# 见build.sh这个文件# rm -rf ./dist# mkdir -p dist# 构建后端二进制文件，因为后面写了contentdir是 dist 文件夹，# 所以dist是打包的上下文# cp -r backend dist/# 构建前端，这里就是普通的前端打包命令，只是指定了输出文件夹# cd ui &amp;&amp; npx vite build --emptyOutDir --outDir ../dist/webbuildscript: sh build.sh# manifest: 指定 lpk 包的 manifest.yml ，一般是这个名字不改manifest: ./lzc-manifest.yml# contentdir: 前面把前后端打包到这个目录还是。contentdir: ./dist# pkgout: lpk 包的输出路径pkgout: ./# icon 指定 lpk 包 icon 的路径路径，如果不指定将会警告# icon 仅仅允许 png 后缀的文件icon: ./lzc-icon.png# dvshell 指定开发依赖的情况，这个我们后面专门来讲讲# 这种情况下，选用 alpine:latest 作为基础镜像，在 dependencies 中添加所需要的开发依赖即可# 如果 dependencies 和 build 同时存在，将会优先使用 dependenciesdevshell: routes: - /=http://127.0.0.1:5173 dependencies: - nodejs - npm - python3 - py3-pip setupscript: | export npm_config_registry=https://registry.npmmirror.com export PIP_INDEX_URL=https://pypi.tuna.tsinghua.edu.cn/simple build.sh 执行完后目录结构大致如下： dist/backend → 后端（可执行/脚本） dist/web → 前端（静态文件） lzc-manifest.yml 示例12345678910111213lzc-sdk-version: 0.1name: 代办清单Pypackage: cloud.lazycat.app.todolistpyversion: 0.0.1description:license: https://choosealicense.com/licenses/mit/homepage:author:application: subdomain: todolistpy routes: - /=file:///lzcapp/pkg/content/web - /api/=exec://3000,./lzcapp/pkg/content/backend/run.sh routes 这里有三种写法： file 代表文件，一般是纯静态文件，比如打包后的前端文件，也就是在 build.sh 里面做的打包前端的操作，npm build 之类的，我们在脚本里指定了 content 的路径就是机器上的/lzcapp/pkg/content/，所以/lzcapp/pkg/content/web 也就是刚才的 dist/web。这个的意思就是说把根路由转发这个静态目录，其实就是类似 Nginx 托管静态文件这个样子，只是不需要手动打包，写好命令之后，打包工具帮忙做了这一套。 http(s)://$hostname/$path， 这个是我们印象里的网关代理后端服务，比如/api/=http(s)://$hostname/$path，其实就类似 Nginx 的 proxy_pass 将/api 转发到 http(s)://$hostname/$path/。 exec：这个和 http(s)很像，后面多加了一个 run.sh，相当于在转发到 http(s)路由之前，先执行这个脚本。一般是用来预置环境，比如 pip install 什么的，但是由于每个人的环境不一样，还是要使用多个镜像源才保险，我上架的应用就遇到用户通过清华源下载报错 HTTP403 以及 腾讯源下载签名不匹配的问题，或者干脆使用 Docker，这个我们后面再说。 附上 pip 多源的例子： 12345678910111213141516# 已有 —— 主索引 &amp; 前两级备用pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simplepip config --add global.extra-index-url https://pypi.mirrors.ustc.edu.cn/simple/pip config --add global.extra-index-url https://mirrors.bfsu.edu.cn/pypi/web/simple/# ③ 阿里云（华东节点评测最稳）pip config --add global.extra-index-url https://mirrors.aliyun.com/pypi/simple/# ④ 华为云（华南线路友好）pip config --add global.extra-index-url https://repo.huaweicloud.com/repository/pypi/simple/# ⑤ 字节跳动开源镜像（火山引擎，带全站 CDN）pip config --add global.extra-index-url https://mirrors.byteimg.com/pypi/simple/# ⑥ 南京大学镜像（NJU，教育网 &amp; 华东建议保留）pip config --add global.extra-index-url https://mirrors.nju.edu.cn/pypi/web/simple/ 打包与安装12345# 打包成 LPKlzc-cli project build -o release.lpk# 在线安装 LPKlzc-cli app install release.lpk 然后是打包，如果缺少 lzc-build.yml，lzc-icon.png，lzc-manifest.yml 三者之一就会报错。 LPK 是懒猫微服应用商店 APP 的安装包格式，其实可以理解为一个配置文件的压缩包，安装之后其实就是在微服内部启动了一个 alpine 的 image，然后通过 build.sh 安装依赖。 通过 lzc-docker 来看，直接打包的就是这个 images registry.lazycat.cloud/lzc/lzcapp:3.20.3 命令如下lzc-docker history –no-trunc registry.lazycat.cloud/lzc/lzcapp:3.20.3，能够看到是 Alpine 作为 base image，然后更换中科大的源，以及安装 gcompat 以兼容 glibc 程序。 1234567(base) lzcbox-029c588e ~ # lzc-docker history --no-trunc registry.lazycat.cloud/lzc/lzcapp:3.20.3IMAGE CREATED CREATED BY SIZE COMMENTsha256:ba7a533c869a26d89e83bdc5ddb978df5a3502ac91452422a649d0d3cf52190b 7 months ago RUN /bin/sh -c apk add gcompat # buildkit 2.48MB buildkit.dockerfile.v0&lt;missing&gt; 7 months ago RUN /bin/sh -c sed -i 's/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g' /etc/apk/repositories # buildkit 97B buildkit.dockerfile.v0&lt;missing&gt; 9 months ago CMD [&quot;/bin/sh&quot;] 0B buildkit.dockerfile.v0&lt;missing&gt; 9 months ago ADD alpine-minirootfs-3.20.3-x86_64.tar.gz / # buildkit 7.8MB buildkit.dockerfile.v0(base) lzcbox-029c588e ~ # 甚至可以看到，这个 image 是连 bash 以及各种开发运行时都没有的。 123456789101112(base) lzcbox-029c588e ~ # lzc-docker run -it registry.lazycat.cloud/lzc/lzcapp:3.20.3 bashdocker: Error response from daemon: failed to create task for container: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: error during container init: exec: &quot;bash&quot;: executable file not found in $PATH: unknown.(base) lzcbox-029c588e ~ # lzc-docker run -it registry.lazycat.cloud/lzc/lzcapp:3.20.3 sh/ # gosh: go: not found/ # npmsh: npm: not found/ # pipsh: pip: not found/ # pythonsh: python: not found/ # 所以这个 backend 文件夹的 run.sh 是拿来安装 Python 依赖的。而前端是使用本地的 npm 打包的。 12345678910111213141516171819202122232425262728#!/bin/sh# 切换到当前目录cd &quot;$(dirname &quot;$0&quot;)&quot;sed -i 's/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g' /etc/apk/repositoriesapk updateapk add python3 py3-pip# ❶ 设主索引，只能有一个# 已有 —— 主索引 &amp; 前两级备用pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simplepip config --add global.extra-index-url https://pypi.mirrors.ustc.edu.cn/simple/pip config --add global.extra-index-url https://mirrors.bfsu.edu.cn/pypi/web/simple/# ③ 阿里云（华东节点评测最稳）pip config --add global.extra-index-url https://mirrors.aliyun.com/pypi/simple/# ④ 华为云（华南线路友好）pip config --add global.extra-index-url https://repo.huaweicloud.com/repository/pypi/simple/# ⑤ 字节跳动开源镜像（火山引擎，带全站 CDN）pip config --add global.extra-index-url https://mirrors.byteimg.com/pypi/simple/# ⑥ 南京大学镜像（NJU，教育网 &amp; 华东建议保留）pip config --add global.extra-index-url https://mirrors.nju.edu.cn/pypi/web/simple/pip install -r ./requirements.txt --break-system-packagespython3 app.py 安装之后的 app 可以通过 lzc-docker 查看，也可以使用 Dozze 查看日志，一般 debug 时候的时候会看这个。 DOZZL 需要安装开发者工具，然后使用https://dev.设备名.heiyu.space/dozzle/访问。 一般来说部署有两个 pod，一个是 App-1 结尾的，主要是涉及到转发，run.sh 自动安装依赖，以及健康检查。 123PATH:&quot;/&quot; is served by &quot;file&quot;://&quot;/lzcapp/pkg/content/dist&quot;PATH:&quot;/api/&quot; is served by &quot;http&quot;://&quot;host.lzcapp:53443&quot;health check finished 应用名字-1 结尾的，这个才是应用的日志。 1234[2025-06-29 17:29:29 +0800] [1] [INFO] Starting gunicorn 23.0.0[2025-06-29 17:29:29 +0800] [1] [INFO] Listening at: http://0.0.0.0:9527 (1)[2025-06-29 17:29:29 +0800] [1] [INFO] Using worker: sync[2025-06-29 17:29:29 +0800] [9] [INFO] Booting worker with pid: 9 希望大家都能够多多为懒猫微服贡献应用。","link":"/posts/ec579c86/"},{"title":"懒猫微服开发篇（二）：远程调试之 Devshell","text":"我们上一篇讲述了如何打包上架 APP，这期我们就来看如何远程调试即将上架的 APP。 简单来讲，这个 devshell 其实就是在微服上打开了一个虚拟机环境，然后我们可以进去里面测试我们的命令。非要说技术实现，那就是 docker exec 了。只不过是做成了本地和微服之间同步的样子。 输入微服的名字/v2/_catalog，可以看到微服里面 Docker 仓库存放的镜像，debug.bridge 开头的就是 devshell 的 image。 1234567{ &quot;repositories&quot;: [ &quot;debug.bridge/231ee20d4e4d8edbd2004e7609fd9c15&quot;, &quot;debug.bridge/ddc6dbf609125b7bd2c0efb0ed4254d1&quot;, &quot;helloworld&quot; ]} 在 lzc-build.yml 里定义了 devshell 的配置，这个的意思是就是安装 node 和 python 的环境，设置国内源，然后讲根目录转发到 5173，这个是 vue 的端口。所以我们可以推断，这个是一个 Vue+python 的全栈项目，所以我们可以开两个终端来进入 devshell，分别调试前后端。 1234567891011devshell: routes: - /=http://127.0.0.1:5173 dependencies: - nodejs - npm - python3 - py3-pip setupscript: | export npm_config_registry=https://registry.npmmirror.com export PIP_INDEX_URL=https://pypi.tuna.tsinghua.edu.cn/simple 使用 lzc-cli project devshell -f 进入 devshell，可以看到这个使用了 registry.lazycat.cloud/lzc-cli/devshell 作为 base image，然后换源安装依赖。最后设置 setupscript 里面的 ENV。而 CMD [“sleep”, “infinity”]会让容器启动后执行sleep infinity` 命令，即无限休眠。目的是防止容器因没有前台进程而自动退出（保持容器处于“运行”状态）。 这里有个问题，如果你在 lzc-manifest.yml 里指定了 routes 也同样会生效。如果你要跑一些初始化脚本，可以在使用这两个办法 在 lzc-manifest.yml 文件中使用/api/=exec://3000,./lzcapp/pkg/content/backend/run.sh lzc-build.yml 中注入脚本 setupscript。 如果你偷懒在 lzc-build.yml 里 routes 的执行/api/=exec://3000,./lzcapp/pkg/cache/backend/run.sh，似乎也只能转发端口，不能运行脚本。 从日志看，也就是说还是安装了一个应用程序上去，只不过我们可以通过类似 ssh remote 的方式来动态调试。如果 APP 上架之后，能做的恐怕只有 lzc-docker exec 了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445跳过执行 buildscript跳过拷贝 contentdir 内容DockerfileSTEP 1/4: FROM registry.lazycat.cloud/lzc-cli/devshell:v0.0.5STEP 2/4: RUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g' /etc/apk/repositories--&gt; Using cache 2302149ded79afb639f9935a07e7ea0d63b5644b10e9890d49ad06786e7b31db--&gt; 2302149ded79STEP 3/4: RUN apk add --no-cache bash nodejs npm py3-pip python3 &amp;&amp; echo &quot;root:root&quot; | chpasswd--&gt; Using cache 9bb679fa2c9d10ab1a2433be4c59c852affb2a6844c62ecd9eb8d727505821fb--&gt; 9bb679fa2c9dSTEP 4/4: CMD [&quot;sleep&quot;, &quot;infinity&quot;]--&gt; Using cache 5ed701af0e0f7040c3dc5409f547b271b4f4e792fd4fcbfc4af8a3abecf8d363COMMIT debug.bridge/ddc6dbf609125b7bd2c0efb0ed4254d1:latest--&gt; 5ed701af0e0fSuccessfully tagged debug.bridge/ddc6dbf609125b7bd2c0efb0ed4254d1:latest5ed701af0e0f7040c3dc5409f547b271b4f4e792fd4fcbfc4af8a3abecf8d363Getting image source signaturesCopying blob sha256:c164879b06ca56693b742ec917059cce495320d4d8f6140bde7e875f53377ea1Copying blob sha256:69bc8c25bce956e4c34fdfee091c531ffa8660454526ea9f76c956f9b930c57bCopying blob sha256:98e60e58e2d093fd95b5d5d61ae6dac25bff89ba1b46d42395d480dfb75bddabCopying blob sha256:d4fc045c9e3a848011de66f34b81f052d4f2c15a17bb196d637e526349601820Copying blob sha256:b244bd08b327b00bfbbbbf4f424ade914ee891a52d9192a573dbe484e22d86abCopying config sha256:5ed701af0e0f7040c3dc5409f547b271b4f4e792fd4fcbfc4af8a3abecf8d363Writing manifest to image destination输出lpk包 /Users/xu/Desktop/todolist-py-lzcapp-demo/cloud.lazycat.app.todolistpy-v0.0.1.lpk开始部署应用开始安装应用安装成功！👉 请在浏览器中访问 https://todolistpy.dev.heiyu.space👉 并使用微服的用户名和密码登录+ export 'npm_config_registry=https://registry.npmmirror.com'+ export 'PIP_INDEX_URL=https://pypi.tuna.tsinghua.edu.cn/simple'+ set -e+ mkdir -p /lzcapp/cache/devshell+ cd /lzcapp/cache/devshell+ exec /bin/sh/lzcapp/cache/devshell #/lzcapp/cache/devshell # lsREADME.md backend build.sh lzc-build.yml lzc-icon.png lzc-manifest.yml ui 我们可以看到文件夹的内容已经被同步过来了，我们可以实时同步开发机文件的创建和修改。不过目前和移动，重命名相关的同步有点小问题，具体表现为 本地删除旧的文件，但是 devshell 里不会同步删除 删除文件 a，但是把 b 重名为 a，devshell 不会同步更改（但是删除 a 重建可以） 相信这两个小问题修好也只是时间问题，当然也有 workaround。 从/data/app/cache/包名这个目录删除 devshell 文件夹之后，然后重新执行 lzc-cli project devshell -f ，这样工作区就被清理干净了。 12345(base) lzcbox-029c588e /data/app/cache/cloud.lazycat.app.todolistpy # lsdevshell(base) lzcbox-029c588e /data/app/cache/cloud.lazycat.app.todolistpy # cd devshell/(base) lzcbox-029c588e /data/app/cache/cloud.lazycat.app.todolistpy/devshell # ls1 1312 README.md backend build.sh lzc-build.yml lzc-icon.png lzc-manifest.yml ui 另外，我们再通过 ssh 进入/data/app 这个目录，有两个子文件夹，一个叫做 cache，一个叫做 var。 cache 就是我们这个 devshell 的工作区。var 就是数据持久化的目录。如果在这里新建一个目录，那么就可以在网盘里实时看到。 1/data/app/var/xu.deploy.lazycat-nav # touch test 以上就是 devshell 的全部内容了，如果你需要借助微服的一些特性还进行开发，比如获取环境变量，OIDC 什么的，可以用这个方法来轻松调试。","link":"/posts/2c167bb4/"},{"title":"懒猫微服开发篇（三）：如何将已有 Docker Compose 应用移植到懒猫微服","text":"本文延续前两篇，演示如何把一个已经在本地运行良好的 Docker Compose 应用打包并上架到懒猫微服应用商店。以 Milvus 为例，逐步拆解 Manifest 配置、路由映射、数据卷绑定以及镜像加速等关键环节，帮助大家快速完成移植。 1. 目录结构与核心文件在懒猫微服中，一个最小可用的应用包仅需两个文件： 文件 作用 lzc-build.yml 描述打包流程及应用图标。简单应用只需指定 icon 即可。 lzc-manifest.yml 定义应用元数据与服务编排，是移植的重点。 本文主要关注 lzc-manifest.yml 的编写。 2. lzc-manifest.yml 字段逐一解析现在有了懒猫应用查看器很方便，我们以商店里的 Milvus 的示例 Manifest 为例，并附带注释说明。 这个 lzc-mainfest.yml 解析是重点。主要是 subdomain，ingress，services 这几个字段。总体上还是延续了 Docker compose 的风格。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061lzc-sdk-version: &quot;0.1&quot;name: Milvuspackage: in.zhaoj.milvusversion: 2.5.8author: milvusapplication: # 子域名：应用上线后将访问 https://milvus.&lt;机器名&gt;.heiyu.space subdomain: milvus background_task: false # 是否允许后台运行 multi_instance: false # 是否允许多实例 gpu_accel: false # 是否请求 GPU routes: # 七层（HTTP）路由 - /=http://attu.in.zhaoj.milvus.lzcapp:3000/ ingress: # 四层（TCP）转发 - protocol: tcp port: 19530 service: standalone - protocol: tcp port: 9091 service: standaloneservices: # 以下基本等同于 docker‑compose 中的 services etcd: image: registry.lazycat.cloud/longixaoyi/milvusdb/etcd:v3.5.18 environment: - ETCD_AUTO_COMPACTION_MODE=revision - ETCD_AUTO_COMPACTION_RETENTION=1000 - ETCD_QUOTA_BACKEND_BYTES=4294967296 - ETCD_SNAPSHOT_COUNT=50000 command: &gt; etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd binds: - /lzcapp/var/etcd:/etcd minio: image: registry.lazycat.cloud/longixaoyi/milvusdb/minio:RELEASE.2023-03-20T20-16-18Z environment: - MINIO_ACCESS_KEY=minioadmin - MINIO_SECRET_KEY=minioadmin command: minio server /minio_data binds: - /lzcapp/var/minio_data:/minio_data health_check: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:9000/minio/health/live&quot;] standalone: image: registry.lazycat.cloud/longixaoyi/milvusdb/milvus:v2.6.0-rc1 command: milvus run standalone environment: - ETCD_ENDPOINTS=etcd:2379 - MINIO_ADDRESS=minio:9000 depends_on: - etcd - minio binds: - /lzcapp/var/milvus:/var/lib/milvus attu: image: registry.lazycat.cloud/longixaoyi/zilliz/attu:latest environment: - MILVUS_URL=standalone:19530 depends_on: - standalone 2.1 subdomainsubdomain 是应用程序上线的域名，例如上述配置上线后即为 https://milvus.&lt;节点名&gt;.heiyu.space。 2.2 routesroute 来做七层的 HTTP 转发，类似 Nginx 的反向代理。规则格式为 本地路径 = 目标 URL。在示例中，根路径 / 被转发到前端服务 attu 的 3000 端口。 URL 规则：服务名.包名.lzcapp:端口。（包名随意起） - /=http://attu.in.zhaoj.milvus.lzcapp:3000/ 这里 attu 是服务名，端口是 3000，in.zhaoj.milvus 是包名。 2.3 ingress用于四层直通转发，适用于非 HTTP 协议（数据库、SSH 等）。示例将 Milvus 的 gRPC (19530) 与 HTTP (9091) 端口暴露给外部。 2.4 bindManifest 中的绑定路径以 /lzcapp/var 为前缀。发布后会被映射到宿主机的 /data/app/var/&lt;package&gt;，也算是为了简化程序移植和学习成本。和 Docker-compose 写绝对路径来说，这里的可移植性执行更好。 健康检查在这里不是必须的，因为打包的上架的时候服务会帮忙做这个事情。 3. 服务映射与 docker-compose.yml 对照懒猫 Manifest 的 services 段几乎一一复刻了传统 Compose 配置，常用键均保持一致。以下列出了 Milvus 官方 docker-compose.yml，方便对照理解： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566version: &quot;3.5&quot;services: etcd: container_name: milvus-etcd image: quay.io/coreos/etcd:v3.5.18 environment: - ETCD_AUTO_COMPACTION_MODE=revision - ETCD_AUTO_COMPACTION_RETENTION=1000 - ETCD_QUOTA_BACKEND_BYTES=4294967296 - ETCD_SNAPSHOT_COUNT=50000 volumes: - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/etcd:/etcd command: etcd -advertise-client-urls=http://etcd:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd healthcheck: test: [&quot;CMD&quot;, &quot;etcdctl&quot;, &quot;endpoint&quot;, &quot;health&quot;] interval: 30s timeout: 20s retries: 3 minio: container_name: milvus-minio image: minio/minio:RELEASE.2023-03-20T20-16-18Z environment: MINIO_ACCESS_KEY: minioadmin MINIO_SECRET_KEY: minioadmin ports: - &quot;9001:9001&quot; - &quot;9000:9000&quot; volumes: - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/minio:/minio_data command: minio server /minio_data --console-address &quot;:9001&quot; healthcheck: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:9000/minio/health/live&quot;] interval: 30s timeout: 20s retries: 3 standalone: container_name: milvus-standalone image: milvusdb/milvus:v2.6.0-rc1 command: [&quot;milvus&quot;, &quot;run&quot;, &quot;standalone&quot;] security_opt: - seccomp:unconfined environment: ETCD_ENDPOINTS: etcd:2379 MINIO_ADDRESS: minio:9000 MQ_TYPE: woodpecker volumes: - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/milvus:/var/lib/milvus healthcheck: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:9091/healthz&quot;] interval: 30s start_period: 90s timeout: 20s retries: 3 ports: - &quot;19530:19530&quot; - &quot;9091:9091&quot; depends_on: - &quot;etcd&quot; - &quot;minio&quot;networks: default: name: milvus 差异点主要体现在： 镜像源：建议通过 lzc-cli appstore copy-image &lt;image&gt; 把镜像同步到 registry.lazycat.cloud，解决国内网络拉取问题。 端口声明：在 Manifest 中，外部访问端口通过 ingress，不再使用 Compose 的 ports。 健康检查：懒猫平台会统一探测容器存活，可按需省略 healthcheck。 4. 镜像加速实践一条命令即可完成镜像复制并输出新的仓库地址： 1234567891011121314lzc-cli appstore copy-image nginx (base) 13:15:36Waiting ... ( copy nginx to lazycat offical registry)uploading23e05839: [####################################################################################################] 100%23e05839: [####################################################################################################] 100%23e05839: [####################################################################################################] 100%3da95a90: [####################################################################################################] 100%48670a58: [####################################################################################################] 100%6c8e51cf: [####################################################################################################] 100%9bbbd7ee: [####################################################################################################] 100%ce713206: [####################################################################################################] 100%ee95256d: [####################################################################################################] 100%uploaded: registry.lazycat.cloud/u04123229/library/nginx:d037205fbaf7d60a 将生成的地址替换到 Manifest 的 image 字段即可。 5. 小结 Manifest 为核心：lzc-manifest.yml 描述了全部运行时需求，移植时优先完善此文件。 路由分层：routes 管理 HTTP，ingress 管理 TCP，二者配合即可覆盖绝大多数场景。 统一数据目录：使用 /lzcapp/var 避免硬编码路径，便于跨节点迁移。 镜像国内托管：通过 lzc-cli appstore copy-image 自动同步到 LazyCat Registry，稳定又快速。 至此，Milvus 的 Docker Compose 应用已成功移植到懒猫微服。更多进阶玩法，例如 OIDC、VNC 集成等，我们将在后续文章继续分享。","link":"/posts/5e5f8aaa/"},{"title":"懒猫微服开发篇（四）：懒猫微服如何使用 OpenID Connect （OIDC）？（上）","text":"OpenID Connect（OIDC）是一个基于 OAuth 2.0 的身份认证协议，允许用户使用一个账号（如 Google、微信、Microsoft 账号）登录多个不同的网站或应用，而无需重复注册。我们经常把他和OAuth 2.0 混为一谈。 它主要用于 身份认证（Authentication），而 OAuth 2.0 主要用于 授权（Authorization）。简单来说： OAuth 2.0 → 让应用能访问你的数据（如获取微信头像），还要自己做用户管理。 OIDC → 让应用能确认“你是谁”（如用微信账号登录） 下面以我的懒猫 ENV 查看器为例，来讲解这个登录流程。 当你在应用处点击登录就会重定向到登录中心，我们通常管这个叫做身份提供商（IDP），如果是其他的软件有可能是 “使用 Google 登录” 或 “微信登录” 。 跳转到认证中心，一般都会提示你是否确认登录，某某应用将要获取登录的权限，查看你的信息。在懒猫微服里这直接点击 Grant Access 即可。在其他的 IDP 中，会让你输入账号密码登录，并同意授权该网站访问你的基本信息（如邮箱、昵称）。 当 IDP 验证完的身份后，返回一个 JWT（JSON Web Token），其中包含你的身份信息。当网站验证 JWT 后，确认你的身份，并让你登录成功。我们也可以在 jwt.io 和 jwt.ms 这个网站去做解码。 我解码了其中一个 token，我们可以看到里面的信息，可以看到加密算法，颁发机构，过期时间，用户信息什么的， 这个是一般登录的流程，比如首次用户名和密码登录成功之后会返回一个 JWT，然后后续把这个 JWT 当做 bear token 来请求后面的资源。我们的 OIDC 和这个原理类似，只不过稍微复杂一些。 在 OIDC 协议中，会遇到三种 Token: id_token, access_token 和 refresh_token。 Access Token 用于基于 Token 的认证模式，允许应用访问一个资源 API。用户认证授权成功后，Authing 会签发 Access Token 给应用。应用后面就带着这个** Access Token** 访问资源 API。 ID Token 相当于用户的身份凭证，开发者的前端访问后端接口时可以携带 ID Token，开发者服务器可以校验用户的 ID Token 以确定用户身份，验证通过后返回相关资源。 AccessToken 和 IdToken 都是 JWT，有效时间通常较短。通常用户在获取资源的时候需要携带 AccessToken，当 AccessToken 过期后，用户需要获取一个新的 AccessToken。 Refresh Token 用于获取新的 AccessToken。这样可以缩短 AccessToken 的过期时间保证安全，同时又不会因为频繁过期重新要求用户登录。用户在初次认证时，Refresh Token 会和 AccessToken、IdToken 一起返回。应用携带 Refresh Token 向 Token 端点发起请求时，这个时候会续签 AccessToken 和 IdToken 与 ID token。 所以我们一般说的 JWT 就是 Access Token 的部分用于授权。而ID Token 用户标注用户信息，Refresh Token 用来续签 Access Token 。 在懒猫微服上使用 OIDC 有一个好处就是，不用在 IDP 上填写申请信息，在程序运行过程中可以直接注入相应的环境变量，这样我们直接用就可以了。相当于传统 IDP 需要填写应用名称，做分组控制而言，这个自动注入的 OIDC 开箱即用很方便。 一般是有这几个信息： CLIENT_ID：从我的 app 来看，这个就是包名 CLIENT_SECRET： 这个是随机的 ISSUER_URI：https://微服域名/sys/oauth TOKEN_URI：https://微服域名/sys/oauth/token USERINFO_URI：https://微服域名/sys/oauth/userinfo 先说 ISSUER_URI，这个是 OIDC 的入口，其中.well-known/openid-configuration 里可以拿到各种 URL，算是 OIDC 的入口，即使环境变量中没给信息我们也可以在这里查看。比如用来校验 JWT 的 jwks_uri。 GET https://&lt;微服域名&gt;/sys/oauth/.well-known/openid-configuration 结果如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243{ &quot;issuer&quot;: &quot;https://&lt;name&gt;.heiyu.space/sys/oauth&quot;, &quot;authorization_endpoint&quot;: &quot;https://&lt;name&gt;.heiyu.space/sys/oauth/auth&quot;, &quot;token_endpoint&quot;: &quot;https://&lt;name&gt;.heiyu.space/sys/oauth/token&quot;, &quot;jwks_uri&quot;: &quot;https://&lt;name&gt;.heiyu.space/sys/oauth/keys&quot;, &quot;userinfo_endpoint&quot;: &quot;https://&lt;name&gt;.heiyu.space/sys/oauth/userinfo&quot;, &quot;device_authorization_endpoint&quot;: &quot;https://&lt;name&gt;.heiyu.space/sys/oauth/device/code&quot;, &quot;introspection_endpoint&quot;: &quot;https://&lt;name&gt;.heiyu.space/sys/oauth/token/introspect&quot;, &quot;grant_types_supported&quot;: [ &quot;authorization_code&quot;, &quot;refresh_token&quot;, &quot;urn:ietf:params:oauth:grant-type:device_code&quot;, &quot;urn:ietf:params:oauth:grant-type:token-exchange&quot; ], &quot;response_types_supported&quot;: [&quot;code&quot;], &quot;subject_types_supported&quot;: [&quot;public&quot;], &quot;id_token_signing_alg_values_supported&quot;: [&quot;RS256&quot;], &quot;code_challenge_methods_supported&quot;: [&quot;S256&quot;, &quot;plain&quot;], &quot;scopes_supported&quot;: [ &quot;openid&quot;, &quot;email&quot;, &quot;groups&quot;, &quot;profile&quot;, &quot;offline_access&quot; ], &quot;token_endpoint_auth_methods_supported&quot;: [ &quot;client_secret_basic&quot;, &quot;client_secret_post&quot; ], &quot;claims_supported&quot;: [ &quot;iss&quot;, &quot;sub&quot;, &quot;aud&quot;, &quot;iat&quot;, &quot;exp&quot;, &quot;email&quot;, &quot;email_verified&quot;, &quot;locale&quot;, &quot;name&quot;, &quot;preferred_username&quot;, &quot;at_hash&quot; ]} 至于回调 URL，这个是需要自己设置的部分。可能由于开发习惯导致每个应用的回调 URL 不一样。相对于在 IDP 中填写信息，在懒猫微服的 lzc-manifest.yml 中加这么一行即可。也只有设置了 application.oidc_redirect_path 之后，才能使用 OIDC 相关的环境变量。 1application.oidc_redirect_path: /callback 可以看看我的懒猫 ENV 查看器的设置。通过 oidc_redirect_path 设置回调地址，然后使用 environment 字段还这是需要的环境变量。 1234567891011121314151617181920lzc-sdk-version: 0.1name: 懒猫ENV查看器package: xu.deploy.envversion: 0.0.2description:license: https://choosealicense.com/licenses/mit/homepage:author: xuapplication: subdomain: env oidc_redirect_path: /callback routes: - /=exec://5005,./lzcapp/pkg/content/run.sh environment: - LAZYCAT_AUTH_OIDC_CLIENT_ID=${LAZYCAT_AUTH_OIDC_CLIENT_ID} - LAZYCAT_AUTH_OIDC_CLIENT_SECRET=${LAZYCAT_AUTH_OIDC_CLIENT_SECRET} - LAZYCAT_AUTH_OIDC_AUTH_URI=${LAZYCAT_AUTH_OIDC_AUTH_URI} - LAZYCAT_AUTH_OIDC_TOKEN_URI=${LAZYCAT_AUTH_OIDC_TOKEN_URI} - LAZYCAT_AUTH_OIDC_USERINFO_URI=${LAZYCAT_AUTH_OIDC_USERINFO_URI} - LAZYCAT_AUTH_OIDC_ISSUER_URI=${LAZYCAT_AUTH_OIDC_ISSUER_URI} 然后我们来看 OIDC 的几种授权模式。 应用类型 授权模式 有后端场景 授权码模式 SPA，无后端 隐式模式 应安全存储密钥 密码模式 服务器之间 Client Credentials 这个是 Authing 推荐的选择方式，不过据我的经验来讲，就 Web 开发而言大多还是选择隐式授权的居多。看的出来懒猫的 OIDC 也是用的这种。 懒猫微服也是用的授权码模式, 所以跳转的时候我们抓浏览器请求会看到： 1https://url/callback?code=xxxx 其实一个良好的 OIDC 流程是这样的： 当访问没有权限的路由的时候，在路由守卫中重定向到登录页面。 当用户登录的时候，跳转到对应的的 IDP 控制页面，然后输入用户凭证。这个时候会走 IDP 的认证。 认证之后会颁发一次性 code（授权码模式），如果是简单的密码模式，那么就会直接返回 Access Token，ID token 以及 refresh token。 使用授权码 code 换取 AccessToken、IdToken 以及 refresh token。授权码模式的好处是，把真正的令牌藏在后端交换，只暴露一次性 code，从而极大降低令牌泄露和被滥用的风险。 最后我们再用 AccessToken 来访问资源。 以上是基于懒猫的 OpenID Connect （OIDC）的理论讲解的部分，后面我们会进行实操，手把手创建可以接入 OIDC 的应用。 备注：关于部分 OIDC 的图文来自 Authing 文档。 https://docs.authing.cn/v2/concepts/oidc/choose-flow.html","link":"/posts/dcc47393/"},{"title":"懒猫微服开发篇（五）：懒猫微服如何使用 OpenID Connect （OIDC）？（下）","text":"先决条件： 需要在lzc-manifest.yml定义 oidc_redirect_path 和 environment。 配置lzc-manifest.ymloidc_redirect_path 就是你的应用的回调地址，只有写了这个之后才能正确使用 OpenID Connect 的环境变量。 回调地址是按照应用而定的，有的是/callback，/oidc/callback 或者/oauth/callback。 1234567891011121314151617181920lzc-sdk-version: 0.1name: 懒猫ENV查看器package: xu.deploy.envversion: 0.0.2description:license: https://choosealicense.com/licenses/mit/homepage:author: xuapplication: subdomain: env oidc_redirect_path: /callback routes: - /=exec://5005,./lzcapp/pkg/content/run.sh environment: - LAZYCAT_AUTH_OIDC_CLIENT_ID=${LAZYCAT_AUTH_OIDC_CLIENT_ID} - LAZYCAT_AUTH_OIDC_CLIENT_SECRET=${LAZYCAT_AUTH_OIDC_CLIENT_SECRET} - LAZYCAT_AUTH_OIDC_AUTH_URI=${LAZYCAT_AUTH_OIDC_AUTH_URI} - LAZYCAT_AUTH_OIDC_TOKEN_URI=${LAZYCAT_AUTH_OIDC_TOKEN_URI} - LAZYCAT_AUTH_OIDC_USERINFO_URI=${LAZYCAT_AUTH_OIDC_USERINFO_URI} - LAZYCAT_AUTH_OIDC_ISSUER_URI=${LAZYCAT_AUTH_OIDC_ISSUER_URI} 定义了环境变量之后，我们就可以在代码中使用环境变量： 开机时一次性从环境变量读取懒猫微服的应用域名、OIDC 客户端 ID/密钥，以及授权、令牌、用户信息三个核心端点，并根据应用域名拼出默认 Redirect URI，从而把所有与 OpenID Connect 登录相关的敏感信息解耦。 这里的 callback 是应用的回调 URL，需要根据应用调整。 123456789LAZYCAT_BOX_DOMAIN = os.environ.get('LAZYCAT_BOX_DOMAIN')LAZYCAT_APP_DOMAIN = os.environ.get('LAZYCAT_APP_DOMAIN')CLIENT_ID = os.getenv(&quot;LAZYCAT_AUTH_OIDC_CLIENT_ID&quot;)CLIENT_SECRET = os.getenv(&quot;LAZYCAT_AUTH_OIDC_CLIENT_SECRET&quot;)AUTH_ENDPOINT = os.getenv(&quot;LAZYCAT_AUTH_OIDC_AUTH_URI&quot;)TOKEN_ENDPOINT = os.getenv(&quot;LAZYCAT_AUTH_OIDC_TOKEN_URI&quot;)USERINFO_ENDPOINT = os.getenv(&quot;LAZYCAT_AUTH_OIDC_USERINFO_URI&quot;)REDIRECT_URI = os.getenv(&quot;OIDC_REDIRECT_URI&quot;, f&quot;https://{LAZYCAT_APP_DOMAIN}/callback&quot;) 登录功能在用户访问 /login 时动态生成一对 PKCE 凭据（随机 code verifier 和其 SHA-256 派生的 code challenge），把 verifier 暂存进会话，再携带 challenge 等参数构造 OIDC 授权码请求，并将用户浏览器重定向到身份提供方完成安全登录；回调阶段可用 session 中的 code verifier 与返回的 code exchange 配合，防止授权码被劫持或重放，从而提升 OAuth 2.0/OIDC 的安全性。 123456789101112131415161718192021222324# ======= 生成 PKCE Code Verifier &amp; Challenge =======def generate_pkce_pair(): code_verifier = base64.urlsafe_b64encode(secrets.token_bytes(32)).rstrip(b'=').decode() code_challenge = base64.urlsafe_b64encode( hashlib.sha256(code_verifier.encode()).digest() ).rstrip(b'=').decode() return code_verifier, code_challenge@app.route('/login')def login(): code_verifier, code_challenge = generate_pkce_pair() session['code_verifier'] = code_verifier auth_url = ( f&quot;{AUTH_ENDPOINT}&quot; f&quot;?response_type=code&quot; f&quot;&amp;client_id={CLIENT_ID}&quot; f&quot;&amp;redirect_uri={REDIRECT_URI}&quot; f&quot;&amp;scope=openid profile email&quot; f&quot;&amp;code_challenge={code_challenge}&quot; f&quot;&amp;code_challenge_method=S256&quot; ) print(auth_url) return redirect(auth_url) generate_pkce_pair() 使用 secrets.token_bytes(32) 随机生成 32 字节高强度随机数。 先经 base64.urlsafe_b64encode 再去掉尾部 = 得到 code verifier。 对 code verifier 做 SHA-256 散列后再次 base64 URL 安全编码并去掉 =，得到 code challenge。 返回二元组 (code_verifier, code_challenge)。 /login 路由 调用 generate_pkce_pair() 生成并拿到 code_verifier 和 code_challenge。 将 code_verifier 写入 Flask session，以便稍后在回调时校验。 拼接授权端点 AUTH_ENDPOINT 形成认证 URL： response_type=code 采用授权码模式 client_id、redirect_uri、scope 等常规 OIDC 参数 code_challenge 与 code_challenge_method=S256 声明使用 PKCE(S256) redirect(auth_url) 将浏览器跳转到身份提供方进行登录 + 授权 回调地址/callback 处理函数先从回调参数取出授权码，再用会话里的 code verifier 按 PKCE + 授权码模式向令牌端点换取 access token 和 ID token；成功后用 access token 调 /userinfo 获取用户资料，并把三者一起返回。如此既完成了 OAuth 2.0 的安全换码，又拿到了 OIDC 提供的登录身份信息，实现前后端分离的单点登录闭环。 12345678910111213141516171819202122232425262728293031323334@app.route('/callback')def callback(): code = request.args.get('code') code_verifier = session.get('code_verifier') # 请求 access token headers = {'Content-Type': 'application/x-www-form-urlencoded'} data = { 'grant_type': 'authorization_code', 'client_id': CLIENT_ID, 'client_secret': CLIENT_SECRET, 'code': code, 'redirect_uri': REDIRECT_URI, 'code_verifier': code_verifier, } token_resp = requests.post(TOKEN_ENDPOINT, data=data, headers=headers) print(token_resp) token_data = token_resp.json() print(token_data) access_token = token_data.get('access_token') id_token = token_data.get('id_token') # 获取用户信息 userinfo_resp = requests.get(USERINFO_ENDPOINT, headers={ 'Authorization': f'Bearer {access_token}' }) return { 'Access Token': access_token, 'ID Token': id_token, 'UserInfo': userinfo_resp.json() } code = request.args.get('code') 从回调 URL 查询参数中取出授权服务器返回的 code（授权码）。 code_verifier = session.get('code_verifier') 读取先前 /login 时存进会话的 code verifier，准备用于 PKCE 校验。 准备换取令牌的 HTTP POST 请求 12345678headers = {'Content-Type': 'application/x-www-form-urlencoded'}data = { 'grant_type': 'authorization_code', # 授权码模式 'client_id': CLIENT_ID, 'code': code, # 回调拿到的授权码 'redirect_uri': REDIRECT_URI, # 必须与首跳一致 'code_verifier': code_verifier, # PKCE 关键参数} code_verifier 会被身份提供方与首跳收到的 code_challenge 做 SHA-256 对比，从而证明客户端的“持有者”身份，防止授权码被截获后被第三方滥用。 token_resp = requests.post(TOKEN_ENDPOINT, data=data, headers=headers) 向令牌端点发送表单数据以换取 Access Token / ID Token。 token_data = token_resp.json() 解析 JSON 响应。例如： 1234567{ &quot;access_token&quot;: &quot;...&quot;, &quot;id_token&quot;: &quot;...&quot;, &quot;expires_in&quot;: 3600, &quot;token_type&quot;: &quot;Bearer&quot;, ...} access_token = token_data.get('access_token') 读取访问令牌，用于调用受保护 API。id_token = token_data.get('id_token') 读取 OIDC ID Token，携带用户身份声明，可本地解码验证。 获取用户信息 1234userinfo_resp = requests.get( USERINFO_ENDPOINT, headers={'Authorization': f'Bearer {access_token}'}) 按 OIDC 规范，用 Bearer Token 调 /userinfo 端点，拿到 JSON 形式的用户信息。 返回聚合结果（此处直接返回给浏览器以便演示） 12345return { 'Access Token': access_token, 'ID Token': id_token, 'UserInfo': userinfo_resp.json()} 在浏览器中可以看到这个登录跳转： 还是这个图，我们继续看这个流程： 拿到 code 之后可以就可以换到 Access token 和 ID Token 了，这个 code 只有一次有效，可以达到防重放的效果。当然这个只是 OIDC 的一个例子，在生产环境的 APP 中还需要做路由守卫以及 access 续签的操作。 完整代码如下： 读取配置 从环境变量获取 Lazycat 平台的域名、OIDC 客户端 ID/密钥，以及授权端点、令牌端点、用户信息端点和回调地址。 用随机 app.secret_key 支持 Flask Session。 PKCE 安全增强 generate_pkce_pair() 动态生成 code_verifier / code_challenge ；后者随登录请求携带，前者保存在 Session，回调时再带给 Token 端点，防止授权码被劫持。 核心路由 /：渲染首页（需自备 index.html）。 /login： 生成 PKCE 对； 拼接授权 URL（response_type=code，scope 含 openid profile email）； 浏览器重定向到 IdP 登录/授权页面。 /callback： 取回 code 与 code_verifier； POST 到 TOKEN_ENDPOINT 换取 access_token 和 id_token； 用 access_token 调用 USERINFO_ENDPOINT 拿到用户信息； 以 JSON 形式返回令牌与用户资料。 注意：生产环境应关闭 debug=True、使用 HTTPS、校验 state 参数防 CSRF，并妥善处理 Token 异常和错误分支。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899import osimport base64import hashlibimport secretsimport requestsfrom flask import Flask, redirect, request, session, url_for, render_templateapp = Flask(__name__)app.secret_key = os.urandom(24)LAZYCAT_BOX_DOMAIN = os.environ.get('LAZYCAT_BOX_DOMAIN')LAZYCAT_APP_DOMAIN = os.environ.get('LAZYCAT_APP_DOMAIN')CLIENT_ID = os.getenv(&quot;LAZYCAT_AUTH_OIDC_CLIENT_ID&quot;)CLIENT_SECRET = os.getenv(&quot;LAZYCAT_AUTH_OIDC_CLIENT_SECRET&quot;)AUTH_ENDPOINT = os.getenv(&quot;LAZYCAT_AUTH_OIDC_AUTH_URI&quot;)TOKEN_ENDPOINT = os.getenv(&quot;LAZYCAT_AUTH_OIDC_TOKEN_URI&quot;)USERINFO_ENDPOINT = os.getenv(&quot;LAZYCAT_AUTH_OIDC_USERINFO_URI&quot;)REDIRECT_URI = os.getenv(&quot;OIDC_REDIRECT_URI&quot;, f&quot;https://{LAZYCAT_APP_DOMAIN}/callback&quot;)print(CLIENT_ID)print(CLIENT_SECRET)print(AUTH_ENDPOINT)print(TOKEN_ENDPOINT)print(USERINFO_ENDPOINT)print(REDIRECT_URI)# ======= 生成 PKCE Code Verifier &amp; Challenge =======def generate_pkce_pair(): code_verifier = base64.urlsafe_b64encode(secrets.token_bytes(32)).rstrip(b'=').decode() code_challenge = base64.urlsafe_b64encode( hashlib.sha256(code_verifier.encode()).digest() ).rstrip(b'=').decode() return code_verifier, code_challenge# ======= 首页 =======@app.route('/')def index(): return render_template('index.html')# ======= 跳转授权页 =======@app.route('/login')def login(): code_verifier, code_challenge = generate_pkce_pair() session['code_verifier'] = code_verifier auth_url = ( f&quot;{AUTH_ENDPOINT}&quot; f&quot;?response_type=code&quot; f&quot;&amp;client_id={CLIENT_ID}&quot; f&quot;&amp;redirect_uri={REDIRECT_URI}&quot; f&quot;&amp;scope=openid profile email&quot; f&quot;&amp;code_challenge={code_challenge}&quot; f&quot;&amp;code_challenge_method=S256&quot; ) print(auth_url) return redirect(auth_url)# ======= 回调处理 =======@app.route('/callback')def callback(): code = request.args.get('code') code_verifier = session.get('code_verifier') # 请求 access token headers = {'Content-Type': 'application/x-www-form-urlencoded'} data = { 'grant_type': 'authorization_code', 'client_id': CLIENT_ID, 'client_secret': CLIENT_SECRET, 'code': code, 'redirect_uri': REDIRECT_URI, 'code_verifier': code_verifier, } token_resp = requests.post(TOKEN_ENDPOINT, data=data, headers=headers) print(token_resp) token_data = token_resp.json() print(token_data) access_token = token_data.get('access_token') id_token = token_data.get('id_token') # 获取用户信息 userinfo_resp = requests.get(USERINFO_ENDPOINT, headers={ 'Authorization': f'Bearer {access_token}' }) return { 'Access Token': access_token, 'ID Token': id_token, 'UserInfo': userinfo_resp.json() }if __name__ == '__main__': app.run(debug=True) 如果使用 authlib 是这样子的.通过 Authlib 把应用接入 OIDC： 启动时先从环境变量读取并校验客户端 ID、密钥及各端点； 随后注册 OIDC 客户端并自动启用 PKCE。 用户访问 /login 时，服务端生成 nonce 并调用 authorize_redirect() 将浏览器跳转到身份提供方登录，同时在会话里保存随机值；身份提供方完成认证后回调到 /callback，authorize_access_token() 会携带先前的 code 和 code verifier 去换取 access token / ID token，并用保存的 nonce 校验 ID Token 防止重放。 成功后解析得到的声明（用户信息）渲染或写入 Session，即可认为用户已登录。如此利用现成库把 PKCE、状态验证、ID Token 验签等安全细节都交给框架处理，只需少量代码就实现了安全的单点登录闭环。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import os, secretsfrom flask import Flask, request, render_templatefrom authlib.integrations.flask_client import OAuthLAZYCAT_BOX_DOMAIN = os.environ.get('LAZYCAT_BOX_DOMAIN')LAZYCAT_APP_DOMAIN = os.environ.get('LAZYCAT_APP_DOMAIN')CLIENT_ID = os.getenv(&quot;LAZYCAT_AUTH_OIDC_CLIENT_ID&quot;)CLIENT_SECRET = os.getenv(&quot;LAZYCAT_AUTH_OIDC_CLIENT_SECRET&quot;)AUTH_URI = os.getenv(&quot;LAZYCAT_AUTH_OIDC_AUTH_URI&quot;)TOKEN_URI = os.getenv(&quot;LAZYCAT_AUTH_OIDC_TOKEN_URI&quot;)USERINFO_URI = os.getenv(&quot;LAZYCAT_AUTH_OIDC_USERINFO_URI&quot;)JWKS_URI = os.getenv(&quot;OIDC_JWKS_URI&quot;, f&quot;https://{LAZYCAT_BOX_DOMAIN}/sys/oauth/keys&quot;)REDIRECT_URI = os.getenv(&quot;OIDC_REDIRECT_URI&quot;, f&quot;https://{LAZYCAT_APP_DOMAIN}/callback&quot;)required = [CLIENT_ID, CLIENT_SECRET, AUTH_URI, TOKEN_URI, USERINFO_URI, JWKS_URI, REDIRECT_URI]if not all(required): missing = [k for k, v in zip( [&quot;OIDC_CLIENT_ID&quot;,&quot;OIDC_CLIENT_SECRET&quot;,&quot;OIDC_AUTH_URI&quot;, &quot;OIDC_TOKEN_URI&quot;,&quot;OIDC_USERINFO_URI&quot;,&quot;OIDC_JWKS_URI&quot;, &quot;OIDC_REDIRECT_URI&quot;], required) if not v] raise RuntimeError(f&quot;缺少环境变量: {', '.join(missing)}&quot;)app = Flask(__name__)app.secret_key = &quot;a-very-secret-key&quot;oauth = OAuth(app)oidc = oauth.register( name=&quot;casdoor&quot;, client_id=CLIENT_ID, client_secret=CLIENT_SECRET, authorize_url=AUTH_URI, access_token_url=TOKEN_URI, userinfo_endpoint=USERINFO_URI, jwks_uri=JWKS_URI, client_kwargs={&quot;scope&quot;: &quot;openid profile email&quot;}, redirect_uri=REDIRECT_URI,)@app.route(&quot;/&quot;)def index(): return render_template(&quot;index.html&quot;)@app.route(&quot;/login&quot;)def login(): nonce = secrets.token_urlsafe(16) resp = oidc.authorize_redirect(redirect_uri=REDIRECT_URI, nonce=nonce) resp.set_cookie(&quot;oidc_nonce&quot;, nonce, max_age=300, httponly=True) return resp@app.route(&quot;/callback&quot;)def callback(): token = oidc.authorize_access_token() nonce = request.cookies.get(&quot;oidc_nonce&quot;) claims = oidc.parse_id_token(token, nonce=nonce) env_vars = sorted(os.environ.items()) return render_template(&quot;callback.html&quot;, access_token=token.get(&quot;access_token&quot;), id_token=token.get(&quot;id_token&quot;), user_info=claims, env_vars=env_vars)@app.route(&quot;/env&quot;, endpoint=&quot;show_env_html&quot;)def show_env_html(): env_vars = sorted(os.environ.items()) return render_template(&quot;env.html&quot;, env_vars=env_vars)if __name__ == &quot;__main__&quot;: app.run(debug=True, port=5005)","link":"/posts/48285dc8/"},{"title":"懒猫微服开发篇（六）:用 Openresty 做反向代理来解决跨域问题","text":"对于 Web 开发而言， 经常会遇到跨域问题。我们先来看一下什么是跨域问题： 跨域问题（Cross-Origin）本质上是浏览器的同源策略（Same-Origin Policy, SOP）在发挥作用： 同源指“协议 + 域名（或 IP）+ 端口”三要素完全一致。只要三者有任何一个不同，就被视为跨域。 为什么浏览器要限制跨域？ 安全：阻止一个站点随意读取或修改另一个站点的敏感资源（如 Cookie、LocalStorage、DOM），避免 XSS、CSRF 等攻击链被无限放大。 隔离：让不同网站在沙盒里各自运行，互不干扰。 同源策略只在浏览器环境生效；后端服务之间（如服务器 A 请求服务器 B）并没有 SOP 的限制。 场景 描述 是否受限 fetch('https://api.foo.com') 从 https://www.bar.com 发出 协议、域名不同 受限 http://example.com:3000 调用 http://example.com:4000 端口不同 受限 ⚠️ 用 Nginx/OpenResty 并不会“自动”解决 CORS。 你可以把前端请求代理到后端 API，使浏览器认为请求仍在同一域名下，达到“变同源”的效果。 或者直接在后端/代理层加 CORS 响应头，两种方式都可以。 懒猫微服的上使用的是 OpenResty，这是一个功能齐全的 Web 应用服务器，它集成了标准的 nginx core、大量第三方 nginx 模块以及它们的大部分外部依赖项。所以和 Nginx 的配置文件是通用的。 以我之前比赛做的项目为例，这个是 Nginx 作为网关，监听 80 端口，然后反向代理到 Next.js 和 Flask。 12345678910111213141516171819202122232425262728services: nginx: build: context: . dockerfile: Dockerfile ports: - &quot;80:80&quot; depends_on: - next-app - backend restart: unless-stopped next-app: image: smart-shopping-app container_name: next-frontend expose: - &quot;3000&quot; environment: - NODE_ENV=production - NEXT_TELEMETRY_DISABLED=1 restart: unless-stopped backend: image: shoppingassistant-backend container_name: backend-app expose: - &quot;5005&quot; restart: unless-stopped 而 Nginx 的配置文件如写，做七成的转发，把根路径转发到前端，/api 转发到后端。所以前端的 axios 请求等于访问的/api 这个端点，所以可以规避跨域的问题。 123456789101112131415161718server { listen 80; server_name localhost; location / { proxy_pass http://next-app:3000; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } location /api { proxy_pass http://backend:5005; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; }} 其实对于懒猫微服的 OpenResty 的也是一样的，好处是不用自己再找 base image 了，直接把配置文件写进去就能用了。 12345678910111213141516171819202122232425262728293031323334lzc-sdk-version: &quot;0.1&quot;name: APP Proxy Testpackage: cloud.lazycat.app.app-proxy-testversion: 0.0.1application: routes: - /=http://app-proxy.cloud.lazycat.app.app-proxy-test.lzcapp:80 subdomain: app-proxy-test #services: app-proxy: image: registry.lazycat.cloud/app-proxy:v0.1.0 setup_script: | cat &lt;&lt;'EOF' &gt; /etc/nginx/conf.d/default.conf server { listen 80; server_name _; # 静态页面 location / { root /usr/local/openresty/nginx/html; index index.html index.htm; } # API 反向代理，保留 /api 前缀 location /api/ { proxy_pass http://flask:5000/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } EOF flask: image: registry.lazycat.cloud/u04123229/cloudsmithy/flask-demo:c14689303facd82c flask 的 image 是我之前做的一个镜像仓库docker run -p 5005:5000 cloudsmithy/flask-demo:latest 然后通过lzc-cli appstore copy-image cloudsmithy/flask-demo 把镜像换成懒猫的镜像，registry.lazycat.cloud/u04123229/cloudsmithy/flask-demo:c14689303facd82c 通过setup_script传入和 Nginx 类似的配置文件，原理是替换 docker image 本身的 entrypoint/command 参数。 12345# 打包成 LPKlzc-cli project build -o release.lpk# 在线安装 LPKlzc-cli app install release.lpk 我们可以看到这个是 OpenResty 的主页，然后访问https://app-proxy-test.micro.heiyu.space/api/ 也能返回 Flask 容器“Hello from multi-arch Flask Docker in production mode!”。 如果你想把根路由直接代理到容器，也可以使用这个办法。这个一般是用来做反向代理来访问内网的服务，即使是 http 也没有关系。这个环境变量应该是懒猫魔改的快捷方式。不要和配置文件混用。 123456789101112131415lzc-sdk-version: &quot;0.1&quot;name: APP Proxy Testpackage: cloud.lazycat.app.app-proxy-testversion: 0.0.1application: routes: - /=http://app-proxy.cloud.lazycat.app.app-proxy-test.lzcapp:80 subdomain: app-proxy-test #services: app-proxy: image: registry.lazycat.cloud/app-proxy:v0.1.0 environment: - UPSTREAM=&quot;http://flask:5000&quot; flask: image: registry.lazycat.cloud/u04123229/cloudsmithy/flask-demo:c14689303facd82c 有时候还会加上BASIC_AUTH_HEADER这个字段来让 nginx/Openresty 自动填写密码，除了你的容器以外，代理外边服务也行。 其实用echo -n &quot;user:password&quot; | base64,的数据来填充BASIC_AUTH_HEADER“Basic “ 12345678910111213141516lzc-sdk-version: &quot;0.1&quot;name: APP Proxy Testpackage: cloud.lazycat.app.app-proxy-testversion: 0.0.1application: routes: - /=http://app-proxy.cloud.lazycat.app.app-proxy-test.lzcapp:80 subdomain: app-proxy-test #services: app-proxy: image: registry.lazycat.cloud/app-proxy:v0.1.0 environment: - UPSTREAM=&quot;https://xxx:9200/&quot; - BASIC_AUTH_HEADER=&quot;Basic YWRt46YzssdsfFlOk=&quot; flask: image: registry.lazycat.cloud/u04123229/cloudsmithy/flask-demo:c14689303facd82c 另外也支持多域名解析，这个在传统的线下机房比较常见，而云上基本上还是 7 层基于路由转发，比如第一种，我也更加熟悉第一种。 这个其实就是加了一个 secondary_domains 的字段，然后把后端单独暴露出来了。这样就子域名就可以访问后端。 123456789101112131415161718192021222324252627282930313233lzc-sdk-version: &quot;0.1&quot;name: APP Proxy Testpackage: cloud.lazycat.app.app-proxy-testversion: 0.0.1application: routes: - /=http://app-proxy.cloud.lazycat.app.app-proxy-test.lzcapp:80 subdomain: app-proxy-test # 应用列表里默认打开的域名 secondary_domains: - flaskservices: app-proxy: image: registry.lazycat.cloud/app-proxy:v0.1.0 setup_script: | cat &lt;&lt;'EOF' &gt; /etc/nginx/conf.d/default.conf server { server_name app-proxy-test.*; location / { root /usr/local/openresty/nginx/html; index index.html index.htm; } } server { server_name flask.*; location / { proxy_pass http://flask:5000; } } EOF flask: image: registry.lazycat.cloud/u04123229/cloudsmithy/flask-demo:c14689303facd82c","link":"/posts/300338c6/"},{"title":"懒猫微服开发篇（七）： 解析 Docker Compose Override","text":"看过很多的 Docker 教程，也都不曾提到过 compose override，第一次接触到这个是在懒猫微服上解开 LPK 看到的，用来注入 docker 引擎的环境变量。但是还以为是懒猫微服的小技巧，今天整理笔记才发现原来的 Docker compose 用来做多环境部署的配置文件，比如用来给开发和生产分别注入不同的环境变量和配置文件。 参考文档：Docker Compose Override - LazyCat Developer Guide 使用场景是这样，在实际开发中，通常我们需要分别为开发和生产环境配置不同的服务和环境变量。虽然可以为每个环境维护独立的 Compose 文件，Docker Compose 提供了一个非常有用的特性，可以将多个 Compose 文件结合使用，简化配置管理。 基础配置文件：第一个 Compose 文件通常作为基础配置，后续的文件可以覆盖该基础文件中的配置。 覆盖配置：每个额外的文件不仅可以覆盖基础文件中的已有配置，还可以添加新的配置。 默认情况下，Compose 会读取以下两个文件： docker-compose.yml：基础配置文件 docker-compose.override.yml：覆盖文件 你还可以通过 -f 参数指定多个非默认的覆盖文件，Compose 会按顺序合并这些文件。 1docker compose -f docker-compose.yml -f dev.override.yml up docker-compose config：这是一个非常有用的命令，可以帮助你验证最终的配置文件，尤其是在使用多个 Compose 文件时。它显示了合并后的 Compose 配置，帮助你确保配置符合预期。 示例：Nginx 配置docker-compose.yml12345services: web: image: nginx:latest ports: - &quot;80:80&quot; docker-compose.override.yml123456services: web: volumes: - ./dev:/usr/share/nginx/html # 使用本地开发文件夹覆盖默认卷 environment: - DEBUG=true # 启用开发环境的调试模式 在这个例子中，docker-compose.override.yml 覆盖了 docker-compose.yml 中的配置，添加了开发环境相关的文件挂载和环境变量设置。 合并后的配置（查看通过 docker-compose config 命令生成的配置）12345678910111213141516171819202122name: &quot;3&quot;services: web: environment: DEBUG: &quot;true&quot; image: nginx:latest networks: default: null ports: - mode: ingress target: 80 published: &quot;80&quot; protocol: tcp volumes: - type: bind source: /Users/name/Desktop/dev target: /usr/share/nginx/html bind: create_host_path: truenetworks: default: name: 3_default 可以看到，通过合并配置，开发环境的调试模式和本地文件夹挂载已经成功加入了配置。 懒猫应用的上的 compose override针对一些 lpk 规范目前无法覆盖到的运行权限需求， 可以通过 compose override 机制来间接实现。 通过应用查看器可以看到，这是 Docker Compose 配置的一部分，用于定义容器中的 containly 服务，并映射 playground 的 docker 引擎。具体的配置说明如下： services: 这是 Docker Compose 文件的顶级字段，定义了服务列表。containly 是定义的一个服务名称。 containly: 这是服务的名称。在此配置下，的服务名是 containly。 volumes: 定义了容器与宿主机（本地）之间的文件夹共享和挂载。该部分的配置是映射一个本地目录到容器内部的目录。 bind: 使用绑定挂载的方式（bind mount），允许宿主机的文件或目录直接映射到容器内部。这里设置了 create_host_path: true，意思是如果宿主机上的 /data/playground 目录不存在，它会自动创建。 source: 宿主机的路径，映射为容器中的目录。这里指定了 /data/playground 作为源路径，意味着宿主机上的这个目录将被挂载到容器内。 target: 容器内的路径，即宿主机上的 source 目录映射到容器内部的 /lzcapp/run/playground 目录。容器内的应用可以访问这个目录。 type: 这里设置的是 bind，表示采用绑定挂载方式 最后 highlight 下 WIKI 里的三句话： 确认最终生成的 lpk 中存在名为 compose.override.yml 的文件，并且内容是一个合法的 Compose 合并文件。 通过 SSH 进入 /data/system/pkgm/run/$appid 目录，确认该目录下是否存在 override.yml 文件。 使用 lzc-docker-compose config 命令查看最终合并后的配置，确保它符合预期。 子/data/system/pkgm/run/$appid 目录里，我的结果如下,供参考。 123456789101112131415161718192021222324docker compose configname: xudeploycontainlyservices: app:....- type: bind source: /data/playground target: /lzcapp/run/playground bind: create_host_path: true...(base) lzcbox-029c588e /data/system/pkgm/run/xu.deploy.containly # lscompose.override.yml docker-compose.yml pkg(base) lzcbox-029c588e /data/system/pkgm/run/xu.deploy.containly # cat compose.override.ymlservices: containly: volumes: - bind: create_host_path: true source: /data/playground target: /lzcapp/run/playground type: bind","link":"/posts/7ac076b/"},{"title":"懒猫微服排查篇（一）：403 Forbidden！记应用商店 pip 使用清华源的报错","text":"由于自身调试 OIDC 需要，写了一个懒猫 ENV 查看器，然后发到商店里给大家使用/ 打包的时候偷了个懒，直接打包的没有用容器，然后其中一位用户就遇到这个问题： 要了下日志，结果是发现访问清华源有问题，被清华源直接返回了 403，这个问题还比较稀奇，毕竟在我的印象里清华源一直都很稳。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566-------------logs:-------------app-1 | 2025-06-23T14:28:36.813573986Z Start Child Process: [sh -c ./lzcapp/pkg/content/run.sh]app-1 | 2025-06-23T14:28:36.813587080Z PATH:&quot;/&quot; is served by &quot;exec&quot;://&quot;5005,./lzcapp/pkg/content/run.sh&quot;app-1 | 2025-06-23T14:28:36.818585835Z fetch https://mirrors.ustc.edu.cn/alpine/v3.20/main/x86_64/APKINDEX.tar.gzapp-1 | 2025-06-23T14:28:36.997192042Z fetch https://mirrors.ustc.edu.cn/alpine/v3.20/community/x86_64/APKINDEX.tar.gzapp-1 | 2025-06-23T14:28:37.251288967Z 2025/06/23 22:28:37 http: proxy error: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:37.251446934Z 2025/06/23 22:28:37 http: proxy error: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:37.444530406Z v3.20.6-201-gd57c9d7d1c9 [https://mirrors.ustc.edu.cn/alpine/v3.20/main]app-1 | 2025-06-23T14:28:37.444552892Z v3.20.6-203-g66ce3a1d0dc [https://mirrors.ustc.edu.cn/alpine/v3.20/community]app-1 | 2025-06-23T14:28:37.444560548Z OK: 24177 distinct packages availableapp-1 | 2025-06-23T14:28:37.732800630Z (1/25) Installing libbz2 (1.0.8-r6)app-1 | 2025-06-23T14:28:37.834399822Z (2/25) Installing libexpat (2.7.0-r0)app-1 | 2025-06-23T14:28:37.978333761Z (3/25) Installing libffi (3.4.6-r0)app-1 | 2025-06-23T14:28:37.996681317Z (4/25) Installing gdbm (1.23-r1)app-1 | 2025-06-23T14:28:38.023808099Z (5/25) Installing xz-libs (5.6.2-r1)app-1 | 2025-06-23T14:28:38.059202322Z (6/25) Installing libgcc (13.2.1_git20240309-r1)app-1 | 2025-06-23T14:28:38.120270779Z (7/25) Installing libstdc++ (13.2.1_git20240309-r1)app-1 | 2025-06-23T14:28:38.219766620Z (8/25) Installing mpdecimal (4.0.0-r0)app-1 | 2025-06-23T14:28:38.244870690Z (9/25) Installing ncurses-terminfo-base (6.4_p20240420-r2)app-1 | 2025-06-23T14:28:38.266752323Z (10/25) Installing libncursesw (6.4_p20240420-r2)app-1 | 2025-06-23T14:28:38.301269438Z (11/25) Installing libpanelw (6.4_p20240420-r2)app-1 | 2025-06-23T14:28:38.318329841Z (12/25) Installing readline (8.2.10-r0)app-1 | 2025-06-23T14:28:38.474049984Z (13/25) Installing sqlite-libs (3.45.3-r2)app-1 | 2025-06-23T14:28:38.628199528Z (14/25) Installing python3 (3.12.11-r0)app-1 | 2025-06-23T14:28:39.316803498Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:39.367766399Z (15/25) Installing python3-pycache-pyc0 (3.12.11-r0)app-1 | 2025-06-23T14:28:39.753346082Z (16/25) Installing pyc (3.12.11-r0)app-1 | 2025-06-23T14:28:39.770701744Z (17/25) Installing py3-setuptools-pyc (70.3.0-r0)app-1 | 2025-06-23T14:28:39.929343816Z (18/25) Installing py3-pip-pyc (24.0-r2)app-1 | 2025-06-23T14:28:40.207250136Z (19/25) Installing py3-parsing (3.1.2-r1)app-1 | 2025-06-23T14:28:40.304655931Z (20/25) Installing py3-parsing-pyc (3.1.2-r1)app-1 | 2025-06-23T14:28:40.317188019Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:40.529573664Z (21/25) Installing py3-packaging-pyc (24.0-r1)app-1 | 2025-06-23T14:28:40.618998893Z (22/25) Installing python3-pyc (3.12.11-r0)app-1 | 2025-06-23T14:28:40.653772503Z (23/25) Installing py3-packaging (24.0-r1)app-1 | 2025-06-23T14:28:40.830130888Z (24/25) Installing py3-setuptools (70.3.0-r0)app-1 | 2025-06-23T14:28:40.995056226Z (25/25) Installing py3-pip (24.0-r2)app-1 | 2025-06-23T14:28:41.318293072Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:41.764687778Z Executing busybox-1.36.1-r29.triggerapp-1 | 2025-06-23T14:28:41.768553945Z OK: 75 MiB in 42 packagesapp-1 | 2025-06-23T14:28:42.318842615Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:42.994899875Z Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simpleapp-1 | 2025-06-23T14:28:43.192401924Z Collecting Flask (from -r ./requirements.txt (line 1))app-1 | 2025-06-23T14:28:43.219653783Z ERROR: HTTP error 403 while getting https://pypi.tuna.tsinghua.edu.cn/packages/3d/68/9d4508e893976286d2ead7f8f571314af6c2037af34853a30fd769c02e9d/flask-3.1.1-py3-none-any.whl (from https://pypi.tuna.tsinghua.edu.cn/simple/flask/) (requires-python:&gt;=3.9)app-1 | 2025-06-23T14:28:43.219966823Z ERROR: Could not install requirement Flask from https://pypi.tuna.tsinghua.edu.cn/packages/3d/68/9d4508e893976286d2ead7f8f571314af6c2037af34853a30fd769c02e9d/flask-3.1.1-py3-none-any.whl (from -r ./requirements.txt (line 1)) because of HTTP error 403 Client Error: Forbidden for url: https://pypi.tuna.tsinghua.edu.cn/packages/3d/68/9d4508e893976286d2ead7f8f571314af6c2037af34853a30fd769c02e9d/flask-3.1.1-py3-none-any.whl for URL https://pypi.tuna.tsinghua.edu.cn/packages/3d/68/9d4508e893976286d2ead7f8f571314af6c2037af34853a30fd769c02e9d/flask-3.1.1-py3-none-any.whl (from https://pypi.tuna.tsinghua.edu.cn/simple/flask/) (requires-python:&gt;=3.9)app-1 | 2025-06-23T14:28:43.319551942Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:43.578023168Z Traceback (most recent call last):app-1 | 2025-06-23T14:28:43.578037493Z File &quot;/lzcapp/pkg/content/app.py&quot;, line 2, in &lt;module&gt;app-1 | 2025-06-23T14:28:43.578038656Z from flask import Flask, request, render_templateapp-1 | 2025-06-23T14:28:43.578039625Z ModuleNotFoundError: No module named 'flask'app-1 | 2025-06-23T14:28:43.581234895Z ChildProcess exit: exit status 1app-1 | 2025-06-23T14:28:44.320074235Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:45.320738420Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:46.321124378Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:47.322143472Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:48.322911993Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:49.323128356Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:50.323783719Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:51.323982245Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:52.324934294Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:53.325225164Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:54.325889637Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:55.326592221Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:56.326903845Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:57.327197993Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refusedapp-1 | 2025-06-23T14:28:58.327666585Z WAIT ./lzcapp/pkg/content/run.sh 127.0.0.1:5005 ERR: dial tcp 127.0.0.1:5005: connect: connection refused GPT 查询了下，可能就是 IP 给限制了。 打开清华的 Pypi 的页面，看到这位的 IP 确实被清华拦截了。 为了防止这个情况，有两个办法： 直接使用 Docker 做好镜像，这样就无关软件源 可以同时设置其他 pypi 源： 1pip config set global.extra-index-url &quot;https://mirrors.aliyun.com/pypi/simple/ https://repo.huaweicloud.com/repository/pypi/simple/ https://mirrors.cloud.tencent.com/pypi/simple/&quot; 然后可以使用 pip config list 查看,能看到我这个是走了腾讯云的： 1234567891011pip install pandasLooking in indexes: https://pypi.org/simple, https://mirrors.aliyun.com/pypi/simple/, https://repo.huaweicloud.com/repository/pypi/simple/, https://mirrors.cloud.tencent.com/pypi/simple/Collecting pandas Downloading https://mirrors.cloud.tencent.com/pypi/packages/9f/cc/ae8ea3b800757a70c9fdccc68b67dc0280a6e814efcf74e4211fd5dea1ca/pandas-2.3.0-cp312-cp312-macosx_11_0_arm64.whl (10.7 MB) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.7/10.7 MB 3.6 MB/s eta 0:00:00Requirement already satisfied: numpy&gt;=1.26.0 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (1.26.4)Requirement already satisfied: python-dateutil&gt;=2.8.2 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)Requirement already satisfied: pytz&gt;=2020.1 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2025.1)Requirement already satisfied: tzdata&gt;=2022.7 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2025.1)Requirement already satisfied: six&gt;=1.5 in /opt/miniconda3/lib/python3.12/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.17.0)Installing collected packages: pandas","link":"/posts/c20c194c/"},{"title":"懒猫微服排查篇（二）：上架应用后，pip 安装报错 HASH 不一致","text":"懒猫 ENV 查看器第二版更新的时候，审核人员和我说遇到了这个错误。说来也奇怪，都用了 docker 了，也会遇到依赖的问题。 https://appstore.lazycat.cloud/#/shop/detail/xu.deploy.env ERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILEExpected sha256 4ceb…Got 5519987f… 因为 pip 在校验阶段就失败，后面的 Flask 等依赖都没装上，于是程序启动时报 ModuleNotFoundError: No module named ‘flask’。 最后我还是替换掉了腾讯云。以清华源为主，其他源为辅： 123456789101112131415#!/bin/sh# 切换到当前目录cd &quot;$(dirname &quot;$0&quot;)&quot;sed -i 's/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g' /etc/apk/repositoriesapk updateapk add python3 py3-pip# 设一条主索引（可选）pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple# 给同一个键追加多条 extra-index-urlpip config set global.extra-index-url https://mirrors.aliyun.com/pypi/simple/pip config set global.extra-index-url https://repo.huaweicloud.com/repository/pypi/simple/pip config set global.extra-index-url https://mirrors.cloud.tencent.com/pypi/simple/pip install -r ./requirements.txt --break-system-packagespython3 app.py 网上还有几种办法，后面再遇到的时候可以再尝试： –no-cache-dir pip cache purge pip install –trusted-host=pypi.org –trusted-host=files.pythonhosted.org example_package rm ~/.cache/pip -rf 关闭机器代理 参考链接： https://stackoverflow.com/questions/71435874/pip-these-packages-do-not-match-the-hashes-from-the-requirements-file","link":"/posts/cf7f5d3/"},{"title":"Mac 上 Orbstack的Docker容器访问微服 Wordpress IPv6 解析问题记录","text":"今天在 Mac 上的 Docker 容器访问微服里的 Wordpress 时，遇到了 IPv6 无法正常访问的问题。现象是：dig 能解析出 IPv6 地址，但容器内网络不可达。 https://appstore.lazycat.cloud/#/shop/detail/dev.beiyu.wordpress 问题现象 dig 查询正常，能返回 IPv6 结果。 但容器内访问（curl、ping6）失败，提示网络不可达。 原因排查查询后发现： 默认情况下，Docker 引擎并未为容器分配 IPv6 地址。 这导致虽然 DNS 能解析，但容器无 IPv6 出口。 解决方法在 Orbstack 设置中开启 IPv6 支持即可： 开启后，Docker 引擎会自动重启。 无需手动添加 --ipv6 启动参数。 验证结果开启 IPv6 后，在容器内执行 curl 获取 Wordpress RSS 链接，正常返回内容： 1curl https://micro.heiyu.space/feed ping6 测试也正常： 123456[root@5c79a5875d68 easysearch]# ping6 micro.heiyu.spacePING micro.heiyu.space(fc03:1136:384f:313:a637:437:d22b:0) 56 data bytes64 bytes from fc03:1136:384f:313:a637:437:d22b:0: icmp_seq=1 ttl=62 time=4.27 ms64 bytes from fc03:1136:384f:313:a637:437:d22b:0: icmp_seq=2 ttl=62 time=5.85 ms64 bytes from fc03:1136:384f:313:a637:437:d22b:0: icmp_seq=3 ttl=62 time=3.36 ms64 bytes from fc03:1136:384f:313:a637:437:d22b:0: icmp_seq=4 ttl=62 time=3.97 ms 总结在 Mac 上运行的 Docker 容器默认不分配 IPv6 地址，需要在 Orbstack 设置中手动开启 IPv6 支持。开启后无需额外配置，容器即可正常解析并访问 IPv6 目标。","link":"/posts/2ad973ba/"},{"title":"懒猫微服故事篇（一）：服务器宕机之后，我和前端靠懒猫微服结对编程","text":"故事篇分享我和懒猫微服的方方面面，这里没有高深的技术，也没有过多的讲解。我始终坚信着技术是服务于生活，因为它能够给我们带来小确幸。更多的时候，我们追求技术，有时候为了兴趣，有时候为了心目中那小小的执念。慢慢在这个过程中会成为别人眼中的哆啦 A 梦。懒猫微服是一个百宝箱，我们能拿出千变万化的道具。事情会过去，但是感动和记忆会留下，我们可以随时追忆。 和前端同学约好晚上一起过一遍 API，主要是确认 Swagger 上的接口和字段设置。我事先把后端代码、API 和 Swagger 文档都部署在服务器上，让他先通过浏览器简单预览一遍，然后再开始写前端代码，这样能提前避免前后端格式对不上的问题。 准备开始之前，结果他突然说：‘你的 Swagger 打不开了。我登陆到管理控制台看了下，果然和之前部署 Dify 一样的问题，telnet 端口和 Ping 都正常，但是 SSH 和 Web 应用全都访问不了了。从基本监控俩看，CPU 和磁盘也没什么问题。大概率又是 OOM 了。 DDL 赶在眼前，得赶紧让他连到我的服务器或者开发机才好。第一个想到的是端口转发，把服务映射到公网上去，一方面调试的时候属于明文传输，在互联网上很容易被监听，篡改报文。另一方面，家里的公网 IP 经常出问题，总有一阵子会封禁所有的端口，所以最后采取了异地组网的方式。 我和他说，我在我的 NAS 上给你开一个账户，然后你试试来访问我的 Macbook 上的服务。你去下载一个懒猫微服，下载地址是https://lazycat.cloud/download，然后扫描我给你的二维码，这样就可以访问我的NAS了。（回看这段感觉有点像电信诈骗哈哈，感谢前端同学的信任） 他下载 APP、注册账号，我分配权限后，确认他能正常访问微服主页，就开启了端口转发。把我的 Macbook 的地址和 Web 的端口映射出去，只允许已登录的微服客户端访问。这样就免去了被其他的人中间攻击的烦恼，尤记得第一次把服务公开到整个互联网的时候，日志里出现的 IP 真是天南地北，北欧的，中东的，非洲的…… 现在用懒猫微服做异地组网，整个流程只需几分钟，再也不用担心这些琐碎的问题了。 他问了我几个问题。 Q1：网址好像打不开。 A1：你打开懒猫微服试试，或者放在后台。需要靠这个软件来做 DNS 解析。 Q2：你的懒猫是什么，软件嘛？还是硬件？ A2：是一个硬件产品，我拍给你，他带了异地组网的功能。 Q3: 还能穿透其他服务嘛？ A3: 除了线下的设备，微服商店里的服务都能穿透，比如使用 planka 来管理进度，有点 Jira 那个味道了。 后面写点感悟，关于云服务器，IDC 和微服民间几种不同的说法： 前期可以用云做一些 POC，然后稳定了之后就可以搬回自己的机房了。 一切的一切都可以交给云厂商来做，一方面减轻了运维人员的负担，另一方面还可以弹性伸缩，即用即付。 一些传统公司或者是自己有 IDC 的机房会喜欢第一种说法，而云厂商会采取第二种说法。 这并不是否定公有云的价值，但在使用过程中，除了价格高之外，还有一个现实问题：售后支持常常跟不上。国内这些厂商追求短期效应，心思都放在大客户上，用各种加班来满足大客户的需求，当然也包括一些 24K 纯白的需求。而对于处于调研初期的大公司，小微企业，或者说技术爱好者并没有得到平等的对待，甚至的毫不关心的态度，相对于潜在的商单，他们更喜欢数着现在的钱。同样很多传统做 NAS 的厂家售后也跟不上，要么是响应时间等很长很长，或者给到完全不靠谱的结论甚至一本正经的一读乱回。需要注意的是，这里不是一棒子打死所有的云厂商和 NAS 厂家，而是当你遇到紧急的问题时候，还是有很高的概率遇到这样的冷处理。所以我们常开的一句话玩笑话：迁走。 现在觉得，如果不是生产环境必须要对互联网公开或者强制遵循一些安全上的 0 信任原则，比如 POC 环境或者个人环境，用懒猫就完全足够了，还要什么云服务器，那么贵又那么脆。 曾经曾经——我也是云计算忠实的拥护者。。。。。。","link":"/posts/d2e0eee4/"},{"title":"懒猫微服故事篇（二）：西湖邂逅后，我手把手教她玩转NAS","text":"去年与她相识于杭州，是在西湖的游船上。参加活动过后，我想在杭州逗留一天，看看被世人称为眼泪的西湖水。没做攻略，匆匆向前台要了手册，然后来到距离最近的码头。磨磨蹭蹭之后总算开船，隔着一堆大爷大妈看着看着她在拍照，也邀请我帮她拍照。于是找她要攻略，一起逛三潭映月，净慈寺，讨论雷峰塔的倒下。 因为苏堤，我们聊到东坡，美食以及宦海沉浮。聊到最爱的粤菜和川菜更是共同的爱好，去成都旅游的时候找他要了攻略，并且约定下次去她的城市旅游给我当导游。 https://appstore.lazycat.cloud/#/shop/detail/cloud.lazycat.shell.files 加了微信一直零零碎碎的聊着。一个周末的早上，她找我帮忙转换视频格式。由于微信的限制无法发送大文件，于是我建议她通过懒猫网盘传给我。 于是开始做思想工作，把数据上传到我的家里的懒猫微服上。这里还是感谢信任和支持，没有认为我这个是一些诈骗盗取的网站。（毕竟曾经在学校讨论代理问题，被文科生当成黑客） 然后开账户，她的 windows 好像没有可以扫码的地方，所以我帮助她注册好，然后发给她。和她自己注册不一样的是，她的设备我登录时候我这边会弹出“安全码”，然后再发给她，这样她就就可以自己处理登录的问题了。我给她开了懒猫相册，清单，网盘和一些好玩的 APP，除了处理这个事情之外，也希望后面也能慢慢用起来其他的功能。 我是一个非常不喜欢 MFA 的人，但是这个二次验证还是能够接受。常规的 MFA 是每次登录都要手动输入二次验证码，而这个相同的设备只需要一次。虽然从系统设计的角度上看二者没有太大的区别，但是还是感觉这个设计，用来节约我们浪费在二次验证上的时间。我们不是牛马，我们是人，我要相信自己的验证。 然后我告诉他把文件上传到网盘上，然后共享整个文件夹给我。在我的不完全测试下只有文件夹才能共享，然后操作完文件之后再做同样的操作共享给她。毕竟对比被共享人而言，这个目录是只读的，所以我们用共享给对方来完成这个操作。 当然中间有个小插曲，就是上传需要等好久。她的是文科生所以对网络一知半解。一开始还以为她家的网速慢，还稍微吐槽了下。 上传完成之后，我于是让她测试下家里的网速。毕竟以前找我修电脑的姑娘，不是电脑配置过时就是，几乎完全的电脑盲。然后测试下来发现她家的网速还算可以，主要是国内的运营商限制比较多。国内是唯一按照 BGP 收费的，加上还要打击 PCDN，所以每家的上传少的可怜，30MBPS 是刚好能玩的水准，转算成实际的速度嘛，还是等等吧。 实际上，她给我的文件竟然有 15 个 G 多。这种大文件如果不是自建 NAS 或者商业方案根本没有传输的办法。QQ 和微信限制大小，就连邮箱也要限速 5 个 G。最早以前，我们用的办法就是，分段压缩成多个压缩包，然后一个个传给对面，对面再用相同的办法解开。十分麻烦并且耗时。而使用传统的 NAS 还要面临不定时封端口的噩梦，装机师傅和客服都解释不清楚，没有地方去问。虽然家里有公网 IP，但是不想每天被这种琐碎的问题困扰，当初购买懒猫微服也是最喜欢他们这个穿透的卖点。内网传统的是永恒的问题，然后是动态域名解析，做好还要加上健康检查，之前休假的时候把家里的机器透传到公网上，然后三五天就被封端口，但是回去看的时候内网怎么都是好的，但公网 telnet 依然有问题，除非重启路由器更换 IP。 现在我不用为了网络穿透的问题烦恼了，不用担心二次验证以及黑客攻击的问题。用拓竹的例子来说吧，只有用懒猫是在玩 NAS，其他的传统硬件都是在折腾。折腾固然好，兴趣价更高。若为自由故，二者皆可抛。 懒猫带给我的，是丰富的硬件资源和社群沟通，以及售后的专业和及时。花钱买省心，剩下抄作业。大抵如此了。","link":"/posts/943b4ba6/"},{"title":"懒猫微服炫技篇（一）：使用懒猫微服的穿透服务，车机使用DS music 远程听歌，黑群晖不用再洗白","text":"声明：炫技篇不是最佳实践，只是为了记录过程和那颗折腾的心。虽然很多时候可以用钱来升级或者多忍一忍就好了。但是折腾的心始终是不安分的，技术在职场中证明不了什么，但是在生活中可以。当晦涩的理论不仅仅存在于书本，才能给我们带来更大的价值。这个过程中能够找到我们到底是为了什么才需要这项技术，问题的痛点，以及这技术的前世今生。。。。。。 前些天给老旧的车载导航升级了 WIFI 功能，大致就是出厂的时候锁了 wifi 的驱动和 UI，然后通过 ADB 解锁的，然后通过路由器 Mesh 升级了老旧的 APP 以及导航数据，这次又带来了全新的功能，给普通车机升级 Carplay。 毕竟我的初衷，就是想在车机上安装懒猫 APP 而已啊。 Part 1：下载懒猫微服 APK，通过 U 盘导入安装，报错：解析错误，解析软件包时出现问题。 于是和懒猫相关技术进行确认，很快 CEO 给到了答复，目前只支持比亚迪和华为。毕竟国产车嘛，路子野一点也正常。 那我如果不用安卓，换 Carplay 呢？是不是就能用 IOS 的客户端直接投过去了？ Part 2：开始改 Carplay。 车载导航是当时赠送的，安卓 6.0。朋友推荐说可以购买 Carplay 盒子，于是疯狂搜索，现在的 Carplay 盒子分为两种。 有线 Carplay 改无线 Carplay 安卓车机改无线 Carplay 我的安卓车机没有 Carplay APP，方向盘也没有语音控制按钮。所以一开始能不能支持 Carplay，我是比较有疑问的。直到搜到了一篇夸赞车连易的帖子，大概说是最早做这个方向的公司，产品比较稳定一类的。 于是买回来调试，需要先安装他们的 autokit 软件检测（买之前需要用 Iphone 检测），这个 APP 后续当 Carplay APP 使用。（这里有个小插曲，之前 adb 调试的时候在改了工厂模式，开了 USB 调试，导致后来 USB 无法识别任何设备，包括 U 盘，2.4G 发射器，手机，以及 Carplay 盒子）对照之前的照片，关了就好了。然后我就拥有了人生第一台 Carplay 车机，盒子一点不烫，就是手机哗哗掉电。 开心之余还不忘记去找懒猫 APP，屏幕上有钉钉，百度网盘，网易云，甚至连 Home Assistant 都有？那我的懒猫微服 APP 呢？原来是 Apple 的白名单限制，美其名曰为了安全。GPT 搜下了，基本上除了导航和音乐一类的设备其他都没有了。那我高速服务区追个剧？好歹让投个屏嘛。。。。。。 同时和微服以及 Carplay 盒子的厂家确认，得到了一份寥寥无几的 APP 名单。 梦碎？ GPT 的解释如下： 以下内容基于 Apple 开发文档（2024 年最新版）及最近一次 iOS 18.4 更新的公开信息整理而成，可作为「CarPlay 现阶段 官方 支持的 App 类型、代表性应用，以及常见限制」速查表。(Apple Developer) 1 | CarPlay 允许上车的 8 大官方类别 类别 典型代表 App 主要交互模板 备注 导航 Apple 地图、Google Maps、Waze、Gaode/高德 地图、仪表盘、列表 iOS 18.4 起可设 默认导航（EU 地区率先落地）(The US Sun) 音频 Apple Music、Spotify、网易云音乐、Podcast、Audible、DS Music（Synology） 播放中、网格、列表 仅音频；禁止歌词滚动、视频封面等会分散注意力 通信 电话、信息、WhatsApp、钉钉、Teams 列表、语音 文本内容不得直接显示，只能通过 Siri 朗读 停车 EasyPark、停简单 列表 提供空位、计费等信息 EV 充电 Tesla、ChargePoint、小桔充电 列表、地图 可筛选功率、空闲桩等 加油 / 加氢 BPme、壳牌加油 列表、地图 仅提供站点 &amp; 价格；支付流程需遵循「停车后才允许」规则 快餐外卖 Dunkin’、星巴克 列表 只能选择常用餐点并一键复购，禁做复杂自定义 驾驶辅助 / 任务 扫盲测试、行车记录提示类 网格、信息 聚焦安全提醒、里程统计等（不含 ADAS 改装） 车企自家 App（空调、座椅、360 环视等）属于「Automaker Apps」，与上表并列但须由车厂提交。(Apple Developer) 2 | 为什么某些 App（视频、文件管理等）上不了 CarPlay？ 场景 限制要点 开发侧原因 视频/娱乐（Netflix、哔哩哔哩） 行车安全：禁止播放分散注意力的可视内容 CarPlay 模板不提供视频区域；审核会拒绝 文件管理（ES 文件浏览器、NAS 探索） 无对应类别；操作路径过复杂 无可用模板且易诱导司机操作 社交媒体（微博、X、抖音） 不得显示滚动 Feed、评论等 CarPlay 指南明令「No social networking」(Apple Developer) 游戏 / 浏览器 驾驶分心 &amp; 没有类别 同上 3 | 作为开发者，要满足哪些门槛？ 申请 CarPlay Entitlement 向 Apple 提交 App ID、类别说明、演示视频；获批后才能编译带 CarPlay 功能的版本。(Apple Developer) 使用系统提供的模板 只能调用列表、网格、地图、Now Playing 等固定 UI；不可自绘按钮或随意布局。(Apple Developer) 全部操作无需拿起 iPhone 登录、付费等「复杂流程」必须设计为停车后才可完成，或通过 SiriKit 语音处理。 严格的内容审核 不得插入横幅广告，禁止收集车辆数据做非核心用途，消息不可明文显示等。 4 | 对普通用户而言的使用限制 维度 具体表现 设备要求 iPhone 6s 及以上（iOS 17+ 建议），Lightning 有线或支持无线 CarPlay。 同时运行数量 iOS 18.4 支持「三排图标」；实际显示取决于车机分辨率。(The US Sun) 地区差异 某些导航/支付/餐饮 App 仅在特定国家可上车，例如中国区暂不开放「Apple 钱包加油」。 多任务 非导航类 App 在后台仅获有限音频/定位权限；切回主屏超过 8 分钟或手动关闭即结束会话。 常见 Q&amp;A 问题 解答 能在 CarPlay 打开 NAS 上的影片吗？ 不行，现阶段只支持「音频类」DS Music；视频需停车使用原车 USB/HDMI 或车企自带系统。 想在车机上用 VSCode、ES 文件浏览器？ 属于生产力 / 文件管理场景，CarPlay 无对应类别，无法过审。 越狱或使用 CarBridge 能装任何 App 吗？ 理论可行但高风险：系统不稳定、Apple Pay 安全受损、保修被拒，不建议在主力机尝试。 官方 仅开放 8 大类别，核心目标是「行车安全 + 切实刚需」。 想把新 App 带到 CarPlay？先判断是否符合这 8 类，然后按模板开发并申请 entitlement。 作为用户，若某款 App 还未上车，说服力最大的途径是：去 App Store 给开发者留言催更，而不是等「万能破解」。 Part3小红书上搜到了 DS audio 的攻略，竟然是群晖套件？评论区还有人推荐 DS music，颜值很高。下载之后我也很喜欢。 不就是群晖嘛，这年头谁还没一个黑群晖了。公网 IP 不定时被封端口，那懒猫转发了解一下？ 于是把群晖的端口映射出来，就在 APP 中可以远程连接使用了，这不比 Synology QuickConnect 还省事嘛。。。。 各类软件测试如下 DS audio 一直提示登录，尽管手机端已经一切正常 DS music 可以正常访问和听歌，这个软件颜值爱了 DS music+ 一直加载失败， DS cloud 和 DS player 在打开时候好像是一样的 UI，能找到歌曲，但是点击没反应 最后喜欢的还是 DS music，功能正常还好看啊。 除了 DS 系列，好像 Q 系列也行，不过吃灰很久很久了。（具体连接待测试） 用懒猫微服解决了公网转发的问题，再也不担心被运行商封端口了，还有车载大屏（除了有点掉帧），也算圆了一个梦吧。 你的车有 Carplay 吗？","link":"/posts/12695041/"},{"title":"懒猫微服炫技篇（二）：使用懒猫微服倒推停电时间","text":"早晨的时候，突然听到饮水机和扫地机器人重启的声音，只有一种可能是电闸重启了。没有人为重启，那就是意外断电了。赶紧 SSH 登录到懒猫微服，第一时间查看 uptime，果然 3 分钟之前重启了。懒猫的 BIOS 有上电自启的功能，所以能够看到确实是停电了。 使用 uptime -s 显示系统最后一次启动的具体时间 然后又看了看群晖，群晖接到了 UPS 上，几乎没受到啥影响。 昨天刚把懒猫从 UPS 上拿下来，因为发现 UPS 有无线干扰。结果第二天就遇到断电，果然是怕啥来啥。 先看看开机时间： 1journalctl --list-boots # 列出所有启动记录 重点观察： LAST ENTRY：上次关机时间 FIRST ENTRY：本次启动时间这两个时间中间如果有一个空档，而没有正常的 shutdown 日志，就极可能是断电。 可以看到从 08:31 到 08:41，系统中断了 10 分钟，符合意外断电并自动重启的特征。 然后看看关机日志，基本都是昨天的手动关机的日志，今天意外断电的日志丢失，也在情理之中。 1journalctl -b -1 | grep -i &quot;shutdown\\|power\\|crash\\|kern.*panic&quot; # 检查上次会话 如果是正常关机，会有 systemd-shutdown 或服务停止记录； 如果是异常断电，则日志会直接中断，没有“收尾”。 到这基本上可以确定是 08 点 31 断电的了，再拉下系统日志：能看到好好的 UPNP 的日志突然中断。然后 10 分钟后转为开机日志。基本上可以确定是意外断电。 1journalctl -S &quot;2025-06-17 08:30:00&quot; -U &quot;2025-06-17 08:42:00&quot; 赶紧查下 SMART 信息，还好没啥事。 1smartctl -a /dev/sda","link":"/posts/b6479fd0/"},{"title":"懒猫微服炫技篇（三）：sunshine+moonlight 双人串流打游戏","text":"之前在懒猫商店上架了坦克大战，一直想着怎么双人一起玩的问题。现在的年轻人除了逢年过节之外很难凑在一起，所以就想着能不能通过远程共享+键盘映射的办法远程双人游戏呢？碰巧刷到了司波图的 NAS 串流打游戏视频，加上之前一直被朋友安利 sunshine+moonlight 的组合，远程 linux 比 VNC 和 XRDP 都要好很多。所以我也来试试。 下载地址：https://app.lizardbyte.dev/Sunshine/?lng=zh-CN 懒猫微服默认没有图形化，所以直接安装串流服务端也没有意义。于是我用懒猫开启了一个 Windows 虚拟机来做服务器，关于后面怎么安装 windows 虚拟机，后面来讲，或者你也可以找一台物理机 windows 来安装懒猫微服的客户端。 然后把 windows 作为串流的服务端（安装 sunshine）。直接 EXE 安装，然后启动之后在浏览器中设置一下串流的密码就好。 为什么不用 RDP？ RDP 的原生限制，想两个人连接同一个屏幕操作，需要改注册表，很麻烦，所以放弃了这个方案。 客户端下载 Monnlight，然后会自动发现局域网设备。（如果是广域网可以考虑组网，朋友之前有试过也可以串流玩 stream） 客户端加入的时候可以使用 PIN 认证，在服务端输入客户端认证弹出的 PIN，然后再输入设备名称。 然后在客户端点击 Desktop 就可以了，第二个设备也可以重复这个操作，实测不会把第一个串流的 Session 挤掉。 我的目的就是用服务器打开懒猫微服的网页，然后两个客户端同时串流玩双人的游戏。 如果是大型游戏的话，可以直接直接从商店下载部署版本，但是这种小游戏还想娱乐一下的，两个人用串流一起玩还是听方便的。 能够看到我用 Ipad 和 Macbook pro 同时串流懒猫微服里的坦克大战，玩双人游戏还可以基本没啥问题的。（只是稍微有点点卡） 也算是圆了一个梦吧。","link":"/posts/2d63e359/"},{"title":"快速检索懒猫商店1000+应用,微服秒变Mac原生APP","text":"懒猫商店如今已有 1000+ 应用，日常使用中经常要在搜索栏反复查找，着实有些不便。有没有更简单的方法呢？答案是：可以直接把网页保存成 Mac 应用，像手机 App 一样快捷打开！ 下面就手把手教大家几种实用的方法。 优雅方案——PWA在 Mac 上，我们有更高级的玩法。不少现代网站都支持 PWA（Progressive Web App），简单来说，就是让网页像 App 一样运行： 可以像应用一样安装在本地 点击图标就能直接启动，无需打开浏览器 界面简洁，没有多余的地址栏和标签页 下面是懒猫清单的安装效果： 支持 PWA 的网站，在地址栏右侧会自动弹出“安装应用”按钮。 只需点击它，就能轻松将网页保存为应用。 PWA 的优点：速度快、体验好、支持离线，真正做到了网页与 App 的无缝结合。 通过 PWA 添加之后，会在 Finder 里弹出 Chrome 应用，我这里添加了懒猫网盘，懒猫原生的 APP 基本都是带 PWA 的，所以这一点体验很好。 添加完桌面应用之后，浏览器会有“在应用中打开”的提示，点击就可以像 APP 一下打开，就是前面第二张懒猫清单的图片。 如何通过 Chrome 中安装懒猫 Web 应用 在 Chrome 浏览器中打开你要保存的网站（如懒猫微服务）。 点击右上角“更多”按钮，依次选择**投放、保存和分享 → 将网页安装为应用…**。 有些网站也会直接在地址栏右侧显示“安装”图标，点一下即可快速安装。 安装时你可以自定义应用名称，这里以 OnlyOffice 为例。 这样做还可以解决 Mac 没有 Office 订阅的痛点，直接通过网页版弥补。 完成后，应用会存放在： 1/Users/你的用户名/Applications/Chrome Apps.localized/ 它们会以.app格式存在，完全就像普通 Mac 应用一样。 123❰~/Applications/Chrome Apps.localized❱✔≻ lsIcon? 懒猫清单.app/ONLYOFFICE Docs.app/ 懒猫网盘.app/ 如何通过 Safari 中把懒猫应用添加为 APP对于不支持 PWA 的网站，Safari 也提供了一个类似的解决方案。 在 Safari 中打开要保存的网页。 选择“文件 → 添加到程序坞”，或者点击“共享”按钮 → 添加到程序坞。 输入自定义的应用名称，点击“添加”。这个应用会自动放在应用程序里面。 应用将会被保存到“应用程序”文件夹中，支持从程序坞、启动台或 Spotlight 快速启动。 直接拖拽到 Dock，一键启动无论是通过 Chrome 还是 Safari 安装的网页 App，安装完成后都可以像普通应用一样拖到 Dock。 只需保持懒猫微服务后台连接，点击 Dock 图标，就能立即打开应用，体验和原生 App 无异！ 进阶玩法：自定义网页启动器当然，你也可以用 Python 快速实现一个简单的网页启动器： 123import webbrowserwebbrowser.open(&quot;https://www.apple.com&quot;) # 打开网页 支持新窗口、新标签等操作，适合简单自定义。 结语通过以上方法，我们就可以把常用的懒猫 APP 变成 Mac 的桌面应用，随时一键直达，告别繁琐的搜索过程，体验飞跃式提升！","link":"/posts/ce3905e3/"},{"title":"懒猫微服买硬件送服务，刚学的计算机知识顺便接了个单","text":"事先声明，懒猫微服不提供接单服务，但是可以通过贡献攻略和移植应用赚取激励。 挺有意思的一个事，头几天刚刚找过懒猫微服的技术帮我配置 cloudflare 相关操作，顺便学习了一下基本使用，把自己在 AWS 的 Route53 上购买的域名迁移过去了，然后代理到了博客，AWS EC2 服务器，甚至家里的机器。 偶然间在微信群看到这样一个需求，这不就是前两天懒猫微服的技术人员手把手教我做的。cloudflare 有很多操作，之前周围的人还有使用 cloudflare 反向代理到家里的 NAS，然后 obsidian 实时同步笔记连回家的。 于是我给了他三个方案： 最省心的：cloudflare 只做域名解析，应用无缝迁移到 Linux 服务器上。 全托管的：cloudflare 做域名解析，然后利用 cloudflare 的 Worker 部署后端 最日常的：使用 cloudflare tunnel 反向代理到家里电脑。 客户选择了方案 3，然后接下来就是配置 cloudflare tunnel，甚至不用再配置 A 记录。 🌐 Cloudflare Tunnel 能干什么？ 把本地 Web 服务（如网站、应用、API、NAS）通过 Cloudflare 安全暴露到公网 无需公网 IP，不管你是在家庭宽带、NAT、内网还是 IPv6-only 网络都能跑 通过 Cloudflare 的全球 CDN 加速和防护（DDoS 保护、TLS、WAF） 支持访问控制（如 Zero Trust） 支持反向代理多服务（如 /app1, /app2）或多个子域名绑定 首先登录到https://dash.cloudflare.com/首页。点击Zero-Trust。 然后选择 网络 - Tunnels ，然后新建隧道来内网穿透。 选择创建隧道，这个哥们是 Windows 的环境，所以隧道类型使用 Cloudflared。 然后选择新建隧道，然后输入隧道名称。 这个时候选择安装 cloudflared 引擎，需要安装一个 agent，基本是全平台都有，甚至还有 Docker 版本的。 然后把 test 子域代理本地的 localhost:8000。 然后通过域名访问就可以了。 这哥们还有一个额外的要求，要开启启动天 Cloudflared ，然后 GPT 了一下 直接启动已安装的 Cloudflared 服务 运行 Start-Service cloudflared 启动服务 使用 Get-Service cloudflared 查看服务状态 设为开机自启 运行 Set-Service cloudflared -StartupType Automatic 将 Cloudflared 设置为自动启动 结语 买 NAS 学的是网络技术，虽然可能是别人眼中的野路子。但是多一分趣味嘛。切身感受到技术的意义。","link":"/posts/cb1ae078/"},{"title":"我用Amazon Q写了一个Docker客户端，并上架了懒猫微服商店","text":"https://appstore.lazycat.cloud/#/shop/detail/xu.deploy.containly 自从被种草了 Amazon Q，我陆陆续续写了不少小软件，其中这个 Docker 客户端是一个典型的例子，比较符合自己平时使用的习惯，也分享给一些朋友和 NAS 爱好者来用。 故事还要用上次折腾黑群晖说起，本意想把 NAS 和打印机共享二合一的，所以把闲着的软路由做了改装。顺便使用 Docker 跑一些服务，有老本行的 ES 集群，也有自己写的一些工具类型的服务。 随着时间增长，部署的服务多了，时间长了就会忘记服务的端口，甚至还要登录群晖 Web 端进行查看，群晖的 Container Manager 很好用，就是登录的密码策略比较复杂，每次登录都比较麻烦，所以后来使用了一个 HomePage 来保存这些服务。但是每次调试 Docker 都非常麻烦。与 Portainer 相比，我需要的只是一个简洁的面板来查看容器的 URI、状态，并进行启停操作，因此我决定自己开发一个。 这个是群晖的 Container Manager，后面还有很多容器。记住这么多端口然后随时维护绝对不是一个容易的事。 我开发容器面板叫做 Containly， 是一个 Container 的管理工具。最早的时候用我是用 GPT 写的。但是随着项目越来越大，GPT 每次都会丢一些东西，而且还没办法操作本地目录，后来才转向了 Amazon Q，这个版本还是用 Q CLI 来做的。 于是写好之后我把这个 APP 上架了懒猫微服的商店，这个是一款国产化的 NAS，可玩性非常高，对开发者也十分友好。上线当日就有很多开发者安装使用了。 Containly 的核心功能是通过目录映射的 Docker 引擎读取所有容器信息，包括容器的启动、退出、停止及其他状态。例如，当容器处于“Create”状态时，它会被标记为“Other”状态，便于管理。 默认情况下，每个容器卡片会显示容器的网桥信息、端口映射和 URL。默认使用 HTTP 协议，鼠标悬停时，会在右侧显示操作按钮。通过点击这些按钮，操作会被保留，再次点击会隐藏，这样子就整个比较美观。 按钮功能包括： 停止/启动 重启 查看日志 SSH 进入容器 切换 HTTP/HTTPS 黑名单管理 此外，Containly 还提供了一个输入框，用户可以输入需要监控的 NAS 域名，面板会自动根据域名和端口拼接成 URI，并存储在 localStorage 中。更进一步，Containly 还支持暗黑模式，提升了用户体验。 另外如果多节点部署服务的话，还可以把从节点放入黑名单，这样子就只显示主节点的信息，面板就比较清爽。如果需要从节点的信息再从黑名单移除。 利用面板的 SSH 功能， 能够直接从面板进去访问容器的 SHELL，不用执行再 docker exec 的命令。 看日志也很方便，也无需再使用 docker logs，这样调试容器的时候就很方便了。 我已经打包好了 Docker 镜像并配置了 GitHub Actions，便于自动化部署。你可以通过以下方式部署 Containly： Docker 部署命令12345docker run -d \\ --name containly \\ -p 5000:5000 \\ # 映射容器端口到主机 -v /var/run/docker.sock:/var/run/docker.sock \\ # 挂载Docker socket，允许访问宿主机Docker cloudsmithy/containly:latest # 使用最新版本的Containly镜像 Compose 配置123456789version: &quot;3.8&quot;services: containly: image: cloudsmithy/containly:latest ports: - &quot;5000:5000&quot; volumes: - /var/run/docker.sock:/var/run/docker.sock restart: unless-stopped 这个是使用 Q 修改的部分代码截图： 后来机缘巧合之下用了 Q pro，看来也不能优化再多。 除了使用 Q CLI，我们还可以通过安装 VSCode 和 JetBrains 插件来使用 Q，安装插件后，免费版本可以使用 Builder ID 登录，Pro 版本则支持使用 IAM Identity Center 登录。 在 VSCode 中，你可以通过 Q 聊天面板与 Q 进行交互，并且支持中文聊天。 与 GPT 相比，Q 的优势在于它可以直接操作本地文件，用户可以直接在文件夹中生成工程文件，极大提升了开发效率。","link":"/posts/8f0212bf/"},{"title":"深度长文：NAS大降价的年代，我为何接受溢价来购买懒猫微服（附送回本攻略）","text":"最早知道懒猫微服，是去年的时候，那个时候最直观的感觉就是价格比同类型产品要贵一些，但是很极客风，不过硬件配置比传统 NAS 要高出很多。但在现在各种小主机盛行的年代，这台机器就显得性价比不高，甚至有些人认为有割韭菜的嫌疑。 今年朋友又过来推荐，说是售后很好，可以根据自己的需求来答疑，比如把三方监控放在存在 NAS 里，比如想用私服搭建游戏服务器等等，而网上不管怎么样，还有说情绪价值一定给拉满的。 第一次咨询的时候，是和 CEO 通了个电话，抱着将新将疑的态度购买回来，拆箱，测评。相信其实很多人即使没听过王勇，也一定听过或者用过 Deepin。大学的时候使用过一段时间的 deepin，很多细节确实符合国人的使用习惯。这个背书对于技术人来说，实在是一下子路转粉。想想自己在电话里还跟对方说，其实专业的技术人员，不用和我说这么直白的词，再想想王总在 Deepin 以及 Emacs 方面的贡献， 实在是有些惭愧。 我本身是开发者，问题是技术细节相关的，比如为何这个实现和群晖类不一样，对某处设计比较反常识的地方询问和拆解，总的来说，像是上了侠客岛一样，平时自认为是开发人员里面最懂 Infra 的，结果到这里谁的 Linux 都比我玩的好。 目前重度使用了一周多，每天都会在 VIP 群里问问题。主要把维护的问题解决出来，好像附送了一个终身的云厂商支持一样。从他们的宣传来看，7 _ 18 的支持显得更加实在一些，服务相比海底捞有过之无不及。我本身用过不少 7 _ 24 小时支持的云厂商，要么低峰时候找不到人，而 24 小时支持又何尝不是对技术从业者的压榨呢？比如随时 on-call，倒班机制是我本人深恶痛绝的，有些厂家号称是 7 * 24 小时支持，但是经常已读乱回要么不回，或者干脆说这个问题和他们产品的交叉是涉及第三方，然后索性不管了。有意思的是，当使用两个公司交叉的业务时，都要让我去找对方。但是在懒猫这里就不会发生这样的问题，之前用的商店里的 dify 有问题，他们去找移植应用的人去修改了。 还有一个卖点，是硬件终身售后，甚至包括磁盘和后续的数据恢复（前提是不加密），有些推吞吐量高要求的情况甚至可以做 Raid0，然后外接 NAS 或者硬盘仓备份，所以这不是一款后端存储的产品，而是放在存储和用户之间的加速器，作为家庭的边缘算力，前面接 MBP 后面接存储池这样子。 商店目前上架了 1000+的应用，虽然官方的应用不多，但是很多三方应用都是他们的开发人员移植的，于是后来才有了越来越多的开发者也跟着移植的过程，在移植的过程中，可以学 docker-compose 的用法，以及跨架构打包 docker image ，还有单点登录的集成。这些都是我的兴趣点，而且也想学一学里面设计的机制，大学毕业的时候我想设计一款 NAS，那也仅仅是基于 centos 做了一些改动，后来买了威联通，虽然不常开案例问问题，但问的也仅仅是关于这个产品本身的东西，包括专业程度和响应级别都不是能够一概而论的。甚至连 trouble shooting 上传日志都很方便。 全容器化的服务以及对操作系统的修改，可以看出沿袭了当年在 deepin 的风骨。包括应用商店在内，很多系统组件都完全采用用容器托管。还有自己的单点登录系统，而对于 OIDC 的支持其实很多企业都没有做到。还有一点不得不提的，开发者的社区很活跃（主要指的是微信群和上架应用商店），每天都会有几位开发人员默默的上架应用和攻略。慢慢的我也熟悉了把 docker images 转换成为懒猫商店的模式。也上架了自己的几个应用，有原创的，也有把喜欢的开源项目移植过来。 最喜欢的原生应用是网盘和清单，首先说网盘曾经有一篇为什么没有人去做网盘的帖子，讲述了网盘研发成本高，就连曾经宣称用不限速的阿里云盘也变节了。改善 NAS 生态是刀山火海、暗礁遍布，却仍要做那一股清流；研发与售后成本明摆在前，却仍坚持全线自研，把服务做到极致。清单有种小清新的感觉，极简风格，日常记录一些 todo，主要同步之后多平台编辑实在很舒服。打破了关于以前产品自带的软件都很烂的固有观念。 想起来《琅琊榜》中的一句话拿来形容创始人，“如此愚蠢，却又如此有胆识的人，已经很久没见到了。” 我一直相信技术是服务生活的，但慢慢的变成了炫技以及慢慢变成了改需求以及最后变成了漫长的牛马生涯，在学生时代一直有一个远景，做一款全平台的软件自己用，后来发现学习成本巨大，而且也没有资金外包出去，虽然这几年接触了 flutter，但也没有构建一个全新的跨平台产品出来。 有了懒猫微服之后，这一切都解决了，只需要打包好 docker image，如果可以的话就上架商店给其他人用。用公网访问，TLS 证书卸载这些都一步搞定。当我们默默的喷绿联，极空间丢数据，群晖如何守旧不肯升级 CPU，以及限制磁盘认证的问题。曾经我们还忽略了这样一款从操作系统，软件生态，甚至应用商店。这款机器比我之前 DIY 构想的还要完善，完美。 我想去拆解他的技术细节。但是不想再出来一个商业竞品来扰乱这份宁静。在我看来这是一款充满着技术者热情和情怀的产品。 附送：懒猫微服社区激励机制一览 贡献类别 具体动作 奖励金额 备注条件 应用移植 成功将一款高质量的自托管应用移植并上架商店 100 元/款 - 必须功能正常- 开源应用需标注上游作者- 若多人移植同一应用，仅首位上架者得奖 对接账户系统 / 网盘右键菜单 在移植基础上完成接口对接 +50 元/款 - 自己移植并对接：共 150 元/款- Fork 他人应用并补充对接：50 元/款 应用攻略编写 发布含截图且经验证可行的攻略，并关联商店应用 50 元/篇 鼓励分享使用经验，惠及社区 不予奖励的应用类型 纯网页游戏、离线 Web App、纯数据库软件等 —— 可自由上传，但暂无红包激励 核心要点 先到先得：同款应用仅首位合规上架者获奖。 质量至上：功能正常、信息完整方可审核通过。 额外加成：完成账户系统/右键菜单对接可叠加奖励。 知识共享：高质量攻略同样有奖，鼓励经验传播。 社区激励机制：https://developer.lazycat.cloud/store-rule.html 懒猫打金服：https://playground.lazycat.cloud/#/guideline/448","link":"/posts/d6c5e7b2/"},{"title":"给传统 NAS 玩家介绍一下懒猫微服","text":"玩过不少 NAS，从最早的黑群晖，威联通开始，后面陆陆续续接触了飞牛，绿联，极空间，UNRAID，EXSI，Proxmox VE，也算有点话语权。 首先最直观的区别是软件客户端，像群晖，威联通的电脑版客户端是用来发现机器的 IP 地址的，然后后续所有的操作都在浏览器完成，比如新建用户，登录，审计，访问数据，查看监控。 而懒猫微服的所有操作几乎都在客户端完成，网页端更像是一个应用的 Dashboard。然后访问的时候使用域名，配合厂家的穿透服务，无论你是互联网访问还是局域网访问机器，用这一个地址就够了，不再需要在路由器上做端口转发，也基本可以告别自己搭建内网穿透的痛苦了。 还有一个非常主要的是社群，懒猫微服既有官方的大群交流技术，也有 VIP 的小群私人定制。大群里有各式各样的玩家，除了懒猫微服之外大家还会交流各种 Github 的开源项目，Linux 技巧以及电脑外设心得， 然后每天大家都贡献攻略。因为公司 base 在武汉嘛，当然也会有接地气的武汉风情。 VIP 小群会针对个性化的需要做一对一的指导，比如曾经帮我排查了家庭宽带 DNS 污染，UPS 信号干扰，甚至 OpenID Connect (OIDC) 的使用和接入等问题，对于开源软件部署在懒猫上有问题也是尽全力 额度支持，届时可以拉一个小会，然后共享屏幕给他们查看。可以放心的 show linux 命令和飙专业术语啥的。 很多的问题可以在半小时到一个小时就能解决，有时候甚至会更短。 不只是自己写的软件部署上去访问有延迟他们会帮忙排查，而且一些商店里社区用户贡献的开源软件的问题，他们也会帮忙查看并且给出一些解答方式。 毕竟开源软件的 issue 真的不少，他们不会叫你去开 issue 然后漫长的等待，他们会去帮忙追。 而传统 NAS 的社群主要靠的是爱好者自己发起和维护的，有问题在群里问可能最后没有讨论出结果就不了了之了。甚至很多时候都会纠结到底是选 Proxmox VE 还是 EXSI。对于攻略部分，大多是散落在资深用户的个人博客上，比如很多威联通的文章都会发在什么值得买上面。而对于提问能不能得到答案，完全取决于作者用爱发电的程度了。如果商业 NAS 提案例，那么响应时间可能要很久，如果你提简单的案例，那么可能立马有人给你打电话，如果是比较难的问题，可能最后就不了了之了。只能说在服务客户这方面亚马逊是在是开了一个很不好的头，大概是这样： 因为 AWS 负责运行、管理和控制从主机操作系统和虚拟层到服务运营所在设施的物理安全性的组件。客户负责管理来宾操作系统（包括更新和安全补丁）、其他相关应用程序软件以及 AWS 提供的安全组防火墙的配置。客户应该仔细考虑自己选择的服务，因为他们的责任取决于所使用的服务、，这些服务与其 IT 环境的集成以及适用的法律法规。责任共担还为客户提供了部署需要的灵活性和控制力。 所以有时候遇到两个产品交叉的问题，我们一般是很难得到方案，很有可能两方都说这涉及三方产品你需要找对方，我们不了解你这个三方产品，没办法给你方案。而对于三方玩家几乎是没有办法同时把两个产品的售后叫到一起的。无论你是开案例还是拉一个会议，这难度很大很大。 然后是系统层面的对比，懒猫微服是 基于 debian 优化一套系统，后来又开了 root 权限，所以基本 Linux 能做的事他都能做，更是出厂预置了 dockage，dozzle 这样方面调试 docker 的软件，基本属于开箱即用。甚至我们还能使用 Docker 打包自己的软件然后上架给其他玩家使用，甚至可以对其他人说； 我的懒猫微服教程是中文圈里非常优秀的实战指南。 我的开发/移植软件也有非常多的懒猫用户在使用。 而开源的 NAS 基本上大家只玩虚拟机和按照教程配置 Docker，几乎是没有包管理工具的，所以安装的软件很受限。 如果真的想移植应用，那个开发者文档也是不太好看。起码对于普通玩家是真的劝退了。 最后一点也就是很重要的一点，关于 APP 访问这块。在从互联网访问这边，传统 NAS 有一个很大的痛点。一个是移动端软件适配不好，还有就是服务多了端口都得自己记住。再加上路由器转发的端口，真的很难记住了。而懒猫微服在移动端和 PC 上的页面几乎是差不多的，所有操作几乎可以在 APP 内部完成。应用商店上架的应用大部分都是 https 的协议和 443 的端口。不用自己做加密同时以及免去了记忆软件信息烦恼，毕竟即使是专业玩家，也不想天天做服务器的运维工作。 普通用户图一个方便。专业用户图一个折腾，然后缺少的就是一个稳定的穿透和传输，精力有限不想自己维护一些底层的东西。买个懒猫微服差不多全能解决了。 我一直有一个愿望，写一本 NAS 的书，让技术融入到爱好者的生活，技术不是枯燥的理论，当我们遇到问题的时候，才能想清楚他们为什么这么设计。技术人永不为奴。","link":"/posts/47885d90/"},{"title":"自带内网穿透,懒猫微服治好了我的NAS焦虑","text":"知道懒猫微服是一两年前，最初的印象是极客机甲风格，有颜值有性能有。近期入手也是出于朋友推荐,主要还是喜欢自带的内网穿透功能,虽然家里有公网 IP，但是不定时会被运营商封端口（不止常用端口），总是一阵一阵的，询问运营商也没有一个明确的结论，倒不如选一个商业的产品然后省去自己折腾的时间吧 虽然我一直很想 DIY 这样一款产品，开源的大多是 KVM-base 的方案，或者还有商业的 EXSI。毕竟个人精力有限，一直搁置到现在，然后随着事情越来越多，就购买了一台来玩玩，也脱胎换骨当甲方提需求。官网如下：https://lazycat.cloud/ 机器是这样的，浓浓的机甲风格连，着运行了几天也一点都不烫。之前还担心炒豆子的问题，其实相对于白天的噪音几乎是没有的。 i5-1135G7，现在来看不算最新的，不过也比很多 NAS 强很多了，手动@群晖 32G 内存（只能一个盘位，所以加满了） 2.5 寸 2T 原装 HDD（预算有限，目前还在测试阶段，自带的盘是叠瓦盘，介意的话可以自己买盘替换） neofetch 能看到是基于 Debian12 的。然后开发团队在上层构建自己的应用，只是 ssh 需要额外申请，不过一会就批了。 提供全平台的客户端，该有的都有了，这里开发适配应该花了不少时间吧。 MacOS 客户端的界面如下, 如果通过 web 访问就是这样，和传统的群晖有个主页不一样，这个更像是服务导向的，对于小白来说，只需要按照 Sass 的方式来使用，比如文件备份，时间机器，异地组网。而对于技术人员来讲，我个人觉得是更加吃力一些，要搞清楚每个服务是怎么启动的，怎么保证网络传输，怎么保证 HA，尽管懒猫团队已经实现了这些，但是出于职业习惯，还是希望抽丝剥茧，搞清楚从 Iass 到 Sass 的原理，然后学一学背后的哲学，以及在懒猫的商店上架自己应用，还有把应用接入懒猫的 SSO 系统。 关于服务嘛，是大多数玩家最喜欢的地方，有专门的 N 对 1 答疑，7*18 服务比 7 *24 听起来要靠谱很多，只能说专业，太专业了。团队是 deepin 二次创业出来的，都是技术流，所以懂用户，在群里可以做深度的技术答疑。在我之前的感受就是，玩 nas 的太多是爱好者，很多不懂 Linux 和开发，或者懂技术的都是理论派，对自己 host-server 或者 application 没有兴趣。以前的同事能因为这个结缘，由于彼此方向不同更多会集中在 Iass 和 network 的层面，而端对端的解决方案甚少。 但是懒猫让我看到了未来 nas 进化的方向，从硬件 - Iass -pass - Sass 做了全套的定制，也做了我一直想做而没有做完的事情，最早我的想发是在 Centos 上用 docker 跑很服务，然后用 NFS 做 share，然后用 KVM 做虚拟化层，然后用商业的方案做异地组网。尽管过过程十分坎坷，遇到了硬盘噪音，纯开源项目支持不到位，商业方案售后不专业等问题，最后就只在内网使用，走了很多弯路吧。 相信懒猫的这个价格，如果用 AWS 的话，最多半年就烧光 credit 了。有如此专业的团队来支持，治好了我的 NAS 焦虑。 文章来源：","link":"/posts/b1e8232f/"},{"title":"懒猫微服进阶心得（一）：M芯片移植懒猫应用构建Docker镜像的常见问题排查及解决方案","text":"本文是使用 Apple silicon 的 MacOS 移植到懒猫商店的踩坑记录，希望能够给大家带来帮助 Apple silicon 很好，在这年几乎带起来 ARM 的生态。但这也拉开了 ARM 和 X86 之战，用户在两大生态中穿梭，只能增加自己应用的兼容性。就比如说用来打包的 Docker image，尽管编程语言和操作系统都在底层屏蔽了硬件架构，但是容器还得用相同架构的。 这是之前移植开源项目时候忘记打包不同架构的 image 而直接推送到懒猫镜像仓库导致的问题。MacOS 默认打包了 ARMv8 架构的镜像，在 X86 上也无法运行。 12pg-docker run -p 5000:5500 registry.lazycat.cloud/u04123229/you/doudizhu-scorer:d1d9085174c0bf8cWARNING: The requested image's platform (linux/arm64/v8) does not match the detected host platform (linux/amd64/v4) and no specific platform was requested 由于打包的时候容器一直在反复重启，所以在 dozzle 上也没有什么明显的报错，所以有个办法就是 ssh 进去用终端pg-docker run，这样所见即所得。dozzle 地址：https://dev..heiyu.space/dozzle/ 于是重新打包，跨架构打包时候需要使用 buildx，当然前提是需要里面的运行时和代码也是跨平台的。 我们先来看概念和原理： buildx 是 Docker 提供的一种扩展功能，它基于 BuildKit 引擎，目的是为 Docker 提供更强大的构建功能，包括： 跨平台构建：支持在一种平台上构建适用于多种平台的 Docker 镜像。 缓存管理：支持高效的缓存管理机制，能够减少重复构建的时间。 多阶段构建：支持复杂的多阶段构建流程。 buildx 使 Docker 能够生成多平台的镜像，这意味着你可以在一个平台上（例如 ARM 或 x86）构建适用于其他平台（如 x86_64、arm64、armv7 等）的 Docker 镜像。 docker buildx build 通过指定 --platform 参数来告诉 Docker 在构建时要生成哪些平台的镜像。例如，linux/amd64 和 linux/arm64 就分别对应 x86 和 ARM 架构。 在 buildx 构建完成后，你得到的不是一个单独的镜像，而是一个支持多平台的 manifest list，这个列表包含了不同架构的镜像。这个列表可以推送到 Docker Hub 等镜像仓库，客户端在拉取时，会根据自己的硬件架构自动选择合适的镜像。 这意味着，我们可以通过同一个镜像标签（如 your_image_name）来支持多个平台的 Docker 镜像，而用户在拉取时会自动选择适合自己平台的镜像。 准备构建环境：Docker Buildx 会首先准备并选择一个构建器（builder）。这个构建器负责在指定的平台上执行构建任务。 选择平台：使用 --platform 参数来选择目标平台，Docker 会通过 QEMU 模拟器或者本地平台来执行构建。 构建镜像：在选择平台后，Buildx 会根据 Dockerfile 和其他构建上下文开始构建镜像。它会处理平台特定的依赖和构建步骤。 生成适配镜像：对于每个平台，Docker Buildx 会生成一个特定的镜像。例如，对于 linux/amd64 和 linux/arm64，它会分别为这两个平台构建独立的镜像，并将它们绑定在一个 manifest list 中。 推送镜像：完成构建后，你可以使用 --push 参数将包含多个架构镜像的 manifest list 推送到 Docker Hub 或其他镜像仓库。这个清单包含了多个平台的镜像，当用户从仓库拉取时，Docker 会自动选择与用户当前平台兼容的镜像 然后来实操 确保 Docker 版本支持 Buildx,用docker buildx version 来验证/ 创建并使用新的 Builder 打包的时候加上平台参数：--platform linux/amd64,linux/arm64 具体命令如下： 1234docker buildx versiondocker buildx create --use --name multiarch-builderdocker buildx build --platform linux/amd64 -t your_image_name .docker buildx build --platform linux/amd64 -t your_dockerhub_username/your_image_name --push . 在这过程中，我们可能还会使用docker tag ，这个命令可以将一个现有的镜像打上新的标签（tag），通常用于将镜像标记为自己的名字或指定版本。这对于推送镜像到 Docker Hub 或其他镜像仓库时非常有用。 1docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG] **SOURCE_IMAGE[:TAG]**：要打标签的源镜像。TAG 是可选的，如果不指定，默认是 latest。 **TARGET_IMAGE[:TAG]**：新的目标标签，通常你可以为镜像指定一个新的名字或版本号。 假设你有一个名为 my_image:latest 的镜像，并且你希望将它标记为属于你自己（例如，your_dockerhub_username/my_image:latest）： 1docker tag my_image:latest your_dockerhub_username/my_image:latest 这条命令会将 my_image:latest 镜像打上 your_dockerhub_username/my_image:latest 的标签。 推送到 dockerhub 之后，然后就可以像往常一样使用 Docker 了。 12docker pull your_dockerhub_username/your_image_namedocker run your_dockerhub_username/your_image_name 如果想走 Github action 一键打包 image 的话，是这样： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849name: Build and Push Docker Imageon: push: tags: - &quot;v*&quot; # 仅在 tag push（如 v1.0.0）时触发jobs: build-and-push: runs-on: ubuntu-latest steps: - name: Checkout source code uses: actions/checkout@v4 - name: Check DockerHub secrets run: | if [ -z &quot;${{ secrets.DOCKER_USERNAME }}&quot; ] || [ -z &quot;${{ secrets.DOCKER_PASSWORD }}&quot; ]; then echo &quot;❌ ERROR: DOCKER_USERNAME or DOCKER_PASSWORD is missing&quot; exit 1 fi - name: Set up QEMU uses: docker/setup-qemu-action@v3 - name: Set up Docker Buildx uses: docker/setup-buildx-action@v3 with: install: true # ✅ 自动创建默认 builder - name: Docker login uses: docker/login-action@v3 with: username: ${{ secrets.DOCKER_USERNAME }} password: ${{ secrets.DOCKER_PASSWORD }} - name: Extract tag name id: vars run: echo &quot;TAG=${GITHUB_REF#refs/tags/}&quot; &gt;&gt; $GITHUB_ENV - name: Build and push Docker image (multi-arch + latest) uses: docker/build-push-action@v5 with: context: . push: true platforms: linux/amd64,linux/arm64 tags: | cloudsmithy/flask-demo:${{ env.TAG }} cloudsmithy/flask-demo:latest 没有把 lzc-cli 写进去的原因是目前只能从终端命令行查看到推送到懒猫仓库的镜像命令，目前还不能存到一个中间位置，所以做了一个通用的版本。 事情到这里本来应该结束的，但似乎有了新的故事。 故事 1：无法打包某次在打包的过程种突然报错，期间一度以为 Orbstack 出现了问题，于是卸载重装，重启电脑，均无效，GPT 和 deepseek 也只是让我检查网络连接。期间重新 docker pull 也是没问题的。 1characters ERROR: failed to dial qRPC: rpc error:code = Internal desc = rpc error: code = Internal desC = header key &quot;x-docker-expoSe-session-name&quot; contains value with non-printable ASCI #2793 无奈只能 Google，在 issue 里有一个评论，打包目录不能出现中文。(我的 OS 默认中文) 参考链接：https://github.com/docker/buildx/issues/2793 故事 2：构建之后没有输出docker buildx build --platform linux/amd64 -t your_image_name . 12WARNING: No output specified with docker-container driver. Build result will only remain in the build cache. To push result image into registry use --push or to load image into docker use --load 这是使用 docker buildx 构建镜像时，指定了 docker-container 驱动，但是没有使用 --push 或 --load 参数。结果是，构建的镜像只会保留在构建缓存中，而不会被推送到镜像仓库或加载到本地 Docker 环境中。 我们可以通过两种方式之一来明确指定输出目标，避免出现此警告： 1. 使用 --push 将镜像推送到远程仓库：如果你希望构建的镜像推送到 Docker Hub 或其他 Docker 镜像仓库，可以使用 --push 参数。例如： 1docker buildx build --platform linux/amd64 -t your_image_name --push . 这将把镜像推送到 Docker 仓库，而不是仅保留在本地构建缓存中。 2. 使用 --load 将镜像加载到本地 Docker 环境：如果你想将构建的镜像加载到本地 Docker 环境中以便后续使用（例如运行容器），可以使用 --load 参数： 1docker buildx build --platform linux/amd64 -t your_image_name --load . 这会将构建的镜像加载到本地 Docker 环境，使你可以在本地运行、调试或进行其他操作。 故事 3：无法同时保存双平台 Image 到本地123docker buildx build --platform linux/amd64,linux/arm64 -t cloudsmithy/shuangpin:latest . --load[+] Building 0.0s (0/0) docker-container:stoic_hellmanERROR: docker exporter does not currently support exporting manifest lists --load 只适用于单平台构建。如果你在跨平台构建（如 linux/amd64,linux/arm64）时使用 --load，则只会将构建的默认平台镜像加载到本地，不会加载所有平台的镜像。跨平台构建时，通常需要使用 --push 将所有平台的镜像推送到远程仓库 1docker buildx build --platform linux/amd64 -t cloudsmithy/shuangpin:latest . --load 使用 --load 时，镜像会被加载到本地 Docker 守护进程中。对于大镜像，加载过程可能需要较长的时间和较多的本地存储空间。因此，如果镜像非常大，可能需要考虑是否使用 --push 直接推送到远程仓库，而不是将其加载到本地。 1docker buildx build --platform linux/amd64,linux/arm64 -t cloudsmithy/shuangpin:latest . --push 故事 3：懒猫仓库黑魔法对了，关于文档上提到的懒猫的 registry 不能在微服外面用，黑魔法的限制其实就是加了认证，直接返回 401. 123docker run -p 5000:5500 registry.lazycat.cloud/u04123229/you/doudizhu-scorer:d1d9085174c0bf8cUnable to find image 'registry.lazycat.cloud/u04123229/you/doudizhu-scorer:d1d9085174c0bf8c' locallydocker: Error response from daemon: Head &quot;https://registry.lazycat.cloud/v2/u04123229/you/doudizhu-scorer/manifests/d1d9085174c0bf8c&quot;: no basic auth credentials. 最后希望这篇文章能够帮助大家在将开源项目移植到懒猫商店时，避免遇到一些常见的坑和问题。祝大家顺利解决跨平台构建和镜像推送中的挑战，提升开发效率！","link":"/posts/126ed22c/"},{"title":"懒猫微服进阶心得（十）：本地开发，如何接入懒猫微服的 OpenID Connect (OIDC)","text":"我们知道懒猫的 OpenID Connect (OIDC) 无需在后台申请，商店里的应用在运行的时候会自动申请，但是本地测试的时候就不太方便。 一般是需要用其他的 IDP 作为测试环境，因为 OIDC 的协议是通用的，不像 OAuth 这么百花齐放。 以我的“家庭任务通知”APP 为例，讲解下在开发模式下接入懒猫微服的 OpenID Connect (OIDC)。 添加 OIDC 登录逻辑首先前端需要有一个 OIDC 的登录按钮，然后做好 OIDC 的逻辑： 使用懒猫 ENV 查看器导出本地配置从应用商店安装我写的“懒猫 ENV 查看器”，导出 env.example 文件，导出项目之后重命名为 .env。这样就可以把商店里的 ENV 复制到本地的开发环境。 不过需要注意的是：应用名字和回调函数还是原来的，不要轻易去改。遇到问题再手动调试。 https://appstore.lazycat.cloud/#/shop/detail/xu.deploy.env 登录后出现回调 URL 报错登录之后我们就看到了这个页面： 点击“授予权限”，会报错。这个是由于回调 URL 不匹配的问题，还是会访问 ENV 查看器的 URL： 手动修改回调 URL然后我们手动把上边的 URL 改成我们自己的回调路由就可以了，如果想自动化，你也可以写一个油猴脚本。 这样就可以完成本地的 OIDC 授权流程啦。开发的时候不用搭 IDP，也能走懒猫的登录流程。是不是很方便？","link":"/posts/4daab20a/"},{"title":"懒猫微服进阶心得（十一）：把懒猫微服当作旁路由，客户端无需转发直接访问内外地址","text":"今天在外面通过懒猫转发访问路由器时，发现需要逐一映射多个内网地址，操作起来有点麻烦，于是想到了一种一劳永逸的解决办法。 最开始我用 Squid 来代理 AWS VPC，后来想到懒猫也可以用作同样的功能。以下是我准备的 Compose 配置，我已经完成了 app 镜像的复制。 1234567services: squid: container_name: squid ports: - 3128:3128 image: registry.lazycat.cloud/u04123229/ubuntu/squid:c534e32e8e1e766enetworks: {} 下面是 Docker 截图： 默认安装后，Squid 的默认规则会屏蔽所有网站。若要访问内网地址，就会看到“访问被拒绝”的提示。接下来，我们需要修改转发规则。 进入 Squid 容器，编辑配置文件，然后重启容器即可生效： 123sudo vim /etc/squid/squid.conf# 在文件底部添加以下行以允许所有 HTTP 访问http_access allow all 现在就可以使用你喜欢的工具进行访问了。 然后就可以在外边访问私有地址了。 或者在终端上，通过设置环境变量以通过代理服务器访问 HTTP 和 HTTPS： 12export http_proxy=http://your_proxy_ip:3128export https_proxy=http://your_proxy_ip:3128 如果你需要白名单功能：首先，创建一个包含你希望允许访问的域名的白名单文件。该文件会用于匹配允许的域名。 打开终端并创建白名单文件。例如，我们将其存放在 /etc/squid/whitelist 路径： 1sudo vim /etc/squid/whitelist 在文件中，每行列出一个希望允许访问的域名。例如： 123.youtube.com.bilibili.com.example.com 这样就允许 youtube.com、bilibili.com 和 example.com 的请求通过代理，而其他未列出的域名将被拒绝。 2. 编辑 squid.conf 配置文件接下来，编辑 Squid 的主配置文件 squid.conf，将白名单配置添加到文件中。 打开 Squid 配置文件： 1sudo vim /etc/squid/squid.conf 在文件中，找到并添加以下规则： 允许 localhost 访问： 1http_access allow localhost 该规则允许本地计算机（localhost）访问代理服务器。 添加白名单配置： 12acl whitelist dstdomain &quot;/etc/squid/whitelist&quot;http_access allow whitelist 这两行配置定义了一个名为 whitelist 的 ACL（访问控制列表），它从 /etc/squid/whitelist 文件中加载允许的域名。然后，我们允许匹配这些域名的请求。 拒绝所有其他访问： 1http_access deny all 该规则确保只有白名单中的域名可以访问代理，其他所有请求都将被拒绝。 配置端口和缓存： 你可以在 squid.conf 文件中设置 Squid 的监听端口并配置缓存目录（如有需要）。例如： 12http_port 3128coredump_dir /var/spool/squid","link":"/posts/5018903b/"},{"title":"懒猫微服进阶心得（二）：一台机器跑三套 Docker？深入解析懒猫容器的共存机制（上）","text":"本文仅代表个人视角对懒猫 Docker 的拆解分析，内容为基于现象的倒推推测，不代表懒猫官方实现方式。 拿到任何 NAS 的第一件事是开启 SSH 功能，第二步就是用 Docker 启动容器。 懒猫微服这个 docker 还不太一样，一个有三个 Docker： docker : 运行系统组件 pg-docker： 普通的 docker，让我们拿来玩 lzc-docker：运行懒猫商店的 docker 三套 Docker 引擎初探我们先来看看这三套 docker 引擎跑了些什么，从 ps 看起： docker ps1234567891011CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1838d4f379e5 registry.lazycat.cloud/lzc/lzcsys:latest &quot;/sspk/bin/pd-service&quot; 9 days ago Up 9 days lzc-runtime-peripheral-device-1c2f6d791181b registry.lazycat.cloud/lzc/lzcsys:latest &quot;/sspk/bin/lzc-ingre…&quot; 9 days ago Up 9 days (healthy) lzc-runtime-ingress-control-19699c428d2b0 registry.lazycat.cloud/dexidp/dex:v2.42.0-alpine &quot;/usr/local/bin/dock…&quot; 9 days ago Up 9 days lzc-runtime-dex57952c3e4ba5 registry.lazycat.cloud/lzc/lzcsys:latest &quot;/sspk/bin/lzc-apise…&quot; 9 days ago Up 9 days (healthy) lzc-runtime-api-servers-1cde0eba62fd2 registry.lazycat.cloud/lzc/lzcsys:latest &quot;/sspk/bin/lzc-pkgm&quot; 9 days ago Up 9 days (healthy) lzc-runtime-pkgm-18e9c780c012c registry.corp.lazycat.cloud/homecloud/lzc-registry-proxy:v0.0.0-2887-gd16c7f25.m &quot;/bin/sh -c /lzc-reg…&quot; 9 days ago Up 9 days 80/tcp lzc-registry-proxy59d3803ef304 registry.corp.lazycat.cloud/homecloud/lzc-installer:v0.0.0-2887-gd16c7f25.m &quot;/docker-entrypoint.…&quot; 9 days ago Up 9 days lzc-installerc7192a7fd471 registry.corp.lazycat.cloud/homecloud/lzc-hal:v0.0.0-2887-gd16c7f25.m &quot;/bin/sh -c /sspk/bi…&quot; 9 days ago Up 9 days lzc-hal1d194e975117 registry.corp.lazycat.cloud/homecloud/lzc-recovery:v0.0.0-2887-gd16c7f25.m &quot;/docker-entrypoint.…&quot; 9 days ago Up 9 days lzc-recovery8338ce6a5c17 registry.corp.lazycat.cloud/homecloud/lzc-recovery:v0.0.0-2887-gd16c7f25.m &quot;/sspk/bin/entrypoin…&quot; 9 days ago Up 9 days 这里可以看到，系统级组件都跑在默认的 docker 下。 pg-docker ps123CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESd0ae10b8fc8f registry.lazycat.cloud/u04123229/qilinzhu/ql-play:fbf2e99a00ef9a7f &quot;sh /app/start.sh&quot; 3 days ago Up 26 hours ql-play0cb9ec655c16 registry.lazycat.cloud/u04123229/cloudsmithy/shuangpin:2a8ede2b23c38be8 &quot;/docker-entrypoint.…&quot; 6 days ago Up 6 days 0.0.0.0:5004-&gt;80/tcp, [::]:5004-&gt;80/tcp unruffled_lichterman pg-docker 实际上就是日常部署、测试容器最常用的那一套运行时环境， Dockge 默认连接的运行时也是这个。只是这里为了区分系统 docker 做了改名，playground 就是随便玩的意思。 lzc-docker ps1234lzc-docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES80c88ae6aa8b registry.lazycat.cloud/app-tv-controller:1.0 &quot;/lzcinit/cloud.lazy…&quot; 16 hours ago Up 16 hours (healthy) cloudlazycatapplzctvcontroller-app-1fdb2211b210e registry.lazycat.cloud/lzc/tvos-release:v0.1.219 &quot;/home/tvos/run.sh&quot; 16 hours ago Up 16 hours 5500/tcp cloudlazycatapplzctvcontroller-tvos-1 这个是懒猫商店的 Docker，实测在客户端中停止应用是是把对应的 docker 删除了，无论是从docker ps -a | grep auth还是可视化工具看来。这也很符合使用容器的习惯，不需要的时候就删除，随用随启动，但是数据仍然还在。 版本和运行时对比我们再来看一下版本，都还是一样的。所以这个就很有意思了。 123456lzcbox-029c588e ~ # docker --versionDocker version 27.5.1, build 9f9e405lzcbox-029c588e ~ # pg-docker --versionDocker version 27.5.1, build 9f9e405lzcbox-029c588e ~ # lzc-docker --versionDocker version 27.5.1, build 9f9e405 再看看存储后端，那是不是有什么魔改呢？看的出来后端都是 containerd。 123456789lzcbox-029c588e ~ # docker info | grep -i 'Runtimes\\|Default Runtime' Runtimes: io.containerd.runc.v2 runc Default Runtime: runclzcbox-029c588e ~ # pg-docker info | grep -i 'Runtimes\\|Default Runtime' Runtimes: io.containerd.runc.v2 runc Default Runtime: runclzcbox-029c588e ~ # lzc-docker info | grep -i 'Runtimes\\|Default Runtime' Runtimes: io.containerd.runc.v2 runc Default Runtime: runc 甚至连 containerd 的版本都一样 12345678910# docker info | grep -i &quot;containerd&quot; Runtimes: io.containerd.runc.v2 runc containerd version: bcc810d6b9066471b0b6fa75f557a15a1cbf31bblzcbox-029c588e ~ # pg-docker info | grep -i &quot;containerd&quot; Runtimes: io.containerd.runc.v2 runc containerd version: bcc810d6b9066471b0b6fa75f557a15a1cbf31bblzcbox-029c588e ~ # lzc-docker info | grep -i &quot;containerd&quot; Runtimes: io.containerd.runc.v2 runc containerd version: bcc810d6b9066471b0b6fa75f557a15a1cbf31bblzcbox-029c588e ~ # 一开始以为是魔改看了下我的 mac 运行的 Orbstack 的配置，好像也没啥差别。 1234567891011docker info | grep -i 'Runtimes\\|Default Runtime' Runtimes: io.containerd.runc.v2 runc Default Runtime: runcdocker info | grep -i &quot;containerd&quot; Runtimes: io.containerd.runc.v2 runc containerd version: 06b99ca80cdbfbc6cc8bd567021738c9af2b36ce 多引擎共存的实现方式DOCKER_HOST 的封装既然三个 docker 都出奇的一致，到底是类似命名空间的隔离嘛？ 123456789101112lzcbox-029c588e ~ # which docker/usr/bin/dockerlzcbox-029c588e ~ # which pg-docker/lzcsys/bin/pg-dockerlzcbox-029c588e ~ # which lzc-docker/lzcsys/bin/lzc-dockerlzcbox-029c588e ~ # file $(which docker)/usr/bin/docker: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=4a41bb12cfd0c306a6ede40f41cfc107b2045371, for GNU/Linux 3.2.0, with debug_info, not strippedlzcbox-029c588e ~ # file $(which pg-docker)/lzcsys/bin/pg-docker: Bourne-Again shell script, ASCII text executablelzcbox-029c588e ~ # file $(which lzc-docker)/lzcsys/bin/lzc-docker: Bourne-Again shell script, ASCII text executable 这就可以发现问题了，docker 是原来的 docker，但是 pg-docker 和 lzc-docker 是封装的脚本，来看一下： 所以我们可以得出一个关键点：懒猫并不是运行了三套完全独立的 Docker 服务，而是通过 shell 脚本封装，复用同一个 docker 客户端，切换不同的 socket 实现了“环境隔离”。这个脚本的作用相当于把 pg-docker 当成 docker 命令使用，还自动附带了环境变量 DOCKER_HOST=...。 123456lzcbox-029c588e ~ # cat $(which pg-docker)#!/bin/bashset -eexport DOCKER_HOST=unix:///data/playground/docker.sockexec docker &quot;$@&quot; 这设置了 DOCKER_HOST 环境变量，使得之后执行的 docker 命令会连接到 /data/playground/docker.sock 这个 Unix Socket，而**不是默认的 /var/run/docker.sock**。 exec 是一个 shell 内建命令，它会用新的进程替换当前脚本的进程。 &quot;$@&quot; 表示把脚本接收到的所有参数（比如 pg-docker ps -a）原样传递给 docker 命令。 之前想上架一个 Docker 可视化工具用来，但是总不知道需要映射哪个 docker.sock，这下子全都清楚了，有了这个就能在 docker 里使用宿主机的 Docker API 了。 daemon.json 配置详解当然与之对应的还有 daemon.json,除了用来改代理之外，我们还能修改这些东西： 1234567891011121314151617lzcbox-029c588e /data/playground/data # cat /lzcsys/var/playground/daemon.json{ &quot;bridge&quot;: &quot;&quot;, &quot;containerd-namespace&quot;: &quot;playground-docker&quot;, &quot;containerd-plugins-namespace&quot;: &quot;playground-docker&quot;, &quot;data-root&quot;: &quot;/data/playground/data/docker&quot;, &quot;default-address-pools&quot;: [ ], &quot;exec-root&quot;: &quot;/data/playground/docker&quot;, &quot;hosts&quot;: [ &quot;unix:///data/playground/docker.sock&quot; ], &quot;insecure-registries&quot;: [ &quot;registry.lazycat.cloud&quot; ], &quot;pidfile&quot;: &quot;/data/playground/docker.pid&quot; 这样多个 Docker 环境就能共存了，例如： 系统默认的 /var/run/docker.sock 一个沙箱环境 /data/playground/docker.sock 这么设置好之后可以快速切换上下文，而不用每次都手动设置 DOCKER_HOST。 在我开发的容器可视化面板总，看到已经可以指定 docker sock 作为连接了,参考： 12345678services: containly: image: registry.lazycat.cloud/u04123229/cloudsmithy/containly:30e4e3279afe9a52 ports: - 5003:5000 volumes: - /data/playground/docker.sock:/var/run/docker.sock restart: unless-stopped 三套 daemon.json 对比分析从实际查找结果来看，懒猫为三套 Docker 引擎配置了不同的 daemon.json 文件和运行时环境： 系统组件专用（docker）：/etc/docker/daemon.json 用户 playground 环境（pg-docker）：/lzcsys/var/playground/daemon.json 懒猫商店环境（lzc-docker）：/lzcsys/etc/docker/daemon.json 123456789sudo find / -type f -name daemon.json 2&gt;/dev/null/etc/docker/daemon.json/run/lzcsys/boot/lzc-os-init/var/playground/daemon.json/run/lzcsys/boot/lzc-os-overlay/lowerdir/lzcsys/etc/docker/daemon.json/run/lzcsys/boot/lzc-os-overlay/lowerdir/lzcsys/lzcsys/etc/docker/daemon.json/lzcsys/etc/docker/daemon.json/lzcsys/var/playground/daemon.json 每个配置文件中都指定了独立的： data-root exec-root pidfile hosts（即 sock 文件路径） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 默认的docker引擎lzcbox-029c588e ~ # cat /etc/docker/daemon.json{ &quot;registry-mirrors&quot;: [ ], &quot;insecure-registries&quot;: [ &quot;registry.lazycat.cloud&quot; ], &quot;log-driver&quot;: &quot;journald&quot;, &quot;cgroup-parent&quot;: &quot;sys_docker.slice&quot;}# 商店的docker引擎lzcbox-029c588e ~ # cat /lzcsys/etc/docker/daemon.json{ &quot;bridge&quot;: &quot;none&quot;, &quot;insecure-registries&quot;: [ &quot;registry.lazycat.cloud&quot; ], &quot;default-address-pools&quot;: [ ], &quot;ipv6&quot;: true, &quot;hosts&quot;: [ &quot;unix:///lzcsys/run/lzc-docker/docker.sock&quot; ], &quot;containerd-namespace&quot;: &quot;lzc-docker&quot;, &quot;containerd-plugins-namespace&quot;: &quot;lzc-docker-plugins&quot;, &quot;exec-root&quot;: &quot;/lzcsys/run/lzc-docker/docker&quot;, &quot;pidfile&quot;: &quot;/lzcsys/run/lzc-docker/docker.pid&quot;, &quot;data-root&quot;: &quot;/lzcsys/run/data/system/docker&quot;, &quot;cgroup-parent&quot;: &quot;lzc_docker.slice&quot;}# playground的docker引擎cat /lzcsys/var/playground/daemon.json{ &quot;bridge&quot;: &quot;&quot;, &quot;containerd-namespace&quot;: &quot;playground-docker&quot;, &quot;containerd-plugins-namespace&quot;: &quot;playground-docker&quot;, &quot;data-root&quot;: &quot;/data/playground/data/docker&quot;, &quot;default-address-pools&quot;: [], &quot;exec-root&quot;: &quot;/data/playground/docker&quot;, &quot;hosts&quot;: [ &quot;unix:///data/playground/docker.sock&quot; ], &quot;insecure-registries&quot;: [ &quot;registry.lazycat.cloud&quot; ], &quot;pidfile&quot;: &quot;/data/playground/docker.pid&quot; 小结懒猫微服总会给我惊讶，除了极客风格的外壳，性能突出的硬件外，里面的软件设计也同样优秀，这个设计让我对 docker 有了更加深刻的认识。 三套 docker 共存不是表面上的魔改，而是通过 containerd 的 namespace 配合脚本封装，在容器之上再抽象一层运行时，把 playground、系统和商店隔离成三界，却又共用一套内核，很好玩。","link":"/posts/1d9319fb/"},{"title":"懒猫微服进阶心得（三）：一台机器跑三套 Docker？深入解析懒猫容器的共存机制（下）","text":"在上一期里，我们剖析了懒猫微服原生的三套 Docker 共存方案，这次我们来看看怎么在懒猫微服上启动新的 dev-docker 引擎，既能拓展使用，但又不与现有环境相互污染。 核心思路 独立 daemon.json 指定专属数据目录 / Socket 一个包装脚本 dev-docker 让你照常敲 docker 命令 需要时随时启用，不用时一条命令即卸载 目录规划我目前是在 root 目录下新建了一个 dev 目录，新的容器所有数据都在这个目录下。 123456.├── dev/│ ├── data/ # 镜像层、容器元数据│ ├── exec/ # 运行时文件│ └── daemon.json└── dev-docker # 包装脚本，照样敲 `docker` 提示：docker.sock、docker.pid 会在启动时自动生成到 dev/ 里。 生成 daemon.json这个是主要的文件，定义了 dev-docker 的数据目录，以及命名空间的隔离。 12345678910111213# 先拿到绝对路径，避免 dockerd 报相对路径错误DDIR=$(realpath ./dev)cat &gt; $DDIR/daemon.json &lt;&lt;EOF{ &quot;data-root&quot;: &quot;$DDIR/data&quot;, &quot;exec-root&quot;: &quot;$DDIR/exec&quot;, &quot;pidfile&quot;: &quot;$DDIR/docker.pid&quot;, &quot;hosts&quot;: [&quot;unix://$DDIR/docker.sock&quot;], &quot;containerd-namespace&quot;: &quot;dev-docker&quot;, &quot;containerd-plugins-namespace&quot;: &quot;dev-docker&quot;}EOF 启动 dev-docker 引擎使用 dockerd 指定配置文件启动 dev-docker，然后放在后台进行。 1sudo dockerd --config-file=$DDIR/daemon.json --log-level=info &amp; 执行之后得到如下的结果： 1234567INFO[2025-05-20T12:55:02.072949048Z] detected 127.0.0.53 nameserver, assuming systemd-resolved, so using resolv.conf: /run/systemd/resolve/resolv.confINFO[2025-05-20T12:55:02.157745008Z] Loading containers: start.INFO[2025-05-20T12:55:02.331021502Z] Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP addressINFO[2025-05-20T12:55:02.394567874Z] Loading containers: done.INFO[2025-05-20T12:55:02.413944743Z] Docker daemon commit=&quot;26.1.3-0ubuntu1~24.04.1&quot; containerd-snapshotter=false storage-driver=overlay2 version=26.1.3INFO[2025-05-20T12:55:02.414179613Z] Daemon has completed initializationINFO[2025-05-20T12:55:02.471933824Z] API listen on /home/ubuntu/ddd/dev/docker.sock 一个 dev-docker 包装脚本这个脚本就是仿照懒猫微幅其他的 docker 实现： 1234567cat &gt; ./dev-docker &lt;&lt;'EOF'#!/usr/bin/env bashexport DOCKER_HOST=unix://$(realpath ./dev/docker.sock)exec docker &quot;$@&quot;EOFchmod +x ./dev-docker 设定DOCKER_HOST=unix://$(realpath ./dev/docker.sock)，然后用 exec docker &quot;$@&quot; 把收到的全部参数原封不动交给真实的 docker 命令执行。 然后就可以正常使用了： 12./dev-docker ps./dev-docker run -d -p 8080:80 nginx 系统自带的 docker 仍在 /var/run/docker.sock 上工作，互不打扰。 将 dev-docker 放入全局 PATH如果想全局生效，运行下方命令。但注意：懒猫微服重启后 /usr/local/bin 会被还原。” 1sudo install -m 755 ./dev-docker /usr/local/bin/ 一键化脚本1234567891011121314151617181920212223242526272829#!/usr/bin/env bash# init-docker-dev.shset -emkdir devBASE=$(realpath &quot;./dev&quot;)mkdir -p &quot;$BASE&quot;/{data,exec}cat &gt; &quot;$BASE/daemon.json&quot; &lt;&lt;EOF{ &quot;data-root&quot;: &quot;$BASE/data&quot;, &quot;exec-root&quot;: &quot;$BASE/exec&quot;, &quot;pidfile&quot;: &quot;$BASE/docker.pid&quot;, &quot;hosts&quot;: [&quot;unix://$BASE/docker.sock&quot;], &quot;containerd-namespace&quot;: &quot;dev-docker&quot;, &quot;containerd-plugins-namespace&quot;: &quot;dev-docker&quot;}EOFdockerd --config-file=&quot;$BASE/daemon.json&quot; --log-level=info &amp;cat &gt; &quot;./dev-docker&quot; &lt;&lt;EOF#!/usr/bin/env bashexport DOCKER_HOST=unix://$BASE/docker.sockexec docker &quot;\\$@&quot;EOFchmod +x ./dev-dockerecho &quot;🎉 Dev Docker 已就绪，使用 ./dev-docker 访问！&quot; 启动脚本： 12chmod +x init-docker-dev.sh # 赋可执行权限（若脚本是下载的）./init-docker-dev.sh 运行完脚本后，后续就在当前目录直接敲 ./dev-docker &lt;command&gt; 即可；如果之前已将 dev-docker 安装到 PATH，全局也可以直接 dev-docker ps 脚本执行记录如下： 123456789🎉 Dev Docker 已就绪，使用 ./dev-docker 访问！ubuntu@ip-172-31-29-78:~$ INFO[2025-05-20T12:55:02.071795870Z] Starting upINFO[2025-05-20T12:55:02.072949048Z] detected 127.0.0.53 nameserver, assuming systemd-resolved, so using resolv.conf: /run/systemd/resolve/resolv.confINFO[2025-05-20T12:55:02.157745008Z] Loading containers: start.INFO[2025-05-20T12:55:02.331021502Z] Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP addressINFO[2025-05-20T12:55:02.394567874Z] Loading containers: done.INFO[2025-05-20T12:55:02.413944743Z] Docker daemon commit=&quot;26.1.3-0ubuntu1~24.04.1&quot; containerd-snapshotter=false storage-driver=overlay2 version=26.1.3INFO[2025-05-20T12:55:02.414179613Z] Daemon has completed initializationINFO[2025-05-20T12:55:02.471933824Z] API listen on /home/ubuntu/ddd/dev/docker.sock sudo ./dev-docker info查看信息： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253sudo ./dev-docker infoClient: Version: 26.1.3 Context: default Debug Mode: falseServer: Containers: 0 Running: 0 Paused: 0 Stopped: 0 Images: 0 Server Version: 26.1.3 Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Using metacopy: false Native Overlay Diff: true userxattr: false Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 runc Default Runtime: runc Init Binary: docker-init containerd version: runc version: init version: Security Options: apparmor seccomp Profile: builtin cgroupns Kernel Version: 6.8.0-1024-aws Operating System: Ubuntu 24.04.2 LTS OSType: linux Architecture: aarch64 CPUs: 2 Total Memory: 1.8GiB Name: ip-172-31-29-78 ID: b6f661de-2099-4b23-aff8-1a55e35833d9 Docker Root Dir: /home/ubuntu/ddd/dev/data Debug Mode: false Experimental: false Insecure Registries: 127.0.0.0/8 Live Restore Enabled: false ./dev-docker pull ubuntu 下载 images： 1234567ubuntu@ip-172-31-29-78:~$ sudo ./dev-docker pull ubuntuUsing default tag: latestlatest: Pulling from library/ubuntu2f074dc76c5d: Pull completeDigest: sha256:6015f66923d7afbc53558d7ccffd325d43b4e249f41a6e93eef074c9505d2233Status: Downloaded newer image for ubuntu:latestdocker.io/library/ubuntu:latest 检查 docker 版本： 12345ubuntu@ip-172-31-29-78:~$ dev-docker --versionDocker version 26.1.3, build 26.1.3-0ubuntu1~24.04.1ubuntu@ip-172-31-29-78:~$ docker --versionDocker version 26.1.3, build 26.1.3-0ubuntu1~24.04.1 不使用的时候如何卸载？办法 1: ps aux | grep dockerd 查看 docker 进程的 PID 号，然后删除1234567891011121314151617ps aux | grep dockerdroot 470 0.8 0.3 2653088 100248 ? Ssl 07:42 0:11 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sockroot 2226 6.6 0.6 7246472 227108 ? Ssl 07:42 1:37 /usr/bin/dockerd --config-file /lzcsys/etc/docker/daemon.jsonroot 27520 0.0 0.2 2874220 90788 ? Ssl 07:46 0:00 /usr/bin/dockerd --config-file /lzcsys/var/playground/daemon.jsonroot 127241 0.5 0.2 2636632 92720 pts/1 Sl 07:52 0:04 dockerd --config-file=/root/dev/daemon.json --log-level=inforoot 405552 0.0 0.0 3748 2048 pts/1 S+ 08:06 0:00 grep --colour=auto dockerd---lzcbox-029c588e ~ # kill -15 127241lzcbox-029c588e ~ # INFO[2025-05-21T08:10:58.184799932+08:00] Processing signal 'terminated'INFO[2025-05-21T08:10:58.198235413+08:00] stopping event stream following graceful shutdown error=&quot;&lt;nil&gt;&quot; module=libcontainerd namespace=dev-dockerINFO[2025-05-21T08:10:58.203590577+08:00] Daemon shutdown complete---lzcbox-029c588e ~ # ps aux | grep dockerdroot 470 0.7 0.3 2653088 100212 ? Ssl 07:42 0:13 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sockroot 2226 7.8 0.7 7246472 233080 ? Ssl 07:42 2:18 /usr/bin/dockerd --config-file /lzcsys/etc/docker/daemon.jsonroot 27520 0.0 0.2 2874220 92644 ? Ssl 07:46 0:00 /usr/bin/dockerd --config-file /lzcsys/var/playground/daemon.jsonroot 568622 0.0 0.0 3748 2048 pts/1 S+ 08:11 0:00 grep --colour=auto dockerd 办法 2: pkill -f ‘./dev/daemon.json’ 指定文件删除：1234567891011pkill -f './dev/daemon.json'INFO[2025-05-21T08:14:06.721816466+08:00] Processing signal 'terminated'lzcbox-029c588e ~ # INFO[2025-05-21T08:14:06.728822927+08:00] stopping event stream following graceful shutdown error=&quot;&lt;nil&gt;&quot; module=libcontainerd namespace=dev-dockerINFO[2025-05-21T08:14:06.734923834+08:00] Daemon shutdown complete[1]+ Done dockerd --config-file=&quot;./dev/daemon.json&quot; --log-level=infolzcbox-029c588e ~ # ps aux | grep dockerdroot 470 0.7 0.3 2653088 100340 ? Ssl 07:42 0:14 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sockroot 2226 8.3 0.7 7246472 234356 ? Ssl 07:42 2:41 /usr/bin/dockerd --config-file /lzcsys/etc/docker/daemon.jsonroot 27520 0.0 0.2 2874220 92500 ? Ssl 07:46 0:01 /usr/bin/dockerd --config-file /lzcsys/var/playground/daemon.jsonroot 663902 0.0 0.0 3748 1792 pts/1 S+ 08:14 0:00 grep --colour=auto dockerd 清除数据 12rm -rf ./dev # 删数据目录sudo rm -f /usr/local/bin/dev-docker # 若装过 PATH 最后再多一套 Docker，不是为了炫技，而是给开发或者测试环境一个“随时可重置、天然隔离、低成本回收”的保险箱。学会这一招，你就能在懒猫微服乃至任何 Linux 服务器上，放心大胆地尝鲜新内核、新 runtime，甚至复刻生产 bug —— 然后一句 pkill + rm -rf dev/，世界瞬间清爽如初。祝玩得尽兴！","link":"/posts/b853f136/"},{"title":"懒猫微服进阶心得（四）：每次重启都丢配置？用 systemctl --user 自动装回环境！","text":"在懒猫微服中，为了防止用户误操作破坏系统，默认启用了“重启还原机制”——每次重启都会还原大部分系统改动。不过，用户主目录的数据是保留的（例如 /root/），这就给我们留下了一条生路。 以往每次重启后，我都要手动重新安装 htop、sudo、httpie 等工具，重复操作实在麻烦。之前在 VIP 群里沟通过能否允许使用 systemctl 自启脚本，现在终于支持了 systemctl --user 的开机启动功能，第一时间来体验一下！ 💻 安装脚本 init.sh我们把需要安装的软件统一写进一个脚本，只安装未安装的部分，避免重复浪费时间。同时也支持远程安装一些工具，例如 superfile。 1234567891011121314151617181920212223242526272829303132333435363738#!/usr/bin/env bashset -e # 任意步骤失败立即终止PACKAGES=( sudo htop wget build-essential httpie exa duf bat # 可以继续添加：docker.io nodejs ...)need_install=()for pkg in &quot;${PACKAGES[@]}&quot;; do if ! dpkg -s &quot;$pkg&quot; &amp;&gt;/dev/null; then need_install+=(&quot;$pkg&quot;) fidoneif (( ${#need_install[@]} )); then echo &quot;==&gt; Installing: ${need_install[*]}&quot; apt-get update DEBIAN_FRONTEND=noninteractive apt-get install -y &quot;${need_install[@]}&quot;else echo &quot;==&gt; All packages already installed.&quot;fi# 安装 Superfile 工具if command -v curl &amp;&gt;/dev/null; then echo &quot;==&gt; Installing Superfile (from https://superfile.netlify.app)&quot; bash -c &quot;$(curl -sLo- https://superfile.netlify.app/install.sh)&quot;else echo &quot;❌ curl not found, skipping Superfile install&quot;fi 你可以把这个脚本保存为 /root/init.sh（懒猫微服会保留这个路径），并赋予执行权限： 1chmod +x /root/init.sh ⚙ systemd 用户服务配置由于懒猫微服现在支持 systemctl --user，我们就可以通过用户级 systemd 服务在登录后自动执行该脚本。 在 ~/.config/systemd/user/ 目录下创建服务文件： 12mkdir -p ~/.config/systemd/uservim ~/.config/systemd/user/bootstrap-packages.service 内容如下： 1234567891011[Unit]Description=Bootstrap Required Packages[Service]Type=oneshot # 关键修改！表示一次性任务ExecStart=/root/init.shRemainAfterExit=yes # 任务完成后仍标记为 &quot;active&quot;（可选）# Restart=no # 默认就是 no，可省略[Install]WantedBy=default.target 注意事项： ExecStart 使用 /root/init.sh 是因为懒猫微服重启不会清空 root 目录； 这是一个 oneshot（一次性任务），运行完就退出； default.target 是用户级别的“登录后启动”目标。 🧪 启用和调试服务配置好之后，使用以下命令启动并设置自动运行： 1234systemctl --user daemon-reload # 重新加载用户服务配置systemctl --user start bootstrap-packages.service # 手动运行一次（测试用）systemctl --user status bootstrap-packages.service # 查看服务状态和日志systemctl --user enable bootstrap-packages.service # 设置登录后自动运行 示例运行结果：12systemctl --user start bootstrap-packages.servicesystemctl --user status bootstrap-packages.service 输出如下： 123456789101112○ bootstrap-packages.service - Bootstrap Required Packages Loaded: loaded (/root/.config/systemd/user/bootstrap-packages.service; enabled; preset: enabled) Active: inactive (dead) since Thu 2025-05-29 20:13:58 CST; 941ms ago Duration: 6.438s Process: 142818 ExecStart=/root/init.sh (code=exited, status=0/SUCCESS) Main PID: 142818 (code=exited, status=0/SUCCESS) CPU: 350msMay 29 20:13:53 lzcbox-029c588e init.sh[142926]: Downloading superfile v1.3.1 for linux (amd64)...May 29 20:13:58 lzcbox-029c588e init.sh[142926]: Installing superfile...May 29 20:13:58 lzcbox-029c588e init.sh[142926]: 🎉 Installation complete!May 29 20:13:58 lzcbox-029c588e init.sh[142926]: You can type &quot;spf&quot; to start! 图示效果如下（安装过程中终端自动拉起）： 🚀 小结 步骤 命令 设置 systemd 服务 vim ~/.config/systemd/user/bootstrap-packages.service 测试运行 systemctl --user start bootstrap-packages.service 设置登录自启 systemctl --user enable bootstrap-packages.service 查看运行状态 systemctl --user status bootstrap-packages.service 搭配懒猫微服的 root 持久策略和 systemd 用户服务功能，我们终于实现了：重启自动恢复开发环境，不用每次手动装包了！","link":"/posts/95e86a3c/"},{"title":"懒猫微服进阶心得（五）：使用懒猫微服做Ventoy启动盘","text":"由于经常给别人装系统，所以经常做了一个多合一的系统盘。这今年基本都没用过 windows 了，都是 MacOS + Linux 的组合。但是 Ventoy 本身不支持 MacOS，以前是用 Windows 虚拟机来做这个事情，把 USB 直通进去再烧录。但是最近实在不想碰 Windows，所以想着是不是能在懒猫微服上做这个操作。 下载并解压 Ventoy1234wget https://github.com/ventoy/Ventoy/releases/download/v1.1.05/ventoy-1.1.05-linux.tar.gztar zxvf ventoy-1.1.05-linux.tar.gzcd ventoy-1.1.05/./VentoyWeb.sh 这个默认是启动在 localhost，如果需要外网访问改成 0.0.0.0，运行 ./VentoyWeb.sh 后，你会看到如下提示： 12345678./VentoyWeb.sh=============================================================== Ventoy Server 1.1.05 is running ... Please open your browser and visit http://127.0.0.1:24680===============================================================################## Press Ctrl + C to exit ##################### 翻了翻脚本，是在这里改。 因为我本地通过 dig 解析懒猫微服的域名是 IPV6，所以没办法直接访问,于是我通过 SSH 创建一个本地端口转发（Local Port Forwarding）隧道： 1ssh -N -L 24680:127.0.0.1:24680 root@lzc ssh: 启动 SSH 客户端。 -N: 不执行远程命令，仅用于端口转发（即登录后不打开 shell）。 -L 24680:127.0.0.1:24680: 本地端口转发规则，格式为 本地端口:远程地址:远程端口。解释如下： 24680: 本地监听的端口（你访问 localhost:24680 时会触发转发）。 127.0.0.1: 这是 SSH 远程主机上的地址，指代远程主机自己。 24680: 最终目标端口。 root@lzc: 使用 root 用户连接名为 lzc 的主机（可以是域名或 /etc/hosts 里配置的别名）。 当本地访问 localhost:24680，会通过 SSH 加密通道转发到远程主机 lzc 上的 127.0.0.1:24680，就像直接在远程主机上访问一样。 这个就是 Ventoy 的页面了，由于默认懒猫没有 GUI，所以没办法使用类似 windows 那种客户端，还好 Venoty 提供了一个 web 端可以用来玩。 点击右侧的绿色， 接着 Ventoy 会再确认一次是否格式化设备，务必确认盘符无误，这一步会清空整盘数据，后期可以无损升级。 写盘成功的提示，后期只需要把 ISO 直接拖拽进来。 小结 懒猫微服 + Ventoy Web 是制作多合一启动盘的 “无桌面” 优雅方案。 通过 SSH 端口转发，可在不暴露服务的情况下安全地使用 Web 界面。 写盘后只需拖拽 ISO，后续增删镜像都无需重新格式化。","link":"/posts/1c49be8c/"},{"title":"懒猫微服进阶心得（六）：以纸砚双拼为例，快速移植纯前端项目到懒猫微服","text":"之前移植了一款颜值极高的纸砚双拼，想着纯前端类的软件应该都是一样的操作，所以把操作记录下来，方便以后复习查看，也相当于一个教程吧。 对于这种场景来说，前端项目开发完成后，我们将构建好的静态页面部署到服务器上。借助 Docker 和 Nginx，可以实现一套轻量、快速、可移植的部署方式，特别适合懒猫微服这种容器化的环境，也很适合日常调试测试使用。 下面将手把手教你如何打包一个 Vue 或 React 项目，并通过 Docker + Nginx 构建一个可复用的前端部署容器镜像，然后就可以把这个部署到懒猫微服删，当然也适用于各种 Linux + Docker 环境。 1 · 准备目录结构纸砚双拼是 Vue 的项目，所以直接执行这个命令打包 12npm inpm run build 打包完成后，项目根目录下会生成一个 dist/ 文件夹，里面包含： index.html 静态 JS、CSS 资源 图片等其他引用资源 基本所有前端工程化的流程都是部署这个 dist/静态目录。 在开始容器化之前，我们先来整理一下项目结构。 12345my-static-site/├── dist/ # 前端打包后的静态资源目录├── nginx.conf # Nginx 配置文件├── Dockerfile # Docker 构建文件└── docker-compose.yml # docker-compose 管理配置（可选） 主要就是把 dist/ 目录映射到 Nginx 的根目录。 .dockerignore（防止把 node_modules 等大文件复制进镜像）项目根目录建议加个 .dockerignore 文件，防止无用文件进入镜像、浪费空间： 12345node_modules.git.vscode*.logdist 这里的 dist 虽然是构建产物，但因为我们用的是双阶段构建，会在容器里重新生成，不需要提前放入。 2 · Dockerfile（双阶段构建：先构建，再用 Nginx 托管）我们采用双阶段构建方案，能够最大限度减小最终镜像体积，只包含运行时必须的内容。 12345678910111213141516171819202122232425262728293031# 构建阶段FROM node:18-alpine AS buildWORKDIR /app# 复制package.json和package-lock.jsonCOPY package*.json ./# 安装依赖 - 使用npm install代替npm ciRUN npm install# 复制源代码COPY . .# 构建应用RUN npm run build# 生产阶段FROM nginx:alpine# 复制构建产物到nginx目录COPY --from=build /app/build /usr/share/nginx/html# 复制nginx配置COPY nginx.conf /etc/nginx/conf.d/default.conf# 暴露80端口EXPOSE 80# 启动nginxCMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] 使用 node:alpine 和 nginx:alpine 轻量镜像，构建出来的镜像体积非常小 分阶段构建，确保生产镜像中没有多余文件 nginx.conf（自定义 Nginx 配置）Nginx 配置文件如下： 123456789101112131415161718192021222324252627server { listen 80; server_name localhost; location / { root /usr/share/nginx/html; index index.html index.htm; try_files $uri $uri/ /index.html; } # 禁止缓存 index.html，确保始终获取最新版本（避免缓存导致更新不生效） location = /index.html { root /usr/share/nginx/html; add_header Cache-Control &quot;no-store, no-cache, must-revalidate&quot;; } # 静态资源缓存设置 location ~* \\.(js|css|png|jpg|jpeg|gif|ico|svg)$ { root /usr/share/nginx/html; expires 1d; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; }} 3 · 构建与部署3.1 本地构建测试执行以下命令构建镜像并启动： 12docker build -t my-frontend .docker run -p 8080:80 my-frontend 打开浏览器访问 http://localhost:8080，确认页面正常显示。如果用的是懒猫微服，可通过它的 web 浏览器或 ssh 转发方式访问容器。 3.2 可选使用 docker-compose如果本地调试可以使用 12345678910version: &quot;3&quot;services: cors-tester: build: context: . dockerfile: Dockerfile ports: - &quot;80:80&quot; restart: unless-stopped 之前打包踩的坑打包多了之后 Docker 会积累不少旧镜像、缓存和挂载卷，下面这些命令能够清理磁盘空间： 使用 pg-docker 或者 lzc-docker 来替代 强制无缓存构建镜像1docker compose build --no-cache 不使用任何缓存，适合依赖变动或调试构建问题时使用。 📦 查看磁盘空间占用详情1docker system df -v 查看镜像、容器、网络和卷的占用情况，排查“空间去哪了”。 🧹 强制清理所有未使用资源（含挂载卷）1docker system prune -af --volumes 删除所有未使用的镜像、容器、网络和卷，释放最大磁盘空间。注意：慎用，可能会清掉你没保存的 volume 数据。","link":"/posts/7294709a/"},{"title":"懒猫微服进阶心得（七）：懒猫的镜像仓库","text":"这几年国内访问 Dockerhub 总有类似的问题，所以很多情况都建议自建 docker 仓库，比如 Habor，Nexus 或者。毕竟 GFW 的花样我们想不到。 云厂商的 ECR。但是对于个人玩家或者爱好者来说这一套实在是太重太难以维护了，可能也就是这个原因，懒猫微服也提供了镜像仓库的和本地仓库的功能。 先说镜像仓库，就是从懒猫微服的服务器上先拉 Docker image，然后再推到自己的 registry。这一步骤通常由出海链路比较好的机器来完成。 懒猫镜像同步功能懒猫提供了便捷的镜像同步命令： 1lzc-cli appstore copy-image cloudsmithy/lazycat-nav 执行之后就可以看到镜像仓库，registry.lazycat.cloud 这个地址。 重要说明：这个地址只能在微服环境中使用，如果在其他地方使用会出现认证错误： 12docker pull registry.lazycat.cloud/u04123229/cloudsmithy/lazycat-nav:854b14e73ab0726eError response from daemon: Head &quot;https://registry.lazycat.cloud/v2/u04123229/cloudsmithy/lazycat-nav/manifests/854b14e73ab0726e&quot;: no basic auth credentials 其实就一个加了认证的 registry，只是微服有凭证可以直接进。 内置 Docker Registry V2懒猫微服内置了一个简化版的 registry，完整使用流程如下： 1234567891011121314# 构建x86架构镜像docker build --platform linux/amd64 -t helloworld:latest .# 获取当前微服名称BOXNAME=$(lzc-cli box default)# 为镜像打上仓库标签docker tag helloworld:latest dev.$BOXNAME.heiyu.space/helloworld:latest# 推送镜像到仓库docker push dev.$BOXNAME.heiyu.space/helloworld:latest# 从仓库拉取镜像docker pull dev.$BOXNAME.heiyu.space/helloworld:latest 实际操作演示： 在 M2 芯片设备上的构建过程： 在 Orbstack 上拉取验证（先删除本地镜像再拉取）： 通过 API 查看镜像列表： 这个简单版本的 docker registry v2，后面用来做跑 CI 的镜像仓库应该是够了。 插曲：如果遇到这个问题，千万别信 AI 是 buildX 坏了，就是中文路径的问题。（AI 查一小时。Google 一分钟） 1docker-container:multiarchERROR: failed to dial gRPC: rpc error: code = Internal desc = rpc error: code= Internal desc =header key&quot;x-docker-expose-session-sharedkey&quot; contains value with non-printable ASCII characters","link":"/posts/8cdf9a5/"},{"title":"懒猫微服进阶心得（八）：如何在 ARM 机器上下载并运行X86镜像以及在X86上运行ARM镜像","text":"之前写好应用做好镜像想扔到懒猫微服上打包，都是先使用 buildx 打包双架构镜像，push 到 dockerhub 上，然后再用微服的 copy image 转成国内的镜像地址，这过程很麻烦。 因为在 Apple Silicon（如 M1/M2 芯片）设备上，默认运行的是 ARM 架构镜像（linux/arm64）。但有些镜像或依赖只支持 X86（linux/amd64）架构。 本文将介绍如何在 ARM 设备上拉取并运行 X86 镜像，以及如何保存和加载镜像。 🐳 拉取 X86 架构的 Docker 镜像使用 --platform=amd64 参数即可拉取 X86 架构镜像： 1docker pull --platform=amd64 nginx:latest docker pull：从远程仓库拉取镜像 --platform=amd64：显式指定拉取 x86_64 架构的镜像 nginx:latest：镜像名与标签 适用于在 M 系列 Mac 上使用 X86 镜像进行兼容性测试或运行仅支持 x86 的应用。 🔍 验证镜像的架构信息拉取完成后，可通过以下命令确认镜像架构： 1docker image inspect nginx:latest --format '{{.Os}}/{{.Architecture}}' 示例输出（成功拉取 X86 架构）： 1linux/amd64 ⚠️ 遇到的运行报错分析执行以下命令尝试运行时： 1docker run --rm -it --platform=amd64 nginx:latest 可能会出现如下错误： 1docker: Error response from daemon: image with reference nginx:latest was found but its platform (linux/amd64) does not match the specified platform (darwin/amd64) 📌 错误原因解析：Docker 镜像是 基于 Linux 内核 的容器运行时，不支持 darwin/amd64 平台。你应显式指定目标平台为： 1--platform=linux/amd64 ✅ 正确命令：1docker run --rm -it --platform=linux/amd64 nginx:latest 此时 Docker Desktop 会自动调用 qemu 进行跨架构模拟（无需额外配置），即在 ARM Mac 上模拟运行 X86 容器。 📦 Docker 镜像的保存与加载Docker 提供 save 和 load 命令，支持将镜像打包导出为文件，便于备份或跨设备迁移。 ✅ 1. 保存镜像为 .tar 文件1docker save -o nginx-amd64.tar nginx:latest -o nginx-amd64.tar：导出的文件名 nginx:latest：指定要导出的镜像标签 也可以一次保存多个镜像： 1docker save -o images.tar nginx:latest redis:alpine ✅ 2. 加载 .tar 镜像文件使用 SCP 或者 FTP 传到懒猫微服上，使用以下命令导入： 1docker load -i nginx-amd64.tar 导入成功后镜像将出现在 docker images 列表中。 ✅ 3. 跨架构导入运行示例如果你从懒猫微服上保存了镜像（如 linux/amd64 的 nginx），在 ARM Mac 上可通过以下方式运行： 1docker run --rm -it --platform=linux/amd64 nginx:latest ✅ 4. 导出为压缩文件（可选）压缩后更便于传输： 1docker save nginx:latest | gzip &gt; nginx.tar.gz 解压并导入： 1gunzip -c nginx.tar.gz | docker load 📝 小结 操作 命令 拉取 X86 镜像 docker pull --platform=amd64 nginx:latest 运行 X86 镜像 docker run --rm -it --platform=linux/amd64 nginx:latest 保存镜像 docker save -o nginx.tar nginx:latest 加载镜像 docker load -i nginx.tar 如果是在 懒猫微服 运行 ARM 镜像呢？ ✅ 拉取 ARM 架构镜像（在 X86 主机上）1docker pull --platform=linux/arm64 nginx:latest 或简写为： 1docker pull --platform=arm64 nginx:latest 这会拉取适用于 linux/arm64 的 nginx 镜像（即 ARM 设备如 Raspberry Pi 或 Apple Silicon 可运行的版本）。 ✅ 运行 ARM 镜像（在 X86 上）1docker run --rm -it --platform=linux/arm64 nginx:latest Docker Desktop 会通过内置的 QEMU 模拟 ARM 架构运行该容器。 ⚠️ 前提是你的 Docker 环境启用了 QEMU 多平台支持（默认大多数 Docker Desktop 安装都已经启用）。 ✅ 验证运行中的容器架构方案一：确认 QEMU 是否已配置（X86 主机想运行 ARM 镜像）如果你在 Intel / X86 主机上运行 –platform=linux/arm64，需要先启用跨架构支持： 1docker run --rm --privileged multiarch/qemu-user-static --reset -p yes 进入容器执行： 1uname -m 输出应为： 1aarch64 说明该容器运行在 ARM 架构上。 如果遇到：exec /docker-entrypoint.sh: exec format error意味着：你尝试在一个 与镜像架构不匹配的主机或模拟环境中运行该镜像，导致容器入口脚本无法被执行。 目标架构 --platform 参数 常见用途 X86 (Intel/AMD) linux/amd64 默认平台，大多数镜像的标准版本 ARM (如 M1/M2/Raspberry Pi) linux/arm64 在 Apple Silicon 上或嵌入式设备运行 在 X86 上模拟 ARM --platform=linux/arm64 跨架构测试、兼容性验证","link":"/posts/86ab1d7c/"},{"title":"懒猫微服进阶心得（九）：商店 App 如何接管 Docker 引擎？","text":"在之前的内容中，我们提到过懒猫微服采用三套独立的 Docker 环境来隔离系统组件、Playground Docker 与商店 App 的 Docker 实例。那么问题来了：如何让商店中上架的 App 操作 Playground 中的 Docker 引擎？ 答案是：通过挂载 docker.sock 文件来实现跨容器控制。 所以我们可以在商店的 APP 中操作 playground docker，其实也就是 Docker 面板或者轻量 Docker 面板做的事情。 为什么不操作其他两个 Docker 引擎？ 系统组件 Docker 无需干预，重启之后可以复原。 应用商店有自己的生命周期，也无需干预。 一、在 build.yml 中挂载 Playground 路径首先，在打包配置 build.yml 中新增 services 字段，用于将宿主机中的 /data/playground 挂载到容器内部： 12345678910111213manifest: ./lzc-manifest.ymlpkgout: ./icon: ./logo.pngservices: containly: volumes: - bind: create_host_path: true source: /data/playground target: /lzcapp/run/playground type: bind 打包后会生成一个名为 compose.override.yml 的文件。请注意：即使你手动创建了 compose.override.yml，也可能无法直接生效，必须通过打包流程自动生成。（此结论基于初步测试） 生成后的 compose.override.yml 内容如下： 12345678services: containly: volumes: - bind: create_host_path: true source: /data/playground target: /lzcapp/run/playground type: bind 二、修改 manifest.yml 实现 docker.sock 映射为了让上架 App 操作 Docker，需要手动编辑 manifest.yml 文件，添加以下内容： 12345binds: - /lzcapp/run/playground/docker.sock:/var/run/docker.sockenvironment: - DOCKGE_STACKS_DIR=/lzcapp/var/stacks - DOCKER_HOST=unix:///lzcapp/run/playground/docker.sock 这样，容器内的 Docker CLI 或管理面板就可以通过 DOCKER_HOST 环境变量，控制宿主机的 Docker 引擎。 三、完整的 manifest.yml 示例以下是完整可运行的 manifest.yml 配置： 1234567891011121314151617181920212223242526272829303132lzc-sdk-version: 0.1package: xu.deploy.containlyversion: 0.0.2name: Containlydescription: &gt;- A fancy, easy-to-use and reactive self-hosted docker compose.yaml stack-oriented manager.license: https://choosealicense.com/licenses/mit/homepage: https://github.com/cloudsmithy/Containlyauthor: xuusage: &gt;- 安装完成后，请重启懒猫微服以启用 Docker。 此应用将接管懒猫微服的独立 Docker 守护进程，可能存在安全风险。在授予容器 privileged 等权限之前，请确保容器是安全的，且不会执行危险操作。为了避免潜在风险，请确保： 1. 您了解容器的行为，并确认它们来自可信的源。 2. 容器中没有运行高危命令，且没有暴露不必要的端口或服务。 建议先查阅懒猫微服开发者手册，了解相关特性和限制，并根据手册中的安全建议配置容器。application: subdomain: containly routes: - /=http://containly.xu.deploy.containly.lzcapp:5000/services: containly: image: registry.lazycat.cloud/u04123229/cloudsmithy/containly:896f4251373d0ebe binds: - /lzcapp/run/playground/docker.sock:/var/run/docker.sock environment: - DOCKGE_STACKS_DIR=/lzcapp/var/stacks - DOCKER_HOST=unix:///lzcapp/run/playground/docker.sock 四、总结通过挂载 docker.sock 文件和设置 DOCKER_HOST，我们可以让商店上架的 App 控制懒猫微服的 Playground Docker 实例。我用这个功能上架了自己写的 Docker 面板，一起来玩一玩嘛？","link":"/posts/e8e61ce7/"},{"title":"INFINI Easysearch尝鲜Hands on","text":"INFINI Easysearch 是一个分布式的近实时搜索与分析引擎，核心引擎基于开源的 Apache Lucene。Easysearch 的目标是提供一个自主可控的轻量级的 Elasticsearch 可替代版本，并继续完善和支持更多的企业级功能。 与 Elasticsearch 相比，Easysearch 更关注在搜索业务场景的优化和继续保持其产品的简洁与易用性。 Easysearch 支持原生 Elasticsearch 的 DSL 查询语法，确保原业务代码无需调整即可无缝迁移。同时，极限科技还支持 SQL 查询，为熟悉 SQL 的开发人员提供更加便捷的数据分析方式。此外，Easysearch 兼容 Elasticsearch 的 SDK 和现有索引存储格式，支持冷热架构和索引生命周期管理，确保用户能够轻松实现数据的无缝衔接。 安装安装脚本无论是 Linux 还是 mac 都是这个一键脚本 1curl -sSL http://get.infini.cloud | bash -s -- -p easysearch 同时也提供了二进制的安装包： 如果不想整理 JAVA 环境问题，还可以使用这个https://release.infinilabs.com/easysearch/stable/bundle/ docker 部署官方提供了 Docker Compose 样例，包括三个服务：easysearch-node1、easysearch-node2 和 console。以下是详细说明： 版本控制： version: '3' 表示使用 Docker Compose 文件的第 3 版格式。 服务定义： easysearch-node1 和 easysearch-node2： 这两个服务使用相同的 Docker 镜像 infinilabs/easysearch:latest来组成双节点的集群。 容器运行时使用用户和组 ID 602:602。 设置了 ES_JAVA_OPTS 环境变量以配置 Java 虚拟机的内存。 ulimits 选项配置了内存锁定和文件描述符的限制，以提升性能。 容器内的配置、数据和日志目录通过卷映射到主机目录中，以便于数据持久化。 服务暴露特定端口，使外部能够访问容器中的服务。 两个节点均加入名为 esnet 的自定义网络中。 console： 该服务使用镜像 infinilabs/console:1.26.0-1552（该镜像没有 latest，需要手动把 latest 更改位特定的版本号）。 同样通过卷将数据和日志目录映射到主机。 暴露 9000 端口用于 Web 界面访问。 使用 links 功能链接到 easysearch-node1 和 easysearch-node2，简化容器之间的通信。 设置了时区环境变量 TZ 为 Asia/Shanghai。 网络配置： esnet 网络使用 bridge 驱动，提供一个隔离的网络环境，配置了特定的子网 172.24.0.0/16，以确保服务之间的网络通信。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071version: '3'services: easysearch-node1: user: &quot;602:602&quot; image: infinilabs/easysearch:latest container_name: easysearch-node1 hostname: easysearch-node1 environment: - &quot;ES_JAVA_OPTS=-Xms1g -Xmx1g&quot; ulimits: memlock: soft: -1 hard: -1 nofile: soft: 65536 hard: 65536 volumes: - $PWD/ezs1/config:/app/easysearch/config - $PWD/ezs1/data:/app/easysearch/data - $PWD/ezs1/logs:/app/easysearch/logs ports: - 9201:9200 - 9301:9300 networks: - esnet easysearch-node2: user: &quot;602:602&quot; image: infinilabs/easysearch:latest container_name: easysearch-node2 hostname: easysearch-node2 environment: - &quot;ES_JAVA_OPTS=-Xms1g -Xmx1g&quot; ulimits: memlock: soft: -1 hard: -1 nofile: soft: 65536 hard: 65536 volumes: - $PWD/ezs2/config:/app/easysearch/config - $PWD/ezs2/data:/app/easysearch/data - $PWD/ezs2/logs:/app/easysearch/logs ports: - 9202:9200 - 9302:9300 networks: - esnet console: image: infinilabs/console:1.26.0-1552 container_name: console hostname: console volumes: - $PWD/console/data:/data - $PWD/console/log:/log networks: - esnet ports: - 9000:9000 links: - easysearch-node1:es1 - easysearch-node2:es2 environment: - TZ=Asia/Shanghainetworks: esnet: driver: bridge ipam: config: - subnet: 172.24.0.0/16 尽管在这里官方提供了详细的命令，完全可以使用这个 docker-compose up 来进行替代。其他的脚本解释如下： init.sh 123456789101112131415#!/bin/bash# 获取当前脚本所在目录的绝对路径CUR_DIR=$(cd $(dirname $0); pwd)# 创建必要的目录结构mkdir -p $CUR_DIR/console/{data,log}mkdir -p $CUR_DIR/{ezs1,ezs2}/{data,logs}# 设置目录的拥有者和权限chown -R 1000:1000 $CUR_DIR/consolechown -R 602:602 $CUR_DIR/{ezs1,ezs2}chmod -R 0600 $CUR_DIR/{ezs1,ezs2}/config# 设置 config 目录的子目录权限find $CUR_DIR/{ezs1,ezs2}/config -type d -print0 | xargs -0 chmod 750 reset.sh 123456789101112131415161718192021222324#!/bin/bash# 获取当前脚本所在目录的绝对路径CUR_DIR=$(cd $(dirname $0); pwd)# 定义确认函数function confirm() { display_str=$1 default_ans=$2 if [[ $default_ans == 'y/N' ]]; then must_match='[yY]' else must_match='[nN]' fi read -p&quot;${display_str} [${default_ans}]:&quot; ans [[ $ans == $must_match ]]}# 提示用户确认删除所有数据confirm &quot;RISK WARN: Delete all data!!!&quot; 'y/N' &amp;&amp; echo || exit# 删除 console、ezs1 和 ezs2 的数据和日志文件rm -rvf $CUR_DIR/console/{data,log}/*rm -rvf $CUR_DIR/{ezs1,ezs2}/{data,logs}/* start.sh 1234#!/bin/bash# 使用 Docker Compose 启动 ezs2 项目中的服务docker-compose -p ezs2 up stop.sh 1234#!/bin/bash# 使用 Docker Compose 关闭并移除 ezs2 项目中的所有服务docker-compose -p ezs2 down 在我的电脑中，可以看到成功启动的容器。 https://infinilabs.cn/docs/latest/easysearch/getting-started/install/docker-compose/ Console 连接设置集群连接参数，比如域名端口，用户名密码。 初始化，这里会新建索引，写一些 sample 数据。 设置后台管理的密码，后期使用这个登录控制台。 检查配置，完成集群关联。这个是后台管理界面，除了用户名密码之外，也支持单点登录： 跨引擎、跨版本、跨集群 独一份！ 使用自带的面板进行查看节点数量： 同时也支持 REST 风格的 API 来进行查询。 接下来来使用 Console 连接 Amazon 的 OpenSearch： 同样是输入集群的 URL，用户名和密码。 然后可以拿到集群的信息，比如地址，版本号，集群状态，节点数量。 最后看到连接成功的信息。 我们可以在集群管理中看到 EasySearch 的集群和我们刚刚添加的 OpenSearch 集群。 是否开源？目前还没有开放源代码。","link":"/posts/8c820eb6/"},{"title":"Easysearch 中 PUT 和 POST 更新索引的区别及常见错误解析","text":"在 Easysearch 中，PUT 和 POST 都用于创建或更新文档，但它们的使用方式和行为有所不同。理解这些区别并正确使用，可以避免常见的错误，并确保数据操作符合预期。 1. PUT 用于创建或完全替换文档PUT 方法要求必须提供文档 ID，用于创建或完全替换已有文档。如果指定的文档 ID 不存在，则 PUT 会创建一个新文档；如果该 ID 已存在，则会完全覆盖原有数据，不会保留任何旧字段。 ✅ 示例1234PUT my_index/_doc/1{ &quot;myindex&quot;: 123} 执行效果 如果 ID 1 存在，原有文档会被完全覆盖，只保留 myindex 字段。 如果 ID 1 不存在，则创建一个新文档。 ❌ 常见错误1PUT my_index/_doc 错误返回1234{ &quot;error&quot;: &quot;Incorrect HTTP method for uri [/my_index/_doc] and method [PUT], allowed: [POST]&quot;, &quot;status&quot;: 405} 错误原因 PUT 需要指定文档 ID，但该请求缺少 ID，导致错误。 2. POST 用于创建或部分更新文档POST 既可以用于创建文档，也可以用于部分更新文档。其最大特点是可以省略文档 ID，让 Easysearch 自动生成唯一 ID。 ✅ 示例 1：创建文档（自动生成 ID）12345POST my_index/_doc{ &quot;name&quot;: &quot;Bob&quot;, &quot;age&quot;: 30} Easysearch 自动分配 ID 并存储数据。 ✅ 示例 2：部分更新如果要仅修改某个字段，而不影响其他数据，应该使用 _update： 123456POST my_index/_update/1{ &quot;doc&quot;: { &quot;age&quot;: 26 }} 只修改 age，不会删除 name 等其他字段。 ❌ 常见错误1234POST my_index/_doc/1{ &quot;a&quot;: 123} 错误原因 POST 传入了指定 ID，但 POST 的默认行为是创建新文档，不适用于替换已有文档，可能会导致数据不一致。因此，**替换文档应使用 PUT，部分更新应使用 _update**。 🚨 不推荐使用 POST 替代 PUT 进行替换，官方推荐： PUT 明确用于创建/替换。 POST 适用于新增（不带 ID）或部分更新（_update API）。 3. POST my_index（省略 _doc）的错误解析❌ 错误示例1234POST my_index{ &quot;name&quot;: &quot;Alice&quot;} ❌ 错误返回1234{ &quot;error&quot;: &quot;Incorrect HTTP method for uri [/my_index] and method [POST], allowed: [HEAD, DELETE, PUT, GET]&quot;, &quot;status&quot;: 405} 错误原因这个是新建索引设置 mapping 的格式，不能用于创建索引数据。 ✅ 正确做法 1234POST my_index/_doc{ &quot;name&quot;: &quot;Alice&quot;} 或者： 1234PUT my_index/_doc/1{ &quot;name&quot;: &quot;Alice&quot;} 4. PUT 和 POST 的区别总结 操作 PUT my_index/_doc/1（替换） POST my_index/_doc/1（不推荐） POST my_index/_doc（创建） POST my_index（错误） 是否需要 ID ✅ 需要 ✅ 需要（不推荐） ❌ 不需要（自动生成） ❌ 不能直接 POST my_index 文档是否存在 ✅ 存在则完全替换 ✅ 存在时完全替换（不推荐） ✅ 创建新文档 ❌ 报错 是否部分更新 ❌ 不支持 ❌ 不支持 ❌ 不支持 ❌ 报错 适用场景 创建/替换整个文档 （不推荐） 创建新文档 ❌ 需要 /_doc 5. 结论与最佳实践为了保证数据的正确性和操作的高效性，推荐使用以下方式： 新增数据（自动 ID） → POST my_index/_doc 新增数据（指定 ID） → PUT my_index/_doc/{id} 修改部分字段 → POST my_index/_update/{id} 完全替换文档 → PUT my_index/_doc/{id} 通过正确使用 PUT 和 POST，可以避免 POST my_index 这种格式错误，并正确管理 Easysearch 的索引和文档，确保数据操作符合预期。 💡 推荐大家在 Easysearch Console 进行实践，以更直观地理解这些区别！ 🚀","link":"/posts/d5a28fff/"},{"title":"Easysearch 使用 AWS S3 进行快照备份与还原：完整指南及常见错误排查","text":"Easysearch 可以使用 AWS S3 作为远程存储库，进行索引的快照（Snapshot）备份和恢复。同时，Easysearch 内置了 S3 插件，无需额外安装。以下是完整的配置和操作步骤。 1. 在 AWS S3 上创建存储桶 登录 AWS 控制台，进入 S3 服务。 创建一个新存储桶（例如 easysearch-backups）。 启用版本控制（可选，但推荐）。 权限配置：确保 IAM 角色具有访问 S3 的权限。 123456789101112131415{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Action&quot;: [&quot;s3:ListBucket&quot;], &quot;Effect&quot;: &quot;Allow&quot;, &quot;Resource&quot;: [&quot;arn:aws:s3:::s3-bucket-name&quot;] }, { &quot;Action&quot;: [&quot;s3:GetObject&quot;, &quot;s3:PutObject&quot;, &quot;s3:DeleteObject&quot;], &quot;Effect&quot;: &quot;Allow&quot;, &quot;Resource&quot;: [&quot;arn:aws:s3:::s3-bucket-name/*&quot;] } ]} 2. 在 Console 上注册 S3 作为快照存储库 使用 Console DevTools 或 API在 Easysearch 的 DevTools 执行： 12345678PUT _snapshot/my_s3_repository{ &quot;type&quot;: &quot;s3&quot;, &quot;settings&quot;: { &quot;bucket&quot;: &quot;easysearch-backups&quot;, &quot;base_path&quot;: &quot;&quot; }} 注意： bucket 需要填写你的 S3 存储桶名称。 region 需要替换成你的 AWS S3 所在区域，SDK 默认美东区。 如果 Bucket 在中国区，还需添加 endpoint: https://s3.&lt;region&gt;.amazonaws.com.cn 参数。 3. 创建快照一旦 my_s3_repository 注册完成，就可以创建快照： 12345PUT _snapshot/my_s3_repository/my_snapshot_001{ &quot;indices&quot;: &quot;my_index&quot;, &quot;include_global_state&quot;: false} 查看当前存储的快照： 1GET _snapshot/my_s3_repository/_all 4. 从 AWS S3 还原快照当你需要恢复索引时： 123456POST _snapshot/my_s3_repository/my_snapshot_001/_restore{ &quot;indices&quot;: &quot;my_index&quot;, &quot;rename_pattern&quot;: &quot;my_index&quot;, &quot;rename_replacement&quot;: &quot;restored_my_index&quot;} 说明：这会从 my_snapshot_001 还原 my_index，但以 restored_my_index 命名，避免与现有索引冲突。 如果要直接覆盖原索引（确保 my_index 为空或已删除）： 123456POST _snapshot/my_s3_repository/my_snapshot_001/_restore{ &quot;indices&quot;: &quot;my_index&quot;, &quot;ignore_unavailable&quot;: true, &quot;include_global_state&quot;: false} 5. 可能的错误与解决方案 错误信息 可能原因 解决方案 repository_s3 plugin not installed 没有安装 repository-s3 插件 运行 bin/elasticsearch-plugin install repository-s3 并重启 NoSuchBucket S3 存储桶不存在 确保 S3 存储桶名称正确 AccessDenied 权限不足 确保 S3 存储桶策略正确，检查 IAM 角色 index_closed_exception 目标索引已关闭 先 POST my_index/_open 再恢复 index_already_exists_exception 目标索引已存在 先 DELETE my_index 再恢复 6. 快照恢复常见错误排查报错 1：无法连接到 S312345678910111213141516171819202122232425{ &quot;error&quot;: { &quot;root_cause&quot;: [ { &quot;type&quot;: &quot;repository_verification_exception&quot;, &quot;reason&quot;: &quot;[my_s3_repository] path [/] is not accessible on master node&quot; } ], &quot;type&quot;: &quot;repository_verification_exception&quot;, &quot;reason&quot;: &quot;[my_s3_repository] path [/] is not accessible on master node&quot;, &quot;caused_by&quot;: { &quot;type&quot;: &quot;i_o_exception&quot;, &quot;reason&quot;: &quot;Unable to upload object [//tests-sXkmh3q5ThCCIX2VJp609g/master.dat] using a single upload&quot;, &quot;caused_by&quot;: { &quot;type&quot;: &quot;sdk_client_exception&quot;, &quot;reason&quot;: &quot;Failed to connect to service endpoint: &quot;, &quot;caused_by&quot;: { &quot;type&quot;: &quot;socket_timeout_exception&quot;, &quot;reason&quot;: &quot;Connect timed out&quot; } } } }, &quot;status&quot;: 500} 解决方案： 在 keystore 中添加 AWS 凭证：12sudo ./bin/easysearch-keystore add s3.client.default.access_keysudo ./bin/easysearch-keystore add s3.client.default.secret_key 如果运行在 EC2 上，确保实例挂载了 IAM Role。 123456789101112131415161718192021{ &quot;error&quot;: { &quot;root_cause&quot;: [ { &quot;type&quot;: &quot;repository_verification_exception&quot;, &quot;reason&quot;: &quot;[my_s3_repositor1] path is not accessible on master node&quot; } ], &quot;type&quot;: &quot;repository_verification_exception&quot;, &quot;reason&quot;: &quot;[my_s3_repositor1] path is not accessible on master node&quot;, &quot;caused_by&quot;: { &quot;type&quot;: &quot;i_o_exception&quot;, &quot;reason&quot;: &quot;Unable to upload object [tests-sUUzs-mTSZeYw1qk372DkQ/master.dat] using a single upload&quot;, &quot;caused_by&quot;: { &quot;type&quot;: &quot;sdk_client_exception&quot;, &quot;reason&quot;: &quot;The requested metadata is not found at http://169.254.169.254/latest/meta-data/iam/security-credentials/&quot; } } }, &quot;status&quot;: 500} 报错 2：索引已存在，无法恢复12345678910111213{ &quot;error&quot;: { &quot;root_cause&quot;: [ { &quot;type&quot;: &quot;snapshot_restore_exception&quot;, &quot;reason&quot;: &quot;[my_s3_repository:1/9gIDCgSySwKzQqEYvaGM_w] cannot restore index [my_index] because an open index with same name already exists in the cluster. Either close or delete the existing index or restore the index under a different name by providing a rename pattern and replacement name&quot; } ], &quot;type&quot;: &quot;snapshot_restore_exception&quot;, &quot;reason&quot;: &quot;[my_s3_repository:1/9gIDCgSySwKzQqEYvaGM_w] cannot restore index [my_index] because an open index with same name already exists in the cluster. Either close or delete the existing index or restore the index under a different name by providing a rename pattern and replacement name&quot; }, &quot;status&quot;: 500} 解决方案： 删除现有索引后恢复：1DELETE /my_index 关闭索引后恢复：1POST /my_index/_close 恢复为新的索引名称：123456POST _snapshot/my_s3_repository/1/_restore{ &quot;indices&quot;: &quot;my_index&quot;, &quot;rename_pattern&quot;: &quot;my_index&quot;, &quot;rename_replacement&quot;: &quot;restored_my_index&quot;} 报错 3：权限错误12345678910111213{ &quot;error&quot;: { &quot;root_cause&quot;: [ { &quot;type&quot;: &quot;security_exception&quot;, &quot;reason&quot;: &quot;no permissions for [] and User [name=admin, external_roles=[admin]]&quot; } ], &quot;type&quot;: &quot;security_exception&quot;, &quot;reason&quot;: &quot;no permissions for [] and User [name=admin, external_roles=[admin]]&quot; }, &quot;status&quot;: 403} 解决方案： 确保用户有 manage_snapshots 角色权限。 排除 .security 索引或全局状态，否则无法恢复。 123456POST _snapshot/my_s3_repositor1/snapshot_002/_restore{ &quot;indices&quot;: &quot;-.security&quot;, &quot;ignore_unavailable&quot;: true, &quot;include_global_state&quot;: false} 📌 存储库（Repository）管理 API存储库用于存储快照，Elasticsearch 支持 AWS S3、GCS、本地等存储。 1️⃣ 查看所有已注册的存储库1GET _snapshot/_all 示例返回： 123456789{ &quot;my_s3_repository&quot;: { &quot;type&quot;: &quot;s3&quot;, &quot;settings&quot;: { &quot;bucket&quot;: &quot;es-snapshots-bucket&quot;, &quot;region&quot;: &quot;us-east-1&quot; } }} 2️⃣ 查看特定存储库信息1GET _snapshot/my_s3_repository 3️⃣ 创建存储库（AWS S3 示例）1234567PUT _snapshot/my_s3_repository{ &quot;type&quot;: &quot;s3&quot;, &quot;settings&quot;: { &quot;bucket&quot;: &quot;es-snapshots-bucket&quot;, }} 4️⃣ 删除存储库1DELETE _snapshot/my_s3_repository ⚠ 删除存储库不会删除快照，需要手动删除快照！ 📌 快照（Snapshot）管理 API快照用于备份和恢复索引数据。 1️⃣ 创建快照备份特定索引 12345PUT _snapshot/my_s3_repository/snapshot_001{ &quot;indices&quot;: &quot;my_index&quot;, &quot;include_global_state&quot;: false} 备份所有索引 1234PUT _snapshot/my_s3_repository/snapshot_002{ &quot;include_global_state&quot;: true} 2️⃣ 查看所有快照1GET _snapshot/my_s3_repository/_all 3️⃣ 查看特定快照信息1GET _snapshot/my_s3_repository/snapshot_001 4️⃣ 删除快照1DELETE _snapshot/my_s3_repository/snapshot_001 📌 快照恢复（Restore）API恢复已备份的索引。 1️⃣ 还原单个索引123456POST _snapshot/my_s3_repository/snapshot_001/_restore{ &quot;indices&quot;: &quot;my_index&quot;, &quot;ignore_unavailable&quot;: true, &quot;include_global_state&quot;: false} 2️⃣ 还原索引并重命名123456POST _snapshot/my_s3_repository/snapshot_001/_restore{ &quot;indices&quot;: &quot;my_index&quot;, &quot;rename_pattern&quot;: &quot;my_index&quot;, &quot;rename_replacement&quot;: &quot;restored_my_index&quot;} 3️⃣ 还原所有索引1POST _snapshot/my_s3_repository/snapshot_002/_restore 📌 快照状态 API查询快照的执行状态。 1️⃣ 查看当前快照任务1GET _snapshot/_status 2️⃣ 查看特定快照状态1GET _snapshot/my_s3_repository/snapshot_001/_status API 用途 GET _snapshot/_all 查看所有存储库 GET _snapshot/my_s3_repository 查看特定存储库 PUT _snapshot/my_s3_repository 创建存储库 DELETE _snapshot/my_s3_repository 删除存储库 PUT _snapshot/my_s3_repository/snapshot_001 创建快照 GET _snapshot/my_s3_repository/_all 查看所有快照 GET _snapshot/my_s3_repository/snapshot_001 查看快照详情 DELETE _snapshot/my_s3_repository/snapshot_001 删除快照 POST _snapshot/my_s3_repository/snapshot_001/_restore 还原快照 GET _snapshot/_status 查看快照状态 🚀 通过本文，你可以高效地使用 AWS S3 进行 Easysearch 快照备份和恢复，并排查可能的错误，确保集群数据安全无忧！","link":"/posts/eab170f2/"},{"title":"Docker-Compose部署 EasySearch 异常问题排查","text":"近期将原本运行在 macOS 上的 EasySearch、Console 和 Coco-server 等服务迁移至群晖 NAS 平台。在迁移过程中遇到了 EasySearch 容器无法正常启动或运行中意外终止的问题。本文记录了这些问题的具体表现及解决方案，旨在为后续类似部署提供参考。 基础部署配置以下是官方推荐的 docker-compose 配置文件：地址如下： https://docs.infinilabs.com/easysearch/main/docs/getting-started/install/docker-compose/ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273version: &quot;3&quot;services: easysearch-node1: user: &quot;602:602&quot; image: infinilabs/easysearch:1.11.1-2000 container_name: easysearch-node1 hostname: easysearch-node1 environment: - &quot;ES_JAVA_OPTS=-Xms1g -Xmx1g&quot; ulimits: memlock: soft: -1 hard: -1 nofile: soft: 65536 hard: 65536 volumes: - $PWD/ezs1/config:/app/easysearch/config - $PWD/ezs1/data:/app/easysearch/data - $PWD/ezs1/logs:/app/easysearch/logs ports: - 9201:9200 - 9301:9300 networks: - esnet easysearch-node2: user: &quot;602:602&quot; image: infinilabs/easysearch:1.11.1-2000 container_name: easysearch-node2 hostname: easysearch-node2 environment: - &quot;ES_JAVA_OPTS=-Xms1g -Xmx1g&quot; ulimits: memlock: soft: -1 hard: -1 nofile: soft: 65536 hard: 65536 volumes: - $PWD/ezs2/config:/app/easysearch/config - $PWD/ezs2/data:/app/easysearch/data - $PWD/ezs2/logs:/app/easysearch/logs ports: - 9202:9200 - 9302:9300 networks: - esnet console: image: infinilabs/console:1.29.1-2000 container_name: console hostname: console volumes: - $PWD/console/data:/data - $PWD/console/log:/log networks: - esnet ports: - 9000:9000 links: - easysearch-node1:es1 - easysearch-node2:es2 environment: - TZ=Asia/Shanghainetworks: esnet: driver: bridge ipam: config: - subnet: 172.24.0.0/16 常见问题及解决方案问题 1：vm.max_map_count 参数不足错误提示： 1[1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 问题分析Lucene 搜索引擎在运行过程中需要创建大量内存映射文件(mmap)，而 Linux 系统默认的虚拟内存区域数量限制(65530)无法满足需求。 解决方案临时设置（重启失效）： 1sudo sysctl -w vm.max_map_count=262144 永久生效配置： 编辑 /etc/sysctl.conf 文件 添加配置项：1vm.max_map_count=262144 应用配置：1sudo sysctl -p 问题 2：Java 堆内存溢出错误信息： 1java.lang.OutOfMemoryError: Java heap space 问题分析容器化环境中，JVM 默认的内存分配策略往往无法正确识别可用的系统资源，导致： 堆内存分配不足（默认通常仅 512MB-1GB） 内存使用超出容器限制后被系统强制终止 解决方案修改 docker-compose 配置，明确指定 JVM 堆内存： 12environment: - ES_JAVA_OPTS=-Xms2g -Xmx2g 配置建议： 堆内存设置为物理内存的 50%以内 最大堆内存不超过 32GB（避免指针压缩失效） 初始堆(-Xms)和最大堆(-Xmx)设为相同值，避免运行时动态调整 这次是部署过程中踩的两个坑，写出来让大家避避雷。","link":"/posts/719d7034/"},{"title":"Easysearch 服务昨天还好好的，为什么今天突然访问不了了？","text":"在使用 Easyearch 搭建本地或云端搜索服务时，难免会遇到服务偶发性或持续性无法访问的问题。本文将从服务状态、端口监听、网络配置、安全组等五个维度，系统梳理排查思路，帮助大家快速定位并解决访问失败的原因。 🚢 一、Docker 部署场景下的排查方法如果你是通过官方的 Docker Compose 部署 EasySearch，一般不会出现太大问题。但如果你像我一样在群晖或 NAS 上做过自定义配置，以下通用排查方法可以帮助你快速定位问题： 示例 Docker Compose 配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273version: &quot;3&quot;services: easysearch-node1: user: &quot;602:602&quot; image: infinilabs/easysearch:1.11.1-2000 container_name: easysearch-node1 hostname: easysearch-node1 environment: - &quot;ES_JAVA_OPTS=-Xms1g -Xmx1g&quot; ulimits: memlock: soft: -1 hard: -1 nofile: soft: 65536 hard: 65536 volumes: - $PWD/ezs1/config:/app/easysearch/config - $PWD/ezs1/data:/app/easysearch/data - $PWD/ezs1/logs:/app/easysearch/logs ports: - 9201:9200 - 9301:9300 networks: - esnet easysearch-node2: user: &quot;602:602&quot; image: infinilabs/easysearch:1.11.1-2000 container_name: easysearch-node2 hostname: easysearch-node2 environment: - &quot;ES_JAVA_OPTS=-Xms1g -Xmx1g&quot; ulimits: memlock: soft: -1 hard: -1 nofile: soft: 65536 hard: 65536 volumes: - $PWD/ezs2/config:/app/easysearch/config - $PWD/ezs2/data:/app/easysearch/data - $PWD/ezs2/logs:/app/easysearch/logs ports: - 9202:9200 - 9302:9300 networks: - esnet console: image: infinilabs/console:1.29.1-2000 container_name: console hostname: console volumes: - $PWD/console/data:/data - $PWD/console/log:/log networks: - esnet ports: - 9000:9000 links: - easysearch-node1:es1 - easysearch-node2:es2 environment: - TZ=Asia/Shanghainetworks: esnet: driver: bridge ipam: config: - subnet: 172.24.0.0/16 1️⃣ 容器是否正常运行？1docker ps -a | grep easysearch 若容器状态为 Exited，说明启动失败。请查看容器日志进一步排查： 1docker logs &lt;容器名&gt; 如果你看到了如下错误信息，而你使用的是自签证书，可以暂时忽略： 12javax.net.ssl.SSLHandshakeException: Empty client certificate chainjavax.net.ssl.SSLHandshakeException: Received fatal alert: certificate_unknown 2️⃣ 容器是否监听端口？进入容器内部查看： 12docker exec -it &lt;容器名&gt; bashnetstat -tlnp 期望看到监听地址为 0.0.0.0:9200 和 0.0.0.0:9300，说明服务对外暴露成功。例如： 12tcp 0 0 0.0.0.0:9200 0.0.0.0:* LISTEN 7/javatcp 0 0 0.0.0.0:9300 0.0.0.0:* LISTEN 7/java 3️⃣ Docker 端口映射是否配置正确？检查 docker-compose.yml 中 ports 映射是否正确，或者用以下命令查看实际映射情况： 1docker ps 确认是否已将容器内部端口映射到宿主机。 宿主机上也可以通过 netstat 或 ss 命令查看端口监听： 1netstat -tlnp | grep 9200 确保监听地址是 0.0.0.0:9200，而非 127.0.0.1。 -t：显示 TCP 连接 -l：仅显示监听状态（Listening）的端口 -n：以数字方式显示地址和端口（避免 DNS 解析） -p：显示监听端口的程序 PID 和名称 4️⃣ 网络配置是否连通？使用 curl 测试： 1curl http://yourhost:9200 如需远程访问，需确认： 容器监听的是 0.0.0.0 映射端口已开放 网络桥接配置正常 🧩 二、非 Docker 部署场景的排查方法1️⃣ 服务是否启动？1ps aux | grep easysearch 也可查看 nohup.out 或 logs 目录中的日志文件，看是否存在环境变量、路径错误、权限不足等问题。 2️⃣ 是否监听了正确的地址？1netstat -tulnp | grep java EasySearch 默认只监听本地，建议修改配置文件： 123# config/easysearch.ymlnetwork.host: 0.0.0.0http.port: 9200 3️⃣ 防火墙是否放行？确认 Linux 主机的防火墙设置： 12sudo ufw statussudo iptables -L -n 确保目标端口（如 9200、9300）已允许外部访问。 🌐 三、通用排查项（适用于所有部署方式）✅ 云服务器：检查安全组云服务商（如 AWS、阿里云）通常还需配置安全组或防火墙规则，确保目标端口对外开放。 ✅ DNS 设置是否正确使用 dig 和 ping 测试域名解析与连通性： 12dig +short yourdomain.comping yourdomain.com 可用 traceroute 进一步分析路径：(我在 MacOS 下测试的) 123456sudo traceroute -P TCP -p 9200 192.168.X.Xtraceroute to 192.168.X.X (192.168.X.X), 64 hops max, 40 byte packets 1 192.168.X.X (192.168.X.X) 3.756 ms 3.208 ms 3.142 ms ✅ 总结：排查 EasySearch 的四步法12341. 服务是否启动？2. 端口是否监听？3. 网络是否打通？4. 安全组是否放行？ 无论是本地部署还是云端部署，掌握上述排查方法，你就能迅速定位并解决 EasySearch 无法访问的问题。如果你觉得有帮助，也欢迎你将本文加入收藏夹，或转发给其他使用 EasySearch 的小伙伴 👇","link":"/posts/8d9611a5/"},{"title":"Easysearch 基础运维扫盲指南：从 HTTP 到 HTTPS、认证与安全访问全解析","text":"众所周知，原生 Elasticsearch 默认开启的是 HTTP 明文接口，并且不开启认证或加密。如果要启用 TLS/SSL 加密和账号认证，通常需要额外配置一系列安全模块。 而在 EasySearch 中，官方通过 initialize.sh 初始化脚本，大大简化了这些安全配置，启动时就能自动生成证书并开启密码保护。不过在一些测试或开发环境中，我们可能希望临时使用 HTTP + 无密码 的简化方式来调试。 本文将从配置文件入手，逐步说明如何启用或关闭认证、如何从 HTTPS 切换回 HTTP，以及如何开放外网访问。 🛠 初始化启动信息与默认密码当你执行 bin/initialize.sh 后，终端和 initialize.log 会输出初始化信息，其中包括自动生成的管理员账号密码，例如： 1curl -ku admin:160824cab0b02193226e https://localhost:9200 默认情况下，服务已启用 HTTPS 与密码认证。 ⚙ 修改配置文件：easysearch.yml配置文件位于： 1config/easysearch.yml 可以在此文件中自定义集群名称： 1cluster.name: my-application 修改前访问效果如下： 1curl -ku admin:160824cab0b02193226e http://localhost:9200 1&quot;cluster_name&quot;: &quot;easysearch&quot;, 修改后再次访问： 1curl -ku admin:160824cab0b02193226e http://localhost:9200 1&quot;cluster_name&quot;: &quot;my-application&quot;, 🌐 开放外网访问（单节点部署）如果你希望让其他设备或公网访问 EasySearch，可以添加以下参数： 123network.host: 0.0.0.0http.port: 9200discovery.type: single-node 此外，为了提高对 Elasticsearch 客户端的兼容性，建议添加： 1elasticsearch.api_compatibility: true 🔒 控制 HTTPS 与密码认证EasySearch 的安全配置由以下两个核心参数控制： 参数 作用 security.enabled 是否启用认证（账号密码）和 HTTPS 模块 security.ssl.http.enabled 是否启用 HTTPS（SSL/TLS 加密） 🔁 配置组合含义如下： security.enabled security.ssl.http.enabled 效果 true true 默认配置，启用认证 + HTTPS（推荐） true false 仅认证，无加密，使用明文 HTTP false true 无认证，HTTPS 加密，仅适合特殊用途 false false 最开放，HTTP + 无密码，不推荐生产使用 你可以根据实际需求选择是否打开加密或认证，适配测试与生产环境。 📸 示例：启用 HTTP 且开启认证如果你修改配置为 security.ssl.http.enabled: false，即可使用 HTTP，但仍要求输入用户名密码进行访问： 12security.enabled: truesecurity.ssl.http.enabled: false 访问效果如下图所示： ✅ 小结 场景 推荐配置 本地测试（不加密、无密码） security.enabled: false + security.ssl.http.enabled: false 本地测试（仅加认证） security.enabled: true + security.ssl.http.enabled: false 安全访问（默认） security.enabled: true + security.ssl.http.enabled: true HTTPS 不认证 security.enabled: false + security.ssl.http.enabled: true EasySearch 提供了灵活的配置方式，适合不同场景自由切换。对于开发者来说，理解这两个参数的作用，是快速上手运维的第一步。 提到认证,我们再看看如何修改密码,由于 Easysearch 默认新建了一个 admin 的用户,并且存在 config/security/user.yml 下 123456789101112131415161718---# This is the internal user database create by initialize# The hash value is a bcrypt hash and can be generated with hash_password.sh_meta: type: &quot;user&quot; config_version: 2# Define your internal users here## Demo usersadmin: hash: &quot;$2y$12$rmNDJxpQdRDb3F1dqk.uweSZqH3VAqeEpkP298vJ6QS99K80kbRoO&quot; reserved: true external_roles: - &quot;admin&quot; description: &quot;Admin user&quot; 这个我们也可以使用 postman 开调用 API.http://localhost:9200/\\_security/account 12345678910111213import requestsurl = &quot;http://192.168.5.8:9200&quot;payload = {}headers = { 'Authorization': 'Basic YWRtaW46MTYwODI0Y2FiMGIwMjE5MzIyNmU='}response = requests.request(&quot;GET&quot;, url, headers=headers, data=payload)print(response.text) 新建用户 查看接口:https://localhost:9200/\\_security/user 不过 yml 文件还是只有 admin,用 api 查看 使用新用户测试可以访问: mysql -P 3306 -u admin -p -h mysqlsource.crtihcoeqzab.us-west-2.rds.amazonaws.com &lt; people.sql mysql -P 3306 -u admin -p -h mysqlsource.crtihcoeqzab.us-west-2.rds.amazonaws.com people psql -h cloudacademylabs-targetcluster-0zdokkxbiyyh.cluster-ro-crtihcoeqzab.us-west-2.rds.amazonaws.com -U postgres -p 5432 people","link":"/posts/1f7436df/"},{"title":"MySQL数据实时接入Easysearch，零代码迁移全流程","text":"随着业务对数据搜索与分析能力的要求不断提高，越来越多的团队开始将关系型数据库中的数据迁移至搜索引擎中。本篇文章将分享如何通过AWS DMS，实现 MySQL 数据无缝迁移到EasySearch，并打通实时同步链路的全过程。 注意：AWS DMS 原生仅支持托管的 OpenSearch 和 Elasticsearch，不直接支持 EasySearch。本文将介绍如何通过一些配置技巧，优雅地解决这个问题。 一、准备 MySQL 源数据库1. 创建数据库与数据表首先，我们需要准备好待迁移的 MySQL 数据库。我这里使用的是DBeaver工具，当然你也可以选择更专业的 MySQL Workbench 或 DataGrip。 新建数据库时，选择utf8mb4编码，库名命名为source（后续 DMS 迁移任务中会用到）。 接下来创建数据表并定义字段。图形化工具可以避免手写 DDL，对非 DBA 用户非常友好。 2. 插入测试数据为了验证迁移效果，我们先写几条假数据。 确认数据已成功写入并提交。 二、配置 AWS DMS 迁移1. 创建源端点（MySQL）在 AWS DMS 中，首先需要定义源端点。MySQL 作为数据源，EasySearch 作为目标端。 2. 创建目标端点（EasySearch）我的 EasySearch 部署在公网的 Linux 服务器上。配置目标端点时，有两个重点： 关闭认证与 TLS，将传输协议改为 HTTP 伪装为开源 Elasticsearch，绕过 DMS 的原生认证要求 只需要调整这两个关键参数，即可完成兼容。 3. 创建复制实例迁移任务需要一个复制实例，即 DMS 后台自动启动的迁移代理服务器。 4. 测试连接实例启动后，记得测试源端（MySQL）和目标端（EasySearch）的连通性，确保网络正常。 三、创建迁移任务并启动在控制台新建迁移任务 1. 预检查：开启 MySQL Binlog为了支持 CDC（持续复制），需要提前在 MySQL 开启 binlog，并调整格式为ROW。 2. 创建迁移任务在 DMS 中创建任务，选择持续复制模式，源库填写source，EasySearch 会自动将数据表转为索引。 注意：目标端为 EasySearch 时需要关闭数据验证，否则迁移任务会因兼容性问题失败。 四、验证迁移效果1. 启动任务并查看索引EasySearch 初始化状态下只有默认索引。启动任务后，DMS 自动创建了一个新索引newtable，映射 MySQL 的数据表。 打开索引，可以看到 MySQL 数据已转换为 EasySearch 的文档格式。 2. 模拟实时数据同步因为是 CDC 持续复制模式，我继续向 MySQL 插入新数据，模拟上游系统的实时写入。 EasySearch 这边几乎实时就收到了新数据，验证了迁移链路的连贯性。 五、总结本次实战中，借助 AWS DMS，我们实现了从 MySQL 到 EasySearch 的实时数据同步，具备以下优势： 无需改造业务系统，兼容现有 MySQL 数据结构 支持 CDC，保证数据的实时同步与一致性 EasySearch 原生接入，数据即迁即用 虽然 AWS DMS 默认并不支持 EasySearch，但通过合理配置与兼容策略，我们依然实现了两者的高效打通。 如果你的业务需要将 MySQL 数据实时同步到 EasySearch，这套方案值得一试。","link":"/posts/7a296932/"},{"title":"从认证到透传：用 Nginx 为 Easysearch 构建一体化认证网关","text":"在构建本地或云端搜索引擎系统时，EasySearch 凭借其轻量、高性能、易部署等优势，逐渐成为众多开发者和技术爱好者的首选。但在实际部署过程中，如何借助 Nginx 为 EasySearch 提供高效、稳定且安全的访问入口，尤其是在身份认证方面，仍然是一个关键技术环节。 本教程将围绕 Basic Auth 认证机制展开，系统讲解如何通过 Nginx 实现安全防护、认证信息透传等常见配置场景，帮助你在多种实际部署环境中快速搭建可靠的访问控制机制。 无论你是在搭建家庭 NAS 服务，还是在企业环境中集成搜索引擎系统，本教程都能为你提供一套可落地、可复用的 Nginx 安全认证解决方案。 下面是我的 Nginx 配置文件示例。我们通过 Docker 启动 Nginx 容器，并将本地编写好的配置文件挂载到容器中，从而实现自定义的反向代理和认证逻辑： 12345docker run -d \\ --name my-nginx \\ -p 80:80 \\ -v $(pwd)/default.conf:/etc/nginx/conf.d/default.conf \\ nginx default.conf配置如下: 123456789101112131415161718192021222324252627282930313233343536373839404142server { listen 80; server_name localhost; # 根路径可选配置，如果你要一个欢迎页 location / { return 200 'Nginx is running.\\n'; add_header Content-Type text/plain; } # 反向代理 EasySearch location /es/ { proxy_pass https://backend:9200/; # 修正请求头 proxy_http_version 1.1; # proxy_pass_request_headers on; ÷ proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; # 如果需要保活连接 proxy_set_header Connection &quot;&quot;; # 可选：允许跨域访问（用于前端 AJAX 调试） add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods 'GET, POST, OPTIONS'; add_header Access-Control-Allow-Headers 'Authorization,Content-Type'; # proxy_set_header Authorization &quot;Basic YWRtaW46MTIzNDU2&quot;; # 清理路径前缀 `/es/` rewrite ^/es/(.*)$ /$1 break; } # 可选：静态资源支持 # location /static/ { # root /usr/share/nginx/html; # }} 🌐 配置整体结构123server { listen 80; server_name localhost; 监听端口：监听本地 80 端口（HTTP 默认端口） 服务名称：用于匹配请求的 Host，这里是 localhost 🎉 欢迎页（根路径 /）1234location / { return 200 'Nginx is running.\\n'; add_header Content-Type text/plain;} 请求 / 会返回纯文本响应 &quot;Nginx is running.&quot;，可用于验证 Nginx 是否启动正常。 add_header Content-Type text/plain：指定响应内容为纯文本。 🔁 /es/ 代理 EasySearch 后端服务 🚚 请求头处理123456proxy_http_version 1.1;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_set_header X-Forwarded-Proto $scheme;proxy_set_header Connection &quot;&quot;; proxy_http_version 1.1：确保代理使用 HTTP/1.1，支持长连接。 Host：保留原始请求的主机名。 X-Real-IP / X-Forwarded-For：传递客户端真实 IP。 X-Forwarded-Proto：传递原始协议（http / https）。 Connection &quot;&quot;：用于避免默认的 keep-alive 设置引起错误（推荐保留）。 🔐 可选的认证头（注释中）1# proxy_set_header Authorization &quot;Basic YWRtaW46MTIzNDU2&quot;; 可选开启，用于将认证信息转发到后端。 上面的字符串是 admin:123456 的 base64 编码。可以根据需要开启。 🌍 CORS 设置（跨域）123add_header Access-Control-Allow-Origin *;add_header Access-Control-Allow-Methods 'GET, POST, OPTIONS';add_header Access-Control-Allow-Headers 'Authorization,Content-Type'; 允许任意源访问（前端页面可以跨域请求 /es/）。 支持的方法：GET、POST、OPTIONS。 允许传递的请求头：Authorization 和 Content-Type。 ✅ 适用于 AJAX 调试、前后端分离等场景。 🔧 URL 重写1rewrite ^/es/(.*)$ /$1 break; 移除 /es/ 前缀，转发给后端。例如：用户请求 /es/_cat/indices 实际转发到 /cat/indices。 break 表示在当前 location 中中止后续重写检查。 📦 可选静态资源（被注释掉）123# location /static/ {# root /usr/share/nginx/html;# } 若开启，可以直接通过 /static/xxx.js 访问 Nginx 本地 /usr/share/nginx/html/static/xxx.js 文件。 🔁 如果你想保留 /es/ 前缀，则删除 rewrite 行。 在启动服务后，当我们通过浏览器访问 Nginx 时，页面会弹出身份验证窗口。需要注意的是，这里的认证提示实际上来自后端的 EasySearch 服务，而非 Nginx 本身，说明请求中的认证信息未在 Nginx 层被处理或透传，因此由 EasySearch 发起了再次认证的要求。 在输入正确的用户名和密码后，我们可以看到 Nginx 成功代理请求，并返回了来自 EasySearch 的 API 响应，说明认证流程已顺利通过，后端服务正常可用。 如果希望由 Nginx 代为完成 EasySearch 的身份验证，也就是实现自动登录的效果，可以在配置文件中添加如下指令，将认证信息通过 HTTP 头部传递给后端： 1proxy_set_header Authorization &quot;Basic YWRtaW46YWRtaW4=&quot;; 其中，YWRtaW46YWRtaW4xMjM= 是使用 Base64 编码后的 用户名:密码 字符串（例如 admin:admin）。Nginx 在转发请求时会自动携带该 Header，从而实现对 EasySearch 的自动认证。 需要注意的是，Nginx 的配置文件修改后不会自动生效。为了确保配置被正确加载，需在每次更改配置文件后重启对应的容器服务。这是容器化部署中常见的操作流程，确保新配置被正确应用。 为了更直观地观察请求行为，我们使用了 Postman 进行测试。可以发现，即使在 Postman 中未显式添加任何认证信息，依然能够成功访问 EasySearch 集群。这说明前端未输入认证信息，但由于 Nginx 曾经缓存了认证状态，或配置了自动透传，导致后端依旧接收到了有效的认证头，从而允许了访问。 这种现象虽然在测试中提升了访问便利性，但在实际部署中可能带来安全风险，因此在生产环境中建议对认证流程进行严格控制，确保后端服务不会因为前端认证机制的疏漏而被绕过。 在一些教程中，常会提到一个名为 .htpasswd 的文件，它用于在 Nginx 层实现基本认证。当启用该机制后，Nginx 会对所有访问进行用户身份验证。 此时，是否将认证信息透传给后端服务，则由 proxy_pass_request_headers 参数决定。该参数默认值为 on，也就是说，当认证通过后，客户端发送的 Authorization 头部信息会被 Nginx 一并转发给后端服务。 为了验证这一行为，我编写了一个简单的 Flask 程序作为后端，用于观察请求中的 Header 内容。在真正将请求代理至 EasySearch 之前，我先让 Nginx 将请求反向代理到这个 Flask 应用，从而可以直观地查看是否存在 Authorization 头被透传的情况。 12345678910111213141516171819202122232425262728293031from flask import Flask, request,abortimport base64app = Flask(__name__)@app.route('/')def hello_world(): print(&quot;📥 Headers received from Nginx:&quot;) print(&quot;Host:&quot;, request.headers.get('Host')) print(&quot;X-Real-IP:&quot;, request.headers.get('X-Real-IP')) print(&quot;X-Forwarded-For:&quot;, request.headers.get('X-Forwarded-For')) print(&quot;X-Forwarded-Proto:&quot;, request.headers.get('X-Forwarded-Proto')) print(request.headers) auth_header = request.headers.get('Authorization') print(&quot;Authorization:&quot;, auth_header) if not auth_header or not auth_header.startswith('Basic '): abort(401, description=&quot;Missing or invalid Authorization header&quot;) # 解码 base64 encoded = auth_header.split(' ')[1] decoded = base64.b64decode(encoded).decode('utf-8') # e.g. admin:123456 username, password = decoded.split(':', 1) print(username, password) return 'Hello World!'if __name__ == '__main__': app.run(host='0.0.0.0', port=8000,debug=True) 这个是 flask 的打印的结果. 1234567891011121314151617181920Host: secure-nginx.orb.localX-Real-IP: 192.168.215.1X-Forwarded-For: 192.168.215.1X-Forwarded-Proto: httpHost: secure-nginx.orb.localX-Real-Ip: 192.168.215.1X-Forwarded-For: 192.168.215.1X-Forwarded-Proto: httpAuthorization: Basic YWRtaW46YWRtaW4=Upgrade-Insecure-Requests: 1User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7Accept-Encoding: gzip, deflateAccept-Language: zh-CN,zh-TW;q=0.9,zh;q=0.8Cookie: perf_dv6Tr4n=1Authorization: Basic YWRtaW46YWRtaW4=admin admin192.168.X.X - - [24/Apr/2025 15:55:59] &quot;GET / HTTP/1.1&quot; 200 - 为了解决双重认证的问题，我们启用了认证信息透传的配置(默认的 roxy_pass_request_headers on;)。启用该配置后，用户只需在访问 Nginx 时进行一次手动身份验证。Nginx 会将用户提供的凭证通过 HTTP Header 透传至后端的 EasySearch 服务，从而避免二次认证。当用户直接访问 EasySearch 时，依然需要单独输入凭证进行认证；但通过 Nginx 访问时，只需在前端认证一次即可完成整个请求流程。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667curl -k https://easysearch:9200{&quot;error&quot;:{&quot;root_cause&quot;:[{&quot;type&quot;:&quot;security_exception&quot;,&quot;reason&quot;:&quot;Missing authentication information for REST request [/]&quot;,&quot;header&quot;:{&quot;WWW-Authenticate&quot;:&quot;Basic realm=\\&quot;Security\\&quot; charset=\\&quot;UTF-8\\&quot;&quot;}}],&quot;type&quot;:&quot;security_exception&quot;,&quot;reason&quot;:&quot;Missing authentication information for REST request [/]&quot;,&quot;header&quot;:{&quot;WWW-Authenticate&quot;:&quot;Basic realm=\\&quot;Security\\&quot; charset=\\&quot;UTF-8\\&quot;&quot;}},&quot;status&quot;:401}⏎------- curl -v -u &quot;admin:admin&quot; http://nginxhost/es/* Trying 192.168.5.171:9201...* Connected to 192.168.5.171 (192.168.5.171) port 9201* ALPN: curl offers h2,http/1.1* (304) (OUT), TLS handshake, Client hello (1):* CAfile: /etc/ssl/cert.pem* CApath: none* (304) (IN), TLS handshake, Server hello (2):* (304) (IN), TLS handshake, Unknown (8):* (304) (IN), TLS handshake, Request CERT (13):* (304) (IN), TLS handshake, Certificate (11):* SSL certificate problem: self signed certificate* Closing connectioncurl: (60) SSL certificate problem: self signed certificateMore details here: https://curl.se/docs/sslcerts.htmlcurl failed to verify the legitimacy of the server and therefore could notestablish a secure connection to it. To learn more about this situation andhow to fix it, please visit the web page mentioned above.* Host localhost:80 was resolved.* IPv6: ::1* IPv4: 127.0.0.1* Trying [::1]:80...* Connected to localhost (::1) port 80* Server auth using Basic with user 'admin'&gt; GET /es/ HTTP/1.1&gt; Host: localhost&gt; Authorization: Basic YWRtaW46YWRtaW4=&gt; User-Agent: curl/8.7.1&gt; Accept: */*&gt;* Request completely sent off&lt; HTTP/1.1 200 OK&lt; Server: nginx/1.27.4&lt; Date: Thu, 24 Apr 2025 07:45:10 GMT&lt; Content-Type: application/json; charset=UTF-8&lt; Content-Length: 552&lt; Connection: keep-alive&lt; Access-Control-Allow-Origin: *&lt; Access-Control-Allow-Methods: GET, POST, OPTIONS&lt; Access-Control-Allow-Headers: Authorization,Content-Type&lt;{ &quot;name&quot; : &quot;easysearch-node1&quot;, &quot;cluster_name&quot; : &quot;infinilabs&quot;, &quot;cluster_uuid&quot; : &quot;VcMD__DwSYSUqear8wp-XA&quot;, &quot;version&quot; : { &quot;distribution&quot; : &quot;easysearch&quot;, &quot;number&quot; : &quot;1.11.1&quot;, &quot;distributor&quot; : &quot;INFINI Labs&quot;, &quot;build_hash&quot; : &quot;4d0be0343919fb1a605e3c8284326b7e069eb9bf&quot;, &quot;build_date&quot; : &quot;2025-03-14T09:33:12.182925Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;8.11.4&quot;, &quot;minimum_wire_lucene_version&quot; : &quot;7.7.0&quot;, &quot;minimum_lucene_index_compatibility_version&quot; : &quot;7.7.0&quot; }, &quot;tagline&quot; : &quot;You Know, For Easy Search!&quot;}* Connection #0 to host localhost left intact 本次将 Nginx 的访问认证密码修改为 admin123 后，发现在请求过程中出现了两次身份验证的提示。具体表现为：当用户输入错误的密码时，Nginx 会首先返回一次 401 Unauthorized。由于 Nginx 与 EasySearch 使用了不同的认证信息，Nginx 在将请求头（包括 Authorization 字段）转发至 EasySearch 时，EasySearch 检测到凭据不匹配，也会返回一次 401。由此导致了双重身份认证失败的现象，影响了正常访问流程。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495curl -v -u &quot;admin:admin&quot; http://localhost/es/* Trying 192.168.5.171:9201...* Connected to 192.168.5.171 (192.168.5.171) port 9201* ALPN: curl offers h2,http/1.1* (304) (OUT), TLS handshake, Client hello (1):* CAfile: /etc/ssl/cert.pem* CApath: none* (304) (IN), TLS handshake, Server hello (2):* (304) (IN), TLS handshake, Unknown (8):* (304) (IN), TLS handshake, Request CERT (13):* (304) (IN), TLS handshake, Certificate (11):* SSL certificate problem: self signed certificate* Closing connectioncurl: (60) SSL certificate problem: self signed certificateMore details here: https://curl.se/docs/sslcerts.htmlcurl failed to verify the legitimacy of the server and therefore could notestablish a secure connection to it. To learn more about this situation andhow to fix it, please visit the web page mentioned above.* Host localhost:80 was resolved.* IPv6: ::1* IPv4: 127.0.0.1* Trying [::1]:80...* Connected to localhost (::1) port 80* Server auth using Basic with user 'admin'&gt; GET /es/ HTTP/1.1&gt; Host: localhost&gt; Authorization: Basic YWRtaW46YWRtaW4=&gt; User-Agent: curl/8.7.1&gt; Accept: */*&gt;* Request completely sent off&lt; HTTP/1.1 401 Unauthorized&lt; Server: nginx/1.27.4&lt; Date: Thu, 24 Apr 2025 09:21:09 GMT&lt; Content-Type: text/html&lt; Content-Length: 179&lt; Connection: keep-alive* Authentication problem. Ignoring this.&lt; WWW-Authenticate: Basic realm=&quot;Restricted Area&quot;&lt;&lt;html&gt;&lt;head&gt;&lt;title&gt;401 Authorization Required&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt;&lt;h1&gt;401 Authorization Required&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx/1.27.4&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;* Connection #0 to host localhost left intact❰xu❙~/OrbStack/docker/containers/secure-nginx/etc/nginx❱✔≻ curl -v https://192.168.5.171:9201/ (base) 17:21:09 curl -v -u &quot;admin:admin123&quot; http://localhost/es/* Trying 192.168.5.171:9201...* Connected to 192.168.5.171 (192.168.5.171) port 9201* ALPN: curl offers h2,http/1.1* (304) (OUT), TLS handshake, Client hello (1):* CAfile: /etc/ssl/cert.pem* CApath: none* (304) (IN), TLS handshake, Server hello (2):* (304) (IN), TLS handshake, Unknown (8):* (304) (IN), TLS handshake, Request CERT (13):* (304) (IN), TLS handshake, Certificate (11):* SSL certificate problem: self signed certificate* Closing connectioncurl: (60) SSL certificate problem: self signed certificateMore details here: https://curl.se/docs/sslcerts.htmlcurl failed to verify the legitimacy of the server and therefore could notestablish a secure connection to it. To learn more about this situation andhow to fix it, please visit the web page mentioned above.* Host localhost:80 was resolved.* IPv6: ::1* IPv4: 127.0.0.1* Trying [::1]:80...* Connected to localhost (::1) port 80* Server auth using Basic with user 'admin'&gt; GET /es/ HTTP/1.1&gt; Host: localhost&gt; Authorization: Basic YWRtaW46YWRtaW4xMjM=&gt; User-Agent: curl/8.7.1&gt; Accept: */*&gt;* Request completely sent off&lt; HTTP/1.1 401 Unauthorized&lt; Server: nginx/1.27.4&lt; Date: Thu, 24 Apr 2025 09:21:16 GMT&lt; Content-Type: application/json; charset=UTF-8&lt; Content-Length: 381&lt; Connection: keep-alive* Authentication problem. Ignoring this.&lt; WWW-Authenticate: Basic realm=&quot;Security&quot; charset=&quot;UTF-8&quot;&lt;* Connection #0 to host localhost left intact{&quot;error&quot;:{&quot;root_cause&quot;:[{&quot;type&quot;:&quot;security_exception&quot;,&quot;reason&quot;:&quot;Missing authentication information for REST request [/]&quot;,&quot;header&quot;:{&quot;WWW-Authenticate&quot;:&quot;Basic realm=\\&quot;Security\\&quot; charset=\\&quot;UTF-8\\&quot;&quot;}}],&quot;type&quot;:&quot;security_exception&quot;,&quot;reason&quot;:&quot;Missing authentication information for REST request [/]&quot;,&quot;header&quot;:{&quot;WWW-Authenticate&quot;:&quot;Basic realm=\\&quot;Security\\&quot; charset=\\&quot;UTF-8\\&quot;&quot;}},&quot;status&quot;:401}⏎ 场景编号 Nginx 是否开启认证 EasySearch 是否开启认证 实际认证次数 说明 ① 否 否 0 次 完全开放，任何请求无需验证。 ② 否 ✅ 是 1 次 访问时直接弹出 EasySearch 的认证窗口，用户需输入凭证。 ③ ✅ 是 否 1 次 仅在 Nginx 层验证，验证通过后直接访问后端。 ④ ✅ 是 ✅ 是 2 次（默认） Nginx 和 EasySearch 各自认证，用户需连续输入两次密码。 ⑤ ✅ 是 ✅ 是 1 次（透传,proxy_pass_request_headers on;） Nginx 开启认证，并通过 proxy_set_header Authorization 透传给 EasySearch，用户仅需输入一次密码即可完成认证。","link":"/posts/c50511c4/"},{"title":"Easysearch 索引关闭与重开全攻略：open close 操作、批量处理及防误操作配置","text":"在 Easysearch（兼容 Elasticsearch 的搜索引擎）中，索引是存储和查询的基本单元。默认情况下，索引是处于 open 状态的，可以正常写入和搜索。当你暂时不使用某些索引，但又不想删除它们时，可以通过 close 操作来关闭索引，从而释放部分内存资源。 📊 查看索引状态使用以下命令可以查看当前集群中所有索引的状态： 1GET _cat/indices?v 创建一个索引并插入数据： 1234POST abc/_doc{ &quot;a&quot;: 1} 此时你会看到索引 abc 已创建，并处于 open 状态： 默认每个索引有 1 个主分片、1 个副本分片，且为可读写状态。 🔒 关闭索引如果你暂时不需要某个索引，又不希望删除它，可以将其关闭： 1POST abc/_close 返回结果： 123456789{ &quot;acknowledged&quot;: true, &quot;shards_acknowledged&quot;: true, &quot;indices&quot;: { &quot;abc&quot;: { &quot;closed&quot;: true } }} 🚫 关闭后的行为限制关闭索引后，不仅不能写入，连搜索都无法进行。 🔍 搜索已关闭索引（403 错误）1GET abc/_search 返回： 1234567{ &quot;error&quot;: { &quot;type&quot;: &quot;cluster_block_exception&quot;, &quot;reason&quot;: &quot;index [abc] blocked by: [FORBIDDEN/4/index closed];&quot; }, &quot;status&quot;: 403} 📝 写入已关闭索引（400 错误）1234POST abc/_doc{ &quot;a&quot;: 2} 返回： 12345678{ &quot;error&quot;: { &quot;type&quot;: &quot;index_closed_exception&quot;, &quot;reason&quot;: &quot;closed&quot;, &quot;index&quot;: &quot;abc&quot; }, &quot;status&quot;: 400} ✳️ 批量关闭索引（支持通配符）1POST ab*,test/_close 返回结果： 123456789{ &quot;acknowledged&quot;: true, &quot;shards_acknowledged&quot;: true, &quot;indices&quot;: { &quot;test&quot;: { &quot;closed&quot;: true }, &quot;abd&quot;: { &quot;closed&quot;: true }, &quot;abc&quot;: { &quot;closed&quot;: true } }} 确认索引状态： 1GET _cat/indices?v 🔓 重新打开索引当需要重新启用这些索引时： 1POST */_open 返回： 1234{ &quot;acknowledged&quot;: true, &quot;shards_acknowledged&quot;: true} ⚙️ 禁止关闭索引的集群配置有些场景中（如运营平台防止误操作），管理员可能会禁止索引关闭操作。设置如下： 123456PUT _cluster/settings{ &quot;persistent&quot;: { &quot;cluster.indices.close.enable&quot;: false }} 返回结果表示设置已生效： 12345678910111213{ &quot;acknowledged&quot;: true, &quot;persistent&quot;: { &quot;cluster&quot;: { &quot;indices&quot;: { &quot;close&quot;: { &quot;enable&quot;: &quot;false&quot; } } } }, &quot;transient&quot;: {}} 🧯 禁止后关闭索引会报错再次尝试关闭索引时，将返回如下错误信息： 12345678910111213{ &quot;error&quot;: { &quot;root_cause&quot;: [ { &quot;type&quot;: &quot;illegal_state_exception&quot;, &quot;reason&quot;: &quot;closing indices is disabled - set [cluster.indices.close.enable: true] to enable it. NOTE: closed indices still consume a significant amount of diskspace&quot; } ], &quot;type&quot;: &quot;illegal_state_exception&quot;, &quot;reason&quot;: &quot;closing indices is disabled - set [cluster.indices.close.enable: true] to enable it. NOTE: closed indices still consume a significant amount of diskspace&quot; }, &quot;status&quot;: 500} 🔍 如何确认关闭被禁用？执行： 1GET _cluster/settings 结果会包含： 1234567891011121314151617181920212223{ &quot;persistent&quot;: { &quot;cluster&quot;: { &quot;indices&quot;: { &quot;close&quot;: { &quot;enable&quot;: &quot;false&quot; } } }, &quot;index_state_management&quot;: { &quot;template_migration&quot;: { &quot;control&quot;: &quot;-1&quot; } }, &quot;rollup&quot;: { &quot;search&quot;: { &quot;enabled&quot;: &quot;true&quot; }, &quot;hours_before&quot;: &quot;24&quot; } }, &quot;transient&quot;: {}} ✅ 总结 操作 是否支持 条件 POST /&lt;index&gt;/_close ✅ 默认支持 除非设置 cluster.indices.close.enable: false POST /&lt;index&gt;/_open ✅ 总是支持 无需额外开启 POST ab*/_close ✅ 支持批量关闭 同上 查看关闭限制配置 GET _cluster/settings?include_defaults=true 关闭索引适用于资源控制、调试排查等场景，但要注意：关闭索引仍会占用磁盘空间，不会释放存储，仅仅是节省内存和 CPU 资源。","link":"/posts/af48f3e/"},{"title":"Easysearch 实战指南：修改索引主分片的三种方式（split  shrink  reindex","text":"在 Easysearch（兼容 Elasticsearch）的架构中，索引的主分片数（index.number_of_shards）一旦创建就无法直接修改。这给实际使用带来挑战： 设得太少，查询/写入瓶颈出现； 设得太多，资源浪费、集群不稳； 想变更结构，却发现配置是“写死”的。 本文将带你深入了解三种常见但本质不同的索引重构方式：split、shrink、reindex，教你如何选择合适方案、安全操作，并解释为什么split + shrink 无法取代 reindex。 📌 一张图概览三种方式 方法 是否重建索引 可否原名使用 改分片数限制 是否保留数据 是否改结构（mapping/settings） 常见用途 split ✅ 新建索引 ❌ 不支持 只能 × 倍数（如 1→2→4） ✅ 是 ❌ 否 提升写入并发/读性能 shrink ✅ 新建索引 ❌ 不支持 只能 ÷ 因数（如 4→2→1） ✅ 是 ❌ 否 合并历史数据分片 reindex ✅ 新建索引 ✅ 支持（先删） 任意 ✅ 是 ✅ 支持 自定义结构/分片/升级 🔧 一、split：将分片数量倍增（如 1 → 2 → 4） 适用于： 提升并发能力、增加查询/写入并行度。 ✅ 条件要求： 原始索引必须设置 index.blocks.write: true（只读）；主要是防止写入继续增长。 新分片数必须是原主分片的 倍数； 不能使用原名，目标索引必须另起新名。 🛠 操作示例：1234567891011121314151617181920212223# 设置只读PUT /abc/_settings{ &quot;settings&quot;: { &quot;index.blocks.write&quot;: true }}如果不设置为只读的话，就报错：```json{ &quot;error&quot;: { &quot;root_cause&quot;: [ { &quot;type&quot;: &quot;illegal_state_exception&quot;, &quot;reason&quot;: &quot;index abc must be read-only to resize index. use \\&quot;index.blocks.write=true\\&quot;&quot; } ], &quot;type&quot;: &quot;illegal_state_exception&quot;, &quot;reason&quot;: &quot;index abc must be read-only to resize index. use \\&quot;index.blocks.write=true\\&quot;&quot; }, &quot;status&quot;: 500} 拆分索引（1 → 4）123456POST /abc/_split/abc_split_2shards{ &quot;settings&quot;: { &quot;index.number_of_shards&quot;: 2 }} 执行结果如下： 12345{ &quot;acknowledged&quot;: true, &quot;shards_acknowledged&quot;: true, &quot;index&quot;: &quot;abc_split_2shards&quot;} 如果不是倍数也会报错： 12345678910111213{ &quot;error&quot;: { &quot;root_cause&quot;: [ { &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;the number of source shards [13] must be a factor of [25]&quot; } ], &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;the number of source shards [13] must be a factor of [25]&quot; }, &quot;status&quot;: 400} 查看索引的信息： 1GET /abc_split_2shards/_settings?flat_settings=true /_settings：Elasticsearch 提供的 API 端点，用于查看索引设置。?flat_settings=true：查询参数，使返回结果以扁平化的键值对形式展示（而非嵌套结构）。 可以看到目标的索引也是只读的，这在 Easysearch 里是 ElasticSearch 不一样的地方。 123456789101112131415161718{ &quot;abc_split_2shards&quot;: { &quot;settings&quot;: { &quot;index.blocks.write&quot;: &quot;true&quot;, &quot;index.creation_date&quot;: &quot;1750747232004&quot;, &quot;index.number_of_replicas&quot;: &quot;1&quot;, &quot;index.number_of_shards&quot;: &quot;2&quot;, &quot;index.provided_name&quot;: &quot;abc_split_2shards&quot;, &quot;index.resize.source.name&quot;: &quot;abc&quot;, &quot;index.resize.source.uuid&quot;: &quot;3NY_W5B_TzimoEGdoA74cg&quot;, &quot;index.routing.allocation.initial_recovery._id&quot;: null, &quot;index.routing_partition_size&quot;: &quot;1&quot;, &quot;index.uuid&quot;: &quot;e2BQiTRKTlaTS5OE8kmiXw&quot;, &quot;index.version.created&quot;: &quot;1130099&quot;, &quot;index.version.upgraded&quot;: &quot;1130099&quot; } }} 然后使用这个来解锁 write block。 123456PUT /abc_split_2shards/_settings{ &quot;settings&quot;: { &quot;index.blocks.write&quot;: false }} 如果你不想让目标索引变成只读。也可以在_split 的时候加上 “index.blocks.write”: false。 12345678POST /abc_split_2sharxds/_split/qwe{ &quot;settings&quot;: { &quot;index.blocks.write&quot;: false, &quot;index.number_of_shards&quot;: 26 }} 🔧 二、shrink：将分片数量整除压缩（如 8 → 4 → 1） 适用于： 历史归档数据压缩、节省内存、提升查询效率。 ✅ 条件要求： 所有主分片必须集中在同一节点； 原索引必须只读； 新分片数必须是旧分片数的 因数； 同样不能保留原名，需新建索引名。 🛠 操作示例：1234567891011121314151617181920212223242526# 强制所有主分片调度到 node-1PUT /source_index/_settings{ &quot;settings&quot;: { &quot;index.blocks.write&quot;: true, &quot;index.routing.allocation.require._name&quot;: &quot;node-1&quot;, &quot;index.number_of_replicas&quot;: 0 }}如果不是只读同样报错：```json{ &quot;error&quot;: { &quot;root_cause&quot;: [ { &quot;type&quot;: &quot;illegal_state_exception&quot;, &quot;reason&quot;: &quot;index test1 must be read-only to resize index. use \\&quot;index.blocks.write=true\\&quot;&quot; } ], &quot;type&quot;: &quot;illegal_state_exception&quot;, &quot;reason&quot;: &quot;index test1 must be read-only to resize index. use \\&quot;index.blocks.write=true\\&quot;&quot; }, &quot;status&quot;: 500} 合并为一个分片1234567POST /source_index/_shrink/source_index_1{ &quot;settings&quot;: { &quot;index.blocks.write&quot;: false, &quot;index.number_of_shards&quot;: 1 }} 解锁123456PUT /source_index_1/_settings{ &quot;settings&quot;: { &quot;index.blocks.write&quot;: false }} 🔧 三、reindex：拷贝数据 + 新建结构 + 替换旧索引 适用于： 任意修改分片数、字段结构、settings，或实现“看起来改了原索引”的效果。 ✅ 优势： 唯一支持任意分片数修改； 可自由重构 mapping、settings； 可支持保留原名（删除旧索引 + 重新创建）； 可带条件、分页、脚本拷贝数据； 是唯一可模拟“修改原索引分片”的方式。 🛠 操作步骤（保留原名但改变结构）：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# 1. 创建临时索引结构（你想要的新结构）PUT /my_index_v2{ &quot;settings&quot;: { &quot;index.number_of_shards&quot;: 5, &quot;index.number_of_replicas&quot;: 1 }, &quot;mappings&quot;: { &quot;properties&quot;: { &quot;user&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;message&quot;: { &quot;type&quot;: &quot;text&quot; } } }}# 2. 拷贝数据POST /_reindex{ &quot;source&quot;: { &quot;index&quot;: &quot;my_index&quot; }, &quot;dest&quot;: { &quot;index&quot;: &quot;my_index_v2&quot; }}# 3. 删除旧索引（谨慎）DELETE /my_index# 4. 创建同名索引（新结构）PUT /my_index{ &quot;settings&quot;: { &quot;index.number_of_shards&quot;: 3, &quot;index.number_of_replicas&quot;: 1 }, &quot;mappings&quot;: { &quot;properties&quot;: { &quot;user&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;message&quot;: { &quot;type&quot;: &quot;text&quot; } } }}# 5. 再次拷贝数据（回填）POST /_reindex{ &quot;source&quot;: { &quot;index&quot;: &quot;my_index_v2&quot; }, &quot;dest&quot;: { &quot;index&quot;: &quot;my_index&quot; }}6. 查看索引，并且删除目标索引GET _cat/indices/my_index*?v![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/64f99ab7b3ba4b4a8e18d53d4e32fab5.png)最后删除my_index_v2 即可DELETE /my_index_v2 ⚠️ 为什么 shrink + split 不能替代 reindex？很多用户会问：能不能 shrink → split 或 split → shrink 拼接出任意分片数？ 答案是：数学上不成立 + 实战限制太多。 操作 说明 split 只能倍增 例如：1 → 2 → 4 → 8 ✅，但不能变成 3、5、6 ❌ shrink 只能整除 例如：8 → 4 → 2 → 1 ✅，但不能变成 3、5 ❌ 二者组合 受限于倍数 × 因数关系，不是万能变换（大多数目标分片数根本到不了） ✅ 唯一万能方式：reindex可以任意： 调整分片数 ✅ 修改字段结构 ✅ 改 settings ✅ 保留索引名 ✅ ✅ 最佳实践总结 场景 推荐方式 理由 写入并发不足（1 → 4） split 快速、低风险 存储/查询优化（8 → 1） shrink 节省资源、适合归档 修改索引结构、字段、settings reindex 最灵活、唯一支持任意结构 想保留原名但改分片数 reindex（配合 delete/recreate） 只有它能实现 不想中断服务 reindex + alias 切换 alias 实现无缝替换 🚀 附加建议S* split/shrink 一般用于 线上小范围结构调整； reindex 用于 升级、清洗、结构优化等更大粒度的改造； 如果你不想中断服务，强烈建议使用 alias + reindex 做平滑切换； 不建议用 shrink + split 拼接方案，实际运维性差、数学关系苛刻。E","link":"/posts/cba11cdd/"},{"title":"本地 RAG 实战：用 Easysearch + Ollama SDK 半小时搭建检索增强问答系统","text":"✅ 目标：只用两台服务器（或同一台）就跑通 “向量检索 + 本地大模型” 原型✅ 特点：完全离线、依赖极少、部署脚本即文档✅ 适合：快速 PoC、内网合规场景、想深挖 RAG 工作机理的开发者 生成式 AI 聊天固然强大，但当问题依赖本地私有知识时，单靠 LLM 参数内的“世界记忆”往往答非所问。RAG（Retrieval-Augmented Generation） 的思路是： 把文档切片 → 向量化 → 入库 用户提问 → 同样向量化 → 检索 将召回片段拼进 prompt，让大模型“带着材料”再回答 多数教程直接用云端 Embedding+OpenAI GPT-4o，但一些团队因隐私、成本或离线环境无法这样做。本文选用： EasySearch (= OpenSearch + Elastiknn) 做向量存取 Ollama SDK 连接本地 LLM Python + requests + ollama 三个依赖即可 1. 系统架构1234用户问题 ──▶ 嵌入模型 (Ollama) ──▶ EasySearch 向量检索 ──▶ Top-k 片段 ▲ │ │ │ LLM (Ollama Chat) ◀── 拼 Prompt + 生成答案 ◀───────────────┘ 嵌入模型：nomic-embed-text（768 维，多语言通用） 检索引擎：EasySearch 2.x + Elastiknn knn_dense_float_vector 对话模型：deepseek-r1:7b（轻量，好部署；可换 llama3 / qwen） 2. 环境与依赖1234import os, json, requests, warningsfrom ollama import Clientfrom requests.packages.urllib3.exceptions import InsecureRequestWarningwarnings.filterwarnings(&quot;ignore&quot;, category=InsecureRequestWarning) 123456# Python 依赖pip install ollama requests# 拉取模型ollama pull nomic-embed-textollama pull deepseek-r1:7b 3. 代码逐段拆解3.1 全局配置12345678910# ────────────── 配置区 ──────────────ES_URL = os.getenv(&quot;ES_URL&quot;, &quot;https://localhost:9200&quot;)ES_AUTH = (&quot;admin&quot;, &quot;c59a759f31e901e8d279&quot;) # 无认证设为 NoneINDEX = &quot;rag_demo&quot;OLLAMA_HOST = os.getenv(&quot;OLLAMA_URL&quot;, &quot;http://localhost:11434&quot;)EMBED_MODEL = &quot;nomic-embed-text&quot; # 向量模型CHAT_MODEL = &quot;deepseek-r1:7b&quot; # 对话模型TOP_K = 4NUM_CAND = 200 这段代码只是给脚本提前设定一些“连接参数”与“模型选择”，方便后面统一引用。逐行解释如下： 1ES_URL = &quot;https://&lt;es_host&gt;:9200&quot; ES_URL：EasySearch / OpenSearch 集群的完整地址（含协议与端口）。 &lt;es_host&gt; 是占位符，实际部署时要替换成你的 IP 或域名。 如果你的集群没开 TLS，可写成 http://10.0.0.8:9200。 1ES_AUTH = (&quot;elastic&quot;, &quot;password&quot;) # 无认证设为 None ES_AUTH：连接集群的账号密码元组。 脚本里传给 requests 的 auth= 参数，会自动加 Basic Auth 头。 若集群关闭了安全认证或走内网匿名访问，就把它设成 None。 1INDEX = &quot;rag_demo&quot; INDEX：向量索引（或文档索引）的名称。 脚本后面会对该索引做 create / bulk write / search 等操作。 换成别的名字时记得保持一致，例如 &quot;knowledge_base&quot;。 1OLLAMA_HOST = &quot;http://&lt;ollama_host&gt;:11434&quot; OLLAMA_HOST：本地 Ollama 服务的 HTTP 起始地址。 &lt;ollama_host&gt; 也是占位符；若脚本与 Ollama 在同一台机器，可写 http://localhost:11434。 端口 11434 是 Ollama 默认 REST 端口。 1EMBED_MODEL = &quot;nomic-embed-text&quot; EMBED_MODEL：用于生成文本向量（embeddings）的模型名。 在脚本里会调用 client.embeddings(model=EMBED_MODEL, …)。 替换规则：先执行 ollama pull &lt;模型名&gt;，确保本地已下载。 1CHAT_MODEL = &quot;deepseek-r1:7b&quot; CHAT_MODEL：负责最终回答的聊天 / 生成式模型。 脚本会用 client.chat(model=CHAT_MODEL, …) 进行对话。 同理，若想用 llama3:8b-chat、qwen:7b-chat 等，先 ollama pull 再改这里。 3.2 嵌入与对话（Ollama SDK）client 是连接 Ollama 模型服务的客户端，用来发请求。 session 是访问 Elasticsearch 用的请求会话，能提高网络效率。 用指定的嵌入模型（比如 nomic-embed-text）把文本转成向量，用于相似度搜索。 用指定的聊天模型（比如 deepseek-r1:7b）回答问题，返回回复文本。 123456789101112131415161718# ────────────── 初始化 ──────────────client = Client(host=OLLAMA_HOST)session = requests.Session()# ────────────── Ollama 封装 ──────────────def embed(text: str) -&gt; list[float]: &quot;&quot;&quot;返回文本向量 (list[float])&quot;&quot;&quot; resp = client.embeddings(model=EMBED_MODEL, prompt=text) return resp[&quot;embedding&quot;]def chat(prompt: str) -&gt; str: &quot;&quot;&quot;与聊天模型对话（完整回复）&quot;&quot;&quot; resp = client.chat( model=CHAT_MODEL, messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}], # stream=False ) return resp[&quot;message&quot;][&quot;content&quot;] 3.3 建索引（Elastiknn）在构建基于向量的 RAG（Retrieval-Augmented Generation）系统时，我们首先需要在向量数据库中创建一个支持向量检索的索引。本文使用 EasySearch 作为底层存储，向其中注册一个支持近似向量搜索的索引结构。 create_index 函数的作用是通过 RESTful API 创建一个名为 rag_demo 的索引，并定义字段结构如下： content：文本内容字段，类型为 text，可用于全文搜索或作为上下文返回。 vec：向量字段，类型为 knn_dense_float_vector，支持高维向量的快速相似度搜索。配置中使用了 LSH（局部敏感哈希）模型与 cosine 相似度度量，同时设定了近似参数 L 与 k，分别控制候选样本数量和返回结果数。 通过设定 “index.knn”: True，该索引支持使用 k-NN 查询来高效地检索与查询向量最相似的文档。在实际使用中，嵌入模型如 nomic-embed-text 可将输入文本转换为高维向量，存入此索引中，与用户查询语义对齐，实现高效的语义检索能力。 1234567891011121314151617181920212223242526# ---------- ① 创建索引：Elastiknn 映射 ----------def create_index(dim: int): mapping = { &quot;settings&quot;: { &quot;index.knn&quot;: True }, &quot;mappings&quot;: { &quot;properties&quot;: { &quot;content&quot;: { &quot;type&quot;: &quot;text&quot; }, &quot;vec&quot;: { &quot;type&quot;: &quot;knn_dense_float_vector&quot;, &quot;knn&quot;: { &quot;dims&quot;: dim, &quot;model&quot;: &quot;lsh&quot;, # 也可 hnsw / exact &quot;similarity&quot;: &quot;cosine&quot;, &quot;L&quot;: 99, &quot;k&quot;: 1 } } } } } r = session.put(f&quot;{ES_URL}/{INDEX}&quot;, json=mapping, verify=False, auth=ES_AUTH) if r.status_code not in (200, 201): if &quot;resource_already_exists_exception&quot; not in r.text: print(&quot;Create index error:\\n&quot;, r.text) r.raise_for_status() 3.4 写入文档以下是对这段 bulk_upload 函数的简明解释，可用于博客正文或技术文档： 在 RAG 系统中，为了支持高效的语义检索，我们需要将原始文本与其对应的向量一起写入向量索引中。bulk_upload 函数正是完成这一任务的核心组件，它使用 Elasticsearch 的 _bulk 接口实现批量写入，显著提高写入效率。 每条记录包含两个部分： index 元数据，指定目标索引（rag_demo）及文档 _id。 实际文档内容，包括： content：原始文本内容； vec：对应的文本向量，必须使用 {&quot;values&quot;: [...]} 的对象结构。 向量通过 embed(t) 获得，调用本地部署的 Ollama 模型（如 nomic-embed-text）生成。 所有数据最终编码为 JSON，通过 Content-Type: application/x-ndjson 提交到 /_bulk API 接口，实现一次性批量写入。 123456789101112131415# ---------- ② 批量写入：向量必须包 {&quot;values&quot;: …} ----------def bulk_upload(texts: list[str]): bulk = [] for i, t in enumerate(texts): bulk.append({ &quot;index&quot;: { &quot;_index&quot;: INDEX, &quot;_id&quot;: i } }) bulk.append({ &quot;content&quot;: t, &quot;vec&quot;: { &quot;values&quot;: embed(t) } # ★ 关键：对象格式 }) ndjson = &quot;\\n&quot;.join(json.dumps(d, ensure_ascii=False) for d in bulk) + &quot;\\n&quot; r = session.post(f&quot;{ES_URL}/_bulk&quot;, data=ndjson.encode(&quot;utf-8&quot;), headers={&quot;Content-Type&quot;: &quot;application/x-ndjson&quot;}, verify=False, auth=ES_AUTH) r.raise_for_status() 3.5 语义检索这段 search 函数的作用是在 RAG 系统中执行基于向量的语义检索，以下是适合用于博客中的简明解释： RAG 系统的核心是从向量索引中找到与用户问题最相近的语义片段。search 函数即完成了这个过程，它调用 EasySearch 的向量检索接口，返回最相似的文本内容。 文本向量化：通过 embed(question) 把用户输入的问题转换成向量 qvec。 构造检索请求：使用 knn_nearest_neighbors 查询 field: 向量字段名（本例中是 &quot;vec&quot;）； vec: 查询向量，必须写成 { &quot;values&quot;: [...] } 的对象结构； model: 向量近似检索模型（如 &quot;lsh&quot;）； similarity: 相似度度量方式（如 &quot;cosine&quot;）； k: 返回的结果数； candidates: 候选池大小，用于粗排优化检索效果。 发送请求并解析响应：请求通过 Elasticsearch _search 接口提交，若返回不成功，则输出报错信息；成功后提取 _source[&quot;content&quot;] 字段，返回给上层用于回答生成。 ✅ 示例用途：用户提问：“张三是谁”，系统会将该问题向量化，然后在已有文本向量中进行相似度匹配，从而返回如“张三是法律专家……”的片段，作为构建回答的上下文。 这段逻辑是 RAG 模型“Retriever”阶段的核心，让大模型在“有知识”的基础上作答，提升准确性和实用性。 12345678910111213141516171819202122def search(question: str, top_k: int = TOP_K): qvec = embed(question) body = { &quot;size&quot;: top_k, &quot;query&quot;: { &quot;knn_nearest_neighbors&quot;: { # 若 Elastiknn 0.7.x 用 elastiknn_nearest_neighbors &quot;field&quot;: &quot;vec&quot;, &quot;vec&quot;: { &quot;values&quot;: qvec }, &quot;model&quot;: &quot;lsh&quot;, &quot;similarity&quot;: &quot;cosine&quot;, &quot;k&quot;: top_k, &quot;candidates&quot;: 200 } } } r = session.post(f&quot;{ES_URL}/{INDEX}/_search&quot;, json=body, verify=False, auth=ES_AUTH) if not r.ok: print(&quot;== ES response ==&quot;, r.text) r.raise_for_status() return [hit[&quot;_source&quot;][&quot;content&quot;] for hit in r.json()[&quot;hits&quot;][&quot;hits&quot;]] 3.6 主循环123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131# ────────────── CLI 主逻辑 ──────────────def main(): docs = [ # 原来的 3 条 &quot;张三是法律专家，擅长合同法与知识产权。&quot;, &quot;李四在人机交互领域研究多年，尤其关注可用性测试。&quot;, &quot;王五是一名资深软件工程师，对云原生、DevOps 有丰富经验。&quot;, # 新增 100 条 &quot;赵六是一名数据科学家，专注机器学习模型调优。&quot;, &quot;孙七具有十年金融风控经验，熟悉巴塞尔协议。&quot;, &quot;周八是区块链开发者，擅长智能合约安全审计。&quot;, &quot;吴九长期研究边缘计算，在 IoT 网关架构方面有实践。&quot;, &quot;郑十是资深 DBA，精通 MySQL 性能调优与高可用。&quot;, &quot;钱十一擅长云原生安全治理，主导多家企业零信任落地。&quot;, &quot;蒋十二是 GPU 运维专家，对 CUDA 优化有深入研究。&quot;, &quot;沈十三专注深度学习推理加速，维护 TensorRT 插件。&quot;, &quot;韩十四是 FaaS 平台架构师，关注冷启动优化策略。&quot;, &quot;姚十五从事量化交易算法开发，对高频数据处理熟练。&quot;, &quot;邵十六是渗透测试工程师，擅长 Web 漏洞挖掘与利用。&quot;, &quot;汪十七主攻 AIGC 版权合规，为多家媒体机构提供方案。&quot;, &quot;孔十八研究联邦学习，解决数据孤岛隐私问题。&quot;, &quot;曹十九负责 SRE 团队，精通混沌工程与错误预算管理。&quot;, &quot;严二十是网络取证专家，参与多起重大案件分析。&quot;, &quot;华二一研发 AutoML 平台，降低模型训练门槛。&quot;, &quot;雷二二在 5G 边缘网协同计算领域发表多篇论文。&quot;, &quot;凌二三是 DevRel 经理，推动开源社区增长。&quot;, &quot;史二四对 RAG 架构有深入实践，优化检索召回率。&quot;, &quot;阮二五是 WebGPU 先行者，致力提升前端渲染性能。&quot;, &quot;杭二六主导多云成本治理项目，节省 30% 预算。&quot;, &quot;乔二七是一名 AIGC Prompt 工程师，专精多模态指令设计。&quot;, &quot;詹二八擅长大规模 AB 测试框架落地。&quot;, &quot;顾二九是 Serverless 架构布道者，编写多本技术书籍。&quot;, &quot;龚三十关注 DORA 指标，用数据驱动 DevOps 改进。&quot;, &quot;计三一是 API 网关专家，实现百万 QPS 低延迟。&quot;, &quot;蒲三二研究影像分割模型，用于医学辅助诊断。&quot;, &quot;邱三三是 Zig 语言早期贡献者，推行内存安全编码。&quot;, &quot;庄三四长期维护 Kafka 集群，擅长 Topic 规划。&quot;, &quot;宫三五是低代码平台架构师，关注插件生态。&quot;, &quot;蓝三六研究 ICEBERG 表格式，提升湖仓查询效率。&quot;, &quot;聂三七在安全编排 SOAR 产品设计上经验丰富。&quot;, &quot;陆三八主导 SaaS 产品国际化，本地化流程成熟。&quot;, &quot;温三九负责混合云 DR 方案，实现分钟级切换。&quot;, &quot;袁四十是语音合成工程师，优化多 speaker 适配。&quot;, &quot;贾四一深入研究 DDD，帮助团队理清领域边界。&quot;, &quot;伏四二从事实时风控大数据平台架构，处理亿级流量。&quot;, &quot;程四三是 ARM SoC 驱动工程师，对电源管理熟悉。&quot;, &quot;屈四四在 Federated GraphQL 网关治理方面有案例。&quot;, &quot;申四五带队实现 MLOps 自动化发布流程。&quot;, &quot;罗四六研究 VDBMS，支持 PB 级向量检索。&quot;, &quot;祝四七是 HTAP 数据库布道者，优化混合负载。&quot;, &quot;左四八在 IAM 与 RBAC 设计领域深耕。&quot;, &quot;冷四九是链路可观测性工程师，推广 OTEL 标准。&quot;, &quot;包五十投入异构计算调度框架研究。&quot;, &quot;滑五一精通 eBPF 在安全可观测性场景的落地。&quot;, &quot;柴五二研究量子安全算法，对国密迁移方案熟悉。&quot;, &quot;谈五三是内核安全研究员，发现多个 0-day 漏洞。&quot;, &quot;鄢五四主导 SaaS 计费系统重构，支持灵活套餐。&quot;, &quot;邸五五是绿色数据中心规划师，推动 PUE 降到 1.2。&quot;, &quot;候五六在自动驾驶 SLAM 算法具有专利。&quot;, &quot;古五七关注 CDP 架构，连接多源营销数据。&quot;, &quot;丁五八是 FPGA 加速工程师，实现低延迟推理。&quot;, &quot;靳五九研究 WASM 边缘运行时，降低冷启动。&quot;, &quot;柴六十在 DevSecOps 流水线集成方面经验丰富。&quot;, &quot;花六一策划大规模黑客马拉松，促成 500+ 项目孵化。&quot;, &quot;牛六二是边缘 AI 推理框架作者，重视功耗优化。&quot;, &quot;焦六三研究自监督学习在推荐系统的应用。&quot;, &quot;商六四是 Rust Web 开发者，推广零拷贝 JSON 解析。&quot;, &quot;阎六五投入数字孪生城市平台研发。&quot;, &quot;弓六六主攻 OTA 升级安全，覆盖汽车 ECU。&quot;, &quot;怀六七是 MAC 数据平面专家，优化转发性能。&quot;, &quot;宓六八参与多场灾备演练，完善演练脚本体系。&quot;, &quot;郝六九是 PKI 架构师，设计大规模证书生命周期。&quot;, &quot;嵇七十致力于多媒体编解码标准化。&quot;, &quot;邝七一研究 EDA 自动布线算法。&quot;, &quot;桑七二打造 AI 工厂流水线，实现模型快速迭代。&quot;, &quot;桂七三专注 DPU 加速网络虚拟化。&quot;, &quot;麻七四是 Supabase 中国社区维护者，推广 BaaS。&quot;, &quot;仇七五实现企业级 KYC 流程自动化。&quot;, &quot;薄七六研究多模态情感分析，用于客服质检。&quot;, &quot;谯七七是 SD-WAN 产品经理，聚焦海外专线优化。&quot;, &quot;巫七八负责 Kafka to Pulsar 迁移方案。&quot;, &quot;桑七九在 DAG 引擎优化 CPS 流水线。&quot;, &quot;邬八十研究端侧 LLM 蒸馏压缩。&quot;, &quot;臧八一是三维重建算法工程师，服务文博数字化。&quot;, &quot;禾八二专攻 S3 兼容对象存储网关。&quot;, &quot;原八三参与可信执行环境 TEE 方案落地。&quot;, &quot;淦八四是工业互联网安全规划顾问。&quot;, &quot;练八五实现 GPU 多租户 QoS 调度器。&quot;, &quot;禹八六关注跨境合规要求，精通 GDPR。&quot;, &quot;廉八七是 SDN 控制器开源贡献者。&quot;, &quot;亓八八专注高并发长连接网关。&quot;, &quot;宗八九打造零代码机器学习平台。&quot;, &quot;公冶九十研究 PIM 存内计算架构。&quot;, &quot;红九一是 MESH 网络性能调优专家。&quot;, &quot;眭九二致力于 AI 合成音频版权检测。&quot;, &quot;米九三推动碳排放数据平台建设。&quot;, &quot;隗九四是机器人运动规划算法专家。&quot;, &quot;拉九五研究语义分割在遥感图像的应用。&quot;, &quot;蔺九六负责 0-RTT QUIC 协议优化。&quot;, &quot;臧九七专注 BERT 在法律文本的细粒度实体抽取。&quot;, &quot;昝九八是 RPG 游戏 AI NPC 行为树作者。&quot;, &quot;贝九九研究差分隐私在广告数据的实践。&quot;, &quot;施一百主导云原生 API 安全监控平台。&quot;, &quot;伏一零一优化 Kafka Connect 大规模同步。&quot;, &quot;堵一零二研究车辆 V2X 协议栈实现。&quot;, &quot;莎一零三聚焦 A/B 决策平台可视化。&quot;,] dim = len(embed(&quot;维度探测&quot;)) # 动态探测向量维度 create_index(dim) bulk_upload(docs) print(f&quot;[√] 初始化完成（向量维度 {dim}）。开始提问，Ctrl+C 退出。\\n&quot;) try: while True: q = input(&quot;Q: &quot;).strip() if not q: continue passages = search(q) context = &quot;\\n&quot;.join(f&quot;资料{i+1}：{p}&quot; for i, p in enumerate(passages)) prompt = (f&quot;已知资料如下：\\n{context}\\n\\n请根据以上资料回答用户问题：{q}&quot;) print(&quot;\\nA:&quot;, chat(prompt)) print(&quot;引用:&quot;, passages, &quot;\\n&quot;) except KeyboardInterrupt: print(&quot;\\nBye!&quot;)if __name__ == &quot;__main__&quot;: main() 4. 运行效果123Q: 张三擅长什么A: 张三是一名法律专家，专长领域为合同法与知识产权。引用: ['张三是法律专家，擅长合同法与知识产权。'] 结果如下： 完整代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235import os, json, requests, warningsfrom ollama import Clientfrom requests.packages.urllib3.exceptions import InsecureRequestWarningwarnings.filterwarnings(&quot;ignore&quot;, category=InsecureRequestWarning)# ────────────── 配置区 ──────────────ES_URL = os.getenv(&quot;ES_URL&quot;, &quot;https://localhost:9200&quot;)ES_AUTH = (&quot;admin&quot;, &quot;c59a759f31e901e8d279&quot;) # 无认证设为 NoneINDEX = &quot;rag_demo&quot;OLLAMA_HOST = os.getenv(&quot;OLLAMA_URL&quot;, &quot;http://localhost:11434&quot;)EMBED_MODEL = &quot;nomic-embed-text&quot; # 向量模型CHAT_MODEL = &quot;deepseek-r1:7b&quot; # 对话模型TOP_K = 4NUM_CAND = 200 # kNN 先粗召回条数# ────────────── 初始化 ──────────────client = Client(host=OLLAMA_HOST)session = requests.Session()# ────────────── Ollama 封装 ──────────────def embed(text: str) -&gt; list[float]: &quot;&quot;&quot;返回文本向量 (list[float])&quot;&quot;&quot; resp = client.embeddings(model=EMBED_MODEL, prompt=text) return resp[&quot;embedding&quot;]def chat(prompt: str) -&gt; str: &quot;&quot;&quot;与聊天模型对话（完整回复）&quot;&quot;&quot; resp = client.chat( model=CHAT_MODEL, messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}], # stream=False ) return resp[&quot;message&quot;][&quot;content&quot;]# ---------- ① 创建索引：Elastiknn 映射 ----------def create_index(dim: int): mapping = { &quot;settings&quot;: { &quot;index.knn&quot;: True }, &quot;mappings&quot;: { &quot;properties&quot;: { &quot;content&quot;: { &quot;type&quot;: &quot;text&quot; }, &quot;vec&quot;: { &quot;type&quot;: &quot;knn_dense_float_vector&quot;, &quot;knn&quot;: { &quot;dims&quot;: dim, &quot;model&quot;: &quot;lsh&quot;, # 也可 hnsw / exact &quot;similarity&quot;: &quot;cosine&quot;, &quot;L&quot;: 99, &quot;k&quot;: 1 } } } } } r = session.put(f&quot;{ES_URL}/{INDEX}&quot;, json=mapping, verify=False, auth=ES_AUTH) if r.status_code not in (200, 201): if &quot;resource_already_exists_exception&quot; not in r.text: print(&quot;Create index error:\\n&quot;, r.text) r.raise_for_status()# ---------- ② 批量写入：向量必须包 {&quot;values&quot;: …} ----------def bulk_upload(texts: list[str]): bulk = [] for i, t in enumerate(texts): bulk.append({ &quot;index&quot;: { &quot;_index&quot;: INDEX, &quot;_id&quot;: i } }) bulk.append({ &quot;content&quot;: t, &quot;vec&quot;: { &quot;values&quot;: embed(t) } # ★ 关键：对象格式 }) ndjson = &quot;\\n&quot;.join(json.dumps(d, ensure_ascii=False) for d in bulk) + &quot;\\n&quot; r = session.post(f&quot;{ES_URL}/_bulk&quot;, data=ndjson.encode(&quot;utf-8&quot;), headers={&quot;Content-Type&quot;: &quot;application/x-ndjson&quot;}, verify=False, auth=ES_AUTH) r.raise_for_status()# ---------- ③ 查询：knn_nearest_neighbors ----------def search(question: str, top_k: int = TOP_K): qvec = embed(question) body = { &quot;size&quot;: top_k, &quot;query&quot;: { &quot;knn_nearest_neighbors&quot;: { # 若 Elastiknn 0.7.x 用 elastiknn_nearest_neighbors &quot;field&quot;: &quot;vec&quot;, &quot;vec&quot;: { &quot;values&quot;: qvec }, &quot;model&quot;: &quot;lsh&quot;, &quot;similarity&quot;: &quot;cosine&quot;, &quot;k&quot;: top_k, &quot;candidates&quot;: 200 } } } r = session.post(f&quot;{ES_URL}/{INDEX}/_search&quot;, json=body, verify=False, auth=ES_AUTH) if not r.ok: print(&quot;== ES response ==&quot;, r.text) r.raise_for_status() return [hit[&quot;_source&quot;][&quot;content&quot;] for hit in r.json()[&quot;hits&quot;][&quot;hits&quot;]]# ────────────── CLI 主逻辑 ──────────────def main(): docs = [ # 原来的 3 条 &quot;张三是法律专家，擅长合同法与知识产权。&quot;, &quot;李四在人机交互领域研究多年，尤其关注可用性测试。&quot;, &quot;王五是一名资深软件工程师，对云原生、DevOps 有丰富经验。&quot;, # 新增 100 条 &quot;赵六是一名数据科学家，专注机器学习模型调优。&quot;, &quot;孙七具有十年金融风控经验，熟悉巴塞尔协议。&quot;, &quot;周八是区块链开发者，擅长智能合约安全审计。&quot;, &quot;吴九长期研究边缘计算，在 IoT 网关架构方面有实践。&quot;, &quot;郑十是资深 DBA，精通 MySQL 性能调优与高可用。&quot;, &quot;钱十一擅长云原生安全治理，主导多家企业零信任落地。&quot;, &quot;蒋十二是 GPU 运维专家，对 CUDA 优化有深入研究。&quot;, &quot;沈十三专注深度学习推理加速，维护 TensorRT 插件。&quot;, &quot;韩十四是 FaaS 平台架构师，关注冷启动优化策略。&quot;, &quot;姚十五从事量化交易算法开发，对高频数据处理熟练。&quot;, &quot;邵十六是渗透测试工程师，擅长 Web 漏洞挖掘与利用。&quot;, &quot;汪十七主攻 AIGC 版权合规，为多家媒体机构提供方案。&quot;, &quot;孔十八研究联邦学习，解决数据孤岛隐私问题。&quot;, &quot;曹十九负责 SRE 团队，精通混沌工程与错误预算管理。&quot;, &quot;严二十是网络取证专家，参与多起重大案件分析。&quot;, &quot;华二一研发 AutoML 平台，降低模型训练门槛。&quot;, &quot;雷二二在 5G 边缘网协同计算领域发表多篇论文。&quot;, &quot;凌二三是 DevRel 经理，推动开源社区增长。&quot;, &quot;史二四对 RAG 架构有深入实践，优化检索召回率。&quot;, &quot;阮二五是 WebGPU 先行者，致力提升前端渲染性能。&quot;, &quot;杭二六主导多云成本治理项目，节省 30% 预算。&quot;, &quot;乔二七是一名 AIGC Prompt 工程师，专精多模态指令设计。&quot;, &quot;詹二八擅长大规模 AB 测试框架落地。&quot;, &quot;顾二九是 Serverless 架构布道者，编写多本技术书籍。&quot;, &quot;龚三十关注 DORA 指标，用数据驱动 DevOps 改进。&quot;, &quot;计三一是 API 网关专家，实现百万 QPS 低延迟。&quot;, &quot;蒲三二研究影像分割模型，用于医学辅助诊断。&quot;, &quot;邱三三是 Zig 语言早期贡献者，推行内存安全编码。&quot;, &quot;庄三四长期维护 Kafka 集群，擅长 Topic 规划。&quot;, &quot;宫三五是低代码平台架构师，关注插件生态。&quot;, &quot;蓝三六研究 ICEBERG 表格式，提升湖仓查询效率。&quot;, &quot;聂三七在安全编排 SOAR 产品设计上经验丰富。&quot;, &quot;陆三八主导 SaaS 产品国际化，本地化流程成熟。&quot;, &quot;温三九负责混合云 DR 方案，实现分钟级切换。&quot;, &quot;袁四十是语音合成工程师，优化多 speaker 适配。&quot;, &quot;贾四一深入研究 DDD，帮助团队理清领域边界。&quot;, &quot;伏四二从事实时风控大数据平台架构，处理亿级流量。&quot;, &quot;程四三是 ARM SoC 驱动工程师，对电源管理熟悉。&quot;, &quot;屈四四在 Federated GraphQL 网关治理方面有案例。&quot;, &quot;申四五带队实现 MLOps 自动化发布流程。&quot;, &quot;罗四六研究 VDBMS，支持 PB 级向量检索。&quot;, &quot;祝四七是 HTAP 数据库布道者，优化混合负载。&quot;, &quot;左四八在 IAM 与 RBAC 设计领域深耕。&quot;, &quot;冷四九是链路可观测性工程师，推广 OTEL 标准。&quot;, &quot;包五十投入异构计算调度框架研究。&quot;, &quot;滑五一精通 eBPF 在安全可观测性场景的落地。&quot;, &quot;柴五二研究量子安全算法，对国密迁移方案熟悉。&quot;, &quot;谈五三是内核安全研究员，发现多个 0-day 漏洞。&quot;, &quot;鄢五四主导 SaaS 计费系统重构，支持灵活套餐。&quot;, &quot;邸五五是绿色数据中心规划师，推动 PUE 降到 1.2。&quot;, &quot;候五六在自动驾驶 SLAM 算法具有专利。&quot;, &quot;古五七关注 CDP 架构，连接多源营销数据。&quot;, &quot;丁五八是 FPGA 加速工程师，实现低延迟推理。&quot;, &quot;靳五九研究 WASM 边缘运行时，降低冷启动。&quot;, &quot;柴六十在 DevSecOps 流水线集成方面经验丰富。&quot;, &quot;花六一策划大规模黑客马拉松，促成 500+ 项目孵化。&quot;, &quot;牛六二是边缘 AI 推理框架作者，重视功耗优化。&quot;, &quot;焦六三研究自监督学习在推荐系统的应用。&quot;, &quot;商六四是 Rust Web 开发者，推广零拷贝 JSON 解析。&quot;, &quot;阎六五投入数字孪生城市平台研发。&quot;, &quot;弓六六主攻 OTA 升级安全，覆盖汽车 ECU。&quot;, &quot;怀六七是 MAC 数据平面专家，优化转发性能。&quot;, &quot;宓六八参与多场灾备演练，完善演练脚本体系。&quot;, &quot;郝六九是 PKI 架构师，设计大规模证书生命周期。&quot;, &quot;嵇七十致力于多媒体编解码标准化。&quot;, &quot;邝七一研究 EDA 自动布线算法。&quot;, &quot;桑七二打造 AI 工厂流水线，实现模型快速迭代。&quot;, &quot;桂七三专注 DPU 加速网络虚拟化。&quot;, &quot;麻七四是 Supabase 中国社区维护者，推广 BaaS。&quot;, &quot;仇七五实现企业级 KYC 流程自动化。&quot;, &quot;薄七六研究多模态情感分析，用于客服质检。&quot;, &quot;谯七七是 SD-WAN 产品经理，聚焦海外专线优化。&quot;, &quot;巫七八负责 Kafka to Pulsar 迁移方案。&quot;, &quot;桑七九在 DAG 引擎优化 CPS 流水线。&quot;, &quot;邬八十研究端侧 LLM 蒸馏压缩。&quot;, &quot;臧八一是三维重建算法工程师，服务文博数字化。&quot;, &quot;禾八二专攻 S3 兼容对象存储网关。&quot;, &quot;原八三参与可信执行环境 TEE 方案落地。&quot;, &quot;淦八四是工业互联网安全规划顾问。&quot;, &quot;练八五实现 GPU 多租户 QoS 调度器。&quot;, &quot;禹八六关注跨境合规要求，精通 GDPR。&quot;, &quot;廉八七是 SDN 控制器开源贡献者。&quot;, &quot;亓八八专注高并发长连接网关。&quot;, &quot;宗八九打造零代码机器学习平台。&quot;, &quot;公冶九十研究 PIM 存内计算架构。&quot;, &quot;红九一是 MESH 网络性能调优专家。&quot;, &quot;眭九二致力于 AI 合成音频版权检测。&quot;, &quot;米九三推动碳排放数据平台建设。&quot;, &quot;隗九四是机器人运动规划算法专家。&quot;, &quot;拉九五研究语义分割在遥感图像的应用。&quot;, &quot;蔺九六负责 0-RTT QUIC 协议优化。&quot;, &quot;臧九七专注 BERT 在法律文本的细粒度实体抽取。&quot;, &quot;昝九八是 RPG 游戏 AI NPC 行为树作者。&quot;, &quot;贝九九研究差分隐私在广告数据的实践。&quot;, &quot;施一百主导云原生 API 安全监控平台。&quot;, &quot;伏一零一优化 Kafka Connect 大规模同步。&quot;, &quot;堵一零二研究车辆 V2X 协议栈实现。&quot;, &quot;莎一零三聚焦 A/B 决策平台可视化。&quot;,] dim = len(embed(&quot;维度探测&quot;)) # 动态探测向量维度 create_index(dim) bulk_upload(docs) print(f&quot;[√] 初始化完成（向量维度 {dim}）。开始提问，Ctrl+C 退出。\\n&quot;) try: while True: q = input(&quot;Q: &quot;).strip() if not q: continue passages = search(q) context = &quot;\\n&quot;.join(f&quot;资料{i+1}：{p}&quot; for i, p in enumerate(passages)) prompt = (f&quot;已知资料如下：\\n{context}\\n\\n请根据以上资料回答用户问题：{q}&quot;) print(&quot;\\nA:&quot;, chat(prompt)) print(&quot;引用:&quot;, passages, &quot;\\n&quot;) except KeyboardInterrupt: print(&quot;\\nBye!&quot;)if __name__ == &quot;__main__&quot;: main() 小结 EasySearch × Ollama 让我们在本地就能体验到“RAG 的爽点”：检索带来实时、可信的上下文，大模型负责自然语言表达，二者合体即是一个可交付的“企业私有知识助手”。如果你也想在内网快速验证 PoC，这份脚本拷过去改两个地址即可开跑。祝玩得开心！","link":"/posts/5a5307d/"},{"title":"Easysearch 数据可视化和管理平台：INFINI Console 使用介绍","text":"上次在《INFINI Easysearch 尝鲜 Hands on》中，我们部署了两个节点的 Easysearch，并设置了 Console 进行集群监控。今天，我们将介绍 INFINI Console 的使用。 DashboardINFINI Console 是一个功能强大的数据管理和分析平台，其仪表盘页面提供了直观简洁的界面，使用户能够快速了解系统状态并进行管理操作。本文将详细介绍仪表盘页面的各项功能。 仪表盘顶部显示系统的实时告警、通知和待办事项的数量，当前数据显示： 告警：0 条 通知：0 条 待办：0 条 在仪表盘的中心区域，用户可以看到几项关键的系统概览信息： 集群数量：当前有 3 个集群正在运行。 节点数量：系统中有 16 个节点。 主机数量：共有 3 台主机。 已用存储：系统已使用存储空间为 2.0GB。 仪表盘页面还提供了几个常用操作的快速入口，方便用户迅速访问常用功能： 集群注册：用户可以通过此入口快速注册新的集群。 数据探索：用户可以访问数据探索工具，对系统中的数据进行分析和查询。 告警管理：提供对告警信息的管理功能，用户可以查看和处理告警。 安全管理：安全管理入口帮助用户维护系统的安全设置和策略。 仪表盘右侧显示了集群的动态信息，包括最近的操作日志。例如： 2024-07-03 22:43:43，index medcl 在 cluster infiniLabs 中的状态更新。 2024-07-03 22:06:43，index medcl 在 cluster infiniLabs 中被创建。 集群管理页面集群管理页面主要分为几个部分：顶部的功能选项卡、中部的集群列表、以及右侧的筛选和排序选项。 页面顶部的功能选项卡包括以下几项： **Clusters (集群)**：显示当前系统中的所有集群。 **Nodes (节点)**：显示集群中的节点详细信息。 **Indices (索引)**：显示集群中的索引信息。 **Hosts (主机)**：显示系统中的主机信息。 集群列表展示了每个集群的详细信息，包括： 集群名称：每个集群的名称，如 “infinilabs”、”mycluster”、”INFINI_SYSTEM (JeanGrey)”。 集群健康状态：以颜色条的形式显示最近 14 天的集群健康状态（绿色表示健康，黄色表示有警告）。 节点数量：集群中包含的节点数量。 索引数量：集群中的索引数量。 分片数量：集群中的分片数量。 文档数量：集群中存储的文档数量。 磁盘使用率：集群的磁盘使用情况。 JVM 堆内存使用率：集群的 JVM 堆内存使用情况。 索引速率：当前集群的索引速率（每秒索引数）。 搜索速率：当前集群的搜索速率（每秒搜索数）。 页面右侧提供了丰富的筛选和排序选项，可以根据以下条件筛选和排序集群： **健康状态 (Health Status)**：根据集群的健康状态筛选，如绿色（健康）和黄色（警告）。 **分布 (Distribution)**：根据集群的分布类型筛选，如 “easysearch” 和 “elasticsearch”。 **版本 (Version)**：根据集群使用的软件版本筛选，如 Easysearch 1.8.2 和 Elasticsearch 7.10.2。 **区域 (Region)**：根据集群所在的区域筛选，如 “china” 和 “default”。 **标签 (Tags)**：根据自定义标签进行筛选。 接下来分别介绍节点、索引和主机层面的信息，这些监控指标与集群层面大同小异。 节点监控 索引监控 主机监控包括了常规的 CPU、内存、磁盘、网络的监控。 监控指标页面监控报表页面提供了对集群运行状况的详细监控和分析功能。用户可以选择最近 15 分钟、1 小时、24 小时等不同时间范围查看数据，并手动点击刷新按钮更新数据，以获取最新的监控信息。 概览信息显示当前集群的基本状态，包括： 集群名称：如 “infinilabs”。 在线时长：如 “3 天”。 集群版本：如 “1.8.2”。 健康状态：如 “green”。 节点数：如 “2”。 索引数：如 “38”。 主/总分片：如 “38/76”。 未分配分片：如 “0”。 文档数：如 “656,803”。 存储空间：如 “1007.2MB/385.4GB”。 JVM 内存：如 “1023.0MB/2.0GB”。 监控报表页面还提供了多个性能指标的图表，包括： 索引吞吐 (doc/s) Total Indexing：总索引吞吐量。 Primary Indexing：主分片的索引吞吐量。 查询吞吐 (query/s) Total Query：总查询吞吐量。 索引延迟 (ms) Indexing Latency：索引延迟时间。 Delete Latency：删除操作的延迟时间。 查询延迟 (ms) Query Latency：查询延迟时间。 Fetch Latency：获取操作的延迟时间。 Scroll Latency：滚动操作的延迟时间。 点击“Advance”可以查看更多监控指标： 节点级别性能监控包括 CPU、负载、JVM 内存、剩余使用空间及磁盘空间、集群启动时间和索引读写情况。 索引级别监控包括集群内索引的数量、状态、主分片和副本分片数量、文档条数和占用空间。 集群动态页面提供集群中各类事件和活动的详细记录和监控功能。 别名管理别名管理页面提供了对索引别名的管理功能，使用户可以方便地管理和配置 Elasticsearch/EasySearch 的索引别名。 创建别名可以通过 DSL 创建别名。例如，创建一个名为 my_index_alias 的别名指向 `my_index `： 1234567891011POST /_aliases{ &quot;actions&quot;: [ { &quot;add&quot;: { &quot;index&quot;: &quot;my_index&quot;, &quot;alias&quot;: &quot;my_index_alias&quot; } } ]} 删除别名删除一个别名同样可以通过 REST API 实现： 1234567891011POST /_aliases{ &quot;actions&quot;: [ { &quot;remove&quot;: { &quot;index&quot;: &quot;my_index&quot;, &quot;alias&quot;: &quot;my_index_alias&quot; } } ]} 索引轮换索引轮换是一种常用的索引管理策略，特别适用于日志和时间序列数据的场景。通过索引轮换，用户可以在索引达到一定条件（如大小或文档数量）时，创建一个新的索引来继续存储数据，而旧的索引可以继续用于查询。 设置写别名：创建一个指向当前写入索引的别名，例如 current_write_index。 定义索引轮换条件：可以基于索引的大小、文档数量或时间来定义轮换条件。 执行轮换操作：当索引满足轮换条件时，创建一个新的索引并更新写别名指向这个新索引。 创建初始索引并设置写别名： 123456PUT /my_index-000001{ &quot;aliases&quot;: { &quot;current_write_index&quot;: {} }} 使用 /_rollover API 定义轮换条件并执行轮换： 12345678910111213POST /current_write_index/_rollover{ &quot;conditions&quot;: { &quot;max_age&quot;: &quot;7d&quot;, &quot;max_docs&quot;: 1000000 }, &quot;settings&quot;: { &quot;number_of_shards&quot;: 1 }, &quot;aliases&quot;: { &quot;current_write_index&quot;: {} }} 通过这种方式，查询操作可以透明地访问所有历史数据，而写操作总是指向最新的索引。 在 INFINI Console 中提供了可视化创建索引及别名的方式。页面右上角提供了新建按钮，用户可以通过点击该按钮创建新的索引别名，填写别名名称、关联索引、索引路由、搜索路由和过滤查询等配置。 平台监控展示了多个关键指标的监控图表，包括： **健康状态 (Health)**：显示系统当前的健康状态。如果没有数据，则显示“暂无数据”。 **引擎分布 (Engines)**：展示系统中不同搜索引擎的分布情况，例如 EasySearch 和 Elasticsearch 的比例。图表显示当前 EasySearch 占 67%，Elasticsearch 占 33%。 **提供商 (Providers)**：显示系统中使用的云服务提供商信息。在示例中，所有资源都托管在 AWS 上。 **JDK 版本 (JDK)**：显示系统中使用的 JDK 版本信息。在示例中，所有节点都使用 JDK 版本 11.0.20。 磁盘使用情况 (Disk Utilization) - Top 10：显示磁盘使用率最高的前 10 个节点。在示例中，easysearch-node1 和 easysearch-node2 的磁盘使用率均为 4%。 JVM 使用情况 (JVM Utilization) - Top 10：展示 JVM 使用率最高的前 10 个节点。在示例中，infinilabs 集群的 easysearch-node1 和 easysearch-node2 节点的 JVM 使用情况有详细的时间序列数据，显示了不同时间点的使用率变化。 我们还能够看到更多指标： 数据探索在数据探索里，可以根据时间、字段等条件对索引或者视图下的数据进行搜索查询和分析，类似 Kibana 的 Discover。这里可以看到集群的警报，目前集群运行良好，没有任何警报。内部会预设一些警报规则，如下：点进去一个请求，比如磁盘的警告，可以针对不同的使用量设置不同的警告级别和通知。这里针对警报设置警报，可以看到现在支持很多平台，Discord、飞书、邮件、微信、Slack 以及钉钉。点击进去可以查看，对于社交软件而言，其实是使用 Webhook 进行通知，除此之外也支持配置邮件服务器和自定义的 Webhook 进行通知。 开发工具Console 的开发工具相当于 Kibana DevTool 的升级版，使用上基本没有大的区别，除了支持 DSL 之外，还支持多集群 Tab 切换、常用命令快速 Load、SQL 查询等。 集群连接凭证管理可以看到连接这三个集群的凭证管理，目前都是有效的。 后台用户授权可以添加用户以及修改 console 管理界面的密码。目前设置了 admin 账号。 审计日志追踪对集群的操作，捕获查看集群监控信息以及集群索引的操作。 结论INFINI Console 的仪表盘页面集成了系统的关键信息和快捷操作入口，使用户可以高效地管理和监控系统。通过详细的概览信息、实时的告警通知、快速的功能入口和动态日志，用户能够对系统的运行状态一目了然，并快速响应各种管理需求。这个设计不仅提升了用户的工作效率，还确保了系统的安全和稳定运行。 INFINI Console 的集群管理页面提供了对系统集群的全面监控和管理功能。通过详细的集群信息展示、便捷的功能选项卡切换以及丰富的筛选和排序功能，用户可以高效地管理和监控系统中的集群状态。这不仅提升了运维效率，还确保了系统的稳定运行和高效管理。 INFINI Console 的节点管理页面提供了对集群节点的全面监控和管理功能。通过详细的节点信息展示、便捷的功能选项卡切换以及丰富的筛选和搜索功能，用户可以高效地管理和监控系统中的节点状态，从而提升运维效率，确保系统的稳定运行和高效管理。 INFINI Console 的监控报表页面提供了对集群运行状况的全面监控和分析功能。通过详细的概览信息和多个性能指标图表，用户可以高效地监控和管理集群的运行状态。这不仅提升了系统运维效率，还确保了集群的稳定运行和高效管理。 通过这些功能，INFINI Console 为用户提供了全面的系统管理工具，帮助他们高效地应对各种运维挑战，确保系统的高效、安全、稳定运行。","link":"/posts/ebd08f3f/"},{"title":"轻松管理 ES 集群：我把 Infinilabs Console 上架了懒猫微服，默认支持外网访问、","text":"之前我的 infinilabs Console 一直跑在群晖里，由于和 Coco-AI 的默认端口冲突，导致经常忘记端口信息，群晖里运行着 Easysearch，Elasticsearch、OpenSearch 三个大集群，也想慢慢迁移到其他性能高的机器上去，正好最近购买了懒猫微服，能够让我做应用的迁移，顺便还得能上架一些应用。 Infinilabs.console 是什么？如果你用过 Elasticsearch，那就一定知道 Kibana。Infinilabs Console，就是极限科技团队开发的国产可视化控制台，是一个面向 Easysearch、Elasticsearch 和 OpenSearch 的运维、监控、数据管理平台，可以看作是国产版的 Kibana 替代品。 最初接触这个款产品的时候让我眼前一亮，它能够借助 Easysearch 或者 Elasticsearch 的 REST API 来连接集群，同时也高效地管理和监控 Elasticsearch、OpenSearch 以及 INFINI Easysearch 等搜索引擎集群，提供统一的运维、监控、安全和数据管理能力。这一点其实是 Kibana 比不了的，尽管是老牌软件，但是初学 ES 的时候 Kibana 连接 ES 要查 log 设置一些 key，这个整个部署过程就花了一个小上午的时间。而且跨版本，跨引擎来支持的能力也是其他可视化工具无法比拟的。简单来说，真的很符合国人的使用习惯。 首先我们可以在连接的时候不同的引擎（Easysearch、Elasticsearch、OpenSearch ），以及你集群的位置（线下还是在各种云上），同时支持 HTTP 和 HTTPS 的连接。 连接之后，可以看到已经正确识别出来了的 Easysearch、Elasticsearch 和 OpenSearch，并且抓取了相应的数据监控，比如基本的集群状态，节点数量，索引，分片以及文档的数量，还有磁盘和 JVM 的占用。 执行 DSL 的时候可以开启多个 TAB 页这个是我最喜欢的功能，尤其在做集群迁移的时候再也不用找不同的系统去登录了，这里手动@aws 的 OpenSearch。除此之外，做快照传到 S3 的时候也不用担心 access_key 读不到的问题了。曾经我是托管 OpenSearch 的用户，托管节点有诸多问题，无法登录，由于服务本身的问题导致业务滞后（升级卡住，看门狗不定时杀进程），做快照必须借助 Postman 来传递 IAM 凭证。但，换了 Infinilabs console 和 Easysearch 之后，整个世界都清净了。 GitHub 项目地址如下：https://github.com/infinilabs/console 为什么选择了懒猫商店？懒猫微服解决了我日常使用 NAS 的几个痛点： 装了一堆服务（Redis、MinIO、MeiliSearch、Adminer、Swagger UI……），入口太分散； 每次看容器状态都要 docker ps 一把梭； Homepage 要手动配置，配置文件写起来太繁琐； 部署成功后会给到一个域名，然后通过域名访问可以自动解析内外网的 IP 地址，同时也自带了路由守卫功能来重定向到懒猫的 SSO， 而在传统 NAS 部署 Authentik 然后再去应用端做 SSO 的适配应该是 NAS 玩家的终极梦想，而上架商店之后自动集成了这样的认证系统（也是单点登录）。然后，在外边的时候也可以监控和操作自己的 ES 集群啦～（随地大小班的理由又多了一条） 因为上架的应用是 HTTP 的，懒猫微服还能自动做了一个 TLS 传输，用的他们自己域名，然后通过 https 访问 Infinilabs Console。 除此之外还自带了 dozzle，可以很方便查看安装应用的上架信息，毕竟对于开发者来说，装机玩 NAS 是兴趣，但是搭建好之后的维护问题也同样劳心费力，真的一点都不想浪费时间和精力，那么杂活就交给平台来管理吧。 进入懒猫微服的【应用商店】，搜索：infinilabs.console一键安装并启动，打开浏览器，开始使用 Infinilabs Console 吧～ 地址如下： https://lazycat.cloud/appstore/#/shop/detail/xu.infinilabs.console 相关链接 infinilabs.console 介绍：https://infinilabs.cn/products/console/ infinilabs Github 介绍：https://infinilabs.cn/products/console/ 懒猫微服上架地址：https://lazycat.cloud/ 懒猫微服官网：https://lazycat.cloud/","link":"/posts/75c015c8/"},{"title":"INFINI Console 使用介绍","text":"上次在《INFINI Easysearch 尝鲜 Hands on》中我们部署了两个节点的 Easysearch，并且也设置了 Console 对集群进行监控。那么今天我们再来介绍下 INFINI Console 的使用。 INFINI Console 仪表盘功能介绍INFINI Console 是一个功能强大的数据管理和分析平台，其仪表盘页面提供了直观、简洁的界面，使用户可以快速了解系统状态并进行各种管理操作。本文将详细介绍仪表盘页面的各项功能。 警告和通知仪表盘顶部显示了系统的实时告警、通知和待办事项的数量，当前数据显示： 告警：0 条 通知：0 条 待办：0 条 这些指标有助于及时了解系统的异常情况和待处理的任务。 概览信息在仪表盘的中心区域，用户可以看到几项关键的系统概览信息： 集群数量：当前有 3 个集群正在运行。 节点数量：系统中有 16 个节点。 主机数量：共有 3 台主机。 已用存储：系统已使用存储空间为 2.0GB。 仪表盘页面还提供了几个常用操作的快速入口，方便用户迅速访问常用功能： 集群注册：用户可以通过此入口快速注册新的集群。 数据探索：用户可以访问数据探索工具，对系统中的数据进行分析和查询。 告警管理：提供对告警信息的管理功能，用户可以查看和处理告警。 安全管理：安全管理入口帮助用户维护系统的安全设置和策略。 仪表盘右侧显示了集群的动态信息，包括最近的操作日志。例如： 2024-07-03 22:43:43，index medcl 在 cluster infiniLabs 中的状态更新。 2024-07-03 22:06:43，index medcl 在 cluster infiniLabs 中被创建。 INFINI Console 集群管理页面功能介绍INFINI Console 是一个用于数据管理和分析的综合平台，其集群管理页面提供了对系统集群、节点、索引和主机的全面监控和管理功能。本文将详细介绍该页面的各项功能和特点。 集群管理页面主要分为几个部分：顶部的功能选项卡、中部的集群列表、以及右侧的筛选和排序选项。 页面顶部的功能选项卡包括以下几项： **Clusters (集群)**：显示当前系统中的所有集群。 **Nodes (节点)**：显示集群中的节点详细信息。 **Indices (索引)**：显示集群中的索引信息。 **Hosts (主机)**：显示系统中的主机信息。 集群列表展示了每个集群的详细信息，包括： 集群名称：每个集群的名称，如 “infinilabs”、”mycluster”、”INFINI_SYSTEM (JeanGrey)”。 集群健康状态：以颜色条的形式显示最近 14 天的集群健康状态（绿色表示健康，黄色表示有警告）。 节点数量：集群中包含的节点数量。 索引数量：集群中的索引数量。 分片数量：集群中的分片数量。 文档数量：集群中存储的文档数量。 磁盘使用率：集群的磁盘使用情况。 JVM 堆内存使用率：集群的 JVM 堆内存使用情况。 索引速率：当前集群的索引速率（每秒索引数）。 搜索速率：当前集群的搜索速率（每秒搜索数）。 页面右侧提供了丰富的筛选和排序选项，可以根据以下条件筛选和排序集群： **健康状态 (Health Status)**：根据集群的健康状态筛选，如绿色（健康）和黄色（警告）。 **分布 (Distribution)**：根据集群的分布类型筛选，如 “easysearch” 和 “elasticsearch”。 **版本 (Version)**：根据集群使用的软件版本筛选，我这里是 easysearch 1.8.2”和 ElasticSearch 7.10.2。 **区域 (Region)**：根据集群所在的区域筛选，如 “china” 和 “default”。 **标签 (Tags)**：根据自定义标签进行筛选。下面分别是节点层面，索引层面，以及主机层面的信息，监控的指标和集群层面大同小异。 节点监控：索引监控：主机的监控： 这里包括了常规的 CPU，内存，磁盘，网络的监控。 监控报表页面提供了对集群运行状况的详细监控和分析功能。本文将详细介绍该页面的各项功能和特点，帮助用户更好地理解和使用该工具。用户可以选择最近 15 分钟、1 小时、24 小时等不同时间范围查看数据。同时，用户可以手动点击刷新按钮更新数据，以获取最新的监控信息。 概览信息部分显示了当前集群的基本状态，包括： 集群名称：如 “infinilabs”。 在线时长：集群已经运行的时间，如 “3 天”。 集群版本：当前集群使用的软件版本，如 “1.8.2”。 健康状态：集群的健康状况，如 “green” 表示健康。 节点数：集群中的节点数量，如 “2”。 索引数：集群中的索引数量，如 “38”。 主/总分片：集群中已分配的主分片和总分片数量，如 “38/76”。 未分配分片：集群中未分配的分片数量，如 “0”。 文档数：集群中存储的文档数量，如 “656,803”。 存储空间：集群使用的存储空间和总可用存储空间，如 “1007.2MB/385.4GB”。 JVM 内存：JVM 堆内存的使用情况，如 “1023.0MB/2.0GB”。 监控报表页面还提供了多个性能指标的图表，包括： 索引吞吐 (doc/s) Total Indexing：总索引吞吐量。 Primary Indexing：主分片的索引吞吐量。 查询吞吐 (query/s) Total Query：总查询吞吐量。 索引延迟 (ms) Indexing Latency：索引延迟时间。 Delete Latency：删除操作的延迟时间。 查询延迟 (ms) Query Latency：查询延迟时间。 Fetch Latency：获取操作的延迟时间。 Scroll Latency：滚动操作的延迟时间。 当然也可以点击 Advance 查看更多的监控指标： 这个是是节点级别的性能监控，包括 CPU，负载，JVM 内存，剩余使用空间以及磁盘空间，集群启动时间和索引一些读写的情况。 这个是索引级别的监控，包括集群里有几个索引，索引状态是 open 还是 close，每个索引有几个主分片和副本分片，每个索引里文档的条数和占用空间， 集群动态页面提供了对集群中各类事件和活动的详细记录和监控功能。别名管理页面提供了对索引别名的管理功能，使用户可以方便地管理和配置 Elasticsearch 的索引别名。 先来介绍下什么是别名以及基于别名的索引轮换： 别名（Alias）是 Elasticsearch 提供的一种机制，使用户可以为一个或多个索引创建一个或多个别名。由于 EasySearch 基于 Elasticsearch 开发，所以同样适用此功能。 创建别名可以通过 DSL 创建别名。例如，创建一个名为 my_index_alias 的别名指向 my_index： 1234567891011POST /_aliases{ &quot;actions&quot;: [ { &quot;add&quot;: { &quot;index&quot;: &quot;my_index&quot;, &quot;alias&quot;: &quot;my_index_alias&quot; } } ]} 删除别名删除一个别名同样可以通过 REST API 实现： 1234567891011POST /_aliases{ &quot;actions&quot;: [ { &quot;remove&quot;: { &quot;index&quot;: &quot;my_index&quot;, &quot;alias&quot;: &quot;my_index_alias&quot; } } ]} 索引轮换是一种常用的索引管理策略，特别适用于日志和时间序列数据的场景。通过索引轮换，用户可以在索引达到一定条件（如大小或文档数量）时，创建一个新的索引来继续存储数据，而旧的索引可以继续用于查询。 设置写别名：创建一个指向当前写入索引的别名，例如 current_write_index。 定义索引轮换条件：可以基于索引的大小、文档数量或时间来定义轮换条件。 执行轮换操作：当索引满足轮换条件时，创建一个新的索引并更新写别名指向这个新索引。 首先，创建初始索引并设置写别名： 123456PUT /my_index-000001{ &quot;aliases&quot;: { &quot;current_write_index&quot;: {} }} 使用 /_rollover API 定义轮换条件并执行轮换： 12345678910111213POST /current_write_index/_rollover{ &quot;conditions&quot;: { &quot;max_age&quot;: &quot;7d&quot;, &quot;max_docs&quot;: 1000000 }, &quot;settings&quot;: { &quot;number_of_shards&quot;: 1 }, &quot;aliases&quot;: { &quot;current_write_index&quot;: {} }} 此命令会检查 current_write_index 别名指向的索引是否满足轮换条件，如果满足，则创建一个新的索引（如 my_index-000002），并更新 current_write_index 别名指向新索引。 在轮换之后，所有的写入操作会自动指向新的索引 my_index-000002，而旧的索引 my_index-000001 可以继续用于查询操作。 可以通过一个独立的读别名来处理查询操作，例如 all_indices，该别名可以指向所有相关的索引： 1234567POST /_aliases{ &quot;actions&quot;: [ { &quot;add&quot;: { &quot;index&quot;: &quot;my_index-000001&quot;, &quot;alias&quot;: &quot;all_indices&quot; }}, { &quot;add&quot;: { &quot;index&quot;: &quot;my_index-000002&quot;, &quot;alias&quot;: &quot;all_indices&quot; }} ]} 通过这种方式，查询操作可以透明地访问所有的历史数据，而写操作总是指向最新的索引。在 INFINI Console 中提供了可视化创建索引以及别名的方式，页面右上角提供了新建按钮，用户可以通过点击该按钮创建新的索引别名，填写别名名称、关联索引、索引路由、搜索路由和过滤查询等配置。 平台概览页面中部展示了多个关键指标的监控图表，包括： **健康状态 (Health)**：显示系统当前的健康状态。如果没有数据，则显示“暂无数据”。 **引擎分布 (Engines)**：展示系统中不同搜索引擎的分布情况，例如 EasySearch 和 Elasticsearch 的比例。图表显示当前 EasySearch 占 67%，Elasticsearch 占 33%。 **提供商 (Providers)**：显示系统中使用的云服务提供商信息。在示例中，所有资源都托管在 AWS 上。 **JDK 版本 (JDK)**：显示系统中使用的 JDK 版本信息。在示例中，所有节点都使用 JDK 版本 11.0.20。 磁盘使用情况 (Disk Utilization) - Top 10：显示磁盘使用率最高的前 10 个节点。在示例中，easysearch-node1 和 easysearch-node2 的磁盘使用率均为 4%。 JVM 使用情况 (JVM Utilization) - Top 10：展示 JVM 使用率最高的前 10 个节点。在示例中，infinilabs 集群的 easysearch-node1 和 easysearch-node2 节点的 JVM 使用情况有详细的时间序列数据，显示了不同时间点的使用率变化。 结下来是更加详细的页面，我们能够看到更多指标： 这个是 Discovery 的页面：这里可以看到集群的警报，目前集群运行良好，没有任何警报。内部会预设一些警报规则，如下：点进去一个请求，比如磁盘的警告，可以到针对不同的使用量设置了不同的警告级别和警告通知。这里针对警报设置警报，可以看到现在支持很多平台，Discord，飞书，邮件，微信，Slack 以及钉钉。点击进去可以查看到，对于社交软件而言，其实是使用 Webhook 的方式进行通知，除此之外也支持配置邮件服务器和自定义的 webhook 进行通知。接下来是开发工具，其实就是 kibana 的 dev tool，中文直译过来，使用上没有任何区别，除了支持 DSL 之外，还支持 SQL 查询。 这里可以看到连接这三个集群的凭证管理，目前都是有效的。 后台的用户授权，我这里目前设置了 admin，也可以在这里添加用户以及修改 console 管理界面的密码。最后审计日子，会追踪对于集群做了什么操作，发出了哪些的 API 请求，可以看到我这里能看到捕获了查看集群监控信息以及查看集群索引的操作。 结论INFINI Console 的仪表盘页面集成了系统的关键信息和快捷操作入口，使用户可以高效地管理和监控系统。通过详细的概览信息、实时的告警通知、快速的功能入口和动态日志，用户能够对系统的运行状态一目了然，并快速响应各种管理需求。这个设计不仅提升了用户的工作效率，还确保了系统的安全和稳定运行。 INFINI Console 的集群管理页面提供了对系统集群的全面监控和管理功能。通过详细的集群信息展示、便捷的功能选项卡切换以及丰富的筛选和排序功能，用户可以高效地管理和监控系统中的集群状态。这不仅提升了运维效率，还确保了系统的稳定运行和高效管理。 INFINI Console 的节点管理页面提供了对集群节点的全面监控和管理功能。通过详细的节点信息展示、便捷的功能选项卡切换以及丰富的筛选和搜索功能，用户可以高效地管理和监控系统中的节点状态，从而提升运维效率，确保系统的稳定运行和高效管理。 INFINI Console 的监控报表页面提供了对集群运行状况的全面监控和分析功能。通过详细的概览信息和多个性能指标图表，用户可以高效地监控和管理集群的运行状态。这不仅提升了系统运维效率，还确保了集群的稳定运行和高效管理。 通过这些功能，INFINI Console 为用户提供了全面的系统管理工具，帮助他们高效地应对各种运维挑战，确保系统的高效、安全、稳定运行。","link":"/posts/bde1966f/"},{"title":"MacOS 环境下运行 EasySearch 报错无法信任 Java 包的解决方案","text":"问题背景近期因 MacBook 系统降级重装，需重新部署 EasySearch 环境。由于系统未预装 Java，选择下载捆绑 JDK 的 EasySearch 版本，但在安装过程中遇到以下问题： 系统安全机制拦截 Java 运行 密码认证异常（持续返回 401 错误） 问题现象 安全拦截MacOS Gatekeeper 阻止运行捆绑的 JDK，即使在「系统偏好设置-安全性与隐私」中手动放行后，仍出现权限不足提示（见图 1）。 认证失效配置文件中的密码校验异常，任何登录尝试均返回 401 状态码。 解决步骤 全局权限设置首先通过终端命令关闭系统安全限制： 1sudo spctl --master-disable 但发现此操作仍无法解决 JDK 运行问题。 最终解决方案采用处理「App 损坏」报错的方法： 重新解压安装包 执行扩展属性清除命令： 1xattr -cr jdk/bin/java 重新初始化 EasySearch 验证结果成功运行 EasySearch 并完成系统初始化（见图 3）。 经验总结MacOS 对未公证应用的限制日趋严格，建议： 优先使用公证版本软件 遇到权限问题时，xattr -cr命令可有效清除可能导致拦截的扩展属性 401 错误可能与系统权限深度关联，需综合处理运行环境和配置文件","link":"/posts/b77119f9/"},{"title":"用Filebeat OSS 7.10.2将收集日志到Easysearch","text":"Filebeat OSS (Open Source Software) 7.10.2 版本是 Elastic 公司提供的开源版本。移除了一些Elasticsearch商业化的功能插件（但是没移出去干净） https://www.elastic.co/cn/downloads/past-releases/filebeat-oss-7-10-2。 这主要还是 AWS 和 Elastic 公司之间的矛盾，AWS 托管的 ES 会和 Elastic 抢客户。所以 Elastic 搞了一个不能商业化的协议，影响了这个生态圈，也给开发者造成了很多不方便。 还记得这个非常戏剧性的 Issue： https://github.com/elastic/beats/issues/8086 下面将介绍如何配置该版本 Filebeat 将日志发送到 Easysearch。 以下是完整的filebeat.yml配置示例： 12345678910111213141516171819filebeat.inputs: - type: log enabled: true paths: - /var/log/messages - /var/log/httpd/*.logoutput.elasticsearch: hosts: [&quot;yourEasysearchEndpoint:443&quot;] protocol: &quot;https&quot; username: &quot;username&quot; password: &quot;password&quot; ssl.verification_mode: none# 以下配置用于处理xpack相关兼容性问题setup.template.name: &quot;filebeat&quot;setup.template.pattern: &quot;filebeat-*&quot;setup.template.enabled: truesetup.ilm.enabled: false setup.template 和 setup.ilm 相关的操作就是和没移除干净的 xpack 有关系，所以得再配置文件加上这些东西。 同时也得在 Easysearch 里面开启兼容 ES 的 API，不然会遇到这个报错。 在我的 MBP 上是这样：（config/easysearch.yml） 123discovery.type: single-nodenetwork.host: 0.0.0.0elasticsearch.api_compatibility: true 启动并测试 Filebeat： 12sudo systemctl start filebeatsudo filebeat test output 检查服务状态： 1sudo systemctl status filebeat 生成测试日志： 1echo &quot;test log $(date)&quot; | sudo tee -a /var/log/messages 在 Easysearch 中查询日志：使用 Dev Tools 执行以下查询： 12345678910111213GET filebeat-*/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;sort&quot;: [ { &quot;@timestamp&quot;: { &quot;order&quot;: &quot;desc&quot; } } ]} 成功响应示例如下： 12345678910111213141516171819202122232425262728293031323334353637383940{ &quot;took&quot;: 5, &quot;timed_out&quot;: false, &quot;_shards&quot;: { &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 }, &quot;hits&quot;: { &quot;total&quot;: { &quot;value&quot;: 1, &quot;relation&quot;: &quot;eq&quot; }, &quot;max_score&quot;: null, &quot;hits&quot;: [ { &quot;_index&quot;: &quot;filebeat-7.10.2-2025.04.18&quot;, &quot;_id&quot;: &quot;XXXXXXX&quot;, &quot;_score&quot;: null, &quot;_source&quot;: { &quot;@timestamp&quot;: &quot;2025-04-29T09:04:09.566Z&quot;, &quot;log&quot;: { &quot;file&quot;: { &quot;path&quot;: &quot;/var/log/messages&quot; }, &quot;offset&quot;: 0 }, &quot;message&quot;: &quot;test log Fri Apr 29 09:04:00 UTC 2025&quot;, &quot;input&quot;: { &quot;type&quot;: &quot;log&quot; }, &quot;ecs&quot;: { &quot;version&quot;: &quot;1.6.0&quot; } } } ] }} 曾经在 ubuntu 上遇到过只要启动 filebeat 就报错一堆内存的信息： 这个文章给了一个解决办法： https://infinilabs.cn/blog/2025/ubuntu_run_filebeat/通过以上配置和步骤，您应该能够成功使用Filebeat OSS 7.10.2 版本将日志收集到 Easysearch 中。","link":"/posts/a0786458/"},{"title":"Easysearch 数据可视化和管理平台：INFINI Console 使用介绍","text":"随着数据分析需求的不断增长，高效查询和分析大数据集变得越来越重要。Easysearch 作为一种强大的国产化搜索和分析引擎，同时作为 Elasticsearch 国产替代方案，支持原生 DSL 查询语法和 SQL 查询，确保原业务代码无需调整即可无缝迁移。Easysearch 兼容 ES 7.x 现有的 SDK 和索引存储格式，支持冷热架构和索引生命周期管理，为用户提供了全面的数据处理解决方案。本文将详细介绍如何使用 ES 7.x Python SDK 与 Easysearch 进行交互，包括安装、连接、数据操作和查询等方面。 1. 安装 Elasticsearch Python 客户端要使用 Elasticsearch Python 客户端，首先需要通过pip进行安装。打开终端或命令提示符，并运行以下命令： 1pip install elasticsearch==7.13.1 如果使用默认版本安装，会安装 8.x 的依赖，可能会报错 elasticsearch.UnsupportedProductError: The client noticed that the server is not Elasticsearch and we do not support this unknown product. 由于 Elasticsearch 7.10.2 以后变更了许可模式，引入了 Server Side Public License (SSPL) 和 Elastic License，很多基于 Elasticsearch 7.10.2 分支出来的搜索引擎需要使用 7.x 版本的 SDK 和 agent，比如 Beats 全家桶。 这是一个获取集群信息的 demo，使用es.cluster.health() 调用 Elasticsearch 集群的健康检查 API，返回集群的健康状态。 由于使用了自签名证书，所以在初始化时加上 verify_certs=False 参数，同时使用 warnings.filterwarnings(&quot;ignore&quot;) 设置 Python 的警告系统，忽略所有发出的警告。这在生产代码中通常不推荐，因为它会隐藏潜在的问题，但在开发或测试环境中，如果警告信息太多干扰调试，可能会暂时使用。 1234567891011121314151617181920212223242526import urllib3import elasticsearchfrom elasticsearch import Elasticsearchimport warningsfrom pprint import pprint# 禁用所有警告warnings.filterwarnings(&quot;ignore&quot;)print(elasticsearch.VERSION)# 禁用警告urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)url = &quot;https://ip:9200/&quot;user_passwd = ('user', 'passwd')# 建立连接es = Elasticsearch( [url], http_auth=user_passwd, verify_certs=False,)# 检查集群健康状态health = es.cluster.health()pprint(health) 2. 准备示例数据在进行查询之前，我们需要在 Easysearch 中创建一些示例数据。 12345678910111213141516171819# 定义示例数据sample_data = [ {&quot;index&quot;: {&quot;_index&quot;: &quot;my_index&quot;}}, {&quot;field&quot;: &quot;value1&quot;, &quot;another_field&quot;: 10}, {&quot;index&quot;: {&quot;_index&quot;: &quot;my_index&quot;}}, {&quot;field&quot;: &quot;value2&quot;, &quot;another_field&quot;: 20}, {&quot;index&quot;: {&quot;_index&quot;: &quot;my_index&quot;}}, {&quot;field&quot;: &quot;value3&quot;, &quot;another_field&quot;: 30}, {&quot;index&quot;: {&quot;_index&quot;: &quot;my_index&quot;}}, {&quot;field&quot;: &quot;bulk_value1&quot;, &quot;another_field&quot;: 100}, {&quot;index&quot;: {&quot;_index&quot;: &quot;my_index&quot;}}, {&quot;field&quot;: &quot;bulk_value2&quot;, &quot;another_field&quot;: 200}, {&quot;index&quot;: {&quot;_index&quot;: &quot;my_index&quot;}}, {&quot;field&quot;: &quot;bulk_value3&quot;, &quot;another_field&quot;: 300}]# 批量插入示例数据response = es.bulk(body=sample_data)print(response) 3. 使用 REST API 进行查询REST API 是与 Easysearch 进行通信的常用方式。通过 REST API，开发者可以发送 HTTP 请求来执行各种操作，包括索引文档、搜索数据等。以下示例展示了如何在 Python 中执行 REST 查询。 由于是 REST API，我们可以先使用 Postman 进行测试。 我们可以看到 HTTP 端点可以正常返回，然后就可以使用编程方式进行访问了： 12345678910111213141516171819202122232425262728import requestsfrom requests.auth import HTTPBasicAuthfrom pprint import pprinturl = &quot;https://ip:9200/&quot;user_passwd = ('user', 'passwd')# 构建查询参数query = { &quot;query&quot;: { &quot;match&quot;: { &quot;field&quot;: &quot;value1&quot; } }}dsl = f&quot;{url}/my_index/_search&quot;response = requests.get(dsl, json=query, auth=HTTPBasicAuth(*user_passwd), verify=False)pprint(response.json())# 处理查询结果if response.status_code == 200: results = response.json() for hit in results['hits']['hits']: print(hit)else: print(f&quot;Error: {response.status_code}&quot;) 4. 通过 DSL 对索引数据进行增删改查DSL（Domain-Specific Language）是 Easysearch 的原生查询语言，允许用户构建复杂的查询。以下是一些示例： 12345678910111213141516171819# 构建 DSL 查询dsl_query = { &quot;query&quot;: { &quot;match&quot;: { &quot;field&quot;: &quot;value1&quot; } }}# 执行 DSL 查询response = es.search(index=&quot;my_index&quot;, body=dsl_query)results = response.get(&quot;hits&quot;)# 处理查询结果if results: for hit in results['hits']: print(hit)else: print(f&quot;Error: {response.status_code}&quot;) 插入数据如果不指定 document ID，那么随机生成一个 ID 并写入。 123doc = {&quot;field&quot;: &quot;value4&quot;, &quot;another_field&quot;: 9999}response = es.index(index=&quot;my_index&quot;, body=doc)print(response) 更新数据指定 ID 为 1 来手动更新索引： 123doc = {&quot;field&quot;: &quot;value4&quot;, &quot;another_field&quot;: 9999}response = es.index(index=&quot;my_index&quot;, body=doc, id=1)print(response) 更新单条数据1234# 更新单条数据update_body = {&quot;doc&quot;: {&quot;another_field&quot;: 50}}response = es.update(index=&quot;my_index&quot;, id=&quot;1&quot;, body=update_body)pprint(response) 删除数据123# 删除单条数据response = es.delete(index=&quot;my_index&quot;, id=&quot;1&quot;)pprint(response) 5. 索引数据 SQL 查询创建客户端实例后，我们可以使用 sql 方法执行 SQL 查询。以下示例展示了如何执行一个简单的 SELECT 查询。 1234567# 执行 SQL 查询query_sql = { &quot;query&quot;: &quot;SELECT * FROM my_index&quot;}res = es.sql.query(body=query_sql)pprint(res) 6. 索引数据批量操作Bulk API 允许用户一次性对多个文档进行创建、更新或删除操作，极大提高了操作效率。以下是一些示例： 批量插入数据12345678910111213# 定义批量插入数据bulk_data = [ {&quot;index&quot;: {&quot;_index&quot;: &quot;my_index&quot;}}, {&quot;field&quot;: &quot;bulk_value1&quot;, &quot;another_field&quot;: 100}, {&quot;index&quot;: {&quot;_index&quot;: &quot;my_index&quot;}}, {&quot;field&quot;: &quot;bulk_value2&quot;, &quot;another_field&quot;: 200}, {&quot;index&quot;: {&quot;_index&quot;: &quot;my_index&quot;}}, {&quot;field&quot;: &quot;bulk_value3&quot;, &quot;another_field&quot;: 300}]# 执行批量插入操作response = es.bulk(body=bulk_data)pprint(response) 批量更新数据1234567891011# 定义批量更新数据bulk_update_data = [ {&quot;update&quot;: {&quot;_id&quot;: &quot;1&quot;, &quot;_index&quot;: &quot;my_index&quot;}}, {&quot;doc&quot;: {&quot;another_field&quot;: 110}}, {&quot;update&quot;: {&quot;_id&quot;: &quot;2&quot;, &quot;_index&quot;: &quot;my_index&quot;}}, {&quot;doc&quot;: {&quot;another_field&quot;: 220}}]# 执行批量更新操作response = es.bulk(body=bulk_update_data)pprint(response) 批量删除数据123456789# 定义批量删除数据bulk_delete_data = [ {&quot;delete&quot;: {&quot;_id&quot;: &quot;1&quot;, &quot;_index&quot;: &quot;my_index&quot;}}, {&quot;delete&quot;: {&quot;_id&quot;: &quot;2&quot;, &quot;_index&quot;: &quot;my_index&quot;}}]# 执行批量删除操作response = es.bulk(body=bulk_delete_data)print(response) 7. 索引级别的操作接下来，介绍索引创建、删除和检查索引是否存在操作。以下是一些示例： 创建索引123456789101112131415# 创建索引index_body = { &quot;settings&quot;: { &quot;number_of_shards&quot;: 1, &quot;number_of_replicas&quot;: 0 }, &quot;mappings&quot;: { &quot;properties&quot;: { &quot;field&quot;: {&quot;type&quot;: &quot;text&quot;}, &quot;another_field&quot;: {&quot;type&quot;: &quot;integer&quot;} } }}response = es.indices.create(index=&quot;new_index&quot;, body=index_body)pprint(response) 删除索引123# 删除索引response = es.indices.delete(index=&quot;new_index&quot;)pprint(response) 检查索引是否存在123# 检查索引是否存在response = es.indices.exists(index=&quot;new_index&quot;)pprint(response) 8. 总结Easysearch 虽然没有专门的 Python SDK，但完全兼容 ES 7.x 的 Python SDK 客户端，这为开发者提供了极大的便利。通过使用 ES 7.x Python SDK，开发者可以轻松地使用 DSL 和 SQL 语法对 Easysearch 进行查询和数据操作。Easysearch 主要优势包括： 兼容性强：无需修改现有代码，即可从 ES 迁移到 Easysearch。 功能全面：支持 DSL 查询、SQL 查询、批量操作等高级功能。 易于使用：提供简洁明了的 API，降低学习成本。 高效性能：批量操作 API 大幅提高数据处理效率。 Easysearch 结合 ES 7.x Python SDK 的强大功能，为开发者提供了一个高效、灵活的大数据处理平台。无论是执行简单的 SQL 查询，还是构建复杂的 DSL 查询，都能满足各种数据分析需求。如果您正在寻找一个强大的搜索和分析解决方案，Easysearch 绝对值得一试。它不仅能帮助您更高效地处理和分析大数据集，还能为数据驱动的决策提供有力支持。","link":"/posts/ebd08f3f/"},{"title":"Easysearch 数据可视化和管理平台：INFINI Console 使用介绍","text":"什么是 EasysearchElasticsearch 是一个基于 Apache Lucene 的开源分布式搜索和分析引擎，它被广泛应用于全文搜索、结构化搜索和分析等多种场景中。作为 Elasticsearch 的国产化替代方案，Easysearch 不仅保持了与原生 Elasticsearch 的高度兼容性，还在功能、性能、稳定性和扩展性方面进行了全面提升。对于开发团队来说，从 Elasticsearch 切换到 Easysearch 不需要做任何业务代码的调整，确保了无缝衔接和平滑迁移。 Easysearch 是基于 Elasticsearch 7.10.2 开源版本二次开发，所以支持 Elasticsearch 原始的 Query DSL 语法，基本的 SQL 语法，并且兼容现有 Elasticsearch 的 SDK，使得应用无需修改代码即可进行迁移。其平滑的迁移特性，如基于网关的无缝跨版本迁移与升级，提供了随时安全回退的能力。 在之前的文章中，我们已经介绍了 Easysearch 的搭建 和 可视化工具的使用，今天我们将探讨 Easysearch 集群的基本概念和常用的 API。 Easysearch 集群的核心概念Easysearch 集群由以下几个核心概念构成： 节点（Node）：集群中的单个服务器，负责存储数据并参与集群的索引和搜索功能。 集群（Cluster）：由一个或多个节点组成，拥有唯一的集群名，协同完成数据索引和查询任务。 索引（Index）：存储相关数据的容器，类似于关系数据库中的数据库，一个索引包含多个文档。 文档（Document）：索引中的基本数据单位，相当于关系数据库中的行。 字段（Field）：文档中的一个属性，相当于数据库中的列。 分片（Shard）：为了提高性能和扩展性，索引可以被分割成多个分片，每个分片是索引的一个部分。 副本（Replica）：分片的副本，用于提高数据的可靠性和在节点出现故障时的可用性。 通过多个 API，例如 _cluster/health 和 _cluster/stats，用户可以轻松查看集群的健康状态和详细信息，这些信息对于维护和优化 Easysearch 集群至关重要。 无论是在性能的提升，还是在功能的兼容性方面，Easysearch 都为用户提供了一个强大的搜索引擎平台，让从 Elasticsearch 到 Easysearch 的迁移变得无缝且高效。掌握其核心概念和 API 的使用，将帮助开发者更好地利用这些工具来构建和优化他们的搜索解决方案。 查看集群信息在 Easysearch 中，可以通过多个 API 来查看集群的各种信息，包括集群的健康状况、节点信息和索引状态。以下是一些常用的查看集群信息的 API 和示例： 查看集群健康状况_cluster/health API 可以查看集群的健康状态，包括集群是否处于正常状态、节点数量、分片状态等。 1GET /_cluster/health 示例响应： 1234567891011121314151617{ &quot;cluster_name&quot;: &quot;my_cluster&quot;, &quot;status&quot;: &quot;green&quot;, &quot;timed_out&quot;: false, &quot;number_of_nodes&quot;: 3, &quot;number_of_data_nodes&quot;: 3, &quot;active_primary_shards&quot;: 5, &quot;active_shards&quot;: 10, &quot;relocating_shards&quot;: 0, &quot;initializing_shards&quot;: 0, &quot;unassigned_shards&quot;: 0, &quot;delayed_unassigned_shards&quot;: 0, &quot;number_of_pending_tasks&quot;: 0, &quot;number_of_in_flight_fetch&quot;: 0, &quot;task_max_waiting_in_queue_millis&quot;: 0, &quot;active_shards_percent_as_number&quot;: 100.0} 查看集群状态_cluster/stats API 可以查看集群的详细状态，包括索引、节点、分片等信息。 1GET /_cluster/stats 示例响应： 123456789101112131415161718192021222324252627282930313233343536373839404142{ &quot;cluster_name&quot;: &quot;my_cluster&quot;, &quot;status&quot;: &quot;green&quot;, &quot;indices&quot;: { &quot;count&quot;: 10, &quot;shards&quot;: { &quot;total&quot;: 20, &quot;primaries&quot;: 10, &quot;replication&quot;: 1.0, &quot;index&quot;: { &quot;shards&quot;: { &quot;min&quot;: 1, &quot;max&quot;: 5, &quot;avg&quot;: 2.0 } } } }, &quot;nodes&quot;: { &quot;count&quot;: { &quot;total&quot;: 3, &quot;data&quot;: 3, &quot;coordinating_only&quot;: 0, &quot;master&quot;: 1, &quot;ingest&quot;: 2 }, &quot;os&quot;: { &quot;available_processors&quot;: 12, &quot;allocated_processors&quot;: 12 }, &quot;process&quot;: { &quot;cpu&quot;: { &quot;percent&quot;: 10 }, &quot;open_file_descriptors&quot;: { &quot;min&quot;: 100, &quot;max&quot;: 300, &quot;avg&quot;: 200 } } }} 查看节点信息_nodes API 可以查看集群中节点的详细信息，包括节点角色、IP 地址、内存使用情况等。 1GET /_nodes 示例响应： 123456789101112131415161718192021222324252627282930313233343536373839{ &quot;cluster_name&quot;: &quot;my_cluster&quot;, &quot;nodes&quot;: { &quot;node_id_1&quot;: { &quot;name&quot;: &quot;node_1&quot;, &quot;transport_address&quot;: &quot;192.168.1.1:9300&quot;, &quot;host&quot;: &quot;192.168.1.1&quot;, &quot;ip&quot;: &quot;192.168.1.1&quot;, &quot;roles&quot;: [&quot;master&quot;, &quot;data&quot;, &quot;ingest&quot;], &quot;os&quot;: { &quot;available_processors&quot;: 4, &quot;allocated_processors&quot;: 4 }, &quot;process&quot;: { &quot;cpu&quot;: { &quot;percent&quot;: 10 }, &quot;open_file_descriptors&quot;: 200 } }, &quot;node_id_2&quot;: { &quot;name&quot;: &quot;node_2&quot;, &quot;transport_address&quot;: &quot;192.168.1.2:9300&quot;, &quot;host&quot;: &quot;192.168.1.2&quot;, &quot;ip&quot;: &quot;192.168.1.2&quot;, &quot;roles&quot;: [&quot;data&quot;], &quot;os&quot;: { &quot;available_processors&quot;: 4, &quot;allocated_processors&quot;: 4 }, &quot;process&quot;: { &quot;cpu&quot;: { &quot;percent&quot;: 15 }, &quot;open_file_descriptors&quot;: 150 } } }} 查看索引状态_cat/indices API 可以查看集群中所有索引的状态，包括文档数、存储大小、分片数等信息。 1GET /_cat/indices?v 示例响应： 123health status index uuid pri rep docs.count docs.deleted store.size pri.store.sizegreen open index_1 SxNUd84vRl6QH5P7g0T4Vg 1 1 0 0 230b 230bgreen open index_2 NxEYib4yToCnA1PpQ8P4Xw 5 1 100 1 10mb 5mb 这些 API 可以帮助你全面了解 Easysearch 集群的状态和健康状况，从而更好地管理和维护集群。 增删改查操作在 Easysearch 中，增删改查操作是管理数据和索引的基本功能。以下是如何使用这些操作的详细示例。 创建索引创建一个新的索引，并指定分片和副本的数量： 1234567PUT /my_index{ &quot;settings&quot;: { &quot;number_of_shards&quot;: 3, &quot;number_of_replicas&quot;: 2 }} 删除索引删除一个不再需要的索引： 1DELETE /my_index 添加文档通过 POST 或 PUT 请求向索引中添加文档： 123456POST /my_index/_doc/1{ &quot;name&quot;: &quot;John Doe&quot;, &quot;age&quot;: 30, &quot;occupation&quot;: &quot;Engineer&quot;} 123456PUT /my_index/_doc/1{ &quot;name&quot;: &quot;John Doe&quot;, &quot;age&quot;: 30, &quot;occupation&quot;: &quot;Engineer&quot;} POST 和 PUT 方法用于不同的操作，尽管它们都可以用于添加或更新文档，但它们的行为有所不同。 POST /my_index/_doc/1 方法用于创建或替换一个文档。如果指定的文档 ID 已经存在，POST 请求将更新整个文档（不会合并字段）。如果文档 ID 不存在，它将创建一个新的文档。 123456POST /my_index/_doc/1{ &quot;name&quot;: &quot;John Doe&quot;, &quot;age&quot;: 30, &quot;occupation&quot;: &quot;Engineer&quot;} PUT /my_index/_doc/1 方法通常用于创建一个新的文档，或者完全替换一个已存在的文档。与 POST 类似，如果指定的文档 ID 已经存在，PUT 请求将替换整个文档。 123456PUT /my_index/_doc/1{ &quot;name&quot;: &quot;John Doe&quot;, &quot;age&quot;: 30, &quot;occupation&quot;: &quot;Engineer&quot;} 使用场景： POST：更适合用于添加或部分更新文档，即使文档 ID 已经存在。 PUT：更适合用于创建或完全替换文档。 ID 自动生成： POST 请求可以不提供文档 ID，此时 Easysearch 会自动生成一个文档 ID。 PUT 请求必须提供文档 ID，如果未提供，则会返回错误。 部分更新： POST 请求可以用于部分更新（通过 _update API）。 PUT 请求用于完全替换文档，不支持部分更新。 如果文档 ID 已经存在，POST 和 PUT 都会覆盖整个文档，并且效果是一样的。但是，通常 POST 用于提交数据，而 PUT 用于上传和替换资源。 使用 POST 方法添加或更新文档： 123456POST /my_index/_doc/1{ &quot;name&quot;: &quot;John Doe&quot;, &quot;age&quot;: 30, &quot;occupation&quot;: &quot;Engineer&quot;} 使用 PUT 方法添加或更新文档： 123456PUT /my_index/_doc/1{ &quot;name&quot;: &quot;John Doe&quot;, &quot;age&quot;: 30, &quot;occupation&quot;: &quot;Engineer&quot;} 在这两个示例中，结果都是在索引 my_index 中创建或更新文档 ID 为 1 的文档。无论使用 POST 还是 PUT，如果文档 ID 已存在，都会覆盖原有的文档内容。 新建文档使用 _create 方法新建文档，如果文档已经存在则返回错误： 1234PUT /my_index/_create/1{ &quot;a&quot;: 1} 如果尝试新建已存在的文档，将会出现如下错误： 12345678910111213141516171819{ &quot;error&quot;: { &quot;root_cause&quot;: [ { &quot;type&quot;: &quot;version_conflict_engine_exception&quot;, &quot;reason&quot;: &quot;[1]: version conflict, document already exists (current version [1])&quot;, &quot;index_uuid&quot;: &quot;1xWdHLTaTm6l6HbqACaIEA&quot;, &quot;shard&quot;: &quot;0&quot;, &quot;index&quot;: &quot;my_index&quot; } ], &quot;type&quot;: &quot;version_conflict_engine_exception&quot;, &quot;reason&quot;: &quot;[1]: version conflict, document already exists (current version [1])&quot;, &quot;index_uuid&quot;: &quot;1xWdHLTaTm6l6HbqACaIEA&quot;, &quot;shard&quot;: &quot;0&quot;, &quot;index&quot;: &quot;my_index&quot; }, &quot;status&quot;: 409} 获取文档通过 ID 获取文档的详细信息： 1GET /my_index/_doc/1 更新文档更新文档的特定字段，保留原有字段： 123456POST /my_index/_update/1{ &quot;doc&quot;: { &quot;age&quot;: 31 }} 删除文档通过 ID 删除指定的文档： 1DELETE /my_index/_doc/1 查询所有文档查询索引中的所有文档： 123456GET /my_index/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }} 这个是《老杨玩搜索》中总结的图，可以作为“小抄”来记忆： 批量操作 (_bulk API)_bulk API 用于在一次请求中执行多个索引、删除和更新操作，这对于批量处理大规模数据非常有用，可以显著提高性能和效率。以下是 _bulk API 的基本使用示例： 1234567POST /my_index/_bulk{ &quot;index&quot;: { &quot;_id&quot;: &quot;1&quot; } }{ &quot;name&quot;: &quot;John Doe&quot;, &quot;age&quot;: 30, &quot;occupation&quot;: &quot;Engineer&quot; }{ &quot;index&quot;: { &quot;_id&quot;: &quot;2&quot; } }{ &quot;name&quot;: &quot;Jane Doe&quot;, &quot;age&quot;: 25, &quot;occupation&quot;: &quot;Designer&quot; }{ &quot;update&quot;: { &quot;_id&quot;: &quot;1&quot; } }{ &quot;doc&quot;: { &quot;age&quot;: 31 } } _bulk API 的请求体由多个操作和文档组成。每个操作行包含一个动作描述行和一个可选的源文档行。动作描述行指明了操作的类型（例如，index、create、delete、update）以及操作的元数据。源文档行则包含了实际的数据。 每个操作之间需要用换行符分隔，并且请求体最后必须以换行符结尾。 1234567POST /_bulk{ &quot;index&quot;: { &quot;_index&quot;: &quot;a&quot;, &quot;_id&quot;: &quot;1&quot; } }{ &quot;name&quot;: &quot;John Doe&quot;, &quot;age&quot;: 30, &quot;occupation&quot;: &quot;Engineer&quot; }{ &quot;index&quot;: { &quot;_index&quot;: &quot;b&quot;, &quot;_id&quot;: &quot;2&quot; } }{ &quot;name&quot;: &quot;Jane Doe&quot;, &quot;age&quot;: 25, &quot;occupation&quot;: &quot;Designer&quot; }{ &quot;update&quot;: { &quot;_index&quot;: &quot;a&quot;, &quot;_id&quot;: &quot;1&quot; } }{ &quot;doc&quot;: { &quot;age&quot;: 31 } } 分词器在 Easysearch 中，分词器（Analyzer）用于将文本分解为词项（terms），是全文搜索和文本分析的基础。分词器通常由字符过滤器（Character Filters）、分词器（Tokenizer）和词项过滤器（Token Filters）组成。以下是关于分词器的详细介绍： 字符过滤器（Character Filters）：在分词之前对文本进行预处理。例如，去除 HTML 标签，替换字符等。 分词器（Tokenizer）：将文本分解为词项（tokens）。这是分词过程的核心。 词项过滤器（Token Filters）：对词项进行处理，如小写化、去除停用词、词干提取等。 只有 text 字段支持全文检索，返回的结果根据相似度打分，我们一起看下 12345678910POST /index/_mapping{ &quot;properties&quot;: { &quot;content&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; } }} POST /index/_mapping 这个部分表示要向名为index的索引添加或更新映射设置。 “properties”: properties定义了索引中文档的字段结构。在这个例子中，定义了一个名为content的字段。 “content”: 定义了名为content的字段。 “type”: “text” type字段指定content字段的数据类型为text。text类型适用于需要分词和全文搜索的字段。 “analyzer”: “ik_max_word” analyzer字段指定索引时使用的分词器为ik_max_word。ik_max_word是 IK 分词器中的一种，它会尽可能多地将文本分解为更多的词项。 “search_analyzer”: “ik_smart” search_analyzer字段指定搜索时使用的分词器为ik_smart。ik_smart是 IK 分词器中的另一种，它会更智能地进行分词，以提高搜索的准确性。 当然，在设置这个 mapping 的时候可以使用同样的分词器，也可以使用不同的分词器。这里介绍下 IK 分词器： IK 分词器是一种中文分词器，适用于中文文本的分词。IK 分词器有两种分词模式：ik_max_word和ik_smart。 ik_max_word：将文本尽可能多地切分成词项，适用于需要更高召回率的场景。 ik_smart：进行最智能的分词，适用于需要更高精度的搜索场景。 这个 DSL 的设置意味着，在向这个索引添加或更新文档时，content字段的文本会使用ik_max_word分词器进行分词处理，以确保文本被尽可能多地切分成词项。而在搜索时，content字段的文本会使用ik_smart分词器进行分词处理，以提高搜索的准确性和相关性。 以下是关于 standard，ik_smart，ik_max_word 这几个分词器的对比： 123456789101112131415161718GET /_analyze{ &quot;tokenizer&quot;: &quot;standard&quot;, &quot;text&quot;: &quot;我,机器人&quot;}GET /_analyze{ &quot;tokenizer&quot;: &quot;ik_smart&quot;, &quot;text&quot;: &quot;我,机器人&quot;}GET /_analyze{ &quot;tokenizer&quot;: &quot;ik_max_word&quot;, &quot;text&quot;: &quot;我,机器人&quot;} 结果如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# GET /_analyze （standard）{ &quot;tokens&quot;: [ { &quot;token&quot;: &quot;我&quot;, &quot;start_offset&quot;: 0, &quot;end_offset&quot;: 1, &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot;: 0 }, { &quot;token&quot;: &quot;机&quot;, &quot;start_offset&quot;: 2, &quot;end_offset&quot;: 3, &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot;: 1 }, { &quot;token&quot;: &quot;器&quot;, &quot;start_offset&quot;: 3, &quot;end_offset&quot;: 4, &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot;: 2 }, { &quot;token&quot;: &quot;人&quot;, &quot;start_offset&quot;: 4, &quot;end_offset&quot;: 5, &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot;: 3 } ]}# GET /_analyze（ik_smart）{ &quot;tokens&quot;: [ { &quot;token&quot;: &quot;我&quot;, &quot;start_offset&quot;: 0, &quot;end_offset&quot;: 1, &quot;type&quot;: &quot;CN_CHAR&quot;, &quot;position&quot;: 0 }, { &quot;token&quot;: &quot;机器人&quot;, &quot;start_offset&quot;: 2, &quot;end_offset&quot;: 5, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 1 } ]}# GET /_analyze （ik_max_word）{ &quot;tokens&quot;: [ { &quot;token&quot;: &quot;我&quot;, &quot;start_offset&quot;: 0, &quot;end_offset&quot;: 1, &quot;type&quot;: &quot;CN_CHAR&quot;, &quot;position&quot;: 0 }, { &quot;token&quot;: &quot;机器人&quot;, &quot;start_offset&quot;: 2, &quot;end_offset&quot;: 5, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 1 }, { &quot;token&quot;: &quot;机器&quot;, &quot;start_offset&quot;: 2, &quot;end_offset&quot;: 4, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 2 }, { &quot;token&quot;: &quot;人&quot;, &quot;start_offset&quot;: 4, &quot;end_offset&quot;: 5, &quot;type&quot;: &quot;CN_CHAR&quot;, &quot;position&quot;: 3 } ]} 如果使用了不存在的分词器会出现这个错误。 12345678910111213{ &quot;error&quot;: { &quot;root_cause&quot;: [ { &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;failed to find global tokenizer under [simple]&quot; } ], &quot;type&quot;: &quot;illegal_argument_exception&quot;, &quot;reason&quot;: &quot;failed to find global tokenizer under [simple]&quot; }, &quot;status&quot;: 400} 精确搜索/正则表达式搜索/通配符在 Easysearch 中，精确搜索、正则表达式搜索和通配符搜索是三种不同的搜索方式，各有其应用场景和特点： **精确搜索 (Term Query)**： 精确搜索用于查找与搜索词完全匹配的文档。 不进行分词处理，通常用于关键字、ID、标签等字段的精确匹配。 适用于结构化数据或不需要分词的字段（如数字、日期、布尔值等）。 1234567{ &quot;query&quot;: { &quot;term&quot;: { &quot;status&quot;: &quot;active&quot; } }} **正则表达式搜索 (Regexp Query)**： 正则表达式搜索用于基于正则表达式模式匹配的文档搜索。 支持复杂的字符串匹配模式，但性能可能较低，特别是当数据量较大时。 适用于需要灵活且复杂匹配条件的搜索。 1234567{ &quot;query&quot;: { &quot;regexp&quot;: { &quot;content&quot;: &quot;Easysearch .*powerful&quot; } }} **通配符搜索 (Wildcard Query)**： 通配符搜索用于通过通配符模式匹配文档。 支持 ?（匹配单个字符）和 *（匹配零个或多个字符）。 性能相对较差，因为通配符搜索可能需要扫描大量数据。 1234567{ &quot;query&quot;: { &quot;wildcard&quot;: { &quot;username&quot;: &quot;john*&quot; } }} 精确搜索：用于需要绝对匹配特定词语或不需要分词的字段。例如，查找特定用户 ID 或状态。 正则表达式搜索：用于需要复杂字符串模式匹配的场景，但要谨慎使用，避免性能问题。 通配符搜索：用于简单模式匹配，但同样需要注意性能影响，尽量避免在大数据集上频繁使用。 接下来看这个例子，我们将使用批量导入数据，然后进行几种不同类型的查询，包括精确查询、通配符查询和正则表达式查询。 1234567891011POST /users/_bulk{ &quot;index&quot;: { &quot;_index&quot;: &quot;users&quot;, &quot;_id&quot;: 1 }}{ &quot;username&quot;: &quot;john_doe&quot;, &quot;status&quot;: &quot;active&quot;, &quot;email&quot;: &quot;john.doe@example.com&quot;, &quot;bio&quot;: &quot;John loves Easysearch and open-source technologies.&quot; }{ &quot;index&quot;: { &quot;_index&quot;: &quot;users&quot;, &quot;_id&quot;: 2 }}{ &quot;username&quot;: &quot;jane_doe&quot;, &quot;status&quot;: &quot;inactive&quot;, &quot;email&quot;: &quot;jane.doe@example.com&quot;, &quot;bio&quot;: &quot;Jane is a data scientist working with big data.&quot; }{ &quot;index&quot;: { &quot;_index&quot;: &quot;users&quot;, &quot;_id&quot;: 3 }}{ &quot;username&quot;: &quot;john_smith&quot;, &quot;status&quot;: &quot;active&quot;, &quot;email&quot;: &quot;john.smith@example.com&quot;, &quot;bio&quot;: &quot;John enjoys hiking and nature.&quot; }{ &quot;index&quot;: { &quot;_index&quot;: &quot;users&quot;, &quot;_id&quot;: 4 }}{ &quot;username&quot;: &quot;alice_jones&quot;, &quot;status&quot;: &quot;active&quot;, &quot;email&quot;: &quot;alice.jones@example.com&quot;, &quot;bio&quot;: &quot;Alice is a software engineer specialized in JavaScript.&quot; }{ &quot;index&quot;: { &quot;_index&quot;: &quot;users&quot;, &quot;_id&quot;: 5 }}{ &quot;username&quot;: &quot;bob_jones&quot;, &quot;status&quot;: &quot;inactive&quot;, &quot;email&quot;: &quot;bob.jones@example.com&quot;, &quot;bio&quot;: &quot;Bob is an AI enthusiast and machine learning expert.&quot; } 精确查询：查询状态为 “active” 的用户。 12345678GET /users/_search{ &quot;query&quot;: { &quot;term&quot;: { &quot;status&quot;: &quot;active&quot; } }} 通配符查询：查询 bio 字段中包含 “John” 开头的词。 12345678GET /users/_search{ &quot;query&quot;: { &quot;wildcard&quot;: { &quot;bio&quot;: &quot;John*&quot; } }} 正则表达式查询：查询用户名以 “john” 开头的用户。 12345678GET /users/_search{ &quot;query&quot;: { &quot;regexp&quot;: { &quot;username&quot;: &quot;john.*&quot; } }} 通过这些例子，你可以看到如何在 Easysearch 中使用批量导入数据，然后使用各种查询方法来检索特定条件的数据。这些查询方法可以帮助你高效地搜索和分析数据，以满足不同的业务需求。 这里同样是《老杨玩搜索》中总结的“小抄”来方便记忆： 多字段查询在 Easysearch 中，多字段查询允许您在多个字段上同时执行搜索，以获取更精确的结果。最常用的多字段查询类型是 multi_match 查询。multi_match 查询是 match 查询的扩展，能够在多个字段中搜索指定的关键词。 multi_match 查询支持多种匹配模式，如 best_fields、most_fields、cross_fields、phrase 和 phrase_prefix。以下是各模式的简要介绍： best_fields：默认模式，选择匹配度最高的字段。 most_fields：计算每个字段的匹配度，然后将匹配度相加。 cross_fields：将多个字段视为一个字段进行匹配，适用于分析文本被分散到多个字段的情况。 phrase：短语匹配，确保词项顺序与查询相同。 phrase_prefix：短语前缀匹配，允许词项的部分匹配。 我们先导入一些示例数据到一个索引 documents 中： 123456789POST /documents/_bulk{ &quot;index&quot;: { &quot;_id&quot;: 1 } }{ &quot;title&quot;: &quot;Easysearch Guide&quot;, &quot;content&quot;: &quot;This is an introductory guide to Easysearch .&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 2 } }{ &quot;title&quot;: &quot;Advanced Easysearch &quot;, &quot;content&quot;: &quot;This guide covers advanced topics in Easysearch .&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 3 } }{ &quot;title&quot;: &quot;Easysearch in Action&quot;, &quot;content&quot;: &quot;Practical guide to Easysearch usage.&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 4 } }{ &quot;title&quot;: &quot;Learning Easysearch &quot;, &quot;content&quot;: &quot;Beginner's guide to learning Easysearch .&quot; } 我们将使用 multi_match 查询在 title 和 content 字段中同时搜索关键词。 基本 multi_match 查询： 123456789POST /documents/_search{ &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;guide&quot;, &quot;fields&quot;: [&quot;title&quot;, &quot;content&quot;] } }} **指定匹配模式为 best_fields**： 12345678910POST /documents/_search{ &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;guide&quot;, &quot;fields&quot;: [&quot;title&quot;, &quot;content&quot;], &quot;type&quot;: &quot;best_fields&quot; } }} **指定匹配模式为 most_fields**： 12345678910POST /documents/_search{ &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;guide&quot;, &quot;fields&quot;: [&quot;title&quot;, &quot;content&quot;], &quot;type&quot;: &quot;most_fields&quot; } }} 使用 cross_fields 模式： 12345678910POST /documents/_search{ &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;Easysearch guide&quot;, &quot;fields&quot;: [&quot;title&quot;, &quot;content&quot;], &quot;type&quot;: &quot;cross_fields&quot; } }} **短语匹配 (phrase)**： 12345678910POST /documents/_search{ &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;introductory guide&quot;, &quot;fields&quot;: [&quot;title&quot;, &quot;content&quot;], &quot;type&quot;: &quot;phrase&quot; } }} **短语前缀匹配 (phrase_prefix)**： 12345678910POST /documents/_search{ &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;introductory gui&quot;, &quot;fields&quot;: [&quot;title&quot;, &quot;content&quot;], &quot;type&quot;: &quot;phrase_prefix&quot; } }} query：要搜索的关键词或短语。 fields：要搜索的字段列表，可以包含一个或多个字段。 type：指定匹配模式，默认为 best_fields。 使用 multi_match 查询，您可以在多个字段上同时执行搜索，获得更精确和全面的结果。通过指定不同的匹配模式，您可以调整查询行为以满足特定的搜索需求。无论是基本关键词匹配、短语匹配还是跨字段匹配，multi_match 查询都提供了强大的功能来处理复杂的搜索场景。 除此之外，还可以使用 boost 参数用于调整特定字段的权重，从而影响搜索结果的相关性评分。multi_match 查询支持为不同字段设置不同的 boost 值，以便在搜索结果中优先显示某些字段的匹配项。 布尔查询布尔查询是 Easysearch 中非常强大且灵活的一种查询方式，它允许用户通过组合多个查询条件来实现复杂的搜索需求。布尔查询使用 bool 查询类型，可以包含以下几种子句：must、filter、must_not 和 should。每种子句都有其特定的用途和语义。 must： 包含在 must 数组中的查询条件必须匹配，类似于逻辑上的 AND 操作。 如果有多个条件，所有条件都必须满足，文档才会被包含在结果集中。 filter： 包含在 filter 数组中的查询条件必须匹配，但它不会影响评分。 filter 子句通常用于对性能要求较高的过滤操作，因为它不计算相关性评分。 must_not： 包含在 must_not 数组中的查询条件必须不匹配，类似于逻辑上的 NOT 操作。 如果有任何一个条件匹配，文档就会被排除在结果集之外。 should： 包含在 should 数组中的查询条件至少匹配一个。 如果布尔查询中没有 must 子句，则至少要匹配一个 should 子句。 should 子句在计算相关性评分时也有影响。 minimum_should_match： 指定 should 子句中至少需要满足的条件数量。 首先，我们需要创建一个名为books的索引，并定义它的映射（mappings）。映射用于指定每个字段的数据类型。在这个例子中，类别和书名字段都被定义为keyword类型，这是因为我们需要进行精确匹配查询。 123456789PUT /books{ &quot;mappings&quot;: { &quot;properties&quot;: { &quot;类别&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;书名&quot;: { &quot;type&quot;: &quot;keyword&quot; } } }} 接下来，我们使用批量操作（bulk API）将一些示例数据导入到books索引中。这些数据包括不同类别的书籍。 1234567891011POST /books/_bulk{ &quot;index&quot;: { &quot;_id&quot;: 1 } }{ &quot;类别&quot;: &quot;文学&quot;, &quot;书名&quot;: &quot;我的阿勒泰&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 2 } }{ &quot;类别&quot;: &quot;文学&quot;, &quot;书名&quot;: &quot;平凡的世界&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 3 } }{ &quot;类别&quot;: &quot;科学&quot;, &quot;书名&quot;: &quot;时间简史&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 4 } }{ &quot;类别&quot;: &quot;文学&quot;, &quot;书名&quot;: &quot;百年孤独&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 5 } }{ &quot;类别&quot;: &quot;文学&quot;, &quot;书名&quot;: &quot;红楼梦&quot; } 现在，我们使用布尔查询来搜索类别为“文学”并且书名为“我的阿勒泰”的文档。这里使用的是must子句，表示查询结果必须满足所有条件。 1234567891011POST /books/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;term&quot;: { &quot;类别&quot;: &quot;文学&quot; } }, { &quot;term&quot;: { &quot;书名&quot;: &quot;我的阿勒泰&quot; } } ] } }} 我们还可以使用filter子句来执行相同的查询。filter子句用于过滤文档，且不会影响文档的相关性评分。这在不需要计算相关性评分时可以提高查询性能。 1234567891011POST /books/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;filter&quot;: [ { &quot;term&quot;: { &quot;类别&quot;: &quot;文学&quot; } }, { &quot;term&quot;: { &quot;书名&quot;: &quot;我的阿勒泰&quot; } } ] } }} 当我们执行上述查询时，期望返回的结果是books索引中类别为“文学”且书名为“我的阿勒泰”的文档。无论是使用must还是filter子句，结果应该都是： 123456789101112131415161718{ &quot;hits&quot;: { &quot;total&quot;: { &quot;value&quot;: 1, &quot;relation&quot;: &quot;eq&quot; }, &quot;hits&quot;: [ { &quot;_index&quot;: &quot;books&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_source&quot;: { &quot;类别&quot;: &quot;文学&quot;, &quot;书名&quot;: &quot;我的阿勒泰&quot; } } ] }} 1234567891011121314151617181920212223242526POST /_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;term&quot;: { &quot;user.id&quot;: &quot;kimchy&quot; } } ], &quot;filter&quot;: [ { &quot;term&quot;: { &quot;tags&quot;: &quot;production&quot; } } ], &quot;must_not&quot;: [ { &quot;range&quot;: { &quot;age&quot;: { &quot;gte&quot;: 10, &quot;lte&quot;: 20 } } } ], &quot;should&quot;: [ { &quot;term&quot;: { &quot;tags&quot;: &quot;env1&quot; } }, { &quot;term&quot;: { &quot;tags&quot;: &quot;deployed&quot; } } ], &quot;minimum_should_match&quot;: 1, &quot;boost&quot;: 1.0 } }} must 子句：必须匹配的条件，文档必须包含user.id为kimchy。 filter 子句：过滤条件，文档必须包含tags为production，但不会影响评分。 must_not 子句：不匹配的条件，文档的age字段不能在 10 到 20 之间。 should 子句：可选匹配条件，至少需要匹配一个should子句中的条件。这里要求tags字段匹配env1或deployed。 **minimum_should_match**：至少需要匹配一个should子句中的条件。 **boost**：提升查询的整体评分。 为了展示这个 DSL，我们需要创建一个索引并导入一些数据。假设我们要在 Easysearch 中创建一个索引users，并插入一些测试数据。 创建索引 12345678910PUT /users{ &quot;mappings&quot;: { &quot;properties&quot;: { &quot;user.id&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;tags&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;age&quot;: { &quot;type&quot;: &quot;integer&quot; } } }} 批量导入数据 1234567891011POST /users/_bulk{ &quot;index&quot;: { &quot;_id&quot;: 1 } }{ &quot;user.id&quot;: &quot;kimchy&quot;, &quot;tags&quot;: [&quot;production&quot;, &quot;env1&quot;], &quot;age&quot;: 25 }{ &quot;index&quot;: { &quot;_id&quot;: 2 } }{ &quot;user.id&quot;: &quot;kimchy&quot;, &quot;tags&quot;: [&quot;production&quot;], &quot;age&quot;: 15 }{ &quot;index&quot;: { &quot;_id&quot;: 3 } }{ &quot;user.id&quot;: &quot;kimchy&quot;, &quot;tags&quot;: [&quot;deployed&quot;], &quot;age&quot;: 30 }{ &quot;index&quot;: { &quot;_id&quot;: 4 } }{ &quot;user.id&quot;: &quot;kimchy&quot;, &quot;tags&quot;: [&quot;test&quot;], &quot;age&quot;: 35 }{ &quot;index&quot;: { &quot;_id&quot;: 5 } }{ &quot;user.id&quot;: &quot;other&quot;, &quot;tags&quot;: [&quot;production&quot;], &quot;age&quot;: 25 } 接下来执行布尔查询： 1234567891011121314151617181920212223242526POST /users/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;term&quot;: { &quot;user.id&quot;: &quot;kimchy&quot; } } ], &quot;filter&quot;: [ { &quot;term&quot;: { &quot;tags&quot;: &quot;production&quot; } } ], &quot;must_not&quot;: [ { &quot;range&quot;: { &quot;age&quot;: { &quot;gte&quot;: 10, &quot;lte&quot;: 20 } } } ], &quot;should&quot;: [ { &quot;term&quot;: { &quot;tags&quot;: &quot;env1&quot; } }, { &quot;term&quot;: { &quot;tags&quot;: &quot;deployed&quot; } } ], &quot;minimum_should_match&quot;: 1, &quot;boost&quot;: 1.0 } }} 根据以上查询，预期返回的结果应该符合以下条件： user.id必须是kimchy（由must子句决定）。 tags必须包含production（由filter子句决定）。 age字段不在 10 到 20 之间（由must_not子句决定）。 tags字段中至少包含env1或deployed中的一个（由should子句和minimum_should_match参数决定）。 123456789101112131415161718192021222324252627282930{ &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: { &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 }, &quot;hits&quot;: { &quot;total&quot;: { &quot;value&quot;: 1, &quot;relation&quot;: &quot;eq&quot; }, &quot;max_score&quot;: 1.3769134, &quot;hits&quot;: [ { &quot;_index&quot;: &quot;users&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1.3769134, &quot;_source&quot;: { &quot;user.id&quot;: &quot;kimchy&quot;, &quot;tags&quot;: [&quot;production&quot;, &quot;env1&quot;], &quot;age&quot;: 25 } } ] }} SQL 搜索Easysearch 直接支持 SQL 查询，无需额外安装插件，同时兼容 Elasticsearch 的 SQL 调用方式，还可以直接编写原生 SQL 查询。 以下是一些测试 SQL 语句的示例： 1234567891011121314151617SELECT * FROM my_index;SELECT * FROM my_index LIMIT 2;SELECT * FROM my_index ORDER BY name;SELECT name AS full_name, age FROM my_index WHERE age &gt; 25;SELECT name AS full_name, age FROM my_index WHERE age = 25;SELECT * FROM my_index WHERE age IS NULL;SELECT DISTINCT age FROM my_index;SELECT MIN(age), MAX(age), AVG(age) FROM my_index;SELECT age, COUNT(*) AS CNT FROM my_index GROUP BY age; 使用 Easysearch 执行 SQL 查询Easysearch 提供了对直接使用 SQL 查询的支持。以下是如何在 Easysearch 中通过 POST 请求使用 _sql 端点进行查询的示例： 执行 SQL 查询非常简单，只需通过 POST 请求发送 SQL 查询即可。以下是一个示例： 1234POST /_sql{ &quot;query&quot;: &quot;SELECT name AS full_name, age FROM my_index WHERE age &gt; 25&quot;} 你也可以规定返回 JSON 格式： 1234POST /_sql?format=json{ &quot;query&quot;: &quot;SELECT name AS full_name, age FROM my_index WHERE age &gt; 25&quot;} 和 Elasticsearch 一样，Easysearch 允许你通过 POST 请求直接在集群上运行 SQL 查询，并返回查询结果。以下是一些常见的 SQL 查询示例及其对应的 POST 请求： 查询所有文档： 1234POST /_sql{ &quot;query&quot;: &quot;SELECT * FROM my_index&quot;} 限制返回文档数： 1234POST /_sql{ &quot;query&quot;: &quot;SELECT * FROM my_index LIMIT 2&quot;} 按字段排序： 1234POST /_sql{ &quot;query&quot;: &quot;SELECT * FROM my_index ORDER BY name&quot;} 筛选条件查询： 1234POST /_sql{ &quot;query&quot;: &quot;SELECT name AS full_name, age FROM my_index WHERE age &gt; 25&quot;} 精确值查询： 1234POST /_sql{ &quot;query&quot;: &quot;SELECT name AS full_name, age FROM my_index WHERE age = 25&quot;} 查询空值： 1234POST /_sql{ &quot;query&quot;: &quot;SELECT * FROM my_index WHERE age IS NULL&quot;} 查询唯一值： 1234POST /_sql{ &quot;query&quot;: &quot;SELECT DISTINCT age FROM my_index&quot;} 聚合函数查询： 1234POST /_sql{ &quot;query&quot;: &quot;SELECT MIN(age), MAX(age), AVG(age) FROM my_index&quot;} 分组统计： 1234POST /_sql{ &quot;query&quot;: &quot;SELECT age, COUNT(*) AS CNT FROM my_index GROUP BY age&quot;} 多表操作的 SQL 语句以下是多表操作的 SQL 语句及其解释： 子查询： 1SELECT * FROM table1 t1 WHERE t1.id IN (SELECT id FROM table2) 这个查询从 table1 中选择所有字段的记录，其中这些记录的 id 在 table2 表中也存在。 内连接： 1SELECT * FROM table1 t1 JOIN table2 t2 ON t1.id = t2.id 这个查询进行内连接，从 table1 和 table2 中选择所有字段的记录，前提是 table1 和 table2 中 id 相等。 左连接： 1SELECT * FROM table1 t1 LEFT JOIN table2 t2 ON t1.id = t2.id 这个查询进行左连接，从 table1 和 table2 中选择所有字段的记录，即使 table2 中没有匹配的记录，也会返回 table1 中的所有记录，未匹配到的部分会用 NULL 填充。 右连接： 1SELECT * FROM table1 t1 RIGHT JOIN table2 t2 ON t1.id = t2.id 这个查询进行右连接，从 table1 和 table2 中选择所有字段的记录，即使 table1 中没有匹配的记录，也会返回 table2 中的所有记录，未匹配到的部分会用 NULL 填充。 假设我们有两个索引 table1 和 table2，对应于 SQL 中的两个表。 **创建索引 table1**： 123456789PUT /table1{ &quot;mappings&quot;: { &quot;properties&quot;: { &quot;id&quot;: { &quot;type&quot;: &quot;integer&quot; }, &quot;name&quot;: { &quot;type&quot;: &quot;text&quot; } } }} **创建索引 table2**： 123456789PUT /table2{ &quot;mappings&quot;: { &quot;properties&quot;: { &quot;id&quot;: { &quot;type&quot;: &quot;integer&quot; }, &quot;value&quot;: { &quot;type&quot;: &quot;text&quot; } } }} **导入数据到 table1**： 123456789POST /table1/_bulk{ &quot;index&quot;: { &quot;_id&quot;: 1 } }{ &quot;id&quot;: 1, &quot;name&quot;: &quot;Alice&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 2 } }{ &quot;id&quot;: 2, &quot;name&quot;: &quot;Bob&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 3 } }{ &quot;id&quot;: 3, &quot;name&quot;: &quot;Charlie&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 4 } }{ &quot;id&quot;: 4, &quot;name&quot;: &quot;David&quot; } **导入数据到 table2**： 123456789POST /table2/_bulk{ &quot;index&quot;: { &quot;_id&quot;: 1 } }{ &quot;id&quot;: 1, &quot;value&quot;: &quot;Value1&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 2 } }{ &quot;id&quot;: 2, &quot;value&quot;: &quot;Value2&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 5 } }{ &quot;id&quot;: 5, &quot;value&quot;: &quot;Value5&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 6 } }{ &quot;id&quot;: 6, &quot;value&quot;: &quot;Value6&quot; } 导入数据后，可以使用 SQL 来执行这些查询： 子查询： 1234POST /_sql{ &quot;query&quot;: &quot;SELECT * FROM table1 WHERE id IN (SELECT id FROM table2)&quot;} 内连接： 1234POST /_sql{ &quot;query&quot;: &quot;SELECT * FROM table1 t1 JOIN table2 t2 ON t1.id = t2.id&quot;} 左连接： 1234POST /_sql{ &quot;query&quot;: &quot;SELECT * FROM table1 t1 LEFT JOIN table2 t2 ON t1.id = t2.id&quot;} 右连接： 1234POST /_sql{ &quot;query&quot;: &quot;SELECT * FROM table1 t1 RIGHT JOIN table2 t2 ON t1.id = t2.id&quot;} 效果如下： SQL 全文检索match 和 match_phrase 是 Easysearch 中用于全文搜索的查询类型，它们在处理文本匹配方面有不同的用途： match 查询： match 查询用于对文档进行全文搜索。 它将搜索关键词进行分词，并对这些分词后的词项进行搜索。 适用于查询单个或多个字段，可以进行布尔操作（如 “AND”, “OR”）。 例如，搜索 “Easysearch is powerful” 会被分词为 “Easysearch “, “is”, “powerful” 三个词，然后对这三个词进行搜索，文档中包含这些词的都会被认为是匹配的。 1234567{ &quot;query&quot;: { &quot;match&quot;: { &quot;content&quot;: &quot;Easysearch is powerful&quot; } }} match_phrase 查询： match_phrase 查询用于短语搜索。 它要求搜索的短语必须在文档中出现且词的顺序相同，词之间的间隔也必须与查询中的短语相同。 适用于需要精确匹配短语的场景。 例如，搜索 “Easysearch is powerful” 时，只有包含这个确切短语的文档才会被认为是匹配的。 1234567{ &quot;query&quot;: { &quot;match_phrase&quot;: { &quot;content&quot;: &quot;Easysearch is powerful&quot; } }} 总结来说，match 更灵活，用于一般的关键词搜索，而 match_phrase 则用于需要精确匹配短语的搜索。 SQL 全文检索示例我们先造一些数据，然后使用 SQL 来进行全文检索。 批量导入数据： 12345678910111213POST /table3/_bulk{ &quot;index&quot;: { &quot;_id&quot;: 1 } }{ &quot;id&quot;: 1, &quot;test&quot;: &quot;The quick brown fox jumps over the lazy dog&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 2 } }{ &quot;id&quot;: 2, &quot;test&quot;: &quot;Foxes are wild animals&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 3 } }{ &quot;id&quot;: 3, &quot;test&quot;: &quot;Jump high to catch the ball&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 4 } }{ &quot;id&quot;: 4, &quot;test&quot;: &quot;Some animals can jump very high&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 5 } }{ &quot;id&quot;: 5, &quot;test&quot;: &quot;The lazy dog sleeps all day&quot; }{ &quot;index&quot;: { &quot;_id&quot;: 6 } }{ &quot;id&quot;: 6, &quot;test&quot;: &quot;The foxes jump all day&quot; } 执行全文检索的 SQL 查询： 12345SELECT * FROM table3;SELECT * FROM table3 WHERE match(test, 'jump');SELECT * FROM table3 WHERE match_phrase(test, 'foxes jump'); 总结随着数据量的不断增加，高效的数据搜索和分析变得尤为重要。Elasticsearch 以其强大的全文搜索能力和灵活的数据处理能力成为行业标准。Easysearch 作为 Elasticsearch 的优化版本，不仅继承了其强大的功能，还在性能和安全性上做了进一步的提升，为企业提供了一个高效、稳定且易于迁移的搜索引擎解决方案。通过深入了解这些技术和实践其应用，开发者和企业能够更好地利用这些工具来应对现代数据挑战，推动业务的持续发展和创新。","link":"/posts/ebd08f3f/"},{"title":"Easysearch、Elasticsearch、Amazon OpenSearch 快照兼容对比","text":"在当今的数据驱动时代，搜索引擎的快照功能在数据保护和灾难恢复中至关重要。本文将对 Easysearch、Elasticsearch 和 Amazon OpenSearch 的快照兼容性进行比较，分析它们在快照创建、恢复、存储格式和跨平台兼容性等方面的特点，帮助大家更好地理解这些搜索引擎的差异，从而选择最适合自己需求的解决方案。 启动集群Easysearch服务器一般情况下默认参数都是很低的，而 Easysearch/Elasticsearch 是内存大户，所以就需要进行系统调优。 1sysctl -w vm.max_map_count=262144 vm.max_map_count 是一个 Linux 内核参数，用于控制单个进程可以拥有的最大内存映射区域（VMA，Virtual Memory Areas）的数量。内存映射区域是指通过内存映射文件或匿名内存映射创建的虚拟内存区域。 这个参数在一些应用程序中非常重要，尤其是那些需要大量内存映射的应用程序，比如 Elasticsearch。Elasticsearch 使用内存映射文件来索引和搜索数据，这可能需要大量的内存映射区域。如果 vm.max_map_count 设置得太低，Elasticsearch 可能无法正常工作，并会出现错误信息。 调整 vm.max_map_count 参数的一些常见原因： 支持大型数据集：应用程序（如 Elasticsearch）在处理大型数据集时可能需要大量内存映射区域。增加 vm.max_map_count 可以确保这些应用程序有足够的内存映射区域来处理数据。 防止内存错误：如果 vm.max_map_count 设置得太低，当应用程序尝试创建超过限制的内存映射时，会出现错误，导致应用程序崩溃或无法正常工作。 优化性能：适当地设置 vm.max_map_count 可以优化应用程序的性能，确保内存映射操作顺利进行。 检查当前的 vm.max_map_count 值： 1sysctl vm.max_map_count 或者查看 /proc/sys/vm/max_map_count 文件： 1cat /proc/sys/vm/max_map_count Elasticsearch 官方建议将 vm.max_map_count 设置为至少 262144。对于其他应用程序。 Easysearch 具体安装步骤见INFINI Easysearch 尝鲜 Hands on Amazon OpenSearch使用 Amazon Web Services 控制台进行创建。 Elasticsearch使用如下 docker compose 部署一个三节点的 ES 集群： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970version: &quot;2.2&quot;services: es01: image: docker.elastic.co/elasticsearch/elasticsearch:7.10.2 container_name: es01 environment: - node.name=es01 - cluster.name=es-docker-cluster - discovery.seed_hosts=es02,es03 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; ulimits: memlock: soft: -1 hard: -1 volumes: - data01:/usr/share/elasticsearch/data ports: - 9200:9200 networks: - elastic es02: image: docker.elastic.co/elasticsearch/elasticsearch:7.10.2 container_name: es02 environment: - node.name=es02 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es03 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; ulimits: memlock: soft: -1 hard: -1 volumes: - data02:/usr/share/elasticsearch/data networks: - elastic es03: image: docker.elastic.co/elasticsearch/elasticsearch:7.10.2 container_name: es03 environment: - node.name=es03 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es02 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; ulimits: memlock: soft: -1 hard: -1 volumes: - data03:/usr/share/elasticsearch/data networks: - elasticvolumes: data01: driver: local data02: driver: local data03: driver: localnetworks: elastic: driver: bridge 由于这个 docker compose 没有关于 kibana 的配置，所以我们还是用 Console 添加原生的 Elasticsearch 集群 集群信息 快照还原的步骤快照前的准备插件安装本次测试选择把索引快照备份到 Amazon S3，所以需要使用 S3 repository plugin，这个插件添加了对使用 Amazon S3 作为快照/恢复存储库的支持。 Easysearch 和 OpenSearch 集群自带了这个插件，所以无需额外安装。 对于自己部署的三节点 Elasticsearch 则需要进入每一个节点运行安装命令然后再重启集群，建议使用自动化运维工具来做这步，安装命令如下: 1sudo bin/elasticsearch-plugin install repository-s3 如果不再需要这个插件，可以这样删除。 1sudo bin/elasticsearch-plugin remove repository-s3 由于需要和 Amazon Web Services 打交道，所以我们需要设置 IAM 凭证，这个插件可以从 EC2 IAM instance profile，ECS task role 以及 EKS 的 Service account 读取相应的凭证。 对于托管的 Amazon OpenSearch 来说，我们无法在托管的 EC2 上绑定我们的凭证，所以需要新建一个 OpenSearchSnapshotRole，然后通过当前的用户把这个角色传递给服务，也就是我们说的 IAM:PassRole。 创建 OpenSearchSnapshotRole，策略如下： 123456789101112131415161718192021222324{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [{ &quot;Action&quot;: [ &quot;s3:ListBucket&quot; ], &quot;Effect&quot;: &quot;Allow&quot;, &quot;Resource&quot;: [ &quot;arn:aws:s3:::bucket-name&quot; ] }, { &quot;Action&quot;: [ &quot;s3:GetObject&quot;, &quot;s3:PutObject&quot;, &quot;s3:DeleteObject&quot; ], &quot;Effect&quot;: &quot;Allow&quot;, &quot;Resource&quot;: [ &quot;arn:aws:s3:::bucket-name/*&quot; ] } ]} 信任关系如下： 123456789101112{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Principal&quot;: { &quot;Service&quot;: &quot;es.amazonaws.com&quot; }, &quot;Action&quot;: &quot;sts:AssumeRole&quot; } ]} 然后在我们的 IAM user 上加上 PassRole 的权限，这样我们就可以把 OpenSearchSnapshotRole 传递给 OpenSearch 集群。 12345678910{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: &quot;iam:PassRole&quot;, &quot;Resource&quot;: &quot;arn:aws:iam::123456789012:role/OpenSearchSnapshotRole&quot; } ]} 注册存储库在源集群执行注册 12345678PUT /_snapshot/snapshot-repo-name{ &quot;type&quot;: &quot;s3&quot;, &quot;settings&quot;: { &quot;bucket&quot;: &quot;&lt;bucket-name&gt;&quot;, &quot;base_path&quot;: &quot;&lt;bucket-prefix&gt;&quot;, } } 在目标集群同样执行这个语句，为了防止覆盖源集群存储库的数据，将 “readonly”: true 添加到”settings” PUT 请求中，这样就只有一个集群具有对存储库的写入权限。 如果 Bucket 在中国区，那么还需要加上endpoint: https://s3.&lt; region &gt;.amazonaws.com.cn这样的参数。 123456789PUT /_snapshot/snapshot-repo-name{ &quot;type&quot;: &quot;s3&quot;, &quot;settings&quot;: { &quot;bucket&quot;: &quot;&lt;bucket-name&gt;&quot;, &quot;base_path&quot;: &quot;&lt;bucket-prefix&gt;&quot;, &quot;readonly&quot;: true, } } 对于 OpenSearch 来说，还需要执行 passrole，所以还需要添加role_arn这个字段，由于 IAM:PassRole 需要对 HTTP 请求做 signV4 日签名，所以这部常常使用 Postman 来完成。把角色传递过去之后，接下来的快照还原操作就可以在 OpenSearch Dashboard 中进行操作了。 需要注意的是，需要在 auth 这里输入 AccessKey，SecretKey，AWS Region，Service Name（es）来做 SignV4 的签名。 请求体如下： 123456789{ &quot;type&quot;: &quot;s3&quot;, &quot;settings&quot;: { &quot;bucket&quot;: &quot;&lt;bucket-name&gt;&quot;, &quot;base_path&quot;: &quot;&lt;bucket-prefix&gt;&quot;, &quot;readonly&quot;: true, &quot;role_arn&quot;: &quot;arn:aws:iam::123456789012:role/OpenSearchSnapshotRole&quot; }} 查看所有注册的存储库： GET _snapshot：这个命令返回所有已注册的快照存储库列表及其基本信息。 1GET _snapshot 123456789{ &quot;es_repository&quot;: { &quot;type&quot;: &quot;s3&quot;, &quot;settings&quot;: { &quot;bucket&quot;: &quot;your-s3-bucket-name&quot;, &quot;region&quot;: &quot;your-s3-bucket-region&quot; } }} 查看特定存储库的详细信息：GET _snapshot/es_repository：这个命令返回名为es_repository的存储库的详细配置信息，包括存储桶名称、区域和其他设置。 1GET _snapshot/es_repository 1234567891011{ &quot;es_repository&quot;: { &quot;type&quot;: &quot;s3&quot;, &quot;settings&quot;: { &quot;bucket&quot;: &quot;your-s3-bucket-name&quot;, &quot;region&quot;: &quot;your-s3-bucket-region&quot;, &quot;access_key&quot;: &quot;your-access-key&quot;, &quot;secret_key&quot;: &quot;your-secret-key&quot; } }} 查看特定存储库中的快照：GET _cat/snapshots/es_repository?v：这个命令返回es_repository存储库中的所有快照及其详细信息，包括快照 ID、状态、开始时间、结束时间、持续时间、包含的索引数量、成功和失败的分片数量等。 1GET _cat/snapshots/es_repository?v 123id status start_epoch start_time end_epoch end_time duration indices successful_shards failed_shards total_shardssnapshot_1 SUCCESS 1628884800 08:00:00 1628888400 09:00:00 1h 3 10 0 10snapshot_2 SUCCESS 1628971200 08:00:00 1628974800 09:00:00 1h 3 10 0 10 创建索引快照12345# PUT _snapshot/my_repository/&lt;my_snapshot_{now/d}&gt;PUT _snapshot/my_repository/my_snapshot{ &quot;indices&quot;: &quot;my-index,logs-my_app-default&quot;,} 根据快照的大小不同，完成快照可能需要一些时间。默认情况下，create snapshot API 只会异步启动快照过程，该过程在后台运行。要更改为同步调用，可以将 wait_for_completion 查询参数设置为 true。 1PUT _snapshot/my_repository/my_snapshot?wait_for_completion=true 另外还可以使用 clone snapshot API 克隆现有的快照。要监控当前正在运行的快照，可以使用带有 _current 请求路径参数的 get snapshot API。 1GET _snapshot/my_repository/_current 如果要获取参与当前运行快照的每个分片的完整详细信息，可以使用 get snapshot status API。 1GET _snapshot/_status 成功创建快照之后，就可以在 S3 上看到备份的数据块文件，这个是正确的快照层级结构： 需要注意的是， “base_path”: ““这里最好不要加/，虽然不影响同集群迁移，这个会为我们在不同厂商的搜索引擎中迁移遇到问题，可能是这样的，所以需要注意。所以在 Open Search 中还原 Elasticsearch 就遇到了这个问题： 1234567891011121314151617{ &quot;error&quot;: { &quot;root_cause&quot;: [ { &quot;type&quot;: &quot;snapshot_missing_exception&quot;, &quot;reason&quot;: &quot;[easy_repository:2/-jOQ0oucQDGF3hJMNz-vKQ] is missing&quot; } ], &quot;type&quot;: &quot;snapshot_missing_exception&quot;, &quot;reason&quot;: &quot;[easy_repository:2/-jOQ0oucQDGF3hJMNz-vKQ] is missing&quot;, &quot;caused_by&quot;: { &quot;type&quot;: &quot;no_such_file_exception&quot;, &quot;reason&quot;: &quot;Blob object [11111/indices/7fv2zAi4Rt203JfsczUrBg/meta-YGnzxZABRBxW-2vqcmci.dat] not found: The specified key does not exist. (Service: S3, Status Code: 404, Request ID: R71DDHX4XXM0434T, Extended Request ID: d9M/HWvPvMFdPhB6KX+wYCW3ZFqeFo9EoscWPkulOXWa+TnovAE5PlemtuVzKXjlC+rrgskXAus=)&quot; } }, &quot;status&quot;: 404} 恢复索引快照1234POST _snapshot/my_repository/my_snapshot_2099.05.06/_restore{ &quot;indices&quot;: &quot;my-index,logs-my_app-default&quot;,} 各个集群的还原 Elasticsearch 7.10.2 的快照可以还原到 Easysearch 和 Amazon OpenSearch 从 Easysearch 1.8.2 还原到 Elasticsearch 7.10.2 报错如下： 1234567891011121314151617{ &quot;error&quot;: { &quot;root_cause&quot;: [ { &quot;type&quot;: &quot;snapshot_restore_exception&quot;, &quot;reason&quot;: &quot;[s3_repository:1/a2qV4NYIReqvgW6BX_nxxw] cannot restore index [my_indexs] because it cannot be upgraded&quot; } ], &quot;type&quot;: &quot;snapshot_restore_exception&quot;, &quot;reason&quot;: &quot;[s3_repository:1/a2qV4NYIReqvgW6BX_nxxw] cannot restore index [my_indexs] because it cannot be upgraded&quot;, &quot;caused_by&quot;: { &quot;type&quot;: &quot;illegal_state_exception&quot;, &quot;reason&quot;: &quot;The index [[my_indexs/ALlTCIr0RJqtP06ouQmf0g]] was created with version [1.8.2] but the minimum compatible version is [6.0.0-beta1]. It should be re-indexed in Elasticsearch 6.x before upgrading to 7.10.2.&quot; } }, &quot;status&quot;: 500} 从 Amazon OpenSearch 2.1.3 还原到 Elasticsearch 7.10.2 报错如下（无论是否开启兼容模式）： 12345678910111213{ &quot;error&quot;: { &quot;root_cause&quot;: [ { &quot;type&quot;: &quot;snapshot_restore_exception&quot;, &quot;reason&quot;: &quot;[aos:2/D-oyYSscSdCbZFcmPZa_yg] the snapshot was created with Elasticsearch version [36.34.78-beta2] which is higher than the version of this node [7.10.2]&quot; } ], &quot;type&quot;: &quot;snapshot_restore_exception&quot;, &quot;reason&quot;: &quot;[aos:2/D-oyYSscSdCbZFcmPZa_yg] the snapshot was created with Elasticsearch version [36.34.78-beta2] which is higher than the version of this node [7.10.2]&quot; }, &quot;status&quot;: 500} 从 Easysearch 1.8.2 还原到 Amazon OpenSearch2.13 报错如下（无论是否开启兼容模式）： 1234567891011121314151617{ &quot;error&quot;: { &quot;root_cause&quot;: [ { &quot;type&quot;: &quot;snapshot_restore_exception&quot;, &quot;reason&quot;: &quot;[easy_repository:2/LE18AWHlRJu9rpz9BJatUQ] cannot restore index [my_indexs] because it cannot be upgraded&quot; } ], &quot;type&quot;: &quot;snapshot_restore_exception&quot;, &quot;reason&quot;: &quot;[easy_repository:2/LE18AWHlRJu9rpz9BJatUQ] cannot restore index [my_indexs] because it cannot be upgraded&quot;, &quot;caused_by&quot;: { &quot;type&quot;: &quot;illegal_state_exception&quot;, &quot;reason&quot;: &quot;The index [[my_indexs/VHOo7yfDTRa48uhQvquFzQ]] was created with version [1.8.2] but the minimum compatible version is OpenSearch 1.0.0 (or Elasticsearch 7.0.0). It should be re-indexed in OpenSearch 1.x (or Elasticsearch 7.x) before upgrading to 2.13.0.&quot; } }, &quot;status&quot;: 500} Amazon OpenSearch 还原到 Easysearch 同样失败 1234567891011121314151617{ &quot;error&quot;: { &quot;root_cause&quot;: [ { &quot;type&quot;: &quot;snapshot_restore_exception&quot;, &quot;reason&quot;: &quot;[aoss:2/D-oyYSscSdCbZFcmPZa_yg] cannot restore index [aos] because it cannot be upgraded&quot; } ], &quot;type&quot;: &quot;snapshot_restore_exception&quot;, &quot;reason&quot;: &quot;[aoss:2/D-oyYSscSdCbZFcmPZa_yg] cannot restore index [aos] because it cannot be upgraded&quot;, &quot;caused_by&quot;: { &quot;type&quot;: &quot;illegal_state_exception&quot;, &quot;reason&quot;: &quot;The index [[aos/864WjTAXQCaxJ829V5ktaw]] was created with version [36.34.78-beta2] but the minimum compatible version is [6.0.0]. It should be re-indexed in Easysearch 6.x before upgrading to 1.8.2.&quot; } }, &quot;status&quot;: 500} Elasticsearch8.14.3 迁移到 Amazon OpenSearch 或者 Elasticsearch 都是有这个报错： 123456789101112131415161718192021{ &quot;error&quot;: { &quot;root_cause&quot;: [ { &quot;type&quot;: &quot;parsing_exception&quot;, &quot;reason&quot;: &quot;Failed to parse object: unknown field [uuid] found&quot;, &quot;line&quot;: 1, &quot;col&quot;: 25 } ], &quot;type&quot;: &quot;repository_exception&quot;, &quot;reason&quot;: &quot;[snap] Unexpected exception when loading repository data&quot;, &quot;caused_by&quot;: { &quot;type&quot;: &quot;parsing_exception&quot;, &quot;reason&quot;: &quot;Failed to parse object: unknown field [uuid] found&quot;, &quot;line&quot;: 1, &quot;col&quot;: 25 } }, &quot;status&quot;: 500} 这是由于 Elasticsearch8 在创建快照的时候会默认加上一个 UUID 的字段，所以我们低版本的 Easysearch、Amazon OpenSearch 中会找不到这个字段，在执行GET _cat/snapshots/snap?v的时候就报错，及时在注册存储库的时候显示加上 UUID 的字段也无事无补。 123456789{ &quot;snapshot-repo-name&quot;: { &quot;type&quot;: &quot;s3&quot;, &quot;uuid&quot;: &quot;qlJ0uqErRmW6aww2Fyt4Fg&quot;, &quot;settings&quot;: { &quot;bucket&quot;: &quot;&lt;bucket-name&gt;&quot;, &quot;base_path&quot;: &quot;&lt;bucket-prefix&gt;&quot;, } }, 以下是兼容性对比，每行第一列代表源集群，第一行代表目标集群： 快照兼容对比 Easysearch 1.8.2 Elasticsearch 7.10.2 OpenSearch 2.13 Easysearch 1.8.2 兼容 不兼容 不兼容 Elasticsearch 7.10.2 兼容 兼容 兼容 OpenSearch 2.13 不兼容 不兼容 兼容 Elasticsearch 的兼容列表官方的列表如下： 参考文献开始使用 Elastic Stack 和 Docker Compose：第 1 部分https://www.elastic.co/cn/blog/getting-started-with-the-elastic-stack-and-docker-compose Docker Compose 部署多节点 Elasticsearch https://www.elastic.co/guide/en/elasticsearch/reference/7.10/docker.html#docker-compose-file repository-s3 教程 https://www.elastic.co/guide/en/elasticsearch/reference/8.14/repository-s3.html https://www.elastic.co/guide/en/elasticsearch/plugins/7.10/repository-s3.html snapshot-restore https://www.elastic.co/guide/en/elasticsearch/reference/7.10/snapshot-restore.html 在亚马逊 OpenSearch 服务中创建索引快照 https://docs.amazonaws.cn/zh_cn/opensearch-service/latest/developerguide/managedomains-snapshots.html#managedomains-snapshot-restore 教程：迁移至 Amazon OpenSearch Service https://docs.amazonaws.cn/zh_cn/opensearch-service/latest/developerguide/migration.html","link":"/posts/80e06f4b/"},{"title":"Macbook Pro快速搭建Easysearch学习环境","text":"在学习过程中，我们有时身边没有可用的服务器，这时就需要借助自己的 Mac 来安装和学习 Easysearch。然而，Easysearch 官网并未提供 Mac 版本的安装教程，下面我将详细整理我在 Mac 上安装和使用 Easysearch 的折腾经历。 EasysearchEasysearch 的运行依赖于 Java，程序启动时会自动从当前目录的 JDK 中查找 Java 环境。因此，即便环境变量中已经配置了 Java，程序也可能无法找到。针对这个问题，有两种解决办法：下载 JDK 的二进制文件，将其重命名为 “jdk”，并放置在 Easysearch 的根目录下。下载 Easysearch 的 bundle 包，该包会自带一个 JDK。下载链接为：https://release.infinilabs.com/Easysearch/stable/bundle/安装步骤如下：首先执行初始化脚本，此脚本会设置 TLS 证书和集群密码。在执行脚本之前，log 目录为空。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364bin/initialize.sh @@@@@@@@@@@ @@@@@@@@@@@@ @@@@@@@@@@@@ @@@@@@@@@&amp;@@@ #@@@@@@@@@@@@@ @@@ @@@@@@@@@@@@@ &amp;@@@@@@@ &amp;@@@@@@@@@@@@@ @&amp;@@@@@@@&amp;@ @@@&amp;@@@@@@@&amp;@ @@@@@@@@@@@@@@@@ @@@@@@@@@@@@@@ @@@@@@@@@@@@@@@@@@&amp; @@@@@@@@@@@@@ %@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @@@@@@@@@@@@&amp;@@@@@@@@@@@@@@@ @@ ,@@@@@@@@@@@@@@@@@@@@@@@&amp; @@@@@. @@@@@&amp;@@@@@@@@@@@@@@ @@@@@@@@@@ @@@@@@@@@@@@@@@# @&amp;@@@&amp;@@@&amp;@@@ &amp;@&amp;@@@&amp;@@@&amp;@ @@@@@@@@@@@@@. @@@@@@@* @@@@@@@@@@@@@ %@@@ @@@@@@@@@@@@@/@@@@@@@&amp;@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ Welcome to INFINI Labs!Now attempting the initializing...RISK WARNING: The initialization script will overwrite certificates and passwords. If this is not the first run, please acknowledge the risks before proceeding. This is a dangerous operation. Do you want to proceed? [y/N]:yNOTICE: Do you want to log credentials to /Users/xu/Desktop/es/Easysearch-1.10.1-1978-mac-arm64-bundle/logs/initialize.log? Default is no logging. Press Enter to skip. [y/N]:yUsing bundled JDK at /Users/xu/Desktop/es/Easysearch-1.10.1-1978-mac-arm64-bundle/jdkCertificate request self-signature oksubject=C = IN, ST = FI, L = NI, O = ORG, OU = UNIT, CN = infini.cloudCertificate request self-signature oksubject=C = IN, ST = FI, L = NI, O = ORG, OU = UNIT, CN = admin.infini.cloud DNS:infini.cloud, DNS:*.infini.cloud DNS:infini.cloud, DNS:*.infini.cloud@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ NOTICE: Please remember the bootstrap credential for further usage @@ admin:db3e19a8c1c9f7755763 @@ Usage: curl -ku admin:db3e19a8c1c9f7755763 https://localhost:9200 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@Your plugins directory is not empty. Please install the plugin manually.Initialization successful! [Easysearch] is ready to use!----------------------------------------------------------------cd /Users/xu/Desktop/es/Easysearch-1.10.1-1978-mac-arm64-bundle &amp;&amp; bin/Easysearch---------------------------------------------------------------- __ _ __ ____ __ _ __ __ / // |/ // __// // |/ // / / // || // _/ / // || // //_//_/|_//_/ /_//_/|_//_/©INFINI.LTD, All Rights Reserved. 这里打印了集群的密码和连接信息： 1curl -ku admin:db3e19a8c1c9f7755763 https://localhost:9200 然后启动集群，默认监听在 9200 端口： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129❰xu❙~/Desktop/es/Easysearch-1.10.1-1978-mac-arm64-bundle❱✔≻ bin/Easysearch (base) 13:50:14[2025-02-11T13:50:28,686][WARN ][o.e.b.Natives ] [xudeMacBook-Pro.local] unable to load JNA native support library, native methods will be disabled.java.lang.UnsatisfiedLinkError: /Users/xu/Library/Caches/JNA/temp/jna114104068097844929.tmp: dlopen(/Users/xu/Library/Caches/JNA/temp/jna114104068097844929.tmp, 0x0001): tried: '/Users/xu/Library/Caches/JNA/temp/jna114104068097844929.tmp' (fat file, but missing compatible architecture (have 'i386,x86_64', need 'arm64e' or 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/xu/Library/Caches/JNA/temp/jna114104068097844929.tmp' (no such file), '/Users/xu/Library/Caches/JNA/temp/jna114104068097844929.tmp' (fat file, but missing compatible architecture (have 'i386,x86_64', need 'arm64e' or 'arm64')) at jdk.internal.loader.NativeLibraries.load(Native Method) ~[?:?] at jdk.internal.loader.NativeLibraries$NativeLibraryImpl.open(Unknown Source) ~[?:?] at jdk.internal.loader.NativeLibraries.loadLibrary(Unknown Source) ~[?:?] at jdk.internal.loader.NativeLibraries.loadLibrary(Unknown Source) ~[?:?] at java.lang.ClassLoader.loadLibrary(Unknown Source) ~[?:?] at java.lang.Runtime.load0(Unknown Source) ~[?:?] at java.lang.System.load(Unknown Source) ~[?:?] at com.sun.jna.Native.loadNativeDispatchLibraryFromClasspath(Native.java:1018) ~[jna-5.5.0.jar:5.5.0 (b0)] at com.sun.jna.Native.loadNativeDispatchLibrary(Native.java:988) ~[jna-5.5.0.jar:5.5.0 (b0)] at com.sun.jna.Native.&lt;clinit&gt;(Native.java:195) ~[jna-5.5.0.jar:5.5.0 (b0)] at java.lang.Class.forName0(Native Method) ~[?:?] at java.lang.Class.forName(Unknown Source) ~[?:?] at org.Easysearch.bootstrap.Natives.&lt;clinit&gt;(Natives.java:30) ~[Easysearch-1.10.1.jar:1.10.1] at org.Easysearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:95) ~[Easysearch-1.10.1.jar:1.10.1] at org.Easysearch.bootstrap.Bootstrap.setup(Bootstrap.java:163) ~[Easysearch-1.10.1.jar:1.10.1] at org.Easysearch.bootstrap.Bootstrap.init(Bootstrap.java:378) ~[Easysearch-1.10.1.jar:1.10.1] at org.Easysearch.bootstrap.Easysearch.init(Easysearch.java:169) ~[Easysearch-1.10.1.jar:1.10.1] at org.Easysearch.bootstrap.Easysearch.execute(Easysearch.java:160) ~[Easysearch-1.10.1.jar:1.10.1] at org.Easysearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:71) ~[Easysearch-1.10.1.jar:1.10.1] at org.Easysearch.cli.Command.mainWithoutErrorHandling(Command.java:112) ~[Easysearch-cli-1.10.1.jar:1.10.1] at org.Easysearch.cli.Command.main(Command.java:75) ~[Easysearch-cli-1.10.1.jar:1.10.1] at org.Easysearch.bootstrap.Easysearch.main(Easysearch.java:125) ~[Easysearch-1.10.1.jar:1.10.1] at org.Easysearch.bootstrap.Easysearch.main(Easysearch.java:67) ~[Easysearch-1.10.1.jar:1.10.1][2025-02-11T13:50:28,689][WARN ][o.e.b.Natives ] [xudeMacBook-Pro.local] cannot check if running as root because JNA is not available[2025-02-11T13:50:28,689][WARN ][o.e.b.Natives ] [xudeMacBook-Pro.local] cannot install system call filter because JNA is not available[2025-02-11T13:50:28,689][WARN ][o.e.b.Natives ] [xudeMacBook-Pro.local] cannot register console handler because JNA is not available[2025-02-11T13:50:28,690][WARN ][o.e.b.Natives ] [xudeMacBook-Pro.local] cannot getrlimit RLIMIT_NPROC because JNA is not available[2025-02-11T13:50:28,690][WARN ][o.e.b.Natives ] [xudeMacBook-Pro.local] cannot getrlimit RLIMIT_AS because JNA is not available[2025-02-11T13:50:28,690][WARN ][o.e.b.Natives ] [xudeMacBook-Pro.local] cannot getrlimit RLIMIT_FSIZE because JNA is not available[2025-02-11T13:50:28,757][INFO ][o.e.n.Node ] [xudeMacBook-Pro.local] version[1.10.1], pid[18338], build[default/tar/1505f74d355bb2bac84162077fe66e9a32fc1be2/2025-01-24T21:02:00.632579Z], OS[Mac OS X/15.3/aarch64], JVM[Azul Systems, Inc./OpenJDK 64-Bit Server VM/17.0.13/17.0.13+11-LTS][2025-02-11T13:50:28,757][INFO ][o.e.n.Node ] [xudeMacBook-Pro.local] JVM home [/Users/xu/Desktop/es/Easysearch-1.10.1-1978-mac-arm64-bundle/jdk][2025-02-11T13:50:28,758][INFO ][o.e.n.Node ] [xudeMacBook-Pro.local] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Xms1g, -Xmx1g, -XX:+UseG1GC, -XX:G1ReservePercent=25, -XX:InitiatingHeapOccupancyPercent=30, -Djava.io.tmpdir=/var/folders/ft/rfbtvz_n5l9dg007x5lsk7jw0000gn/T/Easysearch-134350959148498936, -Djava.security.manager=allow, -Djava.locale.providers=SPI,COMPAT, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -XX:MaxDirectMemorySize=536870912, -Des.path.home=/Users/xu/Desktop/es/Easysearch-1.10.1-1978-mac-arm64-bundle, -Des.path.conf=/Users/xu/Desktop/es/Easysearch-1.10.1-1978-mac-arm64-bundle/config, -Des.distribution.flavor=oss, -Des.distribution.type=tar, -Des.bundled_jdk=false][2025-02-11T13:50:29,116][INFO ][c.i.s.s.t.SSLConfig ] [xudeMacBook-Pro.local] SSL dual mode is disabled[2025-02-11T13:50:29,117][INFO ][c.i.s.SecurityPlugin ] [xudeMacBook-Pro.local] ES Config path is /Users/xu/Desktop/es/Easysearch-1.10.1-1978-mac-arm64-bundle/config[2025-02-11T13:50:29,184][INFO ][c.i.s.s.DefaultSecurityKeyStore] [xudeMacBook-Pro.local] JVM supports TLSv1.3[2025-02-11T13:50:29,185][INFO ][c.i.s.s.DefaultSecurityKeyStore] [xudeMacBook-Pro.local] Config directory is /Users/xu/Desktop/es/Easysearch-1.10.1-1978-mac-arm64-bundle/config/, from there the key- and truststore files are resolved relatively[2025-02-11T13:50:29,389][INFO ][c.i.s.s.DefaultSecurityKeyStore] [xudeMacBook-Pro.local] TLS Transport Client Provider : JDK[2025-02-11T13:50:29,389][INFO ][c.i.s.s.DefaultSecurityKeyStore] [xudeMacBook-Pro.local] TLS Transport Server Provider : JDK[2025-02-11T13:50:29,389][INFO ][c.i.s.s.DefaultSecurityKeyStore] [xudeMacBook-Pro.local] TLS HTTP Provider : JDK[2025-02-11T13:50:29,389][INFO ][c.i.s.s.DefaultSecurityKeyStore] [xudeMacBook-Pro.local] Enabled TLS protocols for transport layer : [TLSv1.3, TLSv1.2][2025-02-11T13:50:29,389][INFO ][c.i.s.s.DefaultSecurityKeyStore] [xudeMacBook-Pro.local] Enabled TLS protocols for HTTP layer : [TLSv1.3, TLSv1.2][2025-02-11T13:50:29,391][INFO ][c.i.s.SecurityPlugin ] [xudeMacBook-Pro.local] Clustername: Easysearch[2025-02-11T13:50:29,745][INFO ][o.e.j.JobSchedulerPlugin ] [xudeMacBook-Pro.local] Loaded scheduler extension: Easysearch-index-management, index: .Easysearch-ilm-config[2025-02-11T13:50:29,748][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded module [aggs-matrix-stats][2025-02-11T13:50:29,749][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded module [analysis-common][2025-02-11T13:50:29,749][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded module [custom-codecs][2025-02-11T13:50:29,749][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded module [geo][2025-02-11T13:50:29,749][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded module [job-scheduler][2025-02-11T13:50:29,749][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded module [lang-expression][2025-02-11T13:50:29,749][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded module [lang-mustache][2025-02-11T13:50:29,749][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded module [lang-painless][2025-02-11T13:50:29,749][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded module [mapper-extras][2025-02-11T13:50:29,749][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded module [parent-join][2025-02-11T13:50:29,749][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded module [percolator][2025-02-11T13:50:29,749][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded module [rank-eval][2025-02-11T13:50:29,750][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded module [reindex][2025-02-11T13:50:29,750][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded module [repository-s3][2025-02-11T13:50:29,750][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded module [repository-url][2025-02-11T13:50:29,750][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded module [security][2025-02-11T13:50:29,750][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded module [transport-netty4][2025-02-11T13:50:29,750][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded plugin [analysis-icu][2025-02-11T13:50:29,750][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded plugin [analysis-ik][2025-02-11T13:50:29,750][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded plugin [analysis-pinyin][2025-02-11T13:50:29,750][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded plugin [analysis-stconvert][2025-02-11T13:50:29,750][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded plugin [cross-cluster-replication][2025-02-11T13:50:29,751][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded plugin [index-management][2025-02-11T13:50:29,751][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded plugin [ingest-common][2025-02-11T13:50:29,751][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded plugin [ingest-geoip][2025-02-11T13:50:29,751][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded plugin [ingest-user-agent][2025-02-11T13:50:29,751][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded plugin [knn][2025-02-11T13:50:29,751][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded plugin [mapper-annotated-text][2025-02-11T13:50:29,751][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded plugin [mapper-murmur3][2025-02-11T13:50:29,751][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded plugin [mapper-size][2025-02-11T13:50:29,751][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded plugin [sql][2025-02-11T13:50:29,751][INFO ][o.e.p.PluginsService ] [xudeMacBook-Pro.local] loaded plugin [transport-nio][2025-02-11T13:50:29,759][INFO ][c.i.s.SecurityPlugin ] [xudeMacBook-Pro.local] Disabled https compression by default to mitigate BREACH attacks. You can enable it by setting 'http.compression: true' in Easysearch.yml[2025-02-11T13:50:29,767][INFO ][o.e.e.NodeEnvironment ] [xudeMacBook-Pro.local] using [1] data paths, mounts [[/System/Volumes/Data (/dev/disk3s5)]], net usable_space [57gb], net total_space [926.3gb], types [apfs][2025-02-11T13:50:29,767][INFO ][o.e.e.NodeEnvironment ] [xudeMacBook-Pro.local] heap size [1gb], compressed ordinary object pointers [true][2025-02-11T13:50:29,784][INFO ][o.e.n.Node ] [xudeMacBook-Pro.local] node name [xudeMacBook-Pro.local], node ID [w5zzEDPfTDSE30HWYkUNcw], cluster name [Easysearch], roles [master, remote_cluster_client, data, ingest][2025-02-11T13:50:30,915][WARN ][c.i.s.c.Salt ] [xudeMacBook-Pro.local] If you plan to use field masking pls configure compliance salt e1ukloTxxxOgPquJ to be a random string of 16 chars length identical on all nodes[2025-02-11T13:50:30,921][INFO ][c.i.s.a.i.AuditLogging ] [xudeMacBook-Pro.local] Message routing enabled: true[2025-02-11T13:50:30,945][INFO ][c.i.s.f.SecurityFilter ] [xudeMacBook-Pro.local] &lt;NONE&gt; indices are made immutable.[2025-02-11T13:50:31,104][INFO ][o.e.t.NettyAllocator ] [xudeMacBook-Pro.local] creating NettyAllocator with the following configs: [name=unpooled, suggested_max_allocation_size=256kb, factors={es.unsafe.use_unpooled_allocator=null, g1gc_enabled=true, g1gc_region_size=1mb, heap_size=1gb}][2025-02-11T13:50:31,132][INFO ][o.e.d.DiscoveryModule ] [xudeMacBook-Pro.local] using discovery type [zen] and seed hosts providers [settings][2025-02-11T13:50:31,250][WARN ][o.e.g.DanglingIndicesState] [xudeMacBook-Pro.local] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually[2025-02-11T13:50:31,335][WARN ][o.e.r.MethodHandlers ] [xudeMacBook-Pro.local] replace existing handler for [/{index}/_search] for method: GET existing:com.infinilabs.security.filter.SecurityRestFilter$1@41fbe8c0 to com.infinilabs.security.filter.SecurityRestFilter$1@1e8fd198[2025-02-11T13:50:31,335][WARN ][o.e.r.MethodHandlers ] [xudeMacBook-Pro.local] replace existing handler for [/{index}/_search] for method: POST existing:com.infinilabs.security.filter.SecurityRestFilter$1@4f75c627 to com.infinilabs.security.filter.SecurityRestFilter$1@1631a614[2025-02-11T13:50:31,344][INFO ][o.e.n.Node ] [xudeMacBook-Pro.local] initialized[2025-02-11T13:50:31,344][INFO ][o.e.n.Node ] [xudeMacBook-Pro.local] starting ...[2025-02-11T13:50:31,345][INFO ][o.e.i.r.a.s.RollupListener] [xudeMacBook-Pro.local] Rollup listener start[2025-02-11T13:50:31,391][INFO ][o.e.t.TransportService ] [xudeMacBook-Pro.local] publish_address {127.0.0.1:9300}, bound_addresses {[::1]:9300}, {127.0.0.1:9300}[2025-02-11T13:50:31,473][WARN ][o.e.b.BootstrapChecks ] [xudeMacBook-Pro.local] system call filters failed to install; check the logs and fix your configuration or disable system call filters at your own risk[2025-02-11T13:50:31,473][WARN ][o.e.b.BootstrapChecks ] [xudeMacBook-Pro.local] the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured[2025-02-11T13:50:31,477][INFO ][o.e.c.c.ClusterBootstrapService] [xudeMacBook-Pro.local] no discovery configuration found, will perform best-effort cluster bootstrapping after [3s] unless existing master is discovered[2025-02-11T13:50:34,481][INFO ][o.e.c.c.Coordinator ] [xudeMacBook-Pro.local] setting initial configuration to VotingConfiguration{w5zzEDPfTDSE30HWYkUNcw}[2025-02-11T13:50:34,576][INFO ][o.e.c.s.MasterService ] [xudeMacBook-Pro.local] elected-as-master ([1] nodes joined)[{xudeMacBook-Pro.local}{w5zzEDPfTDSE30HWYkUNcw}{KMu1pbs-RB2vaWucEO8dmg}{127.0.0.1}{127.0.0.1:9300}{dimr} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 1, version: 1, delta: master node changed {previous [], current [{xudeMacBook-Pro.local}{w5zzEDPfTDSE30HWYkUNcw}{KMu1pbs-RB2vaWucEO8dmg}{127.0.0.1}{127.0.0.1:9300}{dimr}]}[2025-02-11T13:50:34,601][INFO ][o.e.c.c.CoordinationState] [xudeMacBook-Pro.local] cluster UUID set to [kJHbUT_zT2ionNVL9f3raQ][2025-02-11T13:50:34,623][INFO ][o.e.c.s.ClusterApplierService] [xudeMacBook-Pro.local] master node changed {previous [], current [{xudeMacBook-Pro.local}{w5zzEDPfTDSE30HWYkUNcw}{KMu1pbs-RB2vaWucEO8dmg}{127.0.0.1}{127.0.0.1:9300}{dimr}]}, term: 1, version: 1, reason: Publication{term=1, version=1}[2025-02-11T13:50:34,627][INFO ][o.e.i.i.ManagedIndexCoordinator] [xudeMacBook-Pro.local] Cache cluster manager node onClusterManager time: 1739253034627[2025-02-11T13:50:34,637][INFO ][o.e.h.AbstractHttpServerTransport] [xudeMacBook-Pro.local] publish_address {127.0.0.1:9200}, bound_addresses {[::1]:9200}, {127.0.0.1:9200}[2025-02-11T13:50:34,640][INFO ][o.e.n.Node ] [xudeMacBook-Pro.local] started[2025-02-11T13:50:34,640][INFO ][c.i.s.SecurityPlugin ] [xudeMacBook-Pro.local] Node started[2025-02-11T13:50:34,640][INFO ][c.i.s.c.ConfigurationRepository] [xudeMacBook-Pro.local] Will attempt to create index .security and default configs if they are absent[2025-02-11T13:50:34,641][INFO ][c.i.s.SecurityPlugin ] [xudeMacBook-Pro.local] 3 Security modules loaded so far: [Module [type=REST_MANAGEMENT_API, implementing class=com.infinilabs.security.dlic.rest.api.SecurityRestApiActions], Module [type=MULTITENANCY, implementing class=com.infinilabs.security.configuration.PrivilegesInterceptorImpl], Module [type=AUDITLOG, implementing class=com.infinilabs.security.auditlog.impl.AuditLogging]][2025-02-11T13:50:34,641][INFO ][c.i.s.c.ConfigurationRepository] [xudeMacBook-Pro.local] Background init thread started. Install default config?: true[2025-02-11T13:50:34,645][INFO ][c.i.s.c.ConfigurationRepository] [xudeMacBook-Pro.local] Wait for cluster to be available ...[2025-02-11T13:50:34,670][INFO ][o.e.g.GatewayService ] [xudeMacBook-Pro.local] recovered [0] indices into cluster_state[2025-02-11T13:50:36,676][INFO ][o.w.a.d.Dictionary ] [xudeMacBook-Pro.local] try load config from /Users/xu/Desktop/es/Easysearch-1.10.1-1978-mac-arm64-bundle/config/analysis-ik/IKAnalyzer.cfg.xml[2025-02-11T13:50:37,465][INFO ][o.e.c.m.MetadataCreateIndexService] [xudeMacBook-Pro.local] [.security] creating index, cause [api], templates [], shards [1]/[1][2025-02-11T13:50:37,470][INFO ][o.e.c.r.a.AllocationService] [xudeMacBook-Pro.local] updating number_of_replicas to [0] for indices [.security][2025-02-11T13:50:37,657][INFO ][o.e.c.r.a.AllocationService] [xudeMacBook-Pro.local] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.security][0]]]).[2025-02-11T13:50:37,679][INFO ][c.i.s.c.ConfigurationRepository] [xudeMacBook-Pro.local] Index .security created?: true[2025-02-11T13:50:37,685][INFO ][c.i.s.s.ConfigHelper ] [xudeMacBook-Pro.local] Will update 'config' with /Users/xu/Desktop/es/Easysearch-1.10.1-1978-mac-arm64-bundle/config/security/config.yml and populate it with empty doc if file missing and populateEmptyIfFileMissing=false[2025-02-11T13:50:37,720][INFO ][o.e.c.m.MetadataMappingService] [xudeMacBook-Pro.local] [.security/ADtiL1q3TUiUghNCrlfrHQ] create_mapping [_doc][2025-02-11T13:50:37,779][INFO ][c.i.s.s.ConfigHelper ] [xudeMacBook-Pro.local] Doc with id 'config' and version 2 is updated in .security index.[2025-02-11T13:50:37,780][INFO ][c.i.s.s.ConfigHelper ] [xudeMacBook-Pro.local] Will update 'role' with /Users/xu/Desktop/es/Easysearch-1.10.1-1978-mac-arm64-bundle/config/security/role.yml and populate it with empty doc if file missing and populateEmptyIfFileMissing=false[2025-02-11T13:50:37,786][INFO ][o.e.c.m.MetadataMappingService] [xudeMacBook-Pro.local] [.security/ADtiL1q3TUiUghNCrlfrHQ] update_mapping [_doc][2025-02-11T13:50:37,830][INFO ][c.i.s.s.ConfigHelper ] [xudeMacBook-Pro.local] Doc with id 'role' and version 2 is updated in .security index.[2025-02-11T13:50:37,831][INFO ][c.i.s.s.ConfigHelper ] [xudeMacBook-Pro.local] Will update 'role_mapping' with /Users/xu/Desktop/es/Easysearch-1.10.1-1978-mac-arm64-bundle/config/security/role_mapping.yml and populate it with empty doc if file missing and populateEmptyIfFileMissing=false[2025-02-11T13:50:37,838][INFO ][o.e.c.m.MetadataMappingService] [xudeMacBook-Pro.local] [.security/ADtiL1q3TUiUghNCrlfrHQ] update_mapping [_doc][2025-02-11T13:50:37,885][INFO ][c.i.s.s.ConfigHelper ] [xudeMacBook-Pro.local] Doc with id 'role_mapping' and version 2 is updated in .security index.[2025-02-11T13:50:37,886][INFO ][c.i.s.s.ConfigHelper ] [xudeMacBook-Pro.local] Will update 'user' with /Users/xu/Desktop/es/Easysearch-1.10.1-1978-mac-arm64-bundle/config/security/user.yml and populate it with empty doc if file missing and populateEmptyIfFileMissing=false[2025-02-11T13:50:37,898][INFO ][o.e.c.m.MetadataMappingService] [xudeMacBook-Pro.local] [.security/ADtiL1q3TUiUghNCrlfrHQ] update_mapping [_doc][2025-02-11T13:50:37,937][INFO ][c.i.s.s.ConfigHelper ] [xudeMacBook-Pro.local] Doc with id 'user' and version 2 is updated in .security index.[2025-02-11T13:50:37,937][INFO ][c.i.s.s.ConfigHelper ] [xudeMacBook-Pro.local] Will update 'privilege' with /Users/xu/Desktop/es/Easysearch-1.10.1-1978-mac-arm64-bundle/config/security/privilege.yml and populate it with empty doc if file missing and populateEmptyIfFileMissing=false 使用 Postman 尝试连接，可以正常返回 HTTP 的响应： 这里就需要用到上次的那个密码，默认存放在 log/initialize.log 下。 Console下载二进制文件并且运行，服务监听在 9000 端口，通过这个页面连接 Easysearch，用来替代 kibana，个人觉得比 kibana 和 OpenSearch Dashboard 要好用，除了 Easysearch 之外，还可以连接 ES 和 OpenSearch。 1234567891011121314151617181920212223242526272829303132333435363738394041./console-mac-arm64 (base) 14:25:43 ___ ___ __ __ ___ __ __ / __\\/___\\/\\ \\ \\/ _\\ /___\\/ / /__\\ / / // // \\/ /\\ \\ // // / /_\\/ /__/ \\_// /\\ / _\\ \\/ \\_// /__//__\\____|___/\\_\\ \\/ \\__/\\___/\\____|__/HOME: https://github.com/infinilabs/console/[CONSOLE] The easiest way to operate your own search platform, open-sourced under the GNU AGPLv3.[CONSOLE] 1.28.1#1978, 2025-01-25 11:40:24, 2025-12-31 10:10:10, b189b72c11a9, 8ecefd18d9eb, c511f8f4cab9[02-11 14:25:47] [INF] [env.go:216] configuration auto reload enabled[02-11 14:25:47] [INF] [env.go:222] watching config: /Users/xu/Desktop/es/console-1.28.1-1978-mac-arm64/config[02-11 14:25:47] [INF] [app.go:311] initializing console, pid: 20341[02-11 14:25:47] [INF] [app.go:312] using config: /Users/xu/Desktop/es/console-1.28.1-1978-mac-arm64/console.yml[02-11 14:25:47] [INF] [instance.go:100] workspace: /Users/xu/Desktop/es/console-1.28.1-1978-mac-arm64/data/console/nodes/culeqqr55o14utfde2a0[02-11 14:25:47] [INF] [module.go:159] started module: badger[02-11 14:25:47] [INF] [module.go:159] started module: kafka_queue[02-11 14:25:47] [INF] [module.go:159] started module: setup[02-11 14:25:47] [INF] [module.go:159] started module: setup[02-11 14:25:47] [INF] [web.go:226] web server listen at: http://0.0.0.0:9000[02-11 14:25:47] [INF] [module.go:159] started module: web[02-11 14:25:47] [INF] [module.go:184] all modules are started[02-11 14:25:47] [INF] [app.go:537] console is up and running now.[02-11 14:28:03] [WRN] [schema.go:101] duplicated schema rbac-role, infini.sh/console/core/security-role[02-11 14:28:03] [WRN] [schema.go:101] duplicated schema rbac-user, infini.sh/console/core/security-user[02-11 14:28:03] [WRN] [schema.go:101] duplicated schema credential, infini.sh/framework/core/credential-credential[02-11 14:28:04] [INF] [module.go:187] loading [0] remote configs[02-11 14:28:04] [INF] [pipeline.go:418] creating pipeline: merge_metrics[02-11 14:28:04] [INF] [pipeline.go:418] creating pipeline: metadata_ingest[02-11 14:28:04] [INF] [pipeline.go:418] creating pipeline: activity_ingest[02-11 14:28:04] [INF] [pipeline.go:418] creating pipeline: merge_logging[02-11 14:28:04] [INF] [pipeline.go:418] creating pipeline: merge_audit_log[02-11 14:28:04] [INF] [pipeline.go:418] creating pipeline: ingest_merged_requests[02-11 14:28:04] [INF] [load.go:69] loading permission file from /Users/xu/Desktop/es/console-1.28.1-1978-mac-arm64/config/permission.json[02-11 14:28:06] [INF] [pipeline.go:227] config changed, checking for new pipeline configs, CREATE, config/system_config.yml[02-11 14:54:38] [ERR] [v0.go:521] invalid response: https://localhost:9200/.infini_metrics%2A/_search,{&quot;aggs&quot;:{&quot;culf8bj55o14utfdf1u0&quot;:{&quot;aggs&quot;:{&quot;culf8bj55o14utfdf1ug&quot;:{&quot;aggs&quot;:{&quot;culf8bj55o14utfdf1v0&quot;:{&quot;aggs&quot;:{},&quot;terms&quot;:{&quot;field&quot;:&quot;payload.elasticsearch.cluster_health.status&quot;,&quot;missing&quot;:&quot;&quot;,&quot;size&quot;:2}}},&quot;date_range&quot;:{&quot;field&quot;:&quot;timestamp&quot;,&quot;format&quot;:&quot;yyyy-MM-dd&quot;,&quot;ranges&quot;:[{&quot;from&quot;:&quot;now-13d/d&quot;,&quot;to&quot;:&quot;now-12d/d&quot;},{&quot;from&quot;:&quot;now-12d/d&quot;,&quot;to&quot;:&quot;now-11d/d&quot;},{&quot;from&quot;:&quot;now-11d/d&quot;,&quot;to&quot;:&quot;now-10d/d&quot;},{&quot;from&quot;:&quot;now-10d/d&quot;,&quot;to&quot;:&quot;now-9d/d&quot;},{&quot;from&quot;:&quot;now-9d/d&quot;,&quot;to&quot;:&quot;now-8d/d&quot;},{&quot;from&quot;:&quot;now-8d/d&quot;,&quot;to&quot;:&quot;now-7d/d&quot;},{&quot;from&quot;:&quot;now-7d/d&quot;,&quot;to&quot;:&quot;now-6d/d&quot;},{&quot;from&quot;:&quot;now-6d/d&quot;,&quot;to&quot;:&quot;now-5d/d&quot;},{&quot;from&quot;:&quot;now-5d/d&quot;,&quot;to&quot;:&quot;now-4d/d&quot;},{&quot;from&quot;:&quot;now-4d/d&quot;,&quot;to&quot;:&quot;now-3d/d&quot;},{&quot;from&quot;:&quot;now-3d/d&quot;,&quot;to&quot;:&quot;now-2d/d&quot;},{&quot;from&quot;:&quot;now-2d/d&quot;,&quot;to&quot;:&quot;now-1d/d&quot;},{&quot;from&quot;:&quot;now-1d/d&quot;,&quot;to&quot;:&quot;now/d&quot;},{&quot;from&quot;:&quot;now/d&quot;,&quot;to&quot;:&quot;now&quot;}],&quot;time_zone&quot;:&quot;+08:00&quot;}}},&quot;terms&quot;:{&quot;field&quot;:&quot;metadata.labels.cluster_id&quot;,&quot;size&quot;:2}}},&quot;query&quot;:{&quot;bool&quot;:{&quot;filter&quot;:[{&quot;range&quot;:{&quot;timestamp&quot;:{&quot;gte&quot;:&quot;now-15d&quot;,&quot;lte&quot;:&quot;now&quot;}}}],&quot;must&quot;:[{&quot;terms&quot;:{&quot;metadata.labels.cluster_id&quot;:[&quot;infini_default_system_cluster&quot;]}},{&quot;term&quot;:{&quot;metadata.category&quot;:{&quot;value&quot;:&quot;elasticsearch&quot;}}},{&quot;term&quot;:{&quot;metadata.name&quot;:{&quot;value&quot;:&quot;cluster_health&quot;}}}]}},&quot;size&quot;:0},{&quot;error&quot;:{&quot;root_cause&quot;:[{&quot;type&quot;:&quot;runtime_exception&quot;,&quot;reason&quot;:&quot;Unable to unroll aggregation tree. Aggregation [culf8bj55o14utfdf1u0] is of type [UnmappedTerms] which is currently unsupported.&quot;}],&quot;type&quot;:&quot;runtime_exception&quot;,&quot;reason&quot;:&quot;Unable to unroll aggregation tree. Aggregation [culf8bj55o14utfdf1u0] is of type [UnmappedTerms] which is currently unsupported.&quot;},&quot;status&quot;:500}[02-11 14:59:18] [ERR] [config.go:46] agent config not found: missing field accessing 'agent'[02-11 14:59:18] [INF] [certs.go:49] auto generating cert files 查看集群信息，可以看指标，也可以看索引，kibana 有的功能这边基本都有： 同时提供 DSL 查询： GatewayINFINI Gateway 是一个面向搜索场景的高性能数据网关，所有请求都经过网关处理后再转发到后端的搜索业务集群。基于 INFINI Gateway，可以实现索引级别的限速限流、常见查询的缓存加速、查询请求的审计、查询结果的动态修改等等。 Macbook 下有奇怪的安全规则，除了二进制文件之外，yml 文件经验也报错不安全。打开 “系统偏好设置”，进入 “安全性与隐私”，点击 “通用”，有 “仍然允许” 按钮，点击它即可。 然后按照 Easysearch 的配置进行修改，否则会连不上集群。就是这个报错： 12345678910111213141516171819202122232425262728293031323334./gateway-mac-arm64 (base) 14:51:14 ___ _ _____ __ __ __ _ / _ \\ /_\\ /__ \\/__\\/ / /\\ \\ \\/_\\ /\\_/\\ / /_\\///_\\\\ / /\\/_\\ \\ \\/ \\/ //_\\\\\\_ _// /_\\\\/ _ \\/ / //__ \\ /\\ / _ \\/ \\\\____/\\_/ \\_/\\/ \\__/ \\/ \\/\\_/ \\_/\\_/HOME: https://github.com/infinilabs/gateway/[GATEWAY] A light-weight, powerful and high-performance search gateway, open-sourced under the GNU AGPLv3.[GATEWAY] 1.28.1#1978, 2025-01-24 18:34:08, 2025-12-31 10:10:10, 93fd9e32500a, 8ecefd18d9eb, c511f8f4cab9[02-11 14:51:17] [INF] [app.go:311] initializing gateway, pid: 22456[02-11 14:51:17] [INF] [app.go:312] using config: /Users/xu/Desktop/es/gateway-1.28.1-1978-mac-arm64/gateway.yml[02-11 14:51:17] [INF] [instance.go:100] workspace: /Users/xu/Desktop/es/gateway-1.28.1-1978-mac-arm64/data/gateway/nodes/culf6pb55o15fe01mtvgpanic: Get &quot;http://localhost:9200&quot;: EOFgoroutine 433 [running]:infini.sh/framework/modules/elastic/common.InitClientWithConfig({{{0x14000810630, 0x4}, 0x0, 0x0}, {0x103466e7c, 0x4}, {0x14000810630, 0x4}, {0x0, 0x0}, ...}) /root/go/src/infini.sh/framework/modules/elastic/common/config.go:89 +0x880infini.sh/framework/modules/elastic/common.InitElasticInstanceWithoutMetadata({{{0x14000810630, 0x4}, 0x0, 0x0}, {0x103466e7c, 0x4}, {0x14000810630, 0x4}, {0x0, 0x0}, ...}) /root/go/src/infini.sh/framework/modules/elastic/common/config.go:199 +0x64infini.sh/framework/modules/elastic.initElasticInstances({0x14000826008?, 0x1e?, 0x103670600?}, {0x103466e7c, 0x4}) /root/go/src/infini.sh/framework/modules/elastic/module.go:194 +0x7cinfini.sh/framework/modules/elastic.(*ElasticModule).Setup(0x140006fa120?) /root/go/src/infini.sh/framework/modules/elastic/module.go:215 +0x124infini.sh/framework/core/module.Start() /root/go/src/infini.sh/framework/core/module/module.go:123 +0x238main.start() /root/go/src/infini.sh/gateway/main.go:72 +0x1cinfini.sh/framework.(*App).run(0x14000332500) /root/go/src/infini.sh/framework/app.go:493 +0x160created by infini.sh/framework.(*App).Start in goroutine 1 /root/go/src/infini.sh/framework/app.go:429 +0xb4 修改配置文件之后，启动日志如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748./gateway-mac-arm64 (base) 14:53:07 ___ _ _____ __ __ __ _ / _ \\ /_\\ /__ \\/__\\/ / /\\ \\ \\/_\\ /\\_/\\ / /_\\///_\\\\ / /\\/_\\ \\ \\/ \\/ //_\\\\\\_ _// /_\\\\/ _ \\/ / //__ \\ /\\ / _ \\/ \\\\____/\\_/ \\_/\\/ \\__/ \\/ \\/\\_/ \\_/\\_/HOME: https://github.com/infinilabs/gateway/[GATEWAY] A light-weight, powerful and high-performance search gateway, open-sourced under the GNU AGPLv3.[GATEWAY] 1.28.1#1978, 2025-01-24 18:34:08, 2025-12-31 10:10:10, 93fd9e32500a, 8ecefd18d9eb, c511f8f4cab9[02-11 14:53:16] [INF] [app.go:311] initializing gateway, pid: 22599[02-11 14:53:16] [INF] [app.go:312] using config: /Users/xu/Desktop/es/gateway-1.28.1-1978-mac-arm64/gateway.yml[02-11 14:53:16] [INF] [instance.go:100] workspace: /Users/xu/Desktop/es/gateway-1.28.1-1978-mac-arm64/data/gateway/nodes/culf6pb55o15fe01mtvg[02-11 14:53:16] [INF] [module.go:159] started module: badger[02-11 14:53:16] [INF] [api.go:214] local ips: 192.168.5.53[02-11 14:53:16] [INF] [api.go:312] api server listen at: http://0.0.0.0:2900[02-11 14:53:16] [INF] [module.go:159] started module: api[02-11 14:53:16] [INF] [module.go:159] started module: disk_queue[02-11 14:53:16] [INF] [actions.go:420] elasticsearch [logging-server] is available[02-11 14:53:16] [INF] [module.go:159] started module: elasticsearch[02-11 14:53:16] [INF] [module.go:159] started module: kafka_queue[02-11 14:53:16] [INF] [module.go:159] started module: queue[02-11 14:53:16] [INF] [module.go:159] started module: redis[02-11 14:53:16] [INF] [module.go:159] started module: s3[02-11 14:53:16] [INF] [module.go:159] started module: simple_stats[02-11 14:53:16] [INF] [module.go:159] started module: task[02-11 14:53:16] [INF] [actions.go:420] elasticsearch [prod] is available[02-11 14:53:16] [INF] [pipeline.go:418] creating pipeline: pipeline_logging_merge[02-11 14:53:16] [INF] [pipeline.go:418] creating pipeline: ingest_pipeline_logging[02-11 14:53:16] [INF] [pipeline.go:418] creating pipeline: async_messages_merge[02-11 14:53:16] [INF] [pipeline.go:418] creating pipeline: metrics_merge[02-11 14:53:16] [INF] [pipeline.go:418] creating pipeline: request_logging_merge[02-11 14:53:16] [INF] [pipeline.go:418] creating pipeline: ingest_merged_requests[02-11 14:53:16] [INF] [pipeline.go:418] creating pipeline: async_ingest_bulk_requests[02-11 14:53:16] [INF] [module.go:159] started module: pipeline[02-11 14:53:16] [INF] [module.go:178] started plugin: floating_ip[02-11 14:53:16] [INF] [module.go:178] started plugin: force_merge[02-11 14:53:16] [INF] [module.go:178] started plugin: metrics[02-11 14:53:16] [INF] [module.go:178] started plugin: statsd[02-11 14:53:17] [INF] [reverseproxy.go:299] elasticsearch [prod] hosts: [] =&gt; [127.0.0.1:9200][02-11 14:53:17] [INF] [entry.go:420] entry [my_es_entry] listen at: http://0.0.0.0:8000[02-11 14:53:17] [INF] [module.go:178] started plugin: gateway[02-11 14:53:17] [INF] [module.go:184] all modules are started[02-11 14:53:17] [INF] [app.go:537] gateway is up and running now. 认证之后，可以从 Gateway 代理到 Easysearch： Gateway 注册到 Console注册时候用的是 2900 端口，如果注册到 8000 是无法连接的。 注册完成就会显示 Gateway 的信息： 本文围绕在 Mac 系统上安装、配置和使用 Easysearch 展开，详细介绍了各组件的安装过程、遇到的问题及解决办法，以下是详细总结： 1. 安装背景与前期准备在学习阶段缺少服务器时，可使用 Mac 进行 Easysearch 的安装学习，但官网未提供 Mac 版安装教程。Easysearch 运行依赖 Java，程序启动时会从当前目录的 JDK 查找 Java，即便环境变量已配置也可能无法找到，解决办法有：一是下载 JDK 二进制文件，重命名为“jdk”放在 Easysearch 根目录；二是下载自带 JDK 的 Easysearch bundle 包。 2. Easysearch 安装与启动 初始化：执行bin/initialize.sh脚本设置 TLS 证书和集群密码，初始化过程会提示覆盖证书和密码的风险，需确认是否继续，并可选择是否将凭证记录到日志文件。初始化成功后会显示集群的密码和连接信息，如curl -ku admin:db3e19a8c1c9f7755763 https://localhost:9200。 启动集群：启动命令为bin/Easysearch，默认监听 9200 端口。启动过程中可能出现无法加载 JNA 本地支持库的警告，但不影响后续启动和使用。 3. 连接与验证使用 Postman 尝试连接，需用到初始化时生成的密码（默认存放在log/initialize.log），可正常返回 HTTP 响应，验证了 Easysearch 集群的可访问性。 4. Console 使用下载并运行二进制文件./console-mac-arm64，服务监听在 9000 端口，可替代 Kibana 连接 Easysearch、ES 和 OpenSearch。运行过程中会有部分警告信息，如重复的架构定义，但不影响基本功能使用，还可查看集群信息和进行 DSL 查询。 5. Gateway 使用 配置问题与解决：INFINI Gateway 是高性能数据网关，Mac 上运行时可能因安全规则报错，需在“系统偏好设置 - 安全性与隐私 - 通用”中点击“仍然允许”。若配置不正确会出现连接不上集群的错误，修改配置文件后可正常启动。 启动与功能验证：启动命令为./gateway-mac-arm64，启动后各模块和插件依次启动，可实现索引级别的限速限流、缓存加速、查询审计等功能。认证后可从 Gateway 代理到 Easysearch，还可将 Gateway 注册到 Console。","link":"/posts/8b29e69c/"},{"title":"推荐给 Easysearch 新用户的几个 Elasticsearch 可视化工具","text":"Easysearch 作为国产化的 Elasticsearch（ES）替代方案，兼容 Elasticsearch 生态系统中的多种工具。本文将介绍几款适合 Easysearch 用户的可视化工具，帮助您更高效地管理和查询数据。 1. Elasticsearch Head 插件在 ES 培训经常提到的 Elasticsearch Head 是一款基于浏览器的插件，适合不想部署 Kibana 等复杂工具的用户。它提供了简洁的界面，方便用户查看集群状态、索引分布、分片信息等。 主要功能： 索引分布查看 索引详细信息 分片信息查看 DSL 查询 2. Elasticvue 插件Elasticvue 是一款高评分、高颜值的 Chrome 插件，功能全面，适合需要更丰富功能的用户。 主要功能： 节点信息查看 索引查看 DSL 查询 快照存储库管理 3. CerebroCerebro 是一款需要自行部署的工具，建议使用 Docker 进行安装。为了避免端口冲突和 TLS 认证错误，可以通过 Gateway 进行转发。 部署步骤：1docker run -p 9100:9000 lmenezes/cerebro 主要功能： 集群管理 网络请求处理Cerebro 有自己的后端服务，请求并非直接从浏览器发出。因此，启动 Docker 容器时，避免连接 localhost，以免进入容器内部。 查看索引信息： 可视化功能一览： 4. 认证与安全对于需要密码认证的连接，可以使用以下两种方式： 直接连接：https://admin:xxxxx@localhost:9200/ Base64 编码凭证：可以使用 Postman 或其他工具生成 Base64 编码的凭证，并在请求头中传递。 12345678910import requestsurl = &quot;https://localhost:9200&quot;payload = &quot;&quot;headers = { 'Authorization': 'Basic YWRtaW46NzllYTM4MzMwMmM2OGZiYWM0MDc='}response = requests.request(&quot;GET&quot;, url, headers=headers, data=payload)print(response.text) 总结以上工具各有特色，用户可以根据自己的需求选择合适的工具。无论是简单的浏览器插件，还是功能更强大的 Cerebro，都能帮助您更好地管理和查询 Easysearch 集群。","link":"/posts/e3691a5b/"},{"title":"使用 INFINI Console 配置集群监控 Webhook 通知指南","text":"在集群管理中，监控关键指标如 CPU、内存、磁盘、JVM 等是至关重要的。对于 Easysearch 及 ES 生态系统，还需要关注集群本身的指标，例如搜索延迟、集群状态、节点移除等。INFINI Console 不仅提供了默认的监控指标，还支持用户自定义监控项。当监控数值达到预设阈值时，系统可以通过 Webhook 发送通知至 Slack、飞书等平台。 监控配置流程1. 告警对象与通知渠道设置在 INFINI Console 中，首先需要配置监控对象和通知渠道： 2. 告警中心管理 通过告警中心可以集中管理所有监控告警： 3. 告警详情查看每个告警事件都提供详细信息查看功能： 4. 告警历史记录系统完整记录所有历史告警信息： Webhook 实现示例以下是用 Python 实现的 Webhook 接收服务： 12345678910111213141516171819202122232425from flask import Flask, request, jsonifyimport jsonfrom pprint import pprintapp = Flask(__name__)@app.route('/webhook', methods=['POST'])def webhook(): # 获取并处理请求数据 raw_data = request.data decoded_data = raw_data.decode('utf-8') data = json.loads(decoded_data) # 打印接收到的数据 print(&quot;Received data:&quot;) pprint(data) # 返回响应 return jsonify({ &quot;status&quot;: &quot;success&quot;, &quot;message&quot;: &quot;Webhook received&quot; }), 200if __name__ == '__main__': app.run(host='0.0.0.0', port=8000) Webhook 配置步骤 在 Console 中添加 Webhook 配置： 查看捕获的告警信息： 飞书 Webhook 集成1. 创建飞书群组在飞书客户端创建新的群组： 2. 添加自定义机器人选择添加自定义机器人： 3. 配置机器人信息设置机器人名称和描述： 4. 获取 Webhook URL完成配置后获取 Webhook 地址： 通过以上配置，即可实现集群监控告警的实时通知，确保系统运维人员能够及时响应各种异常情况。","link":"/posts/361d01a9/"},{"title":"实现 INFINI Console 与 GitHub 的单点登录集成：一站式身份验证解决方案","text":"本文将为您详细解析如何通过 GitHub OAuth 2.0 协议，为 INFINI Console 实现高效、安全的单点登录（Single Sign-On, SSO）集成。通过此方案，用户可直接使用 GitHub 账户无缝登录 INFINI Console，简化身份验证流程，提升系统安全性与用户体验。 一、GitHub OAuth 应用配置1. 创建 OAuth 应用程序 登录 GitHub，导航至 Settings -&gt; Developer settings -&gt; OAuth Apps。 点击 New OAuth App，创建新的 OAuth 应用程序。 2. 配置应用信息 填写应用的基本信息，包括： Application Name：应用名称（如 “INFINI Console SSO”） Homepage URL：应用主页 URL Authorization callback URL：回调 URL（格式：http://localhost:9000/oauth/callback） 3. 获取客户端凭证 创建应用后，系统将生成 Client ID 和 Client Secret。 这些凭证将用于 INFINI Console 的 OAuth 配置。 4. 查看已注册的 OAuth 应用 创建完成后，您可以在 OAuth 应用列表中查看应用的详细信息。 二、INFINI Console 的 OAuth 集成配置1. 修改配置文件 编辑 INFINI Console 的配置文件，添加以下 OAuth 配置： 12345678910111213security: enabled: true oauth: enabled: true client_id: &quot;xxxx&quot; # 替换为您的 Client ID client_secret: &quot;xxxx&quot; # 替换为您的 Client Secret default_roles: [&quot;ReadonlyUI&quot;, &quot;AllClusters&quot;] # 默认角色 role_mapping: medcl: [&quot;Administrator&quot;] # 特定用户的角色映射 authorize_url: &quot;https://github.com/login/oauth/authorize&quot; token_url: &quot;https://github.com/login/oauth/access_token&quot; redirect_url: &quot;&quot; scopes: [] 2. 配置角色权限 AllClusters 角色：用于管理集群的全局权限。 ReadonlyUI 角色：为只读用户分配受限权限。 三、单点登录流程演示1. 访问 INFINI Console 打开浏览器，访问 http://localhost:9000。 点击 单点登录 按钮，进入登录流程。 2. 使用 GitHub 登录 点击 GitHub 图标，跳转至 GitHub 登录页面。 3. 授权应用访问 在 GitHub 授权页面，确认授权 INFINI Console 访问您的 GitHub 账户。 4. 登录成功 授权成功后，系统将自动跳转回 INFINI Console，并显示您的 GitHub 用户名。 四、总结通过以上步骤，您已成功将 INFINI Console 与 GitHub 的单点登录功能集成。此方案不仅简化了用户的登录流程，还通过 GitHub 的 OAuth 2.0 协议确保了身份验证的安全性。未来，希望 INFINI Console 进一步扩展角色权限管理，或集成其他身份提供者（如 Google、Microsoft 等），打造更加灵活的身份验证体系。","link":"/posts/86ef0187/"},{"title":"CoCo AI APP 初体验：开启智能知识管理新篇章","text":"近日，极限科技的 Coco AI 正式发布。作为一款完全开源、跨平台的统一 AI 搜索与效率工具，Coco AI 能够无缝连接并搜索多种数据源，包括本地应用程序、文件以及云端平台如 Google Drive、Notion、语雀和 Hugo 等。通过集成 DeepSeek 等先进的大模型，Coco AI 不仅实现了智能化的个人知识库管理，还特别注重用户隐私，支持私有部署，帮助用户更快速、更智能地访问和管理信息。 Coco AI本次发布的是 Coco AI 的首个预览版本，目前支持 MacOS 12 及以上操作系统。无论你是知识管理爱好者还是效率工具控，Coco AI 都值得一试。 项目主页: https://coco.rs/ 开源地址: 桌面应用端: https://github.com/infinilabs/coco-app/ 服务端: https://github.com/infinilabs/coco-server Coco AI 分为客户端（APP）和服务端（Server），目前客户端仅提供 MacOS 版本，而服务端则支持 MacOS 和 Linux。今天，我们将重点体验客户端的使用。 下载与安装首先，从项目主页或 GitHub 仓库下载 Coco AI 的安装包。安装过程简单直观，只需几步即可完成。 安装完成后，启动 Coco AI，你会在导航栏中看到它的图标。 初始设置在设置页面，你可以根据个人喜好进行一些基本配置，如设置自动启动、自定义搜索栏热键、以及是否跟随系统主题等。 登录与连接默认情况下，Coco AI 会连接到 Coco Cloud。你可以选择登录以解锁更多功能。目前，Coco AI 支持通过 GitHub 和 Google 进行单点登录（SSO）。 登录成功后，系统会自动重定向到 Coco AI 的主界面。 语料库管理登录后，Coco AI 默认会添加极限科技官方及相关衍生产品作为初始语料库。如果你有自己的服务器，还可以添加更多个性化的语料库，如 Google Docs、语雀、Notion 等。 RAG 搜索体验Coco AI 的强大之处在于其 RAG（Retrieval-Augmented Generation）搜索功能。通过这一功能，你可以快速检索到自己之前撰写的文章或其他文档。 此外，搜索栏还可以作为一个站内聊天机器人使用，默认 Coco Cloud 的后端接入的大模型是 deeseek，进一步提升交互体验。 总结Coco AI 作为一款全新的 AI 搜索与效率工具，凭借其开源、跨平台、智能化等特性，为用户提供了极大的便利。无论是个人知识管理还是团队协作，Coco AI 都能胜任。期待未来更多功能的加入，也欢迎更多用户加入 Coco AI 的体验之旅！","link":"/posts/eb0b4c83/"},{"title":"Coco-AI 接入 Google drive","text":"在 Coco-AI 最早的版本就提供了接入 Google drive 的视频，今天我终于实现了，而且借着全图形化的优势更加方便了。 参考这个文档新建 google SSO（好像也没啥参考性） https://developers.google.com/workspace/drive/api/quickstart/go?hl=zh-cn 创建客户端 填入信息， 然后在数据访问中添加权限 - 缺少的权限加在这里（如图），https://www.googleapis.com/auth/drive 在 coco-sever 更新 google drive 的信息 然后在 coco-server 中连接 跳转 google sso 由于是测试账户，所以会有这个弹窗，继续就好 再次进行测试 获取权限 显示登陆成功 然后可以在数据源中看到对应数据","link":"/posts/10b05aec/"},{"title":"从零到用：RSS 接入 Coco-AI 实战指南","text":"最近 Coco-AI 上线了几个新功能：S3 连接器、本地文件连接器、RSS 连接器。我会逐一介绍，本篇先重点讲 RSS 连接器的接入方法。 一、安装 Coco Server使用 Docker 部署是最省心的方式。 方式 1：映射数据目录（推荐）1234567docker run -d \\ --name cocoserver \\ -p 9000:9000 \\ -v data:/app/easysearch/data \\ -v config:/app/easysearch/config \\ -v logs:/app/easysearch/logs \\ infinilabs/coco:0.7.1-2426 方式 2：快速测试（不映射目录）1234docker run -d \\ --name cocoserver \\ -p 9000:9000 \\ infinilabs/coco:0.7.1-2426 测试环境可以用方式 2，生产环境建议使用方式 1，避免数据丢失。 二、模型配置创建完用户后，我直接设置了 Ollama 作为模型提供商： 地址：http://localhost:11434 模型：deepseek-r1:7b 在「模型提供商」界面可以看到默认开启的 Coco AI，它会直接调用我配置的 Ollama，也支持其他兼容 OpenAI API 的 LLM。 三、数据源概览Coco-AI 默认植入了官方文档和 Hacker News 数据源，这次新增了三类连接器： S3 连接器 本地文件连接器 RSS 连接器（本篇重点） 四、添加 RSS 连接器 选择 RSS 连接器 输入 RSS 地址（这里我用的是我的博客）： 1https://airag.click/atom.xml 刷新时间设为 1 分钟（默认即可） 添加完成后可以看到我同时接入了 S3、本地文件和 RSS： 五、小插曲：RSS 条目数量限制一开始我发现 Coco-AI 只能显示 最近 20 条，以为是 Coco Server 的限制，后来群友提醒才发现是 RSS 服务端设置的问题。 在博客服务端调整配置后，RSS 就能显示 全部文章 了。虽然很多 RSS 只显示最近内容，但其实可以通过配置让它输出完整数据。 六、在 Coco App 中查看数据源登录 Coco App 后，可以看到刚才添加的 S3、本地文件和 RSS 数据源： 七、搜索效果使用 Coco-AI 搜索时，能快速检索到 RSS 中的内容，效果比博客自带的好很多： 点击搜索结果可直接跳转到博客文章。我用的是 Hexo 主题，其他 RSS 源也一样适用。 总结通过 RSS 连接器，Coco-AI 可以实时抓取和索引博客内容，并与本地文件、S3 数据等统一搜索，非常适合做多源聚合知识库。 如果 RSS 输出有限，可以调整博客端的 RSS 配置，让它输出更多历史内容，发挥 Coco-AI 检索的最大价值。","link":"/posts/2c28c43/"},{"title":"Coco AI × Amazon S3：秒搜你的云端文件","text":"随着企业和个人数据量的激增，如何高效管理与搜索云端资料，成为提升工作效率的关键。Coco-AI 新增的 S3 对象存储连接器，可以将 Amazon S3 存储桶直接接入智能检索系统，实现秒级搜索、即时访问，让云端文件像本地文档一样触手可及。 本篇将详细介绍如何通过 Docker 快速部署 Coco Server，并配置 S3 连接器，完成与亚马逊云科技的无缝集成。 一、快速部署 Coco ServerCoco Server 是连接器功能的运行核心，部署好它后才能接入 S3。生产环境建议使用持久化存储方式，避免数据丢失。 推荐部署方式（生产环境）持久化存储，避免数据丢失： 1234567docker run -d \\ --name cocoserver \\ -p 9000:9000 \\ -v data:/app/easysearch/data \\ -v config:/app/easysearch/config \\ -v logs:/app/easysearch/logs \\ infinilabs/coco:0.7.1-2426 测试部署方式（非持久化） 1234docker run -d \\ --name cocoserver \\ -p 9000:9000 \\ infinilabs/coco:0.7.1-2426 建议生产环境使用第一种部署方式，测试环境可选择第二种。 二、配置 AI 模型创建用户后，我选择 Ollama 作为模型提供商： 地址：http://localhost:11434 模型：deepseek-r1:7b 在「模型提供商」界面可以看到默认开启的 Coco AI，它会直接调用我配置的 Ollama，也支持其他兼容 OpenAI API 的 LLM。 三、数据源概览Coco AI 默认内置官方文档和 Hacker News 数据源，近期新增三类连接器： S3 连接器（本篇重点） 本地文件连接器 RSS 连接器 四、接入 Amazon S3 选择 S3 对象存储连接器填写 Endpoint（例：东京区 s3.ap-northeast-1.amazonaws.com）、Bucket 名称、亚马逊云科技凭证（Access Key ID / Secret Access Key），刷新间隔建议保持 1 分钟 默认值。 获取亚马逊云科技访问凭证 登录 亚马逊云科技 IAM 控制台 创建访问密钥（Access Key ID / Secret Access Key） 为用户分配最小化 S3 访问权限（推荐遵循最小权限原则） 这里选择访问密钥 - 创建访问密钥，然后保存 Access Key ID / Secret Access Key 就好。 创建过程中会出现最佳实践提示，不影响后续配置，下载密钥即可使用。其他的凭证方式虽然有 IAM Role 和 Role anywhere，但是我们这次不会用到。 确保这个用户有访问 S3 的权限，如果是生产的环境的话，确保要采用最小权限原则来防止不必要的麻烦。如果你在存储桶上配置了对应桶策略也可以。 对象前缀（Prefix）配置这个是我在 S3 上的对象存储，放了一些 markdown 文件上去。还是这张图，我使用的是东京区的存储桶 dify233，所以 endpoint 是 s3.ap-northeast-1.amazonaws.com。 这里的对象前缀可以理解为目录，在 S3 设置之初会把所有文件夹的名称当作前缀加到文件名前面，所以也有 S3 是扁平化管理一说。 五、集成效果完成连接后，S3 中的 Markdown 文件可被 Coco AI 实时索引与检索，点击搜索结果即可跳转到 S3 公网访问链接，例如： 1https://&lt;bucket&gt;.s3.&lt;region&gt;.amazonaws.com/&lt;对象名&gt; 不仅支持标题关键词搜索，还可结合 LLM 实现语义检索，极大提升信息获取效率。 添加完成后可以看到我同时接入了 S3、本地文件和 RSS，我们这里主要开介绍关于 S3 的连接器。 使用 Coco-AI 搜索时，能快速检索到 s3 中的 markdown 文件。 点击搜索结果可直接跳转到对应链接。 也支持把地址复制出来：https://dify233.s3.ap-northeast-1.amazonaws.com/对象名，其实就是S3的https 链接了。 六、适用场景 企业内部知识库：研发文档、政策文件、培训资料统一存放于 S3 个人云端资料管理：博客、项目资料随时调用 跨团队协作：多地访问，实时共享 通过 Coco AI S3 连接器，只需几步，即可让 ** Amazon S3** 成为高效智能检索系统的云端引擎。无论是个人开发者，还是大型企业团队，都能快速构建跨云端、本地、第三方数据源的统一知识平台。","link":"/posts/f050840/"},{"title":"Coco AI 服务端文件系统检索","text":"随着企业和个人数据量的激增，如何高效管理与搜索文件资料，已成为提升工作效率的关键。 Coco AI 新增的 本地文件连接器，可以直接接入服务端文件系统，实现秒级搜索、即时访问，让服务器上的文件像本地文档一样触手可及。 本文将介绍如何通过 Docker 快速部署 Coco Server，并配置本地文件连接器，实现服务端文件的智能检索。 一、快速部署 Coco ServerCoco Server 是连接器功能的核心组件，部署完成后即可接入本地文件、RSS 等多种数据源。生产环境建议使用持久化存储，避免数据丢失。 1. 推荐部署方式（生产环境）1234567docker run -d \\ --name cocoserver \\ -p 9000:9000 \\ -v data:/app/easysearch/data \\ -v config:/app/easysearch/config \\ -v logs:/app/easysearch/logs \\ infinilabs/coco:0.7.1-2426 2. 测试部署方式（非持久化）1234docker run -d \\ --name cocoserver \\ -p 9000:9000 \\ infinilabs/coco:0.7.1-2426 建议生产环境使用持久化部署（第一种方式），测试环境可选择非持久化部署（第二种方式）。 二、配置 AI 模型创建用户后，我选择 Ollama 作为模型提供商： 地址：http://localhost:11434 模型：deepseek-r1:7b 在「模型提供商」界面可以看到默认启用的 Coco AI，它会直接调用已配置的 Ollama，也支持任何兼容 OpenAI API 协议的 LLM。 三、数据源概览Coco AI 默认内置了 官方文档 和 Hacker News 数据源，并在近期新增： 本地文件连接器（本文重点） RSS 连接器 S3 连接器 四、配置本地文件连接器本地连接器的配置非常简单，只需： 选择文件路径 设置需要索引的文件后缀 等待系统从 localFS 中智能提取内容 使用 Docker 时的注意事项如果通过 Docker 部署 Coco Server，需要将本地目录映射到容器内，因为连接器读取的是容器内部路径，而非主机路径。 当然，也可以像我这样直接在 Orbstack 等容器平台上传文件，省去目录映射的步骤。 添加完成后，可以在连接器列表中看到新建的服务端本地文件连接器： 五、在 Coco App 中查看与检索登录 Coco App 后，可以看到刚刚添加的 本地文件 数据源，并直接进行搜索。 这是刚才添加的服务端文件的搜索结果： 此外，Coco AI 还支持客户端本地文件搜索，但本文重点展示的是服务端文件检索功能： 结尾通过本地文件连接器，Coco AI 不仅能帮助你把服务端的文档、日志、配置文件快速接入 AI 检索，还能结合多数据源进行统一搜索，大幅减少人工查找和信息碎片化的时间成本。 未来你还可以将 本地文件检索 与 RSS、API、数据库连接器组合使用，让企业级信息管理更智能、更实时、更高效。如果你也想让服务器里的海量资料触手可及，不妨部署一个试试——也许你的检索方式，从今天就会不一样。","link":"/posts/ca3451f/"},{"title":"在 Coco AI 中接入 WordPress RSS，实现文章秒级搜索","text":"随着内容创作者不断积累文章，如何让自己的内容被快速检索、精准找到，成为提升网站体验的重要一环。 尤其是对于使用 WordPress 搭建博客或官网的朋友来说，文章虽多，但用户往往需要翻页或依赖站内搜索才能找到所需内容。而如果能把 WordPress 的文章源接入 Coco AI，不仅能实现秒级检索，还可以结合 AI 进行智能问答、聚合分析，让你的内容价值成倍提升。 今天我就来分享一下，如何用 WordPress 自带的 RSS 功能，把文章无缝接入到 Coco AI 中，实现一键搜索全站文章。 1. 准备工作在开始之前，你需要： 已经安装好的 WordPress 网站（如果不会安装，可以参考我之前的文章）👉 WordPress 安装教程 有一个可用的 Coco AI 服务端（本地部署或云端均可） 2. 获取 WordPress RSS 链接WordPress 默认的 RSS 地址格式非常简单： 1http(s)://你的域名/feed 为了确保 RSS 链接正常工作，你可以使用 Fluent Reader 这样的本地 RSS 阅读器测试一下。如果能正常读取文章列表，说明 RSS 输出正常： 3. 设置 RSS 输出数量与摘要长度为了让 Coco AI 一次获取更多的文章，你可以在 WordPress 后台调整 RSS 输出数量： 文章数量：一次输出多少篇文章（根据需求设置，建议 20~50 篇） 摘要长度：决定 AI 抓取的内容字数，摘要越长，AI 的理解能力越强 4. 在 Coco AI 中添加 RSS 连接器接下来进入 Coco AI 管理后台，新建一个 RSS 连接器： 在“数据源”中选择 RSS 填写刚刚获取的 WordPress RSS 链接 设置刷新频率（例如每 5 分钟、15 分钟） 配置完成后，你会在连接器列表中看到刚添加的 WordPress RSS 源： 5. 刷新并查看文章等待 Coco AI 进行第一次数据抓取，稍后就能在文章列表中看到你的 WordPress 文章： 在 Coco AI 客户端的搜索栏中，直接输入关键词，就能实时搜索 WordPress 全站文章： 点击搜索结果，Coco AI 会直接跳转到对应的 WordPress 文章主页： 6. 使用场景与优势通过这种方式接入 RSS，你可以： 快速检索：秒级找到 WordPress 上的历史文章 跨平台聚合：和其他数据源一起接入 Coco AI，实现跨网站统一搜索 AI 智能问答：基于你的网站内容，直接生成读者提问的答案 知识库构建：将博客内容沉淀为长期可用的知识库 只需几个步骤，就能让 WordPress 与 Coco AI 打通，实现全站文章的智能化搜索与访问。如果你的网站内容很多、更新频繁，这种方法能极大提升读者和你的检索效率，让你的文章真正“活”起来。","link":"/posts/2bdb8c4a/"},{"title":"手把手教你hexo接入Coco-AI","text":"","link":"/posts/47752b69/"},{"title":"打造智能语料库：通过Coco AI Server 实现 Notion 笔记 RAG 检索功能","text":"CoCo Server 部署 RAG，使用 Notion 作为语料库（上） 启动 Easysearch，这里把 Easysearch 作为语料库，把 notion 的素材存在 Easysearch 启动 ollama，使用 LLM 进行推理 启动 Coco Server，端口在 9000 Coco App 连接 Sever，输入输入 登录自己 server，依旧使用 Github 登录 Github 登录之后的重定向，我们目前需要抓取最后的, 后面用这个 token 换取访问 Coco Server AI 的 key： 12coco://oauth_callback?code=cupibub55o1cfqbveps0q804ai6aj14in3u91xjhvuk8s7ixirjsq2j9mmyyeut91nmgjwz0b494ngpk&amp;request_id=eb94762b-f054-4710-9c6cf20889d3&amp;provider=coco-cloud 认证步骤如下： 第一步:http://localhost:9000/sso/login/github?provider=coco-cloud&amp;product=coco&amp;request_id=dd9825e1-ebd3-4c84-9e3f-7ccb0421c508 会返回一个 Token,记录下来,这个是只是临时的, 如 XXABC 第二步:curl -H’X-API-TOKEN: XXABC’ “http://localhost:9000/auth/request_access_token?request_id=dd9825e1-ebd3-4c84-9e3f-7ccb0421c508“ 返回的才是你要的 Token 在 postman 中换 token，得到 access_token 和过期时间： 123456789101112131415161718192021222324252627import requestsdef parse_oauth_callback(url): query_params = {param.split('=')[0]: param.split('=')[1] for param in url.split('?')[1].split('&amp;')} code = query_params.get(&quot;code&quot;) request_id = query_params.get(&quot;request_id&quot;) return code, request_iddef request_access_token(code, base_url, request_id): url = f&quot;{base_url}/auth/request_access_token?request_id={request_id}&quot; headers = {&quot;X-API-TOKEN&quot;: code} response = requests.get(url, headers=headers) return response.json()# 示例输入oauth_callback_url = &quot;&quot;&quot;coco://oauth_callback?code=cupibub55o1cfqbveps0q804ai6aj151wu4in3u91xjhvuk8s7ixirjsq2j9mmyyeut91nmgjwz0b494ngpk&amp;request_id=eb94762b-f054-4710-9c6a-0cf2088729d3&amp;provider=coco-cloud&quot;&quot;&quot;base_url = &quot;http://localhost:9000&quot;# 解析 code 和 request_idcode, request_id = parse_oauth_callback(oauth_callback_url)# 发送请求token_response = request_access_token(code, base_url, request_id)print(token_response) 可以用 access_key 查看用户信息： 12345678910111213import requestsurl = &quot;http://localhost:9000/account/profile&quot;payload = {}headers = { 'X-API-TOKEN': 'cupichb55o1cfqbveq90zwomyxs791ul3esbxxt480c8dzgvdtjtvmcnsld4a5v0wvx9l9ofcf1'}response = requests.request(&quot;GET&quot;, url, headers=headers, data=payload)print(response.text) 注册 Notion connector： 12345678910111213141516171819202122232425262728293031323334353637import requestsimport jsondef update_connector(base_url, api_token, connector_name, data): url = f&quot;{base_url}/connector/{connector_name}?replace=true&quot; headers = { &quot;X-API-TOKEN&quot;: api_token, &quot;Content-Type&quot;: &quot;application/json&quot; } response = requests.put(url, headers=headers, data=json.dumps(data)) return response.json()base_url = &quot;http://localhost:9000&quot;api_token = &quot;&lt;token&gt;&quot;notion_data = { &quot;name&quot;: &quot;Notion Docs Connector&quot;, &quot;description&quot;: &quot;Fetch the docs metadata for notion.&quot;, &quot;icon&quot;: &quot;/assets/connector/notion/icon.png&quot;, &quot;category&quot;: &quot;website&quot;, &quot;tags&quot;: [&quot;docs&quot;, &quot;notion&quot;, &quot;web&quot;], &quot;url&quot;: &quot;http://coco.rs/connectors/notion&quot;, &quot;assets&quot;: { &quot;icons&quot;: { &quot;default&quot;: &quot;/assets/connector/notion/icon.png&quot;, &quot;web_page&quot;: &quot;/assets/connector/notion/icon.png&quot;, &quot;database&quot;: &quot;/assets/connector/notion/database.png&quot;, &quot;page&quot;: &quot;/assets/connector/notion/page.png&quot; } }}response_notion = update_connector(base_url, api_token, &quot;notion&quot;, notion_data)print(response_notion) 修改 Notion 配置文件，激活检索 Notion： 在 Notion 这个网站申请 API key，https://www.notion.so/profile/integrations 配置完成之后，设置权限和展示 apikey 配置 Notion Connector，这里需要用到 Notion 的 API Key: 12345678910111213141516171819202122232425262728293031import requestsimport jsondef create_datasource(base_url, api_token, data): url = f&quot;{base_url}/datasource/&quot; headers = { &quot;X-API-TOKEN&quot;: api_token, &quot;Content-Type&quot;: &quot;application/json&quot; } response = requests.post(url, headers=headers, data=json.dumps(data)) return response.json()# 示例输入base_url = &quot;http://localhost:9000&quot;api_token = &quot;&lt;api-key&gt;&quot;datasource_data = { &quot;name&quot;: &quot;My Notion&quot;, &quot;type&quot;: &quot;connector&quot;, &quot;connector&quot;: { &quot;id&quot;: &quot;notion&quot;, &quot;config&quot;: { &quot;token&quot;: &quot;&lt;notion token&gt;&quot; } }}# 发送 POST 请求response = create_datasource(base_url, api_token, datasource_data)print(response) 需要在 Notion 中设置集成，这样 Coco Server 才会搜索到： Coco server 日志中可以检索到 notion 了： 终于可以在搜索栏检索到了。","link":"/posts/3d90967f/"},{"title":"Coco AI 全新升级：全图形化 RAG 配置，一键开启智能知识管理！","text":"Coco AI 再升级，全图形化配置 RAG在《Coco AI APP 初体验：开启智能知识管理新篇章》和《打造智能语料库：通过 Coco AI Server 实现 Notion 笔记 RAG 检索功能》中，我介绍了 Coco AI 的第一个版本 ，我们我需要调用服务端的接口来手动添加数据源和配置登录信息，见那么在 0.2 的版本中，极限科技又开发了一个管理页面用来处理这些繁琐的信息。 同时这次更新也带来了全平台的支持，当然如果你愿意也可以自己编译源代码。 我们先来用 Docker 启动服务端，一行命令搞定，不需要再传递负载的命令行参数，也无需在启动 Easysearch。 1docker run -d --name cocoserver -p 9000:9000 infinilabs/coco:0.2.1-1998 服务启动在 9000 端口，那么在浏览器中打开欢迎页面： 创建账户，选择模型，和之前一样，我还是选择本地部署的 ollama 并且使用 deepseek 模型。 设置完成后我们看到主页面，我们的目的是添加数据源，这样就不用使用复杂的请求。 可以进一步设置 LLM 推理后端： AI 助手这个功能还在开发中，后续可以期待一下。 连接数据源这里我认为是最大的亮点之一，不用再想之前改配置文件了，需要做的事情简单，以 Notion 为例简单填入 Token 和设置刷新时间即可。后按与 Notion 数据源的详细配置，可以回看之前写的《打造智能语料库：通过 Coco AI Server 实现 Notion 笔记 RAG 检索功能》 过了一会就可以在数据源中刷新出来的文档了，目前 Notion 只导入了标题，后期后导入具体内容的计划。 甚至还可以在这里进行搜索，小小的站内搜索吧。 然后回到客户端，进行登录，同时也支持暂时关闭不再需要的数据源。 登录这里不再需要手动抓 token 了，直接重定向，很方便。 登录之后，和之前一样检索，总体来说比之前省心很多。 我之前使用的是 0.1 的版本，再登录之后会遇到这个错误，只要重新安装最新版本的客户端就好了。 升级之后同样这个 chat 也进化了，还支持深度思考。由于这里我只导入了文档的标题，所以它也只给我回了文档。 这次更新体验直接提升了一大截，精简了很多配置，也简化了登录信息。感觉差不多下一步可以把这个服务部署到 NAS 上做日常使用了。","link":"/posts/b126c84d/"},{"title":"Coco AI 智能检索 Hugo Blog 集成指南","text":"在此前的文章中，我们介绍了如何使用 Coco Server 连接 Notion，实现智能内容检索。本次，我们将进一步探索如何在 Coco Server 最新版本 中集成 Hugo Site，以便对 Hugo 站点 进行高效检索。 Coco Server 部署方式要在本地或服务器上运行 Coco Server，可以借助 Docker 进行快速部署。 1. 直接运行 Coco Server（默认配置）执行以下命令，快速启动 Coco Server（版本 0.2.2-2000）： 1docker run -d --name cocoserver -p 9000:9000 infinilabs/coco:0.2.2-2000 此命令将在后台运行 Coco Server，并将 9000 端口 映射到本机，以便通过 Web UI 进行访问。 2. 启用数据持久化（推荐）如果希望数据在容器重启或删除后仍然保留，建议启用 数据持久化，操作步骤如下： （1）创建数据目录并设置权限12mkdir -p $(pwd)/cocoserver/{data,logs}sudo chown -R 602:602 $(pwd)/cocoserver （2）启动 Coco Server 并挂载数据目录123456789101112docker run -d \\ --name cocoserver \\ --hostname coco-server \\ --restart unless-stopped \\ -m 4g \\ --cpus=&quot;2&quot; \\ -p 9000:9000 \\ -v $(pwd)/cocoserver/data:/app/easysearch/data \\ -v $(pwd)/cocoserver/logs:/app/easysearch/logs \\ -e EASYSEARCH_INITIAL_ADMIN_PASSWORD=coco-server \\ -e ES_JAVA_OPTS=&quot;-Xms2g -Xmx2g&quot; \\ infinilabs/coco:0.2.2-2000 这样，所有 检索数据 和 日志信息 都会存储在 ./cocoserver/data 和 ./cocoserver/logs 目录下，即使容器重启，数据仍然可用。 3. 使用 Docker Compose 部署如果你希望使用 docker-compose 进行更便捷的管理，可以采用以下 docker-compose.yml 文件： 12345678910111213141516171819202122232425version: &quot;3.8&quot;services: cocoserver: image: infinilabs/coco:0.2.2-2000 container_name: cocoserver hostname: coco-server restart: unless-stopped ports: - &quot;9000:9000&quot; deploy: resources: limits: memory: 4g cpus: &quot;2&quot; volumes: - ./cocoserver/data:/app/easysearch/data - ./cocoserver/logs:/app/easysearch/logs environment: EASYSEARCH_INITIAL_ADMIN_PASSWORD: &quot;coco-server&quot; ES_JAVA_OPTS: &quot;-Xms2g -Xmx2g&quot;volumes: data: logs: 运行以下命令启动 Coco Server： 1docker-compose up -d 如需停止并删除容器，可执行： 1docker-compose down 如果需要同时删除存储数据，则执行： 1docker-compose down -v Hugo 站点智能检索成功部署 Coco Server 后，即可将 Hugo 站点 作为数据源进行智能检索。 1. 添加 Hugo Site 数据源在 Coco Server Web UI 中，进入 “数据源” 页面，并点击 “添加 Hugo Site”。 2. 设定 Hugo 站点 URL以 Pizza 官网 为示例，在输入框中填入相应的 URL 并保存。 配置完成后，Coco Server 会自动抓取 Hugo 站点的内容并进行索引。 构建自己的 Hugo 站点，并让 Coco 进行检索完成 Pizza 官网的 Hugo 站点检索测试后，我们可以创建 自己的 Hugo 站点，并让 Coco Server 进行智能索引。 1. 安装 HugoMac1brew install hugo Windows1scoop install hugo-extended Linux1sudo apt install hugo 安装完成后，可运行 hugo version 确认是否安装成功。 2. 创建 Hugo 站点1234hugo new site my-hugo-sitecd my-hugo-sitegit initgit submodule add https://github.com/theNewDynamic/gohugo-theme-ananke.git themes/ananke 3. 配置 Hugo 以生成 JSON 数据在 hugo.toml 文件中，添加 JSON 输出 配置： 1234567891011baseURL = &quot;https://example.com/&quot;languageCode = &quot;en-us&quot;title = &quot;My Hugo Site&quot;theme = &quot;ananke&quot;[outputs] home = [&quot;HTML&quot;, &quot;JSON&quot;] section = [&quot;HTML&quot;, &quot;JSON&quot;] taxonomy = [&quot;HTML&quot;, &quot;JSON&quot;] term = [&quot;HTML&quot;, &quot;JSON&quot;] 4. 创建 JSON 模板在 layouts/_default/list.json 文件中，添加以下内容： 1234567891011121314151617[ {{- range $index, $element := .Site.RegularPages -}} {{- if gt $index 0 }},{{ end }} { &quot;category&quot;: {{ $element.Params.category | jsonify }}, &quot;content&quot;: {{ $element.Content | plainify | jsonify }}, &quot;created&quot;: {{ $element.Date | time.Format &quot;2006-01-02T15:04:05Z07:00&quot; | jsonify }}, &quot;lang&quot;: {{ $element.Lang | default &quot;en&quot; | jsonify }}, &quot;subcategory&quot;: {{ $element.Params.subcategory | jsonify }}, &quot;summary&quot;: {{ $element.Params.summary | jsonify }}, &quot;tags&quot;: {{ $element.Params.tags | jsonify }}, &quot;title&quot;: {{ $element.Title | jsonify }}, &quot;updated&quot;: {{ $element.Lastmod | time.Format &quot;2006-01-02T15:04:05Z07:00&quot; | jsonify }}, &quot;url&quot;: {{ $element.RelPermalink | jsonify }} } {{- end -}}] 5. 运行 Hugo 并生成 JSON1hugo server -D 然后在浏览器访问： 1http://localhost:1313/index.json 你将看到 Hugo 站点生成的 JSON 数据，例如： 1234567[ { &quot;title&quot;: &quot;My First Post&quot;, &quot;content&quot;: &quot;This is a test post...&quot;, &quot;url&quot;: &quot;/posts/my-first-post/&quot; }] 6. 让 Coco Server 索引 Hugo JSON API在 Coco Server 数据源管理 中，输入 Hugo 站点 JSON API 地址，例如： 1http://host.docker.internal:1313/index.json 如果 Coco Server 运行在 Docker 内，而 Hugo 站点 运行在本机，则 localhost 访问可能会失效，此时应使用 host.docker.internal 访问宿主机。 添加成功后，Coco Server 会自动抓取并解析 Hugo 站点数据，实现智能检索。 总结通过本指南，我们已成功完成： ✅ 部署 Coco Server（支持 Docker / Docker Compose）✅ 添加 Hugo Site 作为数据源✅ 配置 Hugo 站点，生成 JSON API✅ 让 Coco Server 索引 Hugo 站点，实现智能检索 现在，我们可以使用 Coco AI 高效检索 Hugo 站点内容，大幅提升信息查找效率！🚀","link":"/posts/afa68182/"},{"title":"不建 Hugo、不用 Hexo，纯 Markdown 文件也能接入 Coco-AI！","text":"之前我们介绍过如何通过 Coco-AI 检索 Hugo 和 Hexo 的文件结构。这种方式虽然适合博客类内容，但对于一些零碎的笔记或者并非建站类的 Markdown 文件，显然不够灵活。 为了解决这个问题，我写了一个适配器（connector），并发布了对应的 Docker 镜像，来实现任意 Markdown 文件目录的元数据整理与 API 暴露： 👉 镜像地址：https://hub.docker.com/r/cloudsmithy/flask-markdown-connector 核心原理该 connector 的主要逻辑是： 递归扫描目录及子目录下的 Markdown 文件； 识别或补充元数据（即 YAML Front Matter）； 通过 RESTful API 暴露这些 Markdown 的结构信息和元数据内容。 如下图所示，我们会在每个 Markdown 文件开头添加或提取出 YAML 元数据： 一键部署使用以下命令即可快速拉起服务： 12345docker run -d --name markdown-connector \\ -p 1313:5000 \\ -v &quot;$(pwd):/app/markdown&quot; \\ --restart always \\ cloudsmithy/flask-markdown-connector 参数说明： -d：后台运行容器； --name markdown-connector：指定容器名称； -p 1313:5000：将宿主机的 1313 端口映射到容器的 5000 端口； -v &quot;$(pwd):/app/markdown&quot;：将当前目录挂载进容器； --restart always：配置容器异常退出后自动重启； cloudsmithy/flask-markdown-connector：镜像名称。 API 一览通过浏览器访问 http://localhost:1313/apidocs 即可打开内置 Swagger 文档。方便上层系统（如 Coco-AI）访问 Markdown 文件的元数据与内容。接口结构简洁直观，支持获取索引、刷新缓存、读取内容等功能。 🔹 GET /功能：返回服务启动提示信息说明：用于检查服务是否正常运行示例响应： 1{ &quot;message&quot;: &quot;Markdown Connector is running.&quot; } 🔹 GET /api/posts功能：获取生成的 index.json（缓存版）说明：返回 Markdown 文件的路径与元数据列表，从缓存中读取，响应速度快用途：Coco Server 可用作索引加载入口示例响应： 123456789[ { &quot;title&quot;: &quot;Docker 学习笔记&quot;, &quot;path&quot;: &quot;dev/docker.md&quot;, &quot;tags&quot;: [&quot;docker&quot;, &quot;学习&quot;], &quot;created&quot;: &quot;2024-11-22&quot; }, ...] 🔹 GET /index.json功能：实时渲染当前 Markdown 目录结构说明：等价于 /api/posts，但是实时读取文件而非使用缓存，适合调试或手动使用用途：确保数据为最新状态时使用 🔹 GET /api/refresh功能：重新扫描并生成最新的 index.json 缓存说明：用于强制刷新目录索引，适用于新增 / 修改了 Markdown 文件后响应示例： 1{ &quot;message&quot;: &quot;Index cache refreshed.&quot; } 🔹 GET /posts/功能：列出 Markdown 文件路径列表（不含元数据）说明：返回所有可访问的 Markdown 文件路径，用于构建下拉菜单、快速跳转响应示例： 1[&quot;notes/linux.md&quot;, &quot;dev/docker.md&quot;, &quot;ideas/gpt-agent.md&quot;] 🔹 GET /posts/{filename}功能：获取指定 Markdown 文件的内容参数： {filename}：Markdown 文件路径（相对于挂载目录） 用途：用于前端点击跳转后展示具体笔记内容响应示例： 1234{ &quot;filename&quot;: &quot;dev/docker.md&quot;, &quot;content&quot;: &quot;# Docker 学习笔记\\n\\n## 容器 vs 镜像 ...&quot;} 用于 Coco Server，推荐使用 /api/posts 作为内容索引源； 使用 /api/refresh 后再拉一次 /api/posts 可确保内容最新； 若前端需要展示具体内容，可调用 /posts/{filename}； 若用在其他 AI 项目中，也可用于构建轻量级 Markdown 知识检索接口。 与 Coco Server 集成在 Orbstack 中，我们可以清晰地看到本地 Markdown 文件已经映射到容器中： 接着我们将 connector 的服务地址填入 Coco Server 配置中： 你可以使用 /api/posts 或 /index.json 接口，它们返回的内容基本一致： /api/posts 是来自缓存的接口； /index.json 是实时渲染本地文件结构。 另外，通过 /api/refresh 还可以手动触发缓存刷新： 效果演示成功接入后，Coco Server 就可以读取 Markdown 文件的结构与元数据信息： 点击条目还可以跳转到对应的网页： 当然，和之前一样，也支持在搜索栏中直接搜索并跳转： 小结通过这个 Flask 版 Markdown Connector，我们可以将任意 Markdown 文件目录结构化暴露给 Coco-AI，实现： 笔记内容统一索引 结构与元数据清晰可控 快速部署，无需 Hugo/Hexo 建站 这对于日常碎片化笔记管理来说，是一个非常轻量又灵活的解决方案。","link":"/posts/df454c34/"},{"title":"拓展 Coco AI 功能 - 智能检索 Hexo 博客","text":"在之前的文章中，我们成功让 Coco AI 检索 Hugo 博客，这对于博客作者来说是一大福音。然而，从 Hexo 迁移到 Hugo 的成本不容小觑，毕竟大多数开发者对 Node.js 更熟悉，而 Golang 相对陌生。那么，既然 Coco AI 官方尚未支持 Hexo，是否有办法让它兼容 Hexo 呢？ 当然可以！💡 既然 Coco AI 依赖的是 Hugo 生成的 index.json 进行检索，那我们干脆在 Hexo 中实现 **相同结构的 index.json**，这样就可以直接复用 Hugo 的数据结构，避免字段不兼容导致的潜在 Bug。 接下来，我们将从 0 到 1 实现 Hexo 的智能检索功能！ 🚀 📌 1. 安装 Hexo 并切换到 Next 主题首先，我们需要安装 Hexo 并设置 Next 主题。 安装 Hexo1234pnpm install -g hexo-clihexo init my-blogcd my-blogpnpm install 启动本地服务器： 1pnpm hexo s 访问 http://localhost:4000/，确保 Hexo 站点运行正常。 安装 Next 主题1pnpm add hexo-theme-next 修改 _config.yml： 1theme: next 然后运行： 1pnpm hexo clean &amp;&amp; pnpm hexo s 访问 http://localhost:4000/，确认 Next 主题已生效。 📌 2. 安装 hexo-generator-json-content我们需要安装 JSON 生成插件，用于输出博客文章数据： 1pnpm add hexo-generator-json-content 这些添加到 _config.yml，确保 Hexo 生成完整的 JSON 数据： 123456789101112jsonContent: meta: false pages: false posts: title: true date: true path: false permalink: true excerpt: true content: true categories: true tags: true 运行： 1pnpm hexo clean &amp;&amp; pnpm hexo generate 然后检查 public/index.json： 1cat public/index.json 此时 JSON 已经生成，但 url 不是 Hugo 风格的，我们需要进一步优化。 **📌 3. 自定义 index.json **默认情况下，Hexo 不会生成 /YYYY/MM/DD/slug/ 格式的 URL，因此我们需要手动调整。 📌 创建 scripts/generate_index_json.js在 Hexo 站点目录 下，创建 scripts/generate_index_json.js： 123456789101112131415161718192021222324252627282930313233343536373839404142434445hexo.extend.generator.register(&quot;index_json&quot;, function (locals) { let posts = locals.posts.sort(&quot;-date&quot;).map((post) =&gt; { let category = post.categories &amp;&amp; post.categories.length &gt; 0 ? post.categories.data[0].name : null; let subcategory = post.categories &amp;&amp; post.categories.length &gt; 1 ? post.categories.data[1].name : null; let tags = post.tags ? post.tags.map((tag) =&gt; tag.name) : null; // 解析发布日期 let date = post.date; let formattedDate = `${date.year()}/${String(date.month() + 1).padStart( 2, &quot;0&quot; )}/${String(date.date()).padStart(2, &quot;0&quot;)}`; // 生成 Hugo 风格 URL: `/YYYY/MM/DD/slug/` let postUrl = `/${formattedDate}/${ post.slug || post.title.replace(/\\s+/g, &quot;-&quot;).toLowerCase() }/`; return { category: category, subcategory: subcategory, content: post.content.replace(/(&lt;([^&gt;]+)&gt;)/gi, &quot;&quot;), // 去除 HTML 标签 created: post.date.toISOString(), updated: post.updated ? post.updated.toISOString() : post.date.toISOString(), lang: &quot;en&quot;, // 你可以修改为动态语言检测 summary: post.excerpt || post.content.substring(0, 150) + &quot;...&quot;, tags: tags, title: post.title, url: postUrl, // 确保符合 Hugo 格式 }; }); return { path: &quot;index.json&quot;, data: JSON.stringify(posts, null, 2), };}); 📌 4. 重新生成 index.json运行： 1pnpm hexo clean &amp;&amp; pnpm hexo generate 然后检查 public/index.json： 1cat public/index.json 你应该会看到 JSON 变成： 1234567891011121314[ { &quot;category&quot;: &quot;Technology&quot;, &quot;subcategory&quot;: &quot;Web Development&quot;, &quot;content&quot;: &quot;This is a test post.&quot;, &quot;created&quot;: &quot;2025-03-20T12:00:00+08:00&quot;, &quot;updated&quot;: &quot;2025-03-20T12:00:00+08:00&quot;, &quot;lang&quot;: &quot;en&quot;, &quot;summary&quot;: &quot;This is a test post.&quot;, &quot;tags&quot;: [&quot;Hexo&quot;, &quot;Static Site&quot;], &quot;title&quot;: &quot;Hello World&quot;, &quot;url&quot;: &quot;/2025/03/20/hello-world/&quot; }] ✅ 成功让 URL 变成 /YYYY/MM/DD/slug/ 格式！ 📌 5. 让 Coco AI 识别 Hexo 博客既然 index.json 已经生成，我们可以像 Hugo 那样，在 Coco AI 里添加 Hexo 博客的检索。 在 Coco AI 里，点击 添加 Hugo Site，然后输入： 1http://host.docker.internal:4000/index.json 如果想测试数据同步，我们可以修改同步时间为 1 秒，以便实时观察更新情况。 📌 6. 观察数据同步情况过了一会，我们可以在 Coco AI 界面看到博客数据已经同步，但前提是需要先添加模型！ ✅ Coco AI 的 KNN（近邻搜索） 会按照相关性对内容进行智能排序，使检索更高效！ 🎯 总结 步骤 命令 安装 Hexo 并切换到 Next 主题 pnpm install -g hexo-cli &amp;&amp; hexo init my-blog 安装 hexo-generator-json-content pnpm add hexo-generator-json-content 修改 _config.yml 让 Hexo 生成 index.json 创建 scripts/generate_index_json.js 确保 URL 变成 Hugo 风格 生成 JSON pnpm hexo clean &amp;&amp; pnpm hexo generate 在 Coco AI 里添加 Hexo 站点 输入 http://host.docker.internal:4000/index.json 🚀 结论🎉 通过本教程，你已经成功： ✅ 让 Coco AI 兼容 Hexo 博客，实现智能检索✅ 复用 Hugo 的 index.json 结构，避免迁移成本✅ 让 URL 变成 /YYYY/MM/DD/slug/ 以适配 Hugo Connector✅ 在 Coco AI 里成功同步 Hexo 博客数据，并进行智能查询 💡 现在，你可以愉快地使用 Hexo + Coco AI 进行智能检索了！如果有 更多定制需求（如 author、word count），可以继续优化 generate_index_json.js！🔥🚀","link":"/posts/9eab63c2/"},{"title":"Coco-AI 支持嵌入，让你的网站拥有 AI 搜索力","text":"Coco-AI 支持嵌入，让你的网站支持 AI 搜索在之前的文章中，我们让 Hexo，hugo 博客 支持了 coco AI 检索，也就是说我们还得使用客户端来检索，那是不是把搜索放在博客上呢？ Coco-AI 在 0.3 的版本中 先找一个 html 来看个效果。 123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE html&gt;&lt;html lang=&quot;zh-CN&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot; /&gt; &lt;title&gt;搜索组件嵌入示例&lt;/title&gt; &lt;style&gt; body { font-family: sans-serif; padding: 2rem; } #searchbox { margin-top: 20px; border: 1px solid #ccc; padding: 16px; border-radius: 8px; } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;欢迎使用 Cloudsmithy 搜索组件&lt;/h1&gt; &lt;p&gt;下面是通过 ES Module 引入的搜索框：&lt;/p&gt; &lt;div id=&quot;searchbox&quot;&gt;&lt;/div&gt; &lt;script type=&quot;module&quot;&gt; import { searchbox } from &quot;http://localhost:9000/integration/cvmhvjl92jog2dokvsd0/widget&quot;; searchbox({ container: &quot;#searchbox&quot;, }); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 💡 原始代码：12345&lt;div id=&quot;searchbox&quot;&gt;&lt;/div&gt;&lt;script type=&quot;module&quot;&gt; import { searchbox } from &quot;http://localhost:9000/integration/cvmhvjl92jog2dokvsd0/widget&quot;; searchbox({ container: &quot;#searchbox&quot; });&lt;/script&gt; 🧩 每部分解析1. &lt;div id=&quot;searchbox&quot;&gt;&lt;/div&gt;这是一个空的 div 元素，作为挂载容器。你的 searchbox 组件会被渲染进这个 div。 就像 React 或 Vue 应用会挂载到 &lt;div id=&quot;app&quot;&gt; 一样 你在这里指定了 id 为 searchbox，用于后面初始化组件时绑定 2. &lt;script type=&quot;module&quot;&gt;这表示：这是一个 ES Module 格式的 JavaScript 脚本。 现代浏览器支持原生的模块化加载（无需打包器） 可以使用 import 加载其他模块、组件 3. import { searchbox } from &quot;http://localhost:9000/integration/cvmhvjl92jog2dokvsd0/widget&quot;;从远程地址（本地服务器）中导入 searchbox 函数： 说明这个 URL 返回的是一个 JavaScript 模块，里面导出了 searchbox 类似 Vue、React 中的组件库导入： 1import { Button } from &quot;element-plus&quot;; 4. searchbox({container: &quot;#searchbox&quot;});调用 searchbox 函数，初始化组件，并挂载到页面中： 参数是一个对象，指明组件要渲染在哪个 DOM 元素里 container: &quot;#searchbox&quot; 通过 CSS 选择器指定了上面那个 div 🧠 通俗类比就像你在网页上写： 12345&lt;div id=&quot;chat&quot;&gt;&lt;/div&gt;&lt;script type=&quot;module&quot;&gt; import { chatWidget } from &quot;./chat.js&quot;; chatWidget({ container: &quot;#chat&quot; });&lt;/script&gt; 它就是在某个 div 中挂载一个聊天插件一样。你这段代码的本质就是嵌入并运行一个远程提供的 JS 组件。 ✅ 总结一句话：这段代码的作用是： 把远程加载的 searchbox 组件挂载到网页上的 &lt;div id=&quot;searchbox&quot;&gt; 中，完成动态插入功能。 如果你希望我反向帮你写出那个 searchbox 模块怎么写，或者做成本地文件测试，也可以告诉我~ 下面是一个可以在任意网站自动嵌入你给出的 &lt;div&gt; 和 &lt;script&gt; 的油猴（Tampermonkey）脚本示例： ✅ 功能说明 在页面加载完成后，向 &lt;body&gt; 插入一个 #searchbox 的 div 加载你的远程模块并初始化 searchbox 组件 一开始打算在 hexo 的组件上改，但是在编译阶段有问题，索性使用油猴脚本来实现 🐵 Tampermonkey 脚本示例12345678910111213141516171819202122232425262728// ==UserScript==// @name Searchbox Embedder// @namespace http://tampermonkey.net/// @version 0.1// @description 在任意网页中注入 searchbox 小部件// @author You// @match *://*/*// @grant none// @run-at document-end// ==/UserScript==(function () { &quot;use strict&quot;; // 创建 searchbox 容器 const searchboxDiv = document.createElement(&quot;div&quot;); searchboxDiv.id = &quot;searchbox&quot;; document.body.appendChild(searchboxDiv); // 动态加载模块脚本（ESM） const script = document.createElement(&quot;script&quot;); script.type = &quot;module&quot;; script.textContent = ` import { searchbox } from &quot;http://localhost:9000/integration/cvmhvjl92jog2dokvsd0/widget&quot;; searchbox({ container: &quot;#searchbox&quot; }); `; document.body.appendChild(script);})(); ⚠️ 注意事项 浏览器必须支持 ES Module。 若该域名不是 HTTPS，确保目标网页也是 HTTP，否则会被浏览器拦截跨协议内容。 若需局部生效，请将 @match 改为具体的页面，例如：https://example.com/* 🌟 脚本整体作用这个油猴脚本的作用是：在任何网页上自动插入一个 div#searchbox 容器，并加载你提供的远程模块脚本，渲染搜索框组件。 📜 脚本逐行解析12// ==UserScript==// @name Searchbox Embedder @name 是脚本的名字，显示在 Tampermonkey 的控制面板中。 1// @namespace http://tampermonkey.net/ 命名空间，可以用来区分多个脚本的作者或用途（不重要）。 1// @version 0.1 脚本版本号。 1// @description 在任意网页中注入 searchbox 小部件 简要说明这个脚本做什么。 1// @author You 作者名，可以改成你自己的。 1// @match *://*/* 匹配所有网站页面。如果你只想对某个特定网站注入，可将它改为：// @match https://example.com/* 1// @grant none 没有使用 Tampermonkey 的特殊权限（如 GM_* 方法），所以可以写 none。 1// @run-at document-end 脚本在 DOM 加载完成后执行（类似 DOMContentLoaded）。 💻 主体逻辑解析12(function () { 'use strict'; 启用严格模式，避免某些低级错误。 1234// 创建 searchbox 容器const searchboxDiv = document.createElement(&quot;div&quot;);searchboxDiv.id = &quot;searchbox&quot;;document.body.appendChild(searchboxDiv); 创建一个 &lt;div id=&quot;searchbox&quot;&gt; 并插入到 &lt;body&gt; 中，作为挂载点。 123// 动态加载模块脚本（ESM）const script = document.createElement(&quot;script&quot;);script.type = &quot;module&quot;; 创建一个新的 &lt;script type=&quot;module&quot;&gt;，用来加载 ES 模块。 1234script.textContent = ` import { searchbox } from &quot;http://localhost:9000/integration/cvmhvjl92jog2dokvsd0/widget&quot;; searchbox({ container: &quot;#searchbox&quot; }); `; 直接把模块内容写入 script 标签中： 从你本地地址加载 searchbox 组件 调用 searchbox({ container: &quot;#searchbox&quot; }) 初始化它 12 document.body.appendChild(script);})(); 把这个 &lt;script type=&quot;module&quot;&gt; 插入到 &lt;body&gt; 中，触发模块加载和执行。 ✅ 总结这个脚本做了三件事： 在网页中插入一个 div#searchbox 动态加载你本地的模块组件 初始化这个组件并挂载到 #searchbox 上 你如果希望它在某些页面不显示、加个按钮控制显示、支持浮窗、带样式等等，我也可以帮你升级脚本。需要的话告诉我你的想法~","link":"/posts/e32dbde5/"},{"title":"Coco-AI 集成语雀作为语料库进行检索","text":"coco-AI 把语雀当作语料库做检索说在前面，这个功能需要在语雀后台申请 Personal Access Token。使用的需要超级会员的（不是邀请新用户给的专业会员），所以需要付费使用。 然后在语雀后台，也就是https://www.yuque.com/settings/tokens处可以看见申请token的地方，如果你没有超级会员，这个是没办法用的。 点击新建，创建 token 分发权限，我这边给了所以的权限，语雀和 Notion 不同，这里给了权限就够了，其他地方无需在给权限。（手动@Notion 还要在文档或者文件夹授权） 点击查看详情可以看到 token，这里的 token 是可以反复查看的，由此语雀这一侧的设置完毕。 回到 coco-AI,我这边使用的是这个镜像，这里添加了对个人版本语雀的支持。 1infinilabs/coco:0.3.2_NIGHTLY-20250417 启动命令如下： 1docker run -d --name cocoserver -p 9000:9000 infinilabs/coco:0.3.2_NIGHTLY-20250417 然后进入后台初始化模型，我这里使用的本地部署的 deepseek： 点击数据源，选择 yuque connector 配置的地方很简单，填入数据源名称和 Token 和刷新时间。 然后我们就可以看到刷新的数据了","link":"/posts/6a9ecc86/"},{"title":"Coco-AI 接入自定义数据源","text":"Coco-AI 接入自定义数据源之前使用 Hugo Connector 接入和 hexo 和任意 Markdown，后来官方也支持了对于任意数据源的支持，主要是开放了这个接口： 具体操作如下： 设置 - conntor - 新增，让输入名称和描述等信息，新建出来 conntor 然后我们就能在数据源上的页面上看到刚刚添加的了 Customize Connector 了 点开提示，给了一个 API 然后我们去创建 token，如图 我这边使用 Postman 进行设置 如果你的请求没有带 token，就是这样的。 转成代码的是这样的，当然也可以开发自己的 agent。 1234567891011121314151617181920import requestsimport jsonurl = &quot;http://localhost:9000/datasource/d00eeolvf2xxx/_doc&quot;payload = json.dumps({ &quot;title&quot;: &quot;I am just a Coco doc that you can search&quot;, &quot;summary&quot;: &quot;Nothing but great start&quot;, &quot;content&quot;: &quot;Coco is a unified private search engien that you can trust.&quot;, &quot;url&quot;: &quot;http://coco.rs/&quot;, &quot;icon&quot;: &quot;default&quot;})headers = { 'Content-Type': 'application/json'}response = requests.request(&quot;POST&quot;, url, headers=headers, data=payload)print(response.text)","link":"/posts/271ab503/"},{"title":"如何关闭 AWS root 账号的 MFA 认证","text":"警告：关闭 root 账号的 MFA 认证存在较高风险。AWS 通常不建议此操作，因为 root 账号拥有对所有 AWS 资源的完全控制权限。如果密码或账号信息泄露，可能导致严重的安全事故。 关闭步骤 使用 root 账号登录 AWS 管理控制台 点击右上角账号名称 选择”安全凭证”选项 在页面中找到”多重身份认证(MFA)”部分 点击”删除”即可 然后会收到邮件提醒：","link":"/posts/f4ce40dc/"},{"title":"Amazon OpenSearch Service 现在支持 JSON Web Token（JWT）身份验证和授权","text":"最近，Amazon OpenSearch 推出了一个新功能，支持 JWT 认证和授权。虽然这个功能在开源的 OpenSearch 中早已存在，但在托管的 Amazon OpenSearch 中的实现一直不够理想。 此前的授权方式控制台登录 内部数据库：使用基本的用户名和密码进行 HTTP 验证。如果切换到其他认证方式（如 IAM 或 SAML），此验证方式将被禁用。 IAM 主用户：实际上是通过 Cognito 进行验证。由于中国区没有用户池，设置为 IAM 作为主用户故无法使用。 SAML 单点登录：与 SAML 身份提供商（如 Azure AD、Auth0）集成。SAML 身份验证仅能在浏览器中访问 OpenSearch Dashboard，开启 SAML 后会禁用基本的 HTTP 验证。 编程方式对于 SDK 而言，可以通过在 HTTP 请求中携带用户名和密码，或使用 SignV4 携带 IAM 身份信息进行认证。 常见的解决方案包括： 控制台和 SDK 都使用内部数据库的主用户进行基本 HTTP 验证。 控制台使用内部数据库或 SAML 凭证登录 OpenSearch Dashboard，然后在权限认证中给 IAM 身份单独授权访问索引，这样编程方式就可以使用 SignV4 的签名算法访问集群资源。 JWT 与 OIDCJWT 验证流程 客户端请求：客户端向服务器发出登录请求，提供用户凭证（例如用户名和密码）。 服务器验证凭证：服务器验证用户凭证的有效性。 生成 JWT：如果凭证有效，服务器生成一个包含用户身份信息和其他声明的 JWT，并使用服务器的私钥签名。 返回 JWT：服务器将签名的 JWT 返回给客户端。 客户端存储 JWT：客户端收到 JWT 后，将其存储在本地存储或 cookie 中，以便在后续请求中使用。 携带 JWT 的请求：客户端在每次请求时将 JWT 包含在 HTTP 请求头中（通常是 Authorization: Bearer ）。 服务器验证 JWT：服务器接收到请求后，提取并解析 JWT，验证其签名、有效期和其他声明的合法性。 处理请求：如果 JWT 验证通过，服务器处理请求并返回响应；如果验证失败，返回 401 或 403 错误。 OIDC 验证流程OpenID Connect（OIDC）是在 OAuth 2.0 协议之上构建的一个身份层，用于实现单点登录（SSO）和身份验证。以下是 OIDC 的详细验证流程： 客户端请求身份认证：客户端向身份提供者（IdP）发送身份认证请求，包含 client_id、redirect_uri、scope、response_type 和 state 参数。 用户身份验证：身份提供者显示登录界面，用户输入凭证进行身份验证。 同意授权：用户登录成功后，身份提供者可能会显示同意授权页面。 返回授权码：用户同意授权后，身份提供者重定向客户端到 redirect_uri，并附带一个授权码。 交换授权码：客户端使用授权码向身份提供者的 Token 端点发送请求，以交换 access token 和 ID token。 返回令牌：身份提供者验证授权码后，返回 access token 和 ID token。ID token 是一个包含用户身份信息的 JWT。 验证 ID token：客户端接收到 ID token 后，验证其签名、声明合法性和过期时间。 使用令牌：客户端使用 access token 访问受保护资源，并解码 ID token 中的用户身份信息。 OpenSearch 的 JWT 认证授权2024 年 6 月 19 日 Amazon OpenSearch 在全球区上线了 JWT 认证授权功能，中国区的北京和宁夏区域的此功能在 2024 年 6 月 23 日上线控制台增加了 JWT authentication and authorization 功能，启用此功能需要开启精细访问控制，并导入验证 JWT 有效性的证书。 配置 Auth0配置 JWT 认证授权的步骤包括在 IDP 中创建 API，并使用 API 获取 JWT。以下是使用 Auth0 生成 JWT 的示例代码： 1234567891011121314151617181920212223242526272829303132333435import requestsimport json# 配置AUTH0_DOMAIN = &quot;&lt;domain&gt;.auth0.com&quot;CLIENT_ID = &quot;&lt;CLIENT_ID&gt;&quot;CLIENT_SECRET = &quot;&lt;CLIENT_SECRET&gt;&quot;AUDIENCE = &quot;https://auth0-jwt-authorize&quot;GRANT_TYPE = &quot;client_credentials&quot;TOKEN_URL = f&quot;https://{AUTH0_DOMAIN}/oauth/token&quot;OUTPUT_FILE_PATH = 'jwt_token.json'# 请求负载和头部payload = { &quot;client_id&quot;: CLIENT_ID, &quot;client_secret&quot;: CLIENT_SECRET, &quot;audience&quot;: AUDIENCE, &quot;grant_type&quot;: GRANT_TYPE}headers = { &quot;content-type&quot;: &quot;application/json&quot;}# 发送 POST 请求获取 JWTresponse = requests.post(TOKEN_URL, json=payload, headers=headers)# 处理响应if response.status_code == 200: data = response.json() with open(OUTPUT_FILE_PATH, 'w') as file: json.dump(data, file, indent=4) print(f&quot;JWT 已保存到文件: {OUTPUT_FILE_PATH}&quot;)else: print(f&quot;请求失败，状态码：{response.status_code}&quot;) print(response.text) 我们在 Auth0 中新建一个 API，然后会帮我们生成一个 Application。后续我们会使用这个 Application 的 Client ID 和 Secret ID 以及 Domain 的信息来登录。 也就是说这三个信息确定了一个身份池，然后符合规则的用户可以通过这个身份池来换取 JWT。可以在 Applications-Applications 中看到。 配置好之后，可以通过 Auth0 的 API 来拿到登录后的 JWT，以下是一个官方给的教程可以用来测试功能，当然也可以集成到 APP 中。 auth0 也提供了示例代码供我们测试： 官方提供代码样例可读性不是很高，让我们用用 requests 来改写一下，这个代码会把生成的 JWT 存在一个 Json 文件里面，这样我们就能容易的复制出来。 123456789101112131415161718192021222324252627282930313233343536import requestsimport json# 配置AUTH0_DOMAIN = &quot;&lt;domain&gt;.auth0.com&quot;CLIENT_ID = &quot;&lt;CLIENT_ID&gt;&quot;CLIENT_SECRET = &quot;&lt;CLIENT_SECRET&gt;&quot;AUDIENCE = &quot;https://auth0-jwt-authorize&quot;GRANT_TYPE = &quot;client_credentials&quot;TOKEN_URL = f&quot;https://{AUTH0_DOMAIN}/oauth/token&quot;OUTPUT_FILE_PATH = 'jwt_token.json'# 请求负载和头部payload = { &quot;client_id&quot;: CLIENT_ID, &quot;client_secret&quot;: CLIENT_SECRET, &quot;audience&quot;: AUDIENCE, &quot;grant_type&quot;: GRANT_TYPE}headers = { &quot;content-type&quot;: &quot;application/json&quot;}# 发送POST请求获取JWTresponse = requests.post(TOKEN_URL, json=payload, headers=headers)# 处理响应if response.status_code == 200: data = response.json() with open(OUTPUT_FILE_PATH, 'w') as file: json.dump(data, file, indent=4) print(f&quot;JWT已保存到文件: {OUTPUT_FILE_PATH}&quot;)else: print(f&quot;请求失败，状态码：{response.status_code}&quot;) print(response.text) 我们可以看到控制台多出了一个 JWT authentication and authorization 新功能，使用这个功能需要先开启精细访问控制，我们需要在这里需要导入验证 JWT 有效性的证书。 服务端需要填写验证 JWT 的 PEM 证书，那么我们要从 Auth0 的 API 中拿到这个信息。使用如下代码从.well-known/jwks.json 中解析出来需要的证书，然后填写到 OpenSearch 中。 12345678910111213141516171819202122232425262728293031323334import requestsfrom jwcrypto import jwkimport json# 配置JWKS_URI = 'https://&lt;domain&gt;/.well-known/jwks.json' # 替换为你的Auth0域名OUTPUT_DIR = './pem_keys' # 你希望保存PEM公钥的目录# 创建输出目录import osif not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)# 获取JWKSresponse = requests.get(JWKS_URI)jwks = response.json()# 处理每一个JWKfor index, jwk_key in enumerate(jwks['keys']): try: key = jwk.JWK(**jwk_key) pem = key.export_to_pem(private_key=False, password=None).decode('utf-8') kid = jwk_key['kid'] # 将PEM格式公钥写入文件 pem_file_path = os.path.join(OUTPUT_DIR, f'{kid}.pem') with open(pem_file_path, 'w') as pem_file: pem_file.write(pem) print(f'PEM格式公钥已保存到文件: {pem_file_path}') except Exception as e: print(f'处理公钥时出错: {e}') 配置好后，可以在 OpenSearch 的安全配置中看到 “View JWT details” 信息，验证 JWT 的有效性。通过标准的 JWT 流程使用 Postman 验证时，将 JWT 输入到 Bearer token 中，即可进行验证。 postman 测试 JWT然后我们按照标准的 JWT 流程进行验证，这里使用 Postman，验证方式使用 Bear token，我们把通过应用程序模拟的 JWT 输入进去。 编程方式访问(Python)我们也可以使用编程方式来进行访问，其实就是上加上一个’Authorization’: ‘Bearer ‘的请求头。 123456789101112import requestsurl = &quot;OpenSearch URL&quot;payload = {}headers = { 'Authorization': 'Bearer &lt;jwt token&gt;'}response = requests.request(&quot;GET&quot;, url, headers=headers, data=payload)print(response.text) 几个月前，我参与了一些内部功能的审核工作。当时认为，既然系统支持 JWT，那么这应该也意味着支持 OIDC IDP，并且能够解决中国区 Cognito 无法集成的问题。然而，通过测试发现，JWT 仅能在编程方式中使用，控制台仍然需要使用原来的认证方式。也就是说，预想的从控制台跳转到 OIDC IDP 的方式仍然无法实现。期待未来能够实现从控制台无缝跳转到 OIDC IDP 的目标，为用户提供更便捷和安全的使用体验。 参考文档【1】https://aws.amazon.com/cn/about-aws/whats-new/2024/06/amazon-opensearch-service-jwt-authentication-authorization/ 【2】https://www.amazonaws.cn/new/2024/amazon-opensearch-service-supports-json-web-token-authentication-and-authorization/ 【3】https://docs.aws.amazon.com/zh_cn/opensearch-service/latest/developerguide/JSON-Web-tokens.html","link":"/posts/330e574/"},{"title":"EC2 没有绑定 EIP，重启后 IP 会变？DDNS-GO 自动更新你的域名","text":"在 IPV4 即将枯竭的年代，云服务商的 EIP 也开始收费了。对于没有弹性公网 IP（EIP）的云服务器，我们可以通过 DDNS-GO 实现动态域名解析。本文介绍了如何使用 Docker 快速部署 DDNS-GO，并借助 DDNS 实现动态域名绑定，从而让服务器即使公网 IP 变化，也能够实时更新域名解析记录，这样只需要使用域名访问，不再需要在控制台查看。 安装 Docker使用官方安装脚本快速安装 Docker： 12curl -fsSL https://get.docker.com -o get-docker.shsudo sh get-docker.sh 设置 Docker 开机自启并立即启动： 1sudo systemctl enable --now docker 添加当前用户到 docker 用户组（避免每次用 sudo）1sudo usermod -aG docker $USER 生效方式： 推荐：重新登录终端会话 或使用临时方式立即生效： 1newgrp docker 验证是否配置成功： 1docker info 若无权限报错，则配置已生效。 Docker 中部署 DDNS-GO我们将使用 Docker 的 host 网络模式挂载主机目录，确保 DDNS 能正常检测本地 IP： 1docker run -d --name ddns-go --restart=always --net=host -v /opt/ddns-go:/root jeessy/ddns-go /opt/ddns-go 是主机目录，你可以替换为任意路径，用于持久化配置。 启动后，DDNS-GO 的配置文件为 .ddns-go.yaml，位于挂载目录中。 初始化配置部署完成后，打开浏览器访问： 1http://&lt;Docker主机IP&gt;:9876 你会看到 DDNS-GO 的初始化页面，如图所示： DDNS-GO 是一个开源的动态域名更新工具，支持多个域名服务商，我的域名托管在 cloudflare 上，所以需要在 cloudflare 上申请一个 API-KEY 来做这个更新。 TTL 建议设置为“自动” IP 获取方式推荐使用外网 API（如 ipip.net） 前往 Cloudflare 的 API Token 页面，为 DDNS-GO 创建一个具备修改 DNS 权限的 Token。 建议选择 “Edit zone DNS” 模板，只赋予必要权限，并可以限制在特定域名范围内使用。 此外，DDNS-GO 支持 webhook 通知，可选用如 Slack、Server 酱等方式实时通知 IP 变动情况。 验证 DDNS 的效果我们尝试停止云主机后再重新开启，公网 IP 会发生变化： 重启后 DDNS-GO 会自动检测 IP 变动并更新域名解析： 通过域名访问服务仍然保持不变，无需手动更新 IP。 同时 Server 也会把这个消息推送到手机上： 总结即使云服务器没有绑定弹性公网 IP，借助 DDNS-GO 和 Docker，我们依然可以实现动态域名解析： 低成本：无需购买 EIP，节省开销； 自动化：IP 改变后自动更新域名解析； 易部署：Docker 一键运行，配置简单直观。","link":"/posts/369cde6d/"},{"title":"Filebeat 输出日志到 Opensearch","text":"原文链接，当时一起折腾的，抄个作业。 https://liarlee.site/2023/12/08/Other/Opensearch_Filebeat%20%E8%BE%93%E5%87%BA%E6%97%A5%E5%BF%97%E5%88%B0%20Opensearch/?highlight=opensearch 这个最后基本上可以确认是一个兼容性问题，测试完成发现， 开启兼容模式的 Opensearch+filebeat 的组合， filebeat 还是会不定期重启。 背景需求是，使用 ES + filebeat 模式在收集日志。使用 Supervisor 作为容器的主进程管理工具，启动后分别运行 应用（这里用 nginx 代替） + filebeat 现在想要用 ECS Fargate， 然后依旧还是这个模式， 尽可能新的变动之前的架构， ES 替换成 OpenSearch。 按照这个路数测试。 创建 Opensearch版本：OpenSearch 2.11 (latest)OpenSearch_2_11_R20231113-P1 (latest)Availability Zone(s)1-AZ without standby 构建 Supervisor 管理的容器创建 Dockerfile创建 dockerfile 的部分， 比较难的是 ， 需要找到合适的 filebeat 版本参考页面: Agents and ingestion tools其他的步骤就下载安装就可以. 12345678910111213141516171819# 使用官方Nginx作为基础镜像FROM reg.liarlee.site/docker.io/nginx# 安装SupervisorRUN apt-get update &amp;&amp; apt-get install -y supervisorRUN mkdir -p /var/log/supervisorRUN mkdir -p /etc/filebeat/#RUN curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.11.3-amd64.deb &amp;&amp; dpkg -i filebeat-8.11.3-amd64.debRUN curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-oss-7.12.1-amd64.deb &amp;&amp; dpkg -i filebeat-oss-7.12.1-amd64.debCOPY filebeat.yml /etc/filebeat/filebeat.ymlCOPY nginx.conf /etc/nginx/nginx.conf# 将Supervisor配置文件复制到容器中COPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf# 启动Supervisor来管理Nginx进程CMD [ &quot;/usr/bin/supervisord&quot;, &quot;-n&quot; ] 准备配置文件需要准备的配置文件一共 3 个： supervisord.conf supervisor 的管理配置， 决定了那些进程被管理。 123456789101112131415161718192021222324252627&gt; cat ./supervisord.conf[unix_http_server]file=/var/run/supervisor.sock ; (the path to the socket file)chmod=0700 ; socket file mode (default 0700)chown=nobody:nogroup ; socket file uid:gid owner[supervisord]logfile_maxbytes=50MB ; 日志文件的最大大小logfile_backups=10 ; 日志文件的备份数loglevel=info ; 日志级别nodaemon=false ; 是否以守护进程模式启动Supervisorminfds=1024 ; 可以打开的文件描述符的最小数量minprocs=200 ; 可以创建的进程的最小数量[program:nginx]command=/usr/sbin/nginx -g &quot;daemon off;&quot; ; 启动Nginx的命令autostart=true ; 在Supervisor启动时自动启动autorestart=true ; 程序异常退出后自动重启stderr_logfile=/var/log/nginx/error.log ; 错误日志文件路径stdout_logfile=/var/log/access.log ; 访问日志文件路径[program:filebeat]command=/usr/bin/filebeat -e -c /etc/filebeat/filebeat.yml ; 启动Filebeat的命令autostart=trueautorestart=truestderr_logfile=/var/log/filebeat.err.logstdout_logfile=/var/log/filebeat.out.log filebeat.yml filebeat 的配置文件。 这配置文件 GPT 会直接写出一个可以用 output.opensearch:， 其实还是不能的， 只能使用原本的配置文件。 (也许是我选择的 filebeats 版本不正确, 所以不行吧 filebeat 本身是 es 序列里面的产品， 不支持 opensearch 也合理， 如果写成 opensearch 会找不到 output 的定义， 也说明并不支持这个字段。 2023-12-14T12:03:12.560Z INFO [publisher_pipeline_output] pipeline/output.go:145 Attempting to reconnect to backoff(elasticsearch(https://vpc-ecs-nginx-opensearch-qt7m5rmhddggkiuapyybcmz5oe.cn-north-1.es.amazonaws.com.cn:443)) with 7 reconnect attempt(s) 123456789101112131415161718192021222324252627```shell&gt; cat ./filebeat.ymlfilebeat.inputs:- type: filestream id: nginxaccesslog paths: - /var/log/access.log fields: log_type: accessseccomp.enabled: false # 这个不关闭的话可能会是一个干扰。logging.level: debug # 由于调试方便设置了DEBUG。# 这个配置段是关闭 xpack， xpack功能只在es里面提供， 商业版本。ilm.enabled: falsesetup.ilm.enabled: falsesetup.pack.security.enabled: falsesetup.xpack.graph.enabled: falsesetup.xpack.watcher.enabled: falsesetup.xpack.monitoring.enabled: falsesetup.xpack.reporting.enabled: false# output就是还用esoutput.elasticsearch: enable: true hosts: [&quot;vpc-ecs-nginx-opensearch-qt7m5rmhddggkiuapyybcmz5oe.cn-north-1.es.amazonaws.com.cn:443&quot;] # 这个部分需要手动指定443, 因为是es的默认配置, 所以直接去 9200,就会连接不上. protocol: &quot;https&quot; xpack 报错的日志大概是这样的： 2023-12-14T12:03:12.560Z ERROR [publisher_pipeline_output] pipeline/output.go:154 Failed to connect to backoff(elasticsearch(https://vpc-ecs-nginx-opensearch-qt7m5rmhddggkiuapyybcmz5oe.cn-north-1.es.amazonaws.com.cn:443)): Connection marked as failed because the onConnect callback failed: request checking for ILM availability failed: 401 Unauthorized: {“Message”:”Your request: ‘/_xpack’ is not allowed.”}2023-12-14T12:03:12.560Z INFO [publisher_pipeline_output] pipeline/output.go:145 Attempting to reconnect to backoff(elasticsearch(https://vpc-ecs-nginx-opensearch-qt7m5rmhddggkiuapyybcmz5oe.cn-north-1.es.amazonaws.com.cn:443)) with 7 reconnect attempt(s) nginx.conf 这个是 nginx 应用文件， 模拟一个应用程序， 提供 webserver 服务。配置文件就是标准的配置文件, 修改一下日志输出的路径. 1access_log /var/log/access.log main; 由于 baseimage 用的是 nginx 的， 所以 nginx 的日志输出会软链接到/dev/stdout, filebeat 不收软链接的文件, 开了 DEBUG 会看到跳过这个文件的日志. Buildstage接下来就可以 Build 镜像然后进行测试了。 123&gt; dive build -t reg.liarlee.site/library/superv-nginx:v31 .&gt; docker push reg.liarlee.site/library/superv-nginx:v31&gt; docker run -it --name superv-nginx --rm reg.liarlee.site/library/superv-nginx:v31 运行启动之后可以看到输出的日志是： 122023-12-14 14:03:31,093 INFO success: filebeat entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)2023-12-14 14:03:31,093 INFO success: nginx entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs) 然后查看 Opensearch 创建了默认 index， 名称是filebeat-7.12.1-2023.12.14","link":"/posts/8924813e/"},{"title":"使用 OpenList 将 S3 转换为 WebDAV","text":"Amazon S3 是一种高可扩展、低延迟的对象存储服务，广泛用于存储和管理数据。尽管目前有多个工具来将 S3 与其他存储解决方案（如 Storage Gateway，EMRFS 或者 S3FS 等）集成，但今天我们介绍一个新的方法，通过使用 OpenList，将 S3 存储转换为 WebDAV，简化文件管理和访问。 本文将引导你通过 Docker Compose 启动 OpenList，并将其与 Amazon S3 配置，以便通过 WebDAV 协议进行访问。 步骤 1：使用 Docker Compose 启动 OpenList首先，我们需要通过 Docker Compose 来启动 OpenList 服务。以下是一个示例 docker-compose.yml 配置文件： 12345678910111213services: openlist: image: &quot;openlistteam/openlist:latest&quot; container_name: openlist volumes: - &quot;./data:/opt/openlist/data&quot; ports: - &quot;5244:5244&quot; environment: - PUID=0 - PGID=0 - UMASK=022 restart: unless-stopped 保存该配置后，使用以下命令启动 OpenList 容器： 1docker-compose up -d 启动成功后，OpenList 的 Web 界面将在端口 5244 上可用。你可以通过浏览器访问 http://localhost:5244 进入管理界面。默认用户名为 admin，初始密码可以通过环境变量设置，或者在容器日志中查看。 我用的是 Orbstack，可以很方便的查看容器日志。如果你使用的是 Docker cli，也可以使用 docker logs 进行查看。 步骤 2：配置 S3 存储一开始，OpenList 容器没有绑定任何存储，所以页面将显示为空白。此时需要点击右下角的“管理”按钮，进入存储配置界面。 在“存储”选项卡下，选择“对象存储”作为存储类型。 配置挂载路径（例如 /s3），这相当于 Linux 系统中的挂载目录。 输入你的 S3 存储桶的名称、区域和访问密钥。确保使用正确的 S3 endpoint。我的存储桶位于东京，因此我在配置中使用了 s3.ap-northeast-1.amazonaws.com 作为 endpoint。如果你的存储桶位于其他区域，记得修改为相应区域的 endpoint。 为了方便获取你的 AWS 凭证，可以使用以下命令获取当前机器绑定的凭证： 1pip install awsx 如果你使用 uv 管理 Python 环境，可以运行以下命令打印当前用户名和使用的 Access Key 以及 Secret Key： 1uvx awsx 步骤 3：配置重定向与许多 SDK 的重定向机制不同，如果你在配置中错误地设置了美东区的 endpoint，OpenList 客户端将不会自动在收到 301 重定向响应后转发请求到正确的区域，而是会报错。 例如，如果你将 endpoint 设置为 s3.us-east-1.amazonaws.com，但存储桶位于 ap-northeast-1 区域，你将遇到以下错误： 1BucketRegionError: incorrect region, the bucket is not in 'ap-northeast-1' region at endpoint 's3.us-east-1.amazonaws.com' 解决方法是确保在配置中使用正确的区域，避免跨区域错误。 步骤 4：启用 MFA（可选）为了提高安全性，尤其是在将 OpenList 部署到公网环境时，建议启用多重身份验证（MFA）。启用 MFA 可以增加 AWS 账户的安全性，避免潜在的安全风险。 在 AWS 控制台中启用 MFA 后，记得更新 OpenList 中的凭证配置，确保启用了双重认证。 步骤 5：配置用户权限OpenList 默认情况下将用户权限设置为只读。要赋予 admin 用户 WebDAV 的管理权限，请进入“用户 - 编辑”界面，修改相应的权限设置。 步骤 6：访问 S3 文件完成配置后，OpenList 将自动同步 S3 存储桶的数据。你可以在 Web 界面上方便地进行文件下载、解压、上传文件等操作。 这个是 S3 上页面，可以看到 s3 的数据都被同步到 Openlist 上了。 同时也能够在 Openlist 上在线观看 S3 上的存的视频教程。 同时所有操作都可以通过 WebDAV 协议进行，访问路径为： 1http(s)://&lt;ip&gt;/dav 例如，在 MacOS 上，可以通过 Finder 进行 WebDAV 访问： 在 Finder 中选择“前往”&gt;“连接服务器”。 输入 WebDAV 路径，例如：http://localhost:5244/dav。 输入 OpenList 的用户名和密码进行身份验证。 在 Finder 中使用 WebDAV 进行访问： 你还可以使用 Linux 命令行来操作 WebDAV，减少了学习 S3 命令行的成本。 总结通过使用 OpenList，我们可以轻松地将 Amazon S3 转换为 WebDAV，简化了文件访问和管理。通过本文的步骤，你可以快速启动 OpenList、配置 S3 存储桶，并通过 WebDAV 协议访问存储在 S3 上的文件。希望这篇文章能帮助你更高效地管理 S3 数据，并为你提供更加便捷的文件访问方式。","link":"/posts/21efda6/"},{"title":"组队参加 Amazon Q Idea 1000，我们的作品上了 AWS 峰会","text":"Amazon Transit Gateway (TGW) 是一个强大的网络连接服务，用于在不同的 VPC（虚拟私有云）之间实现高效互联。本文将指导您如何创建和配置 TGW，以便实现跨账户和跨区域的 VPC 互联。 VPC Peering 的局限性点对点连接：VPC Peering 是一个点对点的连接，每次只能连接两个 VPC。如果需要连接多个 VPC，需要为每对 VPC 单独设置 Peering 连接，也就是我们常说的不能进行路由的传递，需要打通的 VPC 很多的时候会非常的麻烦。 手动路由配置：每个 VPC Peering 连接都需要手动配置路由表，这在大规模环境下非常繁琐。 TGW 的优势集中式管理：TGW 作为一个中央枢纽，允许多个 VPC 和本地网络通过单个网关相互连接，简化了网络架构和管理。 自动路由传播：TGW 支持自动路由传播，简化了路由配置，减少了人为错误的风险。 跨账户和跨区域支持：TGW 支持跨多个亚马逊云科技账户和跨区域的连接，提供更大的灵活性和扩展性。 总结下来说，TGW 就是是一个中转网关，使用时候需要在需要打通的 VPC 内创建一个挂载点，TGW 会管理一张路由表来决定流量的转发到对应的挂载点上。本质上是 EC2 的请求路由到 TGW，然后在查询 TGW 的路由表来再来决定下一跳，所以需要同时修改 VPC 内子网的路由表和 TGW 的路由表。 TGW 的网络拓扑图如下： 1. 创建 TGW登录到亚马逊云科技管理控制台，导航到”VPC”服务。在左侧菜单中选择”Transit Gateways”，点击”Create Transit Gateway”。填写 TGW 名称和描述，配置 DNS 支持等选项。 根据要求创建 TGW，如果不需要和本地网络打通，这里填写名称和描述就好。 建议开启以下三个选项： DNS support：开启打通 VPC 的 DNS 支持，这个 DNS support 无法解析对端的私有 R53 记录，还需要使用 Resolver 才行 [^1] Default route table association：自动创建一个路由表并且关联这个 TGW Default route table propagation：自动路由表自动传播，这样每次更新的时候就不用手动管理路由。 2. 在每个 VPC 新建挂载点在 TGW 创建完成后，导航到”Transit Gateway Attachments”。点击”Create Transit Gateway Attachment”，选择目标 VPC 并配置相关选项。 创建挂载点需要选择关联的 TGW 以及挂载点的 Type，除了 VPC 之外还有 peering，DX 类型的可供选择。 同样这里也要开启对 DNS 的支持，另外关于 Appliance Mode support，如果这个功能开启的话，流量只能在相同的可用区进行转发，这个功能开启需要慎重考虑。 3. 设置 TGW 路由手动新建 TGW 的路由表并且关联到一个 TGW，如果前面开启了 Default route table association 和 Default route table propagation 不再需要此步骤。 需要在 Routes 部分手动添加路由规则 4. 设置子网路由为每个 VPC 配置路由表，添加到 TGW 的路由。确保启用路由传播，使 VPC 可以通过 TGW 相互通信。 和 peering 一一样，需要把对应的流量指到对端，这里 10.1.0.0/16 的流量到 TGW。 5. 跨账户 RAM 分享，对端 RAM 接收如果需要跨账户打通网络，那么需要用到 TGW 的 share 功能，其实就是使用 RAM 进行资源共享。 如果需要跨账户共享 TGW，使用 AWS Resource Access Manager (RAM)。 在 RAM 控制台中创建资源共享并邀请其他 AWS 账户。 对方也是需要在 RAM 里进行确认，并且接收方不能二次 share 此 TGW。 拓展阅读： Building a global network using Amazon Transit Gateway Inter-Region peering https://aws.amazon.com/cn/blogs/networking-and-content-delivery/building-a-global-network-using-aws-transit-gateway-inter-region-peering/ Amazon Transit Gateway now supports Inter-Region Peering https://aws.amazon.com/about-aws/whats-new/2019/12/aws-transit-gateway-supports-inter-region-peering/ Transit Gateway inter-Region peering https://docs.aws.amazon.com/solutions/latest/network-orchestration-aws-transit-gateway/transit-gateway-inter-region-peering.html Amazon Transit Gateway - Amazon Virtual Private Cloud Connectivity Options https://docs.aws.amazon.com/whitepapers/latest/aws-vpc-connectivity-options/aws-transit-gateway.html Centralized DNS management of hybrid cloud with Amazon Route 53 and AWS Transit Gateway https://aws.amazon.com/cn/blogs/networking-and-content-delivery/centralized-dns-management-of-hybrid-cloud-with-amazon-route-53-and-aws-transit-gateway/ 通过这些文档，可以全面了解 TGW 在跨区域连接中的显著优势，确保在大规模和复杂网络环境中的高效、安全和可扩展性。","link":"/posts/ac23bcf7/"},{"title":"如何在 AWS EC2 上部署 Isaac Sim","text":"网上已经有一些关于在阿里云和腾讯云上部署 Isaac Sim 的教程，本文将带大家了解如何在 AWS EC2 上部署 NVIDIA Isaac Sim 仿真平台，并以 A10G GPU（g5.2xlarge 实例）为例进行实战操作。 一、环境说明 GPU 类型：A10G（适用于 RTX 渲染） 实例类型：g5.2xlarge 操作系统镜像（AMI）：Deep Learning OSS Nvidia Driver AMI GPU PyTorch 2.7 (Ubuntu 22.04)👉 该镜像自带 NVIDIA 驱动、CUDA、Docker、nvidia-docker，无需手动安装 二、登录 AWS 控制台并创建实例 打开 AWS 官网，点击右上角登录。 选择 使用 Root 账户登录： 输入 root 邮箱和密码，若首次登录需要绑定 MFA（建议使用 Authenticator App）： 进入 AWS 控制台后，选择左侧的 EC2，点击右上角的 “启动实例”。 三、配置 EC2 实例（含 GPU 驱动） 选择操作系统镜像（AMI）：搜索并选择： 1Deep Learning OSS Nvidia Driver AMI GPU PyTorch 2.7 (Ubuntu 22.04) 自带了 NVIDIA 驱动、nvidia-container-toolkit、Docker 等，无需额外安装。 选择实例类型：g5.2xlarge（带 A10G GPU） 创建密钥对：系统会生成 .pem 格式的密钥，下载后： 1chmod 400 your-key.pem 网络设置： 选择已有 VPC，或默认网络 确保启用公网 IP 分配 安全组设置： 开放所需端口 如部署 livestream 或远程访问，确保相应端口可用 四、连接实例并确认环境使用 SSH 登录 EC2 实例： 1ssh -i your-key.pem ubuntu@&lt;EC2公有IP&gt; 查看基本系统信息（需先安装 neofetch）： 12sudo apt update &amp;&amp; sudo apt install neofetch -yneofetch 查看 GPU 驱动是否正常： 1nvidia-smi 查看是否已安装 nvidia-docker 插件： 1docker info | grep -i nvidia 五、安装 Isaac Sim（官方容器方式）接下来按照 NVIDIA 官方文档进行 Isaac Sim 的容器部署即可： 👉 文档链接：https://docs.isaacsim.omniverse.nvidia.com/4.5.0/installation/install_container.html 如果首次启动卡在 RtPso async compilation 阶段较久（10 分钟左右），这是因为光线追踪 shader 正在编译。只要缓存持久化，之后启动会非常快（1 分钟内）。 ✅ 总结通过 AWS 的 G5 系列实例（搭载 A10G GPU），我们可以方便地在云端部署 Isaac Sim。选用 NVIDIA 官方预装驱动的 AMI，可以省去繁琐的 CUDA 和容器配置。搭配持久化缓存和合理的端口管理，即可稳定高效运行 Isaac Sim 的云端仿真。","link":"/posts/10d4e175/"},{"title":"学云计算到底是在学什么？","text":"个人感觉 AWS 甚至很多云计算平台都被过分神话了。以下是个人经验，不喜勿喷。 人话版本学什么？ 怎么启动虚拟机，以及如何进行远程管理，比如 SSH 和 DRP。 对象存储 S3。如果你能自建 MinIO 或者 RustFS 也没问题，如果你喜欢 OpenStack Swift 也行。 Docker/K8S。这帮人天天吹云原生，其实主要还是容器充分可以利用云上的弹性。 网络基础，比如为什么我连不上某台机器，能从网络链路都排查一遍。 为什么还有各种组件？举几个例子： 中间件或者数据库软件很多都有 PaaS 版本，主打一个“开箱即用”。好处是一键配置多可用区，一键安装软件，让开发人员不用考虑多余的事。 曾经的槽点：某些云厂商直接把开源软件托管来卖，所以才有后来一些厂家改商用 License 的事。 分布式计算软件安装繁琐，对小白友好直接控制台点点点，文科生也能学会。 都上云了，你可以不用，但云厂商一定要有，否则对不起“宇宙厂”的名头。 上了云成本就一定小吗？不一定，需要在可用性、经济性、性能之间取舍。 很多 HA 的功能是冗余的，分布式软件自己带了一套，云上又做了一套 Standby。 除非买年度订阅有很大折扣，否则成本不可控。 都在云上，网络延迟肯定比线下 DC 要大。 如果你是纯 C 端用户，玩玩得了，你的这点用量人家根本看不上。 上云的好处在哪里？ 钱花到哪里更加明确了。 PPT 能做得更好看。 产品可以快速出 MVP，能够对全套链有个完整认知。 有些服务可以 Pay as you go。 公网 IP 自由，不过也开始陆续收费了。 减少运维成本，出问题压力直接甩给厂商。 我是一个小白，买软件送服务吗？ 国内云有些支持免费，但海外云需要付费购买售后支持，可以帮你找文档、讲解服务用法、错误排查等。 Serverless 普遍做得很烂，你学习平台规则的成本大于你在平台上部署的成本。 想啥呢？文档都那么烂。 国内和国外云生态对比 海外很多 PaaS 或 SaaS 都基于 AWS 来做，所以看起来国外云计算很火。 国内软件开发和云计算很割裂，整体还是以 SDE 为导向，跟云厂商打交道最多的还是运维。 一些遵守当地合规的云公司夹在中间更难受，选择需谨慎。 总结如果个人爱好者真的有需要，还是自己搭建 Homelab 吧。控制好噪音和功耗就行。","link":"/posts/4b1e0fb/"},{"title":"手把手搞定报名亚马逊科技认证","text":"亚马逊云科技认证考试为我们这些技术从业者提供了提升专业技能的机会。无论选择线上还是线下考试，每种方式都有其独特的优势和挑战。选择合适的考试方式将帮助我们更好地展示自己的技术水平。以下是我对不同考试方式的优缺点介绍，以及各科目的考试代码。希望这些信息能帮助大家在备考过程中做出最优选择。 考试方式介绍线上考试优点： 方便快捷：无需通勤，考生可以根据自己的时间安排进行考试。 高灵活性：考试预约灵活，基本上每天都可以进行。 缺点： 环境要求较高：考试时屋内只能有考生一人，且不能有其他声音，否则监考官会关闭考试界面。 网络要求高：需要连接海外的直播平台发送摄像头内容，如果监考官无法看到考生，考试也会被关闭。 线下考试优点： 环境稳定：无需担心家中环境问题，且由线下监考员监考。 简便的身份验证：只需携带身份证和社保卡即可。 缺点： 考点少且难预约：例如，北京的考点不多且预约困难，多数考点位于郊区，如大兴和昌平。 时间限制：考点通常只在工作日开放，考生可能需要请假参加考试。 各科目考试代码帮助大家更好地准备和选择考试内容。我总结了亚马逊云科技现在的认证： 报名步骤首先，您需要访问 https://aws.amazon.com/certification注册一个账户。我建议使用私人邮箱注册，而非公司邮箱，以确保账户的长期可用性。 点击使用 Pearson Vue 进行安排： 在这里可以选择线上、线下和私人访问码，一般选择前两种，第三种通常是与机构合作的链接。 线下考试需要带好身份证，国内还需要带辅助证件，如社保卡或驾照。 线上考试需要保证良好的网络环境和独立的空间，同时准备好身份证。 接下来是选择考场，这里可以同时选择三个考场，然后下一步查看考场的时间： 可以看到最近的日期是 15 号，那么我们可以尝试预约 15 号。 选好时间之后，下一步准备付款。如果有优惠码，可以在下一步输入。这里可以看到考试时间汇总。 付款完成后，可以下载 ics 文件并添加到日历中，这样的话 Apple 日历就会提前提醒我： 优惠和加时对于非英语母语的考生，可以申请 30 分钟的加时。虽然官网也发布了中文考生可以加时 30 分钟的消息，但尚未说明具体的加时条件。 注意事项 证明身份：线上考试需要身份证或驾照，监考官会帮助新建 case。线下考试需要身份证和社保卡或驾照。 平台：使用 OnVue 平台监考。OnVue 中国区负责报名选考场，如果因网络问题无法考试需要重新预约，技术问题需要联系英文支持。 线上注意事项：检测 WEBRTC 连接和摄像头，考试时全程保持摄像头开启。画面静止或超出摄像头范围，监考官会让退出重进。 Check-in 流程：不能有手表，检查桌面没有其他东西，监考官会询问手机放置位置。 有效期：认证有效期为三年，通过 SAP 考试可自动续 SAA，DOP 可续 SOA 和 DVA，任意助理级考试可续 CLF。 写在最后线上检录界面，需要做一些准备工作，上传证件，清理桌面之类的工作： 这个是线上和考官的聊天界面： 如果需要申诉，会邮件告知新的抵扣码（原来的考试码作废）： 希望这些信息能帮助大家在备考过程中做出最优选择，顺利通过亚马逊云科技认证考试。","link":"/posts/4533e9f8/"},{"title":"记一次Amazon Q pro的使用","text":"参加 AWS 的比赛申请了 Amazon Q pro，平时也在用 builderID 登陆使用免费的账户。Amazon Q pro 需要和 IAM identity center 一起用，不过比赛直接给配置好了，直接分发 IAM identity center 的账户，我们只需要注册，登陆，然后关联 Q pro。 从邮箱里给的链接注册，登录。然后绑定 MFA，这个 MFA 其实就是一个二次验证，如果账户被盗，对方没有 MFA 也是无法登录的。 我用了 2Fauth 来绑定的，当然你也可以使用 google authenticator 之类的软件，绑定六位动态码。当然比较常见的 MFA 就是短信验证码，当然还有打电话的。这边刚刚登录，这边电话马上过来。 注册成功会有这个提示。后面需要使用这个绑定的 MFA 进行登录。 登录之后会跳转到这个门户页面，点击 Q 的图标之后会跳转到 Amazon Q 的官方文档。 完成了登录，我们来做本地的配置： 在 VS code 商店中搜索 Amazon Q 并且安装： Amazon Q 有免费版和 Pro 版。免费版使用 build ID 进行登录，无需 AWS 账户。而今天体验的是 Q pro 版本，还好主办方给配置好了 AWS 的账户， 安装之后右下角就有一个提示登录的弹窗，点击 Sign in，URL 输入邮箱里给的 URL。其实就是 IAM identity center 的登录链接。 然后是跳转浏览器： 以及提示打开浏览器的弹窗： 浏览器打开之后有获取权限的提示： 点击允许之后就大功告成了： 同时 VScode 里的 Q 也会变成这样，最后变成聊天窗口 如图是聊天模式： 如果你使用 Ubuntu server： 下载命令行： 1wget https://desktop-release.q.us-east-1.amazonaws.com/latest/amazon-q.deb 安装 12sudo apt-get install -fsudo dpkg -i amazon-q.deb 打开，然后同样的通过浏览器打开： 1q 如果你用的是苹果系统，就更简单了。从这个链接下载，直接安装就可以了。 https://desktop-release.q.us-east-1.amazonaws.com/latest/Amazon%20Q.dmg 然后在终端中输入 q 或者 Q chat 就可以了。","link":"/posts/56bb1eb7/"},{"title":"组队参加 Amazon Q Idea 1000，我们的作品上了 AWS 峰会","text":"最近生成式 AI 的比赛很多，也报名了 AWS Idea1000 的比赛，作品登录上了 AWS 的峰会。 我们的产品名称是“拍立懂”，团队名称是 “凌晨三点的夜”。主要是拍照识别商品成分、品牌资质，分析价格合理性，为老年人提供购买决策建议；通过实时语音聊天交互，亲人语音陪伴老年人购物，满足空巢老人的情感空缺。 我们的项目团队汇聚了文化创意创业者、资深互联网产品经理、互联网技术博主与 AI 前端工程师等多元背景，形成从商业策略到产品落地的完整闭环。团队成员对创新技术和用户价值怀有共同的热情，彼此协作、优势互补，致力于在商业模式和技术实现上持续突破，为项目注入持久动力。 说人话版本: “拍立懂”首页：先定位、再拍照、还可语音，一站式搞定逛超市！进入小程序，系统会自动识别你所在的门店，保证每一次推荐都“本地有货”。 对准商品“拍一拍”，AI 秒识品牌与规格，为你生成成分/营养解析； 打开语音助手，直接问“这款油健康吗？”，即时语音作答； 想逛逛热卖？下拉切换「日用食品 / 零食饮料 / 时令食材」，AI 列出今日在售优质清单。拍照 + 语音 + 实时库存，让你逛超市不再纠结，用 AI 把复杂信息说得清清楚楚。 架构图如下： 域名与流量入口 Route 53 购买域名以及负责域名解析 ALB 负载均衡 &amp; HTTPS 卸载 应用与模型服务 Next.js (前端+SSR) Flask (语音识别、图像识别、流式对题) + FastAPI （OpenAI realtime 代理） 数据与存储 S3 存音频/图片 Milvus (Zilliz Cloud on GCP) 向量检索做 RAG 多模态交互 OpenAI Vision + Realtime 实时对话 环境 &amp; CI/CD Lightsail 做 POC，懒猫微服异地组网调试 GitHub Actions 一件打包到 Dockerhub Docker-compose 一键部署 这个是最初的设计。 门店定位（顶部） 自动显示 _“上海市黄浦区马当路富民超市”_，说明系统已精准锁定当前购物地点，为后续推荐做铺垫。 商品识别卡片（居中大框） 灰阶渐变 + 相机图标，文案 _“对准商品 拍一拍”_。 点击即可拍照识别商品，进入智能解析流程，是整套体验的“入口 1”。 语音购物助手按钮（绿色条形） 显眼的绿色按钮 _“打开语音购物助手”_。 用户只需轻触，便可与 AI 语音对话，实现“入口 2”。 AI 推荐栏目（下方列表） 栏目标题 _“AI 帮你聪明买”_，右侧分类下拉框默认 _“日用食品”_。 下拉可切换 “零食饮料 / 时令食材” 等，列表随之刷新“今日在售”优选商品。 拍一下，AI 帮你把配料表翻译成人话！识别完成后，只需点开「成分分析」，AI 会： 精准列出主要成分、配料比例； 提醒潜在风险（如高糖、高钠或人工添加）； 结合膳食指南，给出健康建议。如果想进一步了解热量、矿物质等信息，切换到「营养价值」即可；想知道同类好物怎么选？点「选购建议」一键获得。拍立懂，让任何瓶瓶罐罐都不再是“天书”，分分钟看懂喝得放心！ “拍一下成分表，让 AI 帮你读懂配料、评估健康影响，真正做到买得安心、喝得放心。” “坚果零食好不好？拍立懂 3 秒告诉你！”拍照上传后，AI 自动识别到「烤坚果夹片 145 g × 24 片」，并细致解析： 坚果种类、外层配料、甜味剂 / 添加剂 全部列出； 逐项点评对心血管、体重管理、过敏风险的影响； 支持一键切换到「营养价值」查看热量、蛋白质等详细数据，或点「选购建议」获取更健康替代品。拍立懂 —— 把复杂配料表翻译成人话，让零食的健康度一眼可见！ 一句话上手语音购物助手点一下麦克风，不用输入、不用切页面，直接对 AI 说：“这款牛奶适合减肥吗？”——拍立懂立刻回答，让逛超市像跟朋友聊天一样简单。 极速连接：3 秒内完成网络 &amp; 麦克风检测 实时反馈：对话状态一目了然，杜绝“说了没听见” 智能引导：AI 主动提问，帮你快速聚焦购物痛点语音 + AI，让信息检索更高效，让购物决策更轻松！ “无需打字，长按语音键即可提问。拍立懂即刻为你解惑，让购物沟通更流畅。” 商业计划书https://edwqcun7v5.feishu.cn/docx/VBtWdFMB3omZxhxT2FGco73MnIe 产品演示文档https://edwqcun7v5.feishu.cn/docx/RNvldJCQVoU1nixqHjrcZ2TNnfc ⏰ 凌晨三点的夜 还在码字、调参，但有热情就不困。拍立懂，让爸妈“拍一拍就懂”，也让我们更懂爸妈。","link":"/posts/ac23bcf7/"},{"title":"修改 Hexo 的 RSS 阅读数量（Icarus 主题）","text":"Icarus 主题本身不直接生成 RSS，只是提供 RSS 链接的展示位置（例如导航栏、侧边栏的 RSS 按钮）。真正生成 RSS/Atom 的功能，需要依赖 Hexo 的插件（通常是 hexo-generator-feed）。 因此，要修改 RSS 条数，需要分两步： 1. 安装 RSS 生成插件在博客根目录（_config.yml 所在目录）执行： 1npm install hexo-generator-feed --save 2. 在站点 _config.yml（根目录）配置 RSSRSS 条数由站点配置控制，而不是主题配置。示例： 1234feed: type: atom # 类型，可选 atom、rss2、json path: atom.xml # 输出文件名 limit: 50 # 输出文章数，0 表示全部文章 如果不写 limit，默认值是 20（插件源码中 var limit = config.limit || 20）。 3. 在 Icarus 主题 _config.yml 添加 RSS 链接Icarus 主题只是显示你生成好的 RSS 地址，常见的配置方式有两种： 导航栏： 123navbar: menu: RSS: /atom.xml # 对应 feed.path 的路径 侧边栏（Profile 小部件）： 1234567widgets: - position: left type: profile social_links: RSS: icon: fas fa-rss url: /atom.xml 4. 重新生成站点1hexo clean &amp;&amp; hexo g 然后访问： 1http://你的域名/atom.xml 即可查看 RSS 内容。 优先级说明 RSS 条数生成逻辑 → 由 hexo-generator-feed 插件控制，只读取 站点 _config.yml 的 feed 配置。 RSS 链接展示 → 由主题（如 Icarus）控制，在主题 _config.yml 中设置按钮或链接。 如果两个地方都有 feed: 配置，站点 _config.yml 优先级更高，主题配置不会覆盖它。","link":"/posts/2d0d3922/"},{"title":"Proxmox Virtual Environment (PVE) 虚拟机安装不完全指南","text":"本文将详细介绍如何在 Proxmox Virtual Environment (PVE) 中安装虚拟机。我们将从系统安装开始，逐步引导您完成虚拟机的创建和配置。 准备工作我选择使用 Ventoy 进行引导，这样可以避免反复使用 Etcher 等工具进行写盘操作。 系统安装 启动安装程序 启动后，您将看到如下界面： 用户协议 阅读并接受用户协议： 选择安装目录 选择安装 Proxmox VE 的磁盘： 设置密码 设置 root 用户的密码，邮箱地址可以随意填写： 配置网络 设置系统的 IP 地址： 开始安装 确认所有设置后，开始安装： 安装完成 安装完成后，系统将提示您访问 Web 管理界面，默认端口为 8006： 重启系统 拔掉引导 U 盘并重启系统： 登录与配置 登录系统 使用前面设置的密码登录系统： Web 管理界面 登录后，您将看到 Proxmox VE 的 Web 管理界面： 测试网络连通性 确保网络连接正常： 创建虚拟机 上传 ISO 文件 首先，上传操作系统的 ISO 文件： 创建虚拟机 设置虚拟机编号 为虚拟机设置一个编号： 选择镜像 选择之前上传的 ISO 文件作为安装镜像： 配置硬件 主板信息 保持默认设置即可： 磁盘设置 建议选择 VirtIO 以提高性能： CPU 配置 注意不要超过宿主机的 CPU 核心数，否则虚拟机将无法启动： 内存分配 根据需求分配内存： 网络设置 同样建议选择 VirtIO： 确认信息 确认所有设置无误后，点击完成： 启动虚拟机 启动虚拟机并开始安装操作系统： 操作系统安装 安装过程 按照提示进行操作系统安装： 加载驱动 在安装过程中，加载 VirtIO 驱动： 分区与安装 对磁盘进行分区并开始安装： 复制安装文件 安装程序将复制文件并进行系统安装： 设置时间 设置系统时区： 网络配置 安装完成后，系统可能暂时无法联网，稍后我们将安装网络驱动： 设置用户名和密码 为操作系统设置用户名和密码： 安装 VirtIO 驱动 安装 VirtIO 网络驱动以确保网络功能正常： Linux 系统安装对于 Linux 系统，安装过程类似，但通常 Linux 系统已经自带 VirtIO 驱动，无需手动安装： 通过以上步骤，您应该已经成功在 Proxmox VE 中安装并配置了虚拟机。希望本指南对您有所帮助！","link":"/posts/13af016a/"},{"title":"找到了一个wedav的项目","text":"win10 连接 Mac 共享的 SMB 有问题，所以想挂载 webdav，于是发现了这个项目： 可以不话心思解决 mac 个 windows 关于 Sambda 的兼容问题。 https://github.com/mar10/wsgidav WsgiDAV 是一个支持 SSL 的独立 WebDAV 服务器，可以在 Linux、OSX 和 Windows 上作为 Python 命令行脚本运行。它的主要功能包括： 主要功能： WebDAV 支持：它提供完整的 WebDAV 协议实现，用于通过 HTTP 协议远程访问、管理和编辑文件。 SSL 支持：你可以为 WsgiDAV 启用 SSL 加密，确保文件传输的安全性。 文件系统提供程序：通过文件系统提供程序，允许你将文件夹暴露为 WebDAV 共享。 基本认证和 PAM 登录认证：支持基本认证，并且支持在 Linux 或 OSX 上使用 PAM 认证。 Docker 支持：WsgiDAV 提供了一个实验性的 Docker 镜像，可以在 Docker 容器中运行 WebDAV 服务。 多线程支持：支持高性能的多线程 Web 服务器功能。 安装： 安装 wsgidav 和 cheroot： 1pip install wsgidav cheroot 启动 WsgiDAV 服务器并启用匿名访问： 1wsgidav --host=0.0.0.0 --port=80 --root=/tmp --auth=anonymous 配置选项： --auth=anonymous 启用匿名认证，允许没有身份验证的访问。 --auth=pam-login 启用基于 PAM 的认证（在 Linux 或 OSX 上使用）。 启用 SSL（推荐使用）： 1wsgidav --host=0.0.0.0 --port=8080 --root=/tmp --auth=anonymous --ssl-adapter pyopenssl 用 Docker 启动 WebDAV 服务器： 拉取 Docker 镜像： 1docker pull mar10/wsgidav 运行 Docker 容器： 1docker run --rm -it -p 8080:8080 -v /tmp:/var/wsgidav-root mar10/wsgidav 扩展功能： 虚拟文件系统：通过 WebDAV 使数据结构呈现为可编辑的文件系统。 文档编辑：支持在线编辑 MS Office 文档。 集成 WSGI：WsgiDAV 可以作为 WSGI 应用程序在其他 WSGI 兼容的 Web 服务器上运行。 结论：WsgiDAV 是一个灵活、强大的 WebDAV 解决方案，适合用于文件共享、在线文档编辑等应用场景。如果你需要在 Python 环境中快速部署 WebDAV 服务，它提供了简单的命令行启动选项以及 Docker 支持。如果需要更多自定义功能，还可以通过配置文件和 WSGI 中间件进行扩展。","link":"/posts/3ebd9b42/"},{"title":"飞牛OS虚拟机初体验","text":"前段时间，飞牛 OS 上线了虚拟机功能，尽管目前仍处于公测阶段，但已经可以尝鲜体验。官方文档也相当详细，感兴趣的可以参考：虚拟机文档。 公测声明官方的公测声明如下： 通俗来说，这个虚拟机功能可以看作是一个精简版的 PVE（Proxmox Virtual Environment）。在使用时，磁盘和网卡建议选择 virtio，这是一种半虚拟化方案，能够提供更好的性能和兼容性。 配置磁盘和网卡磁盘部分推荐选择 virtio 驱动，以获得更好的 I/O 性能： 网卡同样支持 半虚拟化，可以在创建虚拟机时选择： Windows 虚拟机驱动安装由于 Windows 默认不包含 virtio 驱动，因此需要手动下载并安装：VirtIO 官方下载地址 安装后，需要手动选择对应的驱动，这样才能正确识别到磁盘： 如果安装过程中未能识别到网卡驱动，可以在进入系统后再安装： Guest-tools 安装ISO 镜像中包含 Guest-tools，相当于虚拟机的 agent，需要安装，以提升性能和兼容性： 安装方式很简单，可以直接从 ISO 镜像里安装，里面包含所有必要的驱动和工具： 安装过程如下： 性能测试安装完成后，可以看到网卡已正常识别，并且协商速率为 10G： 测速结果表明，CPU 占用率相对较低，性能表现良好： 在内网环境下，测速几乎可以跑满 10G 网桥带宽： 总体来看，飞牛 OS 的虚拟机功能虽处于公测阶段，但体验已经相当不错。对于有轻量级虚拟化需求的用户来说，已经具备一定可玩性。如果你也对这项功能感兴趣，不妨动手试试！🚀","link":"/posts/3608dae8/"},{"title":"SSD介绍","text":"slc、mlc、tlc 闪存芯片颗粒区别介绍在 U 盘、SSD 等固态存储产品中，闪存芯片颗粒是核心，其关乎产品成本、寿命以及速度。闪存芯片颗粒主要有三种类型，分别为 SLC、MLC、TLC，三者之间的区别，如下。 SLC = Single-Level Cell，即 1bit/cell，速度快寿命长，价格贵（约 MLC 3 倍以上的价格），约 10 万次擦写寿命； MLC = Multi-LevelCell，即 2bit/cell，速度一般寿命一般，价格一般，约 3000—10000 次擦写寿命 TLC =Trinary-Level Cell，即 3bit/cell，也有 Flash 厂家叫 8LC，速度慢寿命短，价格便宜，约 500-1000 次擦写寿命。 1.速度最快，寿命最长，价格最贵的 SLC 颗粒intel 傲腾 900P 固态硬盘是英特尔针对商业客户和游戏发烧友推出高性能 SSD，它使用的就是 SLC 闪存颗粒， 持续写入速度 2.0G/S，4K 写入 50 万 IOPS； 持续读取速度 2.4G/S，4K 读取 55 万 IOPS； 寿命约为全盘写入 15000 次，每天全盘写入一次，预估寿命为 40 年； SLC 闪存颗粒就像这款搭载它的傲腾 900P 一样，尽管已经是“宇宙级最强 SSD”了，但因为贵，所以销量惨淡！ 2.速度较快，寿命较长、价格较贵的 MLC 颗粒三星 960 Pro 是三星针对游戏发烧友和专业级用户推出的高性能 SSD，它使用的是 MLC 闪存颗粒， 持续写入速度是 2.0G/S,4K 写入 33 万 IOPS; 持续读取速度是 3.2G/S，4K 读取 33 万 IOPS； 寿命约为全盘写入 1500 次，每天全盘写入一次，预估寿命为 4 年； 对普通人用户来说，SLC 颗粒就像劳斯莱斯幻影，好是好，但是太贵，所以，极少有人买；MLC 颗粒就像宝马 7 系，车还算可以，但还是贵，买的人还是少； 只有 TLC 颗粒就像福克斯，虽然性能和品质远不如劳斯莱斯和宝马 730，但是价格实惠，所以，买的人最多； 3.速度较慢，寿命较短、价格最便宜的 TLC 颗粒三星针对消费级市场推出的廉价版 SSD，虽然它采用了速度最慢的 TLC 闪存颗粒，但因为它使用了 PCIE3.0*4 通道作为数据传输通道，所以，它的读取速度还是甩了所有 SATA 接口 SSD 几条街； 三星 960EVO 持续写入速度为 1.5G/S，4K 写入 30 万 IOPS； 持续读取速度为 3.2G/S，4K 读取 33 万 IOPS； 寿命约为全盘写入 700 次，每天全盘写入 1 次，预估寿命为 2 年； 当然，普通用户根本没有那么大的写入数据需求，以每天 20G 的数据写入量，即便是寿命最短的三星 960EVO，预期寿命也有 20 年； 最后，我想说，以普通用户的日常数据处理量，TCL 闪存颗粒肯定够用了，没有必要去追求什么 SLC、MLC；我们只要性价比，我突然发现一个事实：目前某东上热销的 SSD 都是 TLC 固态！ 转载地址","link":"/posts/2e34d332/"},{"title":"PXE 装机：iventoy 聊胜于无","text":"ventoy 是装机神器，iventoy 便是其网络版。只需将 ISO 文件放入指定目录，设置 DHCP 启动池，并启动服务即可。其操作简单，适合需要批量装机的场景。 这里的 DHCP 池是上级路由器的一小部分，一是为了防止 IP 冲突，而是免费版只能 20 个客户端 首先要在 BIOS 上开启 PXE 启动，由于我的机器比较老，所以只能支持 legacy 的方式，启动之后是这样的： 然后在启动项中选择网络启动： 客户端自动寻找 PXE 服务端： 然后就会自动跳出这个页面： 在传输镜像的过程中并没有跑满 1G 内网，这个速度其实是不如大部分 U 盘的： 尝试下来，聊胜于无。 win11 的镜像没有加载出来，不知道是不是机器太老。 每次启动网启的提示要闪很多遍，没有用 U 盘装机干净利落。 走千兆网络速度不能跑慢，适合批量不急的时候装机。 王小波风格 by deepseekPXE 装机：iVentoy 这东西，聊胜于无吧Ventoy 是个好东西，装机神器，iVentoy 就是它的网络版。这东西用起来倒也简单，扔几个 ISO 文件进去，设个 DHCP 启动池，启动服务，完事儿。听起来挺美好，可实际用起来嘛，总有点“理想很丰满，现实很骨感”的意思。 DHCP 池是从上级路由器里划出来的一小块，一来怕 IP 冲突，二来免费版只支持 20 个客户端。这就像你请客吃饭，桌子太小，只能坐 20 个人，再多就得站着吃了。站着吃也行，但总归不太舒服。 我的机器比较老，BIOS 里只能开 Legacy 模式，启动后就是这么个界面。看着这老古董，我心里有点感慨：科技这东西，跑得飞快，可我的机器还停留在上个世纪。启动时得选网络启动，像极了在旧书店里翻一本发黄的书，翻来翻去，终于找到了想要的那一页。 客户端会自动找 PXE 服务端，像一只迷路的小狗，东闻闻西嗅嗅，终于找到了回家的路。然后，屏幕上跳出这么个页面： 看起来挺顺利，可接下来的事情就不那么美好了。传输镜像时，速度没跑满 1G 内网，甚至还不如大部分 U 盘。这就像你开着一辆跑车，结果发现油门踩到底，速度还不如隔壁老王的自行车。 用下来，总结几点感受： Windows 11 镜像没加载出来。可能是我的机器太老，老得连新系统都不愿意搭理它。这就像你去参加一个年轻人的派对，结果发现自己连门都进不去。 每次启动网启的提示闪很多遍。这玩意儿像个唠叨的老太太，一遍又一遍地提醒你：“别忘了网络启动！”可我只想干净利落地装个系统，不想听它啰嗦。 千兆网络速度跑不满。适合批量装机，但前提是你得有不急的耐心。这就像你去排队买票，队伍很长，但你又不赶时间，只好慢慢等。 总的来说，iVentoy 这东西，聊胜于无吧。它有点像那种“能用，但别指望太好用”的工具。如果你有耐心，又不介意它的那些小毛病，那它还是能派上用场的。但如果你追求的是高效、稳定，那它可能还差点意思。 最后，我想说，科技这东西，总是让人又爱又恨。爱它的便利，恨它的不完美。可正是这些不完美，才让我们有了继续折腾的动力。折腾吧，朋友们，生活不就是一场永无止境的折腾吗？ 鲁迅风格 by ChatGPTPXE 装机：iventoy 也不过如此Ventoy 是装机的利器，iventoy 便是它的网络版。把 ISO 文件丢进目录，设定 DHCP 启动池，开机，完事。操作简便，适合批量装机。 但凡事总有些许不尽如人意。 DHCP 池呢，不过是从上级路由器分出的一小块地方，一是怕 IP 冲突，二是免费版只能给二十个客户端，这点倒是想得周到。 BIOS 里得先开 PXE，我这机器年纪大了，只认得 legacy 的启动方式，没办法。好不容易启动了，见到个画面，心里稍安。 接着得在启动项里选网络启动，设备便开始四处张望，寻找 PXE 服务器。等它找着了，蹦出来个界面，算是进了正题。 然而这装机过程，谈不上利落。镜像传输时，千兆网络竟跑不满，速度竟不及寻常 U 盘。Win11 的镜像更是直接消失，或许是我这老机器力不从心。每次启动时，那网启提示闪来闪去，晃得人头晕，哪有 U 盘插上就干脆利索？ 尝试一番，感慨一句：聊胜于无。","link":"/posts/3ff07059/"},{"title":"intel 12代CPU折腾记","text":"最近小米新出了迷你主机，甚至连 nuc 贴纸都没摘，所以还不如直接买 intel 的 nuc 华尔街峡谷，毕竟从 nuc8 的黑苹果一路走过来的。什么都不用改，直接用豆子峡谷的 vesa 壁挂。但是也有一些问题。 大小核的问题12 核 16 线程其实是 4 大核 8 小盒，所谓大小核问题，就是在以 vmware 为首的很软件，经常出现小核跑满大核限制的情况，然而在任务管理器中还显示 CPU 占用 100%。 需要在电源模式中开启性能模式，然后才能解开大小核的显示，后续的时候没有发现特别不适应的地方。 显示器延迟问题因为主机是双 HDMI 和双 typec 的接口，所以必须要接一台 typec 的的显示器，但是 Philip 网红显示器接上有很长的延时点亮问题，有时候甚至比开机时间还要长，同时也咨询过 intel 和 Philip 的售后支持人员，答复如下： intel：从 Xe 显卡开始就有这种兼容问题，存在和 philip，aoc 部分型号的兼容问题 philip：客服说显示器 10s 点亮正常，到了售后说是更长的时间，最后到厂家说 32s 才正常（东西不错，售后真的太差。。。 另外显示器有时候不能 4K60@刷新，客服说要把显示器的 hub 改成 2.0，但是这样就只能接一些键鼠摄像头一类的东西了。 2.5g 网口驱动问题2.5G 驱动目前好像只能离线安装。目前 win10 和 win11 系统内部没有集成 2.5G 网口的驱动，所以需要手动去官网下载驱动，然后手动安装。这里不太推荐驱动精灵一类的第三方软件。但是其他驱动只能联网之后安装，所以还是先准备个 U 盘吧。 Win11 强制登陆 MS 账户win11 虽然很丑，但是据说只有这个对大小核兼容好一点，现在只有企业版核教育版可以不用强制登陆 MS，其他的都绕不过去，有的输入神秘代码亲自测无效，估计是 MS 家修复了这个问题。 系统缓存的问题装好系统之后，遇到了 C 盘占用特别高的问题，网上查询之后是因为内存太大，导致 OS 自动做了休眠文件，为了把内存都压到磁盘里。 PCLE4唯一值得安慰的是 PCLE4 的 NVME，顺序读取有 6600MB/S，总之还算不错。但是总归是 TLC 的，毕竟我连 MLC 都能写坏…","link":"/posts/5821c3b8/"},{"title":"ventoy引导wtg","text":"ventoyventoy 是一个可以支持启动很多镜像的工具，可以理解为 win + linux 的版本的 PE。现在也兼容了 openwrt，chromeOS， EXSI 这些系统了，虽然还不支持 MacOS 哈哈哈哈 WTG现在民间有萝卜头的 Windows To Go 辅助工具|WTG 辅助工具 v5.6，可以轻松的安装系统到 U 盘。 https://bbs.luobotou.org/thread-761-1-1.html 我的系统是 CZ880 的 256G 版本,读写均可达到 400MB/S 左右，这个速度已经很接近 Sata3 固态硬盘了。 WTG + ventoy 按照下图设置好，vhdx 容量选择 64G。然后选好 U 盘和对应镜像，写盘完成之后从 U 盘启动完成初始化，进入一次系统，不然据说 ventoy 进去的时候会导致系统起不来。（动态存储，64G，实际安装完只有 8G，随着使用会慢慢增大） 备份刚才安装好了 vhdx，然后安装 ventoy，这次会格式化所有的分区，而且默认分区是 EXFAT，如果想使用 WTG 的话需要把系统格式化 NTFS，这样才能运行 windows。不格式化的话，就会….Any way 就是花式错误 把一开始 vhdx 拷贝回来就行啦。（需要安装个插件 新建 ventoy 目录里 ventoy_vhdboot.img 白名单有时候不想让 ventoy 显示其他的东西，比如黑苹果的 EFI，office 的 ISO，这样就需要设置显示 image_list 的白名单。 就是在 ventoy 目录下 ventoy.json 这个格式，而且只会显示这里的镜像。 1234567891011121314151617181920{ &quot;image_list&quot;: [ &quot;/ventoy/OS/win10wtg.vhdx&quot;, &quot;/ventoy/OS/linux/archlinux-2023.02.01-x86_64.iso&quot;, &quot;/ventoy/OS/linux/CentOS-7-x86_64-DVD-2009.iso&quot;, &quot;/ventoy/OS/linux/chromeos_15117.112.0_reven_recovery_stable-channel_mp-v2.bin&quot;, &quot;/ventoy/OS/linux/Fedora-Workstation-Live-x86_64-37-1.7.iso&quot;, &quot;/ventoy/OS/linux/FydeOS_for_PC_iris_v16.0-stable&quot;, &quot;/ventoy/OS/linux/kali-linux-2022.4-installer-amd64.iso&quot;, &quot;/ventoy/OS/linux/linuxmint-21.1-xfce-64bit.iso&quot;, &quot;/ventoy/OS/linux/manjaro-gnome-22.0.2-230203-linux61.iso&quot;, &quot;/ventoy/OS/linux/pop-os_22.04_amd64_intel_22.iso&quot;, &quot;/ventoy/OS/linux/pop-os_22.04_amd64_nvidia_22.iso&quot;, &quot;/ventoy/OS/linux/ubuntu-22.04.1-desktop-amd64.iso&quot;, &quot;/ventoy/OS/windows/cn_windows_10_enterprise_ltsc_2019_x64_dvd_9c09ff24.iso&quot;, &quot;/ventoy/OS/windows/win7.iso&quot;, &quot;/ventoy/OS/windows/zh-cn_windows_11_business_editions_version_22h2_updated_jan_2023_x64_dvd_82450200.iso&quot;, &quot;/ventoy/OS/windows/zh-cn_windows_server_2022_updated_oct_2022_x64_dvd_884ce1ea.iso&quot; ]} PS：找 chatgpt 要了一份自动生成 json 文件的代码： 1234567891011121314151617181920212223import osimport jsondir_name = os.path.basename(os.getcwd())def convert_to_unix_path(windows_path): return windows_path.replace('\\\\', '/')def get_files_in_directory(path): files = [] for root, _, filenames in os.walk(path): for filename in filenames: file_path = os.path.join(root, filename) relative_path = f&quot;\\{dir_name}\\{path}\\{os.path.relpath(file_path, path)}&quot; files.append(convert_to_unix_path(relative_path)) return filesventoy_json = { &quot;image_list&quot;: get_files_in_directory(&quot;OS&quot;)}with open('ventoy.json', 'w') as f: json.dump(ventoy_json, f, indent=4)","link":"/posts/874b576b/"},{"title":"等了半年的 POE 系统，铭凡 S100 不完全测评","text":"这个电脑吸引我的点是 POE 供电，如果配上 POE 交换机岂不是妥妥的软路由圣体，抱着这样的目的下单的。 先写吐槽 原来店家宣传的是 16G 内存，后来改成 8G，之前还经常断货 差评率很高，基本是吐槽锁功耗和预装 win11（如果是准系统还能省点 lisence 的钱） N100 这个价位性价比其实很低，可以购买 N305 了 这机器磁盘用的 UFS2.1，是在太落后了 运行的时候很热，风扇声音很大。 而铭凡这个厂家也是比较口碑两极化，这几年国产小主机层出不穷，minisforum 应该算是最早的一批。一部分玩家为了性价比方案选择国产小主机，而另一部分玩家还是只认电脑三巨头再加上 Apple。就比如雷神被吐槽是，一线的价格，二线的产品，三线的售后。（来自网络，不代表本人观点） 回到电脑本身，自带的 windows 真的卡，非常卡！！！！我是觉得实际办公都卡，跑 geekbeanch 也很卡。 然后换了 Ubuntu，网上说要根据 UFS 做一些更改，卖家也表示不支持除了 windows 以外的系统。但是我实际用的 ubuntu24.0，直接随身碟也装上了，安装时候也很卡，甚至不如大学的笔记本=。=，不确定是性能是在拉垮还是这几年 ubuntu 越来越臃肿了。 网上是这个方案，我先贴出来，Mark 一下。https://www.reddit.com/r/MiniPCs/comments/1eb8dgv/minisforum_s100_only_runs_windows_anyone_else/ 12345678910111213sudo mount --bind /dev &quot;$PWD/dev&quot;sudo mount --bind /proc &quot;$PWD/proc&quot;sudo mount --bind /sys &quot;$PWD/sys&quot;Type:sudo chroot &quot;$PWD&quot; /bin/bash --loginType:echo &quot;ufshcd&quot; &gt;&gt; /etc/initramfs-tools/modulesecho &quot;ufshcd-pci&quot; &gt;&gt; /etc/initramfs-tools/modulesType:update-initramfs -u -k all 这是加了详细注释的版本（完全针对新手也能理解的程度）： 将 Ubuntu 系统的根分区挂载到/mnt 目录（假设你已经挂载好了，这一步是之前完成的） 12# 进入挂载好的/mnt目录cd /mnt 挂载必要的系统目录，确保在 chroot 环境中能正常使用系统功能 12345678# 绑定/dev目录，这样chroot后能访问设备文件（如磁盘、终端等）sudo mount --bind /dev &quot;$PWD/dev&quot;# 绑定/proc目录，这样chroot后能访问进程信息sudo mount --bind /proc &quot;$PWD/proc&quot;# 绑定/sys目录，这样chroot后能访问内核信息sudo mount --bind /sys &quot;$PWD/sys&quot; 切换到 chroot 环境，相当于“进入”你的 Ubuntu 系统中，像正常启动一样操作 1sudo chroot &quot;$PWD&quot; /bin/bash --login 说明：这样之后你在这个终端里的所有操作，都会直接作用于你挂载的 Ubuntu 系统上（而不是 LiveCD 或恢复环境）。 在 initramfs 的配置文件中添加模块，确保开机时加载 UFS 硬盘相关驱动 12echo &quot;ufshcd&quot; &gt;&gt; /etc/initramfs-tools/modulesecho &quot;ufshcd-pci&quot; &gt;&gt; /etc/initramfs-tools/modules 说明：这里ufshcd和ufshcd-pci是 UFS 存储设备的驱动模块，如果不加，可能开机找不到硬盘导致无法启动。 更新 initramfs，将刚才加入的模块纳入系统启动时加载的内容 1update-initramfs -u -k all 说明：-u 表示更新现有的 initramfs，-k all表示为所有内核版本更新。这一步非常重要，否则刚才写入的模块不会生效。 退出 chroot 环境 1exit 说明：这会退出你刚才“进入”的 Ubuntu 系统，回到正常的恢复环境终端。 总结一句话整个流程的作用是：在离线状态下手动为 Ubuntu 系统补充 UFS 硬盘驱动，确保系统下次启动时可以识别和加载 UFS 硬盘，从而正常启动。 这个是在安装了 ubuntu 系统的 geekbench6 的跑分，这个是调整功耗到 9W 的，如果是默认的 6W 跑分只有 665，是完全没眼看的程度。期间也尝试过在 Bios 把功耗调整到 12.5W，但是分数反而降到 145 左右，不确定是不是降频或者功耗撞墙什么的。https://browser.geekbench.com/v6/cpu/11818077 改功耗：https://www.youtube.com/watch?v=g6Dk3BMgoYw程度 本来还想试试 openwrt 的，但是也没成功，UFS2.1 也没啥折腾的必要。用了前面修复 UFS 的命令，执行之后 boot 里也没有引导。 1sudo dd if=immortalwrt-24.10.0-x86-64-generic-ext4-combined-efi.img of=/dev/sda bs=4M status=progress 写在最后如果追求桌面办公的话，适合对性能要求不高，能容忍卡顿的。 如果安装 Linux 的话，不强制追求 X86 话，还是树莓派吧，不过价格能够降一半倒是一个可以接受的方案。 这个能 POE 一线通固然是优点，但是 Typec 供电+wifi 网卡也没差太多。虽然放弱电箱真的好看好管理，但是 N100 对于现在的我来说，也就只能跑跑路由器系统或者轻 NAS 了吧。","link":"/posts/a7aa5f43/"},{"title":"电容键盘体验","text":"曾经向往过 HHKB,也用过一段时间的国产宁芝,总体来说体验还算可以,只是买的早但是只支持有线最后还是弃坑了 这里记录一次电容充电的记录,尽管理论上电容键盘是无限寿命,但是也遇到了按键失灵的问题,客服解释说是缺电需要充电,同时提供了对应的驱动软件,大概过程就是插上电脑,然后用检验工具按下任意键就好了.印象里就充了一次电然后好几年都没问题.特此记录下来","link":"/posts/7b93b635/"},{"title":"打印机改无线","text":"过年回家给家里的老式打印机改装了无线打印，了解到目前无线打印分为以下几种： 自带的无线功能，插网线就能用 有线打印机 + 小白盒子 有线打印机 + 电脑共享 安装驱动前两种基本没有什么差异，不过需要手机和电脑分别安装打印机驱动，无线的可能支持微信无线打印，但是用盒子自己改的目前还不支持移动端，这种一般是打印机使用连接路由器，一般公司是这种。 无需安装驱动当然有办法可以让手机不用安装驱动，需要使用 PC/MacOS 安装驱动之后再局域网共享打印机，这样 windows 和安卓都能搜到。 苹果特殊的协议有一些老式的打印机会出现苹果设备搜不到打印机的情况， 是因为没有兼容 airprint 协议导致的。当然新的打印机无需考虑这个问题。曾经有个 airprint 的软件，现在已经停更，也不想折腾了。Anyaway，劝退 apple 全家桶的最后一根稻草。","link":"/posts/79388b04/"},{"title":"老式打印机改 Airprint 之 cups","text":"很多年以前就想把家里的老式打印机改成无线，前前后后摸索了这些方案： 用小白盒连接路由器：其实这个思路了网络打印机很类似，就是打印机 over IP，企业里几乎也都是这样的做法。缺点就是需要客户端安装驱动，所以相比之下就牺牲了移动端。 windows/MacOS 共享：由于缺少 airprint，所以 Apple 设备无法使用隔空打印。其实 Windows 的兼容性是最好的。 在 OpenWrt 上安装 Cups 驱动，然后打印机接路由器当做无线使用。 感谢这篇文章，给了我很大的帮助：https://www.bilibili.com/opus/720655857020305463 我的方案是在打印机接群晖，然后使用 Docker 运行 Cups，来支持 Airprint。 虽然群晖自己支持了 cups，但是驱动不全，联想的打印机基本没有驱动，换几个其他的打印机型号也无法正确驱动起来，反而因为指令集冲突打印机一直在出空白页。 于是，打上了 docker 的主意。。。。 因为懒，也觉得没必要做数据映射： 1sudo docker run -d --name=airprint --net=host --privileged=true -e TZ=&quot;Asia/Shanghai&quot; -e CUPSADMIN=&quot;admin&quot; -e CUPSPASSWORD=&quot;pass&quot; -e HOST_OS=&quot;Synology&quot; -e TCP_PORT_631=&quot;631&quot; chuckcharlie/cups-avahi-airprint:latest 从 631 端口进去 web 页， 选择识别的打印机： 填写信息，选择共享这个打印机。 没有打印机的驱动，所以我选了兄弟的。 打印机信息一览： 一个小插曲： Mac 升级之后把高级选项弄丢了，需要在这里邮件，选择自定义工具栏 要把 logo 拖放到 2 处而不是 1 处，这个设计很反人类。 主要原因是一开始使用其他的 docker 镜像无法识别打印机，所以在这里使用 http 和 ipp 添加 http 的这么添加： ipp 的把这串输入到浏览器,MacOS 可以，手机和 Ipad 不行： 1ipp://192.168.5.171:631/printers/Lenovo_M7400_Pro 这俩 docker 怎么都搜不到打印机（iPhone 不行，Window 可以，Mac 可以用上述办法添加），踩了几个小时的坑： 换了最上边那个容器之后全平台都可以了： 第二个就是我的打印机，第一个是群晖自己 cups 映射出来的，有 bug systemctl stop cupsd 也关不掉，不过也没啥影响。 MacOS 结果： Iphone 默认无法选择打印机，只能点击分享，然后下拉菜单选择打印： Iphone 默认只支持隔空打印，但是使用 Cups 之后我们的打印机不在列表中，但是也能正常的使用了。 整了这么多测试页，主打一个折腾开心： 最后还是有一个小问题，就是打印机由于关机或者拔掉 USB 的再重启的话，这个 docker 服务没有轮训机制，所以如果不常用的话，就需要每次打开打印机之后再手动运行重启下容器。 虽然现在的打印机都支持了 Airpint，cups 虽然已经成为了历史了，这么做算是圆了一个以前折腾的梦吧。 写了一个重启 CUPS docker 的 web： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot; /&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt; &lt;title&gt;Restart Container&lt;/title&gt; &lt;style&gt; body { font-family: Arial, sans-serif; background-color: #f4f4f9; display: flex; justify-content: center; align-items: center; height: 100vh; margin: 0; } .container { text-align: center; background: white; padding: 2rem; border-radius: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); } h1 { color: #333; margin-bottom: 1.5rem; } #restart-btn { background-color: #007bff; color: white; border: none; padding: 0.75rem 1.5rem; font-size: 1rem; border-radius: 5px; cursor: pointer; transition: background-color 0.3s ease; } #restart-btn:hover { background-color: #0056b3; } #status { margin-top: 1.5rem; font-size: 1.1rem; color: #555; } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;container&quot;&gt; &lt;h1&gt;Restart Docker Container&lt;/h1&gt; &lt;button id=&quot;restart-btn&quot;&gt;重启打印机服务&lt;/button&gt; &lt;p id=&quot;status&quot;&gt;&lt;/p&gt; &lt;/div&gt; &lt;script&gt; document .getElementById(&quot;restart-btn&quot;) .addEventListener(&quot;click&quot;, async () =&gt; { const statusElement = document.getElementById(&quot;status&quot;); statusElement.textContent = &quot;Restarting...&quot;; try { const response = await fetch(&quot;/restart&quot;, { method: &quot;POST&quot;, }); const result = await response.json(); statusElement.textContent = result.message; } catch (error) { statusElement.textContent = &quot;Failed to restart container.&quot;; } }); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 后端使用 Flask： 12345678910111213141516171819202122from flask import Flask, render_template, request, jsonifyimport dockerapp = Flask(__name__)client = docker.from_env()@app.route('/')def index(): return render_template('index.html')@app.route('/restart', methods=['POST'])def restart_container(): container_name = 'airprint' # 你要重启的容器名字 try: container = client.containers.get(container_name) container.restart() return jsonify({'status': 'success', 'message': f'Container {container_name} restarted successfully!'}) except Exception as e: return jsonify({'status': 'error', 'message': str(e)}), 500if __name__ == '__main__': app.run(host='0.0.0.0', port=8000) 做好容器放在群晖上，完美～ 123docker buildx build --platform linux/amd64 -t printer:latest --load .docker save printer:latest &gt; 1.tardocker run -d --name printer_container -p 8888:8000 -v /var/run/docker.sock:/var/run/docker.sock --restart unless-stopped printer:latest","link":"/posts/6fcedbb0/"},{"title":"Lighting 原生不支持OTG！","text":"我还留着 Lighting 的设备，由于大疆 pocket3 最近更新了直连手机文件管理器的功能，所以试试。 用了 Apple 的原装线连接 pocket3 和 iPhone 结果没反应，但是在 IPAD 上就能够成正常连接。 然后换了移动硬盘连接 IPhone 同样也不行，和 IPhone 的售后 battle 了好久对方也说不明白。最后还是 Apple 论坛上找找到一个帖子， Lighting 原生不支持 OTG，还得买转接头，这算盘打的真响。 https://discussionschinese.apple.com/thread/252659031?=undefined&amp;previousThread=255169304321&amp;sortBy=rank 最后感谢欧盟，要求 Apple 更换 Typec 接口，解决了 USB2.0 的问题，也可以和安卓设备一样用高速传输了。","link":"/posts/d969a069/"},{"title":"MacOS 26 beta 如何恢复启动台","text":"苹果最新版的系统使用了年份命名，主要是毛玻璃风格，虽然毛玻璃用了几天慢慢习惯了。 另一个槽点是 apple 把启动台去掉了，改成了 apps，用搜索栏统一搜索。 除了检索应用，也能检索邮件和文件什么的，属于是一键搜索了。 那么我们怎么改原来的启动台呢？执行这两个命令然后重启： 123sudo mkdir -p /Library/Preferences/FeatureFlags/Domainsudo defaults write /Library/Preferences/FeatureFlags/Domain/SpotlightUI.plist SpotlightPlus -dict Enabled -bool false GPT 解释如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#### 第 1 行：```bashsudo mkdir -p /Library/Preferences/FeatureFlags/Domain```* 创建一个目录用于配置 **macOS 内部功能标志（FeatureFlags）**。* `-p` 参数确保中间目录不存在时也一并创建。#### 第 2 行：```bashsudo defaults write /Library/Preferences/FeatureFlags/Domain/SpotlightUI.plist SpotlightPlus -dict Enabled -bool false```* 使用 macOS `defaults` 命令写入系统级别的配置文件。* `SpotlightUI.plist` 是控制 Spotlight（聚焦搜索）的功能标志文件。* `SpotlightPlus` 是 macOS 14 Sonoma 起的一个实验性 Spotlight 增强功能。* `Enabled -bool false` 意思是**禁用 Spotlight Plus（新版搜索界面）**。---### 🧩 背景用途：这个配置被用来：| 场景 | 描述 || ------------------ | ---------------------------------------- || 💻 macOS Sonoma 用户 | 禁用默认启用的“Spotlight Plus”功能，恢复旧版 Spotlight || 🧪 实验功能控制 | macOS 通过隐藏的 feature flag 启用或禁用某些 GUI 功能 || ⚙️ 解决兼容问题 | 有些用户觉得新版 Spotlight 太慢或不兼容快捷键脚本，想禁用 |---### 🚨 注意事项：1. 更改后可能需要 **重启系统或注销登录** 才能生效。2. 如果系统升级，Apple 可能会重置该设置。3. 这种方法是“非公开支持”的隐藏设置，未来 macOS 可能废弃此路径。---如果你想恢复 Spotlight Plus，只需执行：```bashsudo defaults delete /Library/Preferences/FeatureFlags/Domain/SpotlightUI.plist SpotlightPlus```或者将 `-bool true` 写回去。---如你还有其他想隐藏或禁用的 macOS 功能（比如 Siri、Stage Manager、控制中心某模块），我可以帮你查找对应的 `defaults write` 配置。需要吗？ 重启之后我们的启动台就回来了：","link":"/posts/83eb1399/"},{"title":"MacOS安装的软件无法打开","text":"因为 PicGo 没有签名，所以会被 macOS 的安全检查所拦下。 安装后打开遇到「文件已损坏」的情况，请按如下方式操作： 信任开发者，会要求输入密码: 1sudo spctl --master-disable 然后放行 PicGo : 1xattr -cr /Applications/PicGo.app 然后就能正常打开。 https://github.com/Molunerfinn/PicGo/blob/dev/FAQ.md","link":"/posts/3ab0fe4d/"},{"title":"京东售后拒修 AirPods 称&quot;无问题&quot;，苹果官方检测后直接换新！京东竟删除检测记录？","text":"去年在京东买的 Airpod Pro2 售后记录，以前都是在官网买的，还是图省事了。结果闹了个哭笑不得。 故障问题是，只有一边的耳机有声音，于是京东寄修，得到的答案是没问题，直接给我原反了。然后后台给我一个一张检测单（请记住这个，后面京东后台竟然把这个删了） 所谓京东的人给我打电话，是沈阳口音，然后听起来就是一点不懂技术的样子。说耳机是固件的 bug，然后直接把固件降级然后就好了。 然后我直接三连问： airpod 的固件是自动升级的，用户没办法干预，怎么保证下次自动升级不会再有问题？ 有没有什么硬件问题？有时候合上盖子还有声音？ 有时候一个耳机掉电快，另外一个基本满电能不能看一看？ 口头说好找人看，然后耳机直接给寄回来了，没有任何后续。 京东 Apple 里的耳机检测图片，一看就很不专业，像是某种小店。一口一个有苹果官方的人员主场，一口一个不解决问题，怕不是外包 hhh 但是，寄回来的耳机仍然是一样的问题。再次申请售后是不予受理。理由是上一次检测没有问题，让我去 Apple 线下自行解决。从普通客服到专员，再到所谓的客服经理无一不如此。真是，体验简直太差。那就让我去 Apple 直营店打你们的脸吧。 去了 Apple 三里屯，检测确实有硬件问题，左耳机收音有问题，右耳机能隔着盒子放出来声音，于是给换新了。贴一下检测单。 然后继续去京东 battle，说 apple 给换新了，你们京东为啥检测不出来。然后仍然是不予受理，继续装死。然后默默的把之前检测没问题的单子给删除了。（最前面的一张） 这里的红框圈起来的部分，本来是原来那个检测单的，后来竟然给删了，销毁证据，京东你真行。 以后电子产品大件还怎么放心在京东买啊？","link":"/posts/c67acea7/"},{"title":"你的下一个电脑还得是电脑","text":"M4 芯片先给了 Ipad，这是没想到的，最近 Apple 的操作是越来越看不懂了。到同事打赌一年不买苹果产品的期限还没到（M2 Pro 买了半年就发 M3 Pro 被刺），关于 8G 起步内存的事也没怎么关注，倒是趁着这次发布会想起来被吃灰的 Ipad。 “买前生产力，买后爱奇艺”。吃灰了好久还是决定利用起来。现在的定位感觉还是视频剪辑，甚至还不能写代码，所以一些重量级别的事情只好远程连接 windows。 这个是外接显示器的效果，距离 M1 可以外接显示已经好几年了，但是 ipad 锁屏之后外接显示器也会黑屏的这个问题还是没有修复，最后只能把 ipad 的亮度调到最低。 这个是 RDP 连接 Windows 的效果，除了 RDP logo 之外也看不出来其他的东西，然后就可以使用妙控键盘来控制了。 由于合上盖子会导致自动锁屏，所以需要在设置里关闭自动锁定。（本来为了省电设计的功能，到这里就变成了负优化） 这个是合上盖子的效果。 合上盖子 RDP 的效果： 已经只用 MacOS 当主力系统已经很多年了，就让 Windows 活在虚拟机里吧。","link":"/posts/c40f7be/"},{"title":"使用ipad 串流 MacOS","text":"服务端是 sunshine，客户端叫做 moonlight MacOS 安装的命令如下： 使用该命令会自动拉取源码包并且自动编译，然后使用 sunshine 命令启动： 12brew tap LizardByte/homebrew brew install sunshine 这个服务会启动在 47990 端口，进入网页是这个样子 客户端是使用 moonlight，可以在 app store 直接下载 点击 Add Host Manully，填入服务端的 ip。 然后会提示提示配对，这里给了一串 PIN 码，需要填写到服务端的 WEB 中 然后把上一步 moonlight 的 PIN 写到这里 然后对于 MacOS 来说，需要给到终端录屏和辅助功能的权限。 然后就可以开心的玩了～","link":"/posts/474f606e/"},{"title":"如何使用 Iphone 拍摄 JPG 格式的照片","text":"在写笔记的时候需要 Iphone 拍摄照片到 Macbook 上面，但是 Apple 默认的 HEIC 格式没办法在 Markdown 笔记以及图床上很好的进行渲染，这个时候要么截图，要么转码成 jpg/png 的格式。 设置里选择相机： 选择格式： 选择兼容性最佳： 然后 AirDrop 到 MacBook 上面，两个格式的图片大小差不多。 下一步就可以开心的把图片拖拽到笔记里了。","link":"/posts/4bc0fb74/"},{"title":"MacOS干扰那些事","text":"随航掉帧https://discussionschinese.apple.com/thread/253757661 直接查有线之后，速度有很大改进，原来不是随航掉帧，是路由器不行。 airpod pro 和蓝牙设备串扰2.4G 干扰https://support.apple.com/zh-cn/HT201542没辙，换 homepod 吧，起码 homepod 还真的不错","link":"/posts/9afa2bcc/"},{"title":"高版本的MacOS如何降级？","text":"很早问过Apple客服MacOS的降级机制，半天也没说明白。但是M芯片的Macbook经常崩溃，如果说windows的蓝屏时，那我这个MacBook就能崩溃出彩虹色。 寻找过Apple支持，答案就是升级系统。Apple的行政关系团队给我找了一个非常不靠谱的人，一问三不知，问她什么就是再转问工程团队，然后所有的事情都推第三方软件。然后行政关系团队陈某说对技术不做评价，然后一再坚持他们的人都是专业培训上岗的，然后坚持不换人，坚持不解决电脑问题来给客户扣不配合的帽子。 然后一直拖到过保。以前iphone接不到电话是这样，现在Macbook还是这样。 言归正传。Mac刷机一般几种办法。 U盘刷机，这个是传统了，玩过PE的都懂。 系统内格式化：就跟手机差不多的那种。个人感觉不彻底。 DFU刷机：需要你有另外一个MacOS的电脑。类似于安卓线刷。 MacOS降级我采用的是U盘装机。参考这个帖子 https://support.apple.com/zh-cn/101578 从Apple Store下载OS，然后把U盘的label改成/Volumes/MyVolume，最后做随身碟 可以选择各个MacOS大版本的最后的release。 烧录命令是： 1sudo /Applications/Install\\ macOS\\ Ventura.app/Contents/Resources/createinstallmedia --volume /Volumes/MyVolume 如果需要其他的系统，那么换一个版本号即可。 我的23年的M2 Pro，当时出长的时候是MacOS13 Ventura，所以当我想换回MacOS12的时候下载都报错。 如果直接安装还会报错：这个卷无法降级。（不理解这个操作，windows的话随便格式化） 需要进入磁盘工具降级： 然后安装就可可以了，剩下就是漫长的等待。 从Intel黑苹果时代走过来的，结果白的还没黑的好用。。。。","link":"/posts/5b6f9bd/"},{"title":"小米4A刷OpenWrt","text":"最近由于 ipad 随航经常卡断，导致体验直线下降，有如下几个怀疑： 小米路由器偷工减料无线功能不行 电脑带不动 升级了 MacOS13 就说咱对于国产的偏见，以及小米路由器频繁抽风挂后台，还有小米的生态做的稀烂，在和客服人员沟通后得到了模棱两可十分不专业的回答之后下定决心把手边的小米 4A 刷成 OpenWrt，毕竟对于爱好者而言，客服就是半路出家的半吊子，毕竟解决不了问题咱就迁走嘛。本身是资深软路由用户，刷机也没啥成本。 刷前提醒 不要偷懒不刷 breed，否则刷崩了就只能救砖 救砖只能用小米自己的软件，毕竟封装的太多了，能用开源就用开源，尽量屏蔽厂家这一层 可以找下国内魔改的 Rom，虽然官方有小米的适配，但是刷完默认 Wi-Fi，还有过几十分钟 5G Wi-Fi 变成公开的问题。 还是建议使用有线刷机，无线的话无法刷入 Breed 官方的地址，看看就好 救砖刷机之前还是很有必要先说下救砖，只能用到小米的官方工具，而且只有 Windows 版本，所有这里需要准备一台 windows 带网口的设备。 MIWIFIRepairTool.x86.zip(980 kB) 用网线把电脑网口和路由器的 Lan 口连在一起，这样在刷机工具中会看到电脑有一张网卡被路由器 DHCP 分配了 IP，192.168.31.X, 此时无法登陆 web 后台。这里建议在打开软件之前先执行这个刷机步骤： 1 断开电源，按住 Rest 键，再接通电源，直到橙灯闪烁再松开2 打开刷机软件，这里回识别一会网卡3 等待路由器恢复，完成之后指示灯会变成蓝色4 然后就可以通过 192.168.31.1 进入后台界面了 这个有个小插曲：我一开始在刷机最后一步断电重启的路由器，试了两三次均不能刷入，论坛上也建议不成功的话多刷几次。没有出现需要降级路由器固件的情况。 解锁 SSH网上提供了一个 Python 脚本来解锁路由器的 telnet 和 SSH，然后会预制一个 Buybox 的环境，其实就是一个 Linux 的工具箱环境，我们可以执行 curl，wget 等命令。telnet 的用户名和密码都是 root。 SSH 会遇到这个错误，所以用 telnet 了： 本地可以用 Python 启动一个文件服务器方便路由器下载文件，用 SCP，FTP 啥的也行 可以用浏览器访问 IP:8000 来访问文件服务器，然后 wget 提取文件链接。 刷入 BreedBreed 更像是 BIOS 一类的东西，每次 Reset 路由器之后，就会进入到 breed 后台，IP 地址是 192.168.1.1，如果进不去后台可以把 IP 改为 C 类 IP 地址的网段，然后就可以进到 Breed 后台来输入 OpenWrt 固件了。 breed-mt7621-pbr-m1.bin.zip(95 kB) 路由器没啥空间了，所以都要放在/tmp 文件夹下，把链接换成自己文件服务器的链接。 进入到临时目录:cd /tmp. 下载”breed”:curl https://breed.hackpascal.net/breed-mt7621-pbr-m1.bin –output firmware.bin 执行命令:mtd -r write /tmp/firmware.bin Bootloader 重启后浏览器进入”Breed Web 恢复控制台”:192.168.1.1 v2.5.29 小米 4A 千兆版 OpenWrt 固件.zip(39.8 MB) Breed 的下载页面：https://breed.hackpascal.net/ 备份分区 我这里先刷的 openwrt-ramips-mt7621-xiaomi_mi-router-4a-gigabit-initramfs-kernel.bin，其实已经可以进入路由器后台使用了，然后刷到 sysupgrade 镜像，其实应该在 OP 后台刷这个 sysupgrade 镜像。 刷入 openwrt刷完之后，路由器会自动重启，此时 telnet 会断开。把 IP 地址改成自动获取，这个时候可以进入到路由器后台了。 设置完无线的用户名密码之后有个很奇怪的问题，WI-FI 一直没有网，但是有线正常，后来在 Network 中删除掉 Wan6 的 DHCP Set 就好了。 参考https://www.right.com.cn/forum/thread-4317222-1-1.htmlhttps://blog.51cto.com/xfxuezhang/5866060","link":"/posts/63a7a8fe/"},{"title":"Cudy TR3000 刷 Openwrt","text":"想了好久，还是有必要把软路由从 All in one 中分离开，基于性价比的原因，看上了这款 Cudy RT3000，相对于 400 价位的 MT3000 而言，内存只有 128M，而且没有风扇，不过也已经足够了。 据说是出口转内销，不过我的这个是纯中文版本。成品长这样，和 MT3000 很像 。 一下是刷了论坛上大分区的版本，如果想刷原版的 Openwrt，可以找客服要。 1. 接入路由器 WIFI 进入后台，地址是 192.168.1.1，这个是原厂固件，几乎没什么用 在这里刷入过渡包 重启之后，连接电脑和路由器 LAN 口，手动配置为静态 IP 地址, 路由器默认 IP 是 192.168.1.1. 然后回出现登录页面，密码为空，直接登录 2. 升级过渡固件 不保留当前配置 然后继续刷写 刷新之后自动跳转到这个页面, 登录进入到 openwrt 页面，密码 password 3. 刷写 uboot 不死后台 网页上传 uboot，打开 ttyd 刷入执行 mtd write /tmp/upload/mt7981_cudy_tr3000-mod-u-boot.fip FIP 电脑依旧更改静态 IP，长按 reset 按键，红灯闪烁即可松手进入 uboot 后台 4. 选择固件进行更新，上传最后的固件之后，点击更新就可以了 这个是刷写之后的效果，可以看到 uboot mod 100 多元的小玩意，拿来做旁路由还可以，刷完之后发热也比原厂低了不少。","link":"/posts/3e1838df/"},{"title":"小米Ax5400双宽带叠加","text":"硬路由宽带叠加作为临时解决方案，目前只有 AX5400 和 AX9000 支持，并且只能是不同的运营商。 高级设置 -&gt; 其他 -&gt; 双 WAN 设置 注意： 1.开启双 WAN 功能后会与部分功能冲突，若仍想使用冲突功能，请先尝试关闭双 WAN 后再试 2.若某些终端设备出现金融类 app 无法正常使用的情况，可尝试在“WAN 口策略”功能中将该设备设置为“WAN1 优先”或“WAN2 优先”后再试 3.请勿将 WAN1 或 WAN2 口与其他 Mesh 组网设备相连 设置完成的结果","link":"/posts/4625bf56/"},{"title":"车机锁 Wi‑Fi 奸商跑路，高楼组 Mesh 极客破局","text":"五一假期的时候家里人打算自驾游，才发现车载地图已经很多年没更新了，找不到要去的地方，于是打算重新弄下，来一个全新的体验。 车载的导航是安卓，虽然已经很久没更新过了。从早些年折腾刷机的经验来看，就算不能连接 wifi，也应该是能够用 USB 转接的。尝试一圈，基本是这个情况，流量卡失效，wifi 功能被禁用掉，USB 转接有线网卡也无法识别。 于是打电话到 4S 店询问是否能够提供些许的支持，他们转到技术，然后告诉只能把车开到他们那里去看，不提供上门的支持。而作为这个年代的资深消费者，已经有千万遍劳心费力的折腾最后被售后三两句打发走的经历。 好说歹说发一张图片过去，尽管对方语气中透着些许的不耐烦。“你这个是赠送的，我们不了解情况，不是我们原厂的东西，而且很多车机是无法升级的”。于是又开始推销了自己的产品，问到是否还会遇到上述情况，还得 case by case 来看。“你这个车已经买了很多年了，早就没有保修了。” 我的需求无外服这三种： 更新高德地图数据，不管是更新版本还是导入离线包。 升级 carplay，需要买一个盒子，还需要做安装 Autokit 硬件检测，最快也要明天到。 刷一个有 wifi 功能的正常版本，让我正常更新数据。（最后也没实现，不过估计新版本更卡） 朋友帮我查了下这个版本的卡槽，需要把整个导航拆下来，不过弄不好还耽误用倒车影像，遂放弃。 在这个论坛：http://www.allmost.org/2019/11/android-head-unit-root-device-model.html 糟糕的高德地图无法联网更新，首先想到的是离线数据包，于是致电400-810-0080，这次都是机器人接听，无法转人工。 然后根据提示给了我这样的一条信息。 1【高德地图】尊敬的高德用户您好，您咨询的地图数据升级问题，操作方法：请您点击链接 https://auto.amap.com/download/map_data#public ，选择对应版本下载即可；同时您可在下载界面点击我不会安装查看说明， 感谢您对高德的关注与支持！ 在年初的时候还针对 Mac 端的高德地图无法更新的问题咨询客服，却被告知没有这样的产品进而“建议”使用网页版。，而我一直是在 App Store 下载的。当时几乎想到距离我两三公里的高德总部去要个说法，而这次的离线数据包更是提示升级中，无法下载。 于是退而求其次，我下载一个最新的机车版是不是会更好一些？安装之前还担心数据丢失问题，于是看到下面这个话就“放心”了。 但是安装之后，之前的离线地图全部消失，甚至很”贴心“的把之前旧数据的磁盘空间都释放了出来。原来马上爆满的磁盘空间，突然瘦身了。但，实时导航，手机同步，问题反馈都共用报错无法联网，这次而且无法回滚。不能上网的车机，不能联网的地图，被清空的旧版数据。第二次想杀到高德总部。 ADB 的奇迹大学同学在嵌入式行业，经验比我丰富些，于是去求助。他告诉我可以尝试通过 ADB 进入调试系统，然后使用命令行拉起来 wifi 的进程 ，看看是否能够改善。 分析之后查看到，车机的版本是 Android6.0，基于 Linux3.18 的内核，连包管理工具也没有，甚至连 top 都会把上位机卡死。于是开始分析思路，能够开启热点说明有 wifi 模块，然后依次排查进程是否启动，驱动是否安装，内核在启动时是否正常加载该驱动。那一刹那，感觉自己从调侃的修电脑，修家电，修水电，最后到了修车侠。 还好支持开发者模式，adb 调试的时候使用了甲壳虫助手，比用 USB 连接安卓 ADB 方便的多，把软件安装在车机上，不用再像以前刷机一样一遍又一遍的执行 adb device -l 查找设备，虽然这个机器慢一点，但是总归还是能够很稳的连接 ABD，然后一遍一遍尝试命令，Google，GPT，Deepseek，一遍又一遍。 机车给了一个 USB 的接口，刚好拿来外接键盘，把 MBP 搬到车里查资料，手机开了热点越来越烫，然后就是一遍的调试，而 MBP 不能通过 adb 扫描到机车，不确定是不是和工厂模式里的设置有关系。这过程有点像刷机，有一点想像服务器上调 Linux。在此之前也想过用 USB 转 J45 连接路由器，就算没有网络的情况下，也应该能够显示一张没有网络连接的以太网卡。试验之后是完美没有，和朋友讨论之后，猜想是和内核驱动在编译的时候没有打包通用驱动或者这张卡驱动导致的。（来自之前 UFS 安装 Linux 的经验）而这个机器上完全无法执行 lsmod 和和 cat /proc/modules，而**dmesg | grep -i &quot;load&quot;**的记录也是空，实在无法想象这个系统是如何加载底层驱动的。 最后思来想去大概是这几个命令生效了，因为后来重启才发现 wifi 模块加载出来了，中间加执行了很多。 12345678910111213141516171819# 在甲壳虫中可以省略adb shell字眼# 1. 直接指定组件启动 wifi（好像是自动进入 WLAN 搜索页面）am start -n com.android.settings/.wifi.WifiSettings# 2. 用系统通用 Intent（推荐）am start -a android.settings.WIFI_SETTINGS# 开启 Wi‑Fiadb shell settings put global wifi_on 1# 立即让系统刷新一次广播（有的 ROM 必须）adb shell am broadcast -a android.intent.action.WIFI_STATE_CHANGED --ez state true验证：adb shell settings get global wifi_on → 返回 1；adb shell dumpsys wifi | grep &quot;Wi-Fi is&quot; → 出现 enabled 回去看到 GPT 的提示，说操作完一定重启，否则配置不会写入 NVRAM。（我之前忽略了这个，走了很多弯路） GPT 这些内容帮助很大，可以用来验证：我的dumpsys wifi 里出现的那一行长这样， 1Wi‑Fi is disabled 它只说明 系统目前把 Wi‑Fi 开关拨到了“关”，并不直接告诉你“有没有 Wi‑Fi 硬件”。要分清楚是“硬件存在但关掉”还是“根本没有硬件/驱动”，可以再看 4 处信号： | 检查点 | 如何查看 | 典型输出 | 结论 || ——————- | ————————————– | ———————– | —————————————————- | ———————————————- | — || 1. Service 列表 | adb shell service list | grep -i wifi | wifi: [android.net.wifi.IWifiManager] | 看到这一行 → Framework 里 有 Wi‑Fi 服务 || 2. 驱动状态 | adb shell getprop wlan.driver.status | ok / ready / unloaded | 有值 → 内核认识 Wi‑Fi 芯片；空值 → 多半缺驱动/被裁掉 || 3. 网络接口 | adb shell ifconfig -a | grep wlan | wlan0 ... | 能看到 wlan0 → 芯片已初始化；完全没有 → 未加载 || 4. 内核模块 | adb shell lsmod \\| grep -E &quot;8188 | rt5370 | wlan&quot; | | | 结果判读 情况 解释 解决办法 Service 有，wlan0 有，driver=ok，但 dumpsys 显示 disabled 硬件存在，只是软件开关关掉 用 UI 开关或adb shell settings put global wifi_on 1再重启 Wi‑Fi Service 有，但 wlan0/驱动都没有 Framework 在，但 内核缺驱动/Factory 里关闭了 Wi‑Fi 先在工厂设置里勾选 WIFI 并保存；如仍无驱动 → 刷带 wifi_bt 的 ROM 或插 USB 网卡 Service 没有（grep 不到 wifi） ROM/MCU 层完全裁掉了 Wi‑Fi 只能刷完整固件或硬改/外接网卡 Service 有，driver=unloaded 驱动文件在，但未成功加载 Factory 里未启用 / 模块版本不匹配 → 勾选保存或换匹配的系统+MCU 快速打开 Wi‑Fi（无 svc 的情况下）1234adb shell settings put global wifi_on 1adb shell am broadcast -a android.intent.action.WIFI_STATE_CHANGED --ez state true# 然后再查看adb shell dumpsys wifi | grep &quot;Wi‑Fi is&quot; 如果改完仍显示 disabled，就说明硬件/驱动层面还没点亮，需要回“工厂设置”勾选 Wi‑Fi 或换带驱动的固件。 一句话：dumpsys wifi 看到 disabled 只是“当前关着”，并不代表“没有 Wi‑Fi”。再看服务列表、驱动状态、wlan0 接口等就能分辨： 都在 → 只是没开； 驱动/接口缺失 → 硬件被关闭或驱动裁掉，需要在工厂设置启用或刷新固件。 我的结果是。无法执行 lsmod，服务正常，驱动正常，而网络接口必须在启动共享热点的时候才能看到，最后在工厂模式的时候手滑点了重启才发现一切正常。 看到这个页面的时候就感觉一切的付出都值得了，所谓念念不忘，必有回想吧。（设置里还是没有 wifi 选项，还得自己从下拉菜单启动） 工厂模式：主要用来开关一些功能，实际在我这个过程中好像没有起到太大的作用，这个主要针对整个 OS 而言，有些版本可能在这里启动 wifi，但是我这个没有，主要还是见识一下车机模式，图一乐。 这些是 GPT 给的，没有真正执行： ADB 直接拉起 123456bash复制编辑adb shell am start -n com.twd.settings/.FactorySetting # FYT/TS10 系常见adb shell am start -n com.android.settings/.DeviceInfoFactory # 某些 XY‑Auto 若提示 Error type 3 仍找不到，说明 ROM 确实删掉了对应 Activity。 Mesh：高层 WIFI 的荣耀家里在高层，即使把车开到楼下也不见能够有多好的信号，也能是根本就搜不到。然后突发奇想，正好之前有一个 交流的移动电源，然后把 Mesh 子路由拿到楼下供电，然后把楼上的路由放在窗户上。这才是有线 Mesh 的正确用法，尽管在高层，还能跑到 10M 以上的速度，然后再用楼下的子路由无线桥接，可以媲美一些无线路由器的速度了。 其实还有一个方案，借助 POE 路由的便携性，把网线从窗户顺下去，然后顺便也解决供电的问题。但是，翻了翻箱子，确实没有这么长的网线，那么就速战速决，将就一下把。 设备如下，方案做好了，摸黑也要实施完。 这过程中的命令和帖子一些安卓 8 以上才可以用的命令，先记录下来，作为折腾的过程。 123456789iwlist wlan0 scanadb shell am broadcast -a android.intent.action.WIFI_STATE_CHANGED --ez state trueadb shell am start -n com.android.settings/.wifi.WifiSettingshttps://blog.csdn.net/BOJUE01/article/details/136684847https://blog.csdn.net/BOJUE01/article/details/136684847https://www.cnblogs.com/linux-37ge/p/11111596.htmlhttps://blog.csdn.net/pwp032984/article/details/126286159http://www.allmost.org/2019/11/android-head-unit-root-device-model.html 以下来自 GPT，也帮了很大的忙下面给你 4 种常用办法，按「年代新 → 旧」排列，只要你的 ROM 里有对应的命令或工具，就能在 PC 端终端 直接看到扫描结果。不用担心全记不住，逐个试，命令不认识就跳下一个。 方法 适用 Android 版本 是否要 root 命令示例 A. cmd wifi 子命令 8.1 (Oreo) 及以上，只要系统内置 cmd ❌ bash\\nadb shell cmd wifi enable # 先确保开 Wi‑Fi\\nadb shell cmd wifi scan # 立即触发一次扫描\\nadb shell cmd wifi list-scan-results # 打印扫描结果（BSSID/SSID/信号）\\n B. dumpsys wifi 解析 4.0+（几乎所有） ❌ ```bash\\nadb shell dumpsys wifi C. wpa_cli 工具链 ROM 里带 wpa_supplicant + wpa_cli ⭕（通常要 root） bash\\nadb shell su -c 'wpa_cli scan'\\nadb shell su -c 'wpa_cli scan_results'\\n D. iw/iwlist 直查射频 内核自带 mac80211/CFG80211，工具在 /system/xbin ⭕ ```bash\\nadb shell su -c ‘iw dev wlan0 scan 步骤拆解（通用） 让 ADB 连上车机 1adb devices # 出现 device 才算连上 确保 Wi‑Fi 已经启用 可用 adb shell cmd wifi enable 或 settings put global wifi_on 1 后再开一次 UI 开关。 查看状态：adb shell dumpsys wifi | grep &quot;Wi‑Fi is&quot; → enabled/disabled。 触发一次扫描 新版用 cmd wifi scan；旧版可发送广播： 1adb shell am broadcast -a android.intent.action.SCAN_RESULTS 查看结果 任选上表 4 种方法里你设备支持的那一行。 若看不到 SSID，只见一堆 &lt;hidden&gt;：说明热点隐藏了 SSID，属正常现象。 命令输出示例（cmd wifi list-scan-results）1234BSSID frequency level SSID60:45:cb:aa:1b:30 2462 -55 HomeWiFi_2G60:45:cb:aa:1b:34 5200 -70 HomeWiFi_5Gb0:d5:9d:cc:31:c0 2412 -65 MiPhoneHotspot 字段含义： 字段 解释 BSSID 无线 AP 的 MAC 地址 frequency 2412 – 2472 MHz = 2.4 GHz；5180 + = 5 GHz level 信号强度，单位 dBm（-30≈ 满格，-80≈ 临界） SSID 热点名称（隐藏网络会显示 &lt;hidden&gt;） 常见坑 &amp; 对策 症状 原因 解决 cmd: not found ROM 删了 toybox / cmd 改用 方法 B、C、D cmd wifi: Unknown command Android 7.1 及以下 用 dumpsys 或 wpa_cli permission denied / su: not found 没 root 选不用 root 的 方法 A 或 B 扫描结果为空 Wi‑Fi 实际没启用、没有天线、驱动缺失 先 settings put global wifi_on 1 并从 UI 打开；或检查硬件/ROM 小贴士 批量重扫：想每 5 秒自动扫一次可用循环： 1while true; do adb shell cmd wifi scan; adb shell cmd wifi list-scan-results | head -n 10; sleep 5; done 只取最强信号： 1adb shell cmd wifi list-scan-results | sed 1d | sort -k3 -n | head 无 Wi‑Fi 硬件时：任何扫描命令都会报错或空结果 —— 确认已在 Factory Setting 勾选 Wi‑Fi、或插上 RTL8188EU/RT5370 USB 网卡后重试。 一句话：连好 ADB → 开 Wi‑Fi → 在 PC 端执行 **cmd wifi scan &amp;&amp; cmd wifi list-scan-results**（Android 8.1+ 最方便）；旧版系统就用 adb shell dumpsys wifi 或 root 下的 wpa_cli scan_results / iw dev wlan0 scan 来列出热点。祝你早日看到满屏 SSID！ dumpsys 是 只读（dump） 的诊断工具——它只能把系统当前状态“倒”出来给你看，完全没有写入/控制能力。所以： dumpsys wifi 只能查看 Wi‑Fi 的开关状态、扫描结果、连接信息等，不能直接把开关从 OFF 变成 ON。 为什么 dumpsys 不能改状态？ 实现方式：dumpsys 调用各系统服务的 dump() 接口，这个接口按约定必须是“无副作用”的纯输出。 权限限制：即使给 dumpsys root 权限，它也只有 READ 能力。 系统设计：修改 Wi‑Fi 状态属于 IWifiManager.setWifiEnabled() 这一类“更改设备行为”的 API，必须走 Binder 或写全局设置值，不能通过 dump。 不用 UI 打开 Wi‑Fi 的正规方法（回顾） 任选其一，具体支持情况取决于你的 ROM / 是否 root 方法 是否 root Android 版本 示例 settings put global wifi_on 1 不要求 4.0+ adb shell settings put global wifi_on 1 service call wifi 13 i32 1 需要 4.1+ adb shell su -c 'service call wifi 13 i32 1' cmd wifi enable 不要求 8.1+ adb shell cmd wifi enable 广播／Intent(部分 ROM 有效) 不要求 4.0+ adb shell am start -a android.settings.WIFI_SETTINGS（拉起设置页后系统会自动打开） svc wifi enable 也是写操作，但你的 ROM 把 svc 精简掉了，所以用不了。 一键脚本（无 root 情况下最通用）123456# 1. 打开 Wi‑Fi（写 settings）adb shell settings put global wifi_on 1adb shell settings put system wifi_on 1# 2. 触发系统刷新（广播）adb shell am broadcast -a android.intent.action.WIFI_STATE_CHANGED --ez state true 大多数 MT3561 Android 6/7 车机用这两行就能把 Wi‑Fi 开关拨到 ON。如果执行后 dumpsys wifi 仍显示 disabled，说明： ROM 在启动脚本里强制关掉 —— 去“工厂设置”里把 WIFI 复选框勾上并保存； 硬件或驱动缺失 —— 需要刷带 Wi‑Fi 的完整 ROM，或外接 RTL8188EU/RT5370 免驱 USB 网卡。 结论 dumpsys wifi 只能看，不能改。 想无 UI 打开 Wi‑Fi：用 settings put …、service call wifi …、cmd wifi enable（≥8.1）等写操作；提前确保 ROM 没把 Wi‑Fi 功能裁掉，或已在“工厂设置”里启用。祝你折腾顺利！ dumpsys wifi 里出现的那一行通常长这样： 1Wi‑Fi is disabled 它只说明 系统目前把 Wi‑Fi 开关拨到了“关”，并不直接告诉你“有没有 Wi‑Fi 硬件”。要分清楚是“硬件存在但关掉”还是“根本没有硬件/驱动”，可以再看 4 处信号： | 检查点 | 如何查看 | 典型输出 | 结论 || ——————- | ————————————– | ———————– | —————————————————- | ———————————————- | — || 1. Service 列表 | adb shell service list | grep -i wifi | wifi: [android.net.wifi.IWifiManager] | 看到这一行 → Framework 里 有 Wi‑Fi 服务 || 2. 驱动状态 | adb shell getprop wlan.driver.status | ok / ready / unloaded | 有值 → 内核认识 Wi‑Fi 芯片；空值 → 多半缺驱动/被裁掉 || 3. 网络接口 | adb shell ifconfig -a | grep wlan | wlan0 ... | 能看到 wlan0 → 芯片已初始化；完全没有 → 未加载 || 4. 内核模块 | adb shell lsmod \\| grep -E &quot;8188 | rt5370 | wlan&quot; | | | 结果判读 情况 解释 解决办法 Service 有，wlan0 有，driver=ok，但 dumpsys 显示 disabled 硬件存在，只是软件开关关掉 用 UI 开关或adb shell settings put global wifi_on 1再重启 Wi‑Fi Service 有，但 wlan0/驱动都没有 Framework 在，但 内核缺驱动/Factory 里关闭了 Wi‑Fi 先在工厂设置里勾选 WIFI 并保存；如仍无驱动 → 刷带 wifi_bt 的 ROM 或插 USB 网卡 Service 没有（grep 不到 wifi） ROM/MCU 层完全裁掉了 Wi‑Fi 只能刷完整固件或硬改/外接网卡 Service 有，driver=unloaded 驱动文件在，但未成功加载 Factory 里未启用 / 模块版本不匹配 → 勾选保存或换匹配的系统+MCU 快速打开 Wi‑Fi（无 svc 的情况下）1234adb shell settings put global wifi_on 1adb shell am broadcast -a android.intent.action.WIFI_STATE_CHANGED --ez state true# 然后再查看adb shell dumpsys wifi | grep &quot;Wi‑Fi is&quot; 如果改完仍显示 disabled，就说明硬件/驱动层面还没点亮，需要回“工厂设置”勾选 Wi‑Fi 或换带驱动的固件。 一句话：dumpsys wifi 看到 disabled 只是“当前关着”，并不代表“没有 Wi‑Fi”。再看服务列表、驱动状态、wlan0 接口等就能分辨： 都在 → 只是没开； 驱动/接口缺失 → 硬件被关闭或驱动裁掉，需要在工厂设置启用或刷新固件。 在 Android 6.0（API 23）＋ Linux 3.x 内核的 MT3561 车机上 下面所有命令都在 PC 端终端 输入（前面带 adb），车机端只需提前打开「USB 调试」。 1 功能概览：Android 6.0 能/不能用什么 功能 Android 6.0 支持情况 备注 cmd wifi … ❌ 没有（8.1 才加入） svc wifi enable/disable ✅ 系统自带 toybox svc但你的 ROM 把 svc 删掉，才会显示 not found settings put global wifi_on ✅ 无 root 也能写 service call wifi … ✅ 需要 root/SU wpa_cli / iwlist / iw 取决于 ROM 是否编译进 /system/xbin 2 无 svc 情况下打开 Wi‑Fi（不需要 root）123456# 打开 Wi‑Fiadb shell settings put global wifi_on 1adb shell settings put system wifi_on 1 # 某些 ROM 还要写 system 表# 立即广播一次状态，让 Framework 赶紧刷新adb shell am broadcast -a android.intent.action.WIFI_STATE_CHANGED --ez state true 校验开关是否生效12adb shell settings get global wifi_on # 应返回 1adb shell dumpsys wifi | grep &quot;Wi‑Fi is&quot; # 应变成 enabled 如果还是 _disabled_，说明 Factory Setting 里仍把 Wi‑Fi 禁掉 或 驱动没加载——请回工厂菜单勾选 WIFI 或插免驱 USB 网卡后再试。 3 有 root 时的“硬开”——直接调 Binder12345# 查询 wifi 服务是否存在adb shell service list | grep -i wifi# 调用 setWifiEnabled(true)adb shell su -c 'service call wifi 13 i32 1' # 13 是 Android 6.* 通常的事务码 返回 result=0x1 表示成功；0x0 表示失败（多半被 Factory 关闭或驱动缺失）。 4 在 Android 6.0 上扫描 Wi‑Fi 热点 方法 是否 root 命令 settings + dumplog（最稳） ❌ ```bash\\nadb shell dumpsys wifi wpa_cli（ROM 带 wpa_supplicant） ⭕ bash\\nadb shell su -c 'wpa_cli scan'\\nadb shell su -c 'wpa_cli scan_results'\\n iwlist（busybox） ⭕ ```bash\\nadb shell su -c ‘busybox iwlist wlan0 scanning 5 驱动检查——确认 8188EU/RT5370 是否加载123adb shell lsmod | grep -E &quot;8188|rt5370|wlan&quot;adb shell getprop wlan.driver.statusadb shell ifconfig -a | grep wlan 结果 说明 后续 能看到 8188eu / rt5370sta 等模块 驱动已插 只需把 Wi‑Fi 开关打开即可 没有任何模块 / getprop 为空 内核缺驱动 or Factory 关闭 1) Factory 勾选 WIFI 保存 2) 刷带 wifi_bt 的 ROM3) 外接免驱 USB 网卡 6 Factory Setting 触摸不到 Wi‑Fi 条目的两大原因 MCU/System 不匹配 → 刷同型号、带 wifi_bt 标记的 全量包 硬件本身无 Wi‑Fi 芯片 → 外接 RTL8188EU / RT5370 USB 网卡（Android 6 内核 3.x 自带驱动） 一句话总结在 Android 6.0 + Linux 3.x 的 evb3561sv 车机里： svc 被删时，用 settings put global wifi_on 1 + 状态广播 就能无界面开 Wi‑Fi； 若有 root，也可 service call wifi 13 i32 1 直接写 Binder； dumpsys wifi 看到 disabled 只是开关关着，不代表硬件不存在——再看 service list、lsmod、wlan0 就能判断； 真缺驱动或 Factory 关闭时，要么在隐藏菜单勾选 WIFI，要么刷带 Wi‑Fi 驱动的完整固件，或者插 RTL8188EU/RT5370 免驱 USB 网卡。祝你早点连上网！ shell: svc wifi enable 这条命令只是 Android 自带的小工具封装；你那台 evb3561sv 的 ROM 把 toybox/toolbox 精简了，直接把 svc 可执行文件删掉，所以才提示 _not found_。没关系，核心功能还在——我们可以绕过 svc，改用 系统设置 / Binder 服务 / cmd 三种办法来“硬切” Wi‑Fi。先按难度从低到高排一下，你照顺序尝试即可。 0 先确认两件事 检查 命令 (PC 端执行) 说明 车机是否连上 ADB adb devices 看到 device 才算连通；若是 unauthorized，去车机点“始终允许”。 ROM 里有没有 cmd/settings/service adb shell which cmd; which settings; which service 至少会有 settings 和 **service**；有哪个就用哪个。 1 用 settings 写系统值（多数无 root 机器可用）12345678910# 开启 Wi‑Fiadb shell settings put global wifi_on 1adb shell settings put system wifi_on 1# 立即让系统刷新一次广播（有的 ROM 必须）adb shell am broadcast -a android.intent.action.WIFI_STATE_CHANGED --ez state true# 可选：重启 Wi‑Fi 子系统（有 sh 脚本时）adb shell stop wifiadb shell start wifi 验证：adb shell settings get global wifi_on → 返回 1；adb shell dumpsys wifi | grep &quot;Wi-Fi is&quot; → 出现 enabled。 如果重启车机后又变回 0，说明 ROM 在启动脚本里把 Wi‑Fi 强行关掉——请继续看下一招。 2 用 service call wifi 直接打 Binder（需 root，但最稳） 先确认系统里有 wifi 服务： 12adb shell service list | grep -i wifi# 正常会看到 &quot;wifi: [android.net.wifi.IWifiManager]&quot; 之类 调用 setWifiEnabled(true)（在 Android 5/6 上通常是 事务码 13；如果无效换 6、8 试）： 12adb shell su -c 'service call wifi 13 i32 1' # 开adb shell su -c 'service call wifi 13 i32 0' # 关 若提示 su: not found 就表示没 root；跳过这个方案或先刷 Magisk。 3 用 cmd wifi（Android 8.1‑O 以后才有）12adb shell cmd wifi enableadb shell cmd wifi disable 在 MT3561 Android 8.1（Oreo）第三方 ROM 上测试可行；如果返回 Unknown command 就说明版本还在 7.1 以下，没有 cmd wifi 子命令。 4 如果上述全部无效 → 八成是 ROM 层面禁用 / 缺硬件 再回 Factory Setting 密码 3368 / 8888 → 勾选 WIFI → Save → 重启。 没有该项 = ROM 完全裁掉了 Wi‑Fi。 查驱动 12adb shell lsmod | grep -E '8188|rt5370|wlan'adb shell dmesg | grep -i wlan 空白 = 说明内核没加载任何 Wi‑Fi 模块。 解决思路 路线 说明 刷带 wifi_bt 字样的 完整 ROM + MCU 与主板编码 evb3561sv_w_65_m0 对应的版本，一键恢复 Wi‑Fi。 外接 RTL8188EU / RT5370 USB 网卡 车机对这两款芯片免驱，插上后重启即可在「网络与互联网」里出现 Wi‑Fi。 临时上网 手机 USB 共享网络 (Tethering) → 车机当“有线客户端”，不依赖 Wi‑Fi 射频。 常见报错对照 报错 / 现象 判断 处理 svc: not found ROM 精简掉 toybox → 用 settings / service 方案 见步骤 1/2 settings: not found 工具也被删 装一个 busybox 或 toybox APK，或直接跳到 service call wifi service call wifi … result=0x0 且 Wi‑Fi 仍 off Binder 调用了，但返回 false 多半 “Factory” 里没勾选 Wi‑Fi 或硬件缺失 service list 根本没 wifi 内核 / Framework 把整个 Wi‑Fi Manager 移除了 只能刷新 ROM 或外接 USB 网卡 一句话总结 你的 ROM 砍掉了 svc 可执行文件，所以 svc wifi enable 无法用；先尝试 **settings put global wifi_on 1**，再不行就（有 root 时）用 **service call wifi 13 i32 1**。若系统连 wifi 服务都不存在，就说明 Wi‑Fi 在 Factory Setting 被禁用或 ROM/硬件干脆没装，最终只能刷含驱动的完整固件或外接免驱 USB 网卡。祝折腾顺利！ 下面给你一份最通用、从零到一的操作清单，帮你重新进入 evb3561sv 车机的「工厂设置（Factory Setting）」隐藏菜单，并把 Wi‑Fi 模块启/停用。整套流程 3‑5 分钟，风险低，只要别在保存‑重启时断电即可。 步骤 详细做法 补充说明 1 回到主界面 点实体 🏠 键或手势返回，退出你现在的「运行命令」App，回到桌面。 2 打开系统设置 桌面找灰色齿轮 → 设置（Settings/设置中心/Car Setting）。如果桌面上没有，可在所有 App 列表里找“设置”或“车机设置”。 3 定位“工厂设置”入口 不同 ROM 位置略有差异，常见三种：① 系统 → 关于设备 → 工厂设置② Car Setting → 版本信息 页面右上角小齿轮/🔧③ 直接在主设置页底部看到 Factory/“工厂” 按钮 还有少数机型需要在顶部状态栏下拉，长按 ⚙️ 5 秒弹出“工厂模式”，可先试前两种常见路径再换招。 4 输入密码 出现数字键盘后依次试：• 8888（XY‑Auto 机型）• 3368（FYT 机型，多数 evb3561sv 属此族）• 3711、0000、123456 等备选 正确密码会立刻进入隐藏菜单；错了则原样返回，继续换密码即可。(XDA Forums, FCC Report) 5 勾选/取消 Wi‑Fi 进入后通常会看到 General / Feature / Hardware 等标签：• 找到 WIFI / WLAN / WIFI&amp;BT 这一项• 启用 → 打勾；停用 → 取消勾选• 若有 BT 选项，可一并视需要勾选 字段名可能稍有区别，但一定带 “WIFI” 字样；看不到这一行多半是刷错 MCU 或 ROM 被阉割。 6 保存并重启 点页面底部 Save / Apply / OK；系统提示 Reboot now? 选 Yes，或手动重启一次电源。 期间千万别断 12 V 电源（ACC + B+)。 7 验证生效 重启后进 设置 → 网络与互联网：• 若出现 Wi‑Fi 开关并能扫描热点，说明启用成功；• 若仍无开关，则回隐藏菜单检查是否勾选保存成功，或确认硬件/驱动。 想进一步排错：adb shell getprop wlan.driver.status 应返回 ok/ready；空值说明驱动仍未加载。 如果根本找不到“工厂设置”按钮怎么办？ 用 Activity Launcher 类工具 在 APK 市场搜索并安装 “Activity Launcher” 或 “QuickShortcutMaker”； 打开后搜索 factory / settings.FactorySetting / com.twd.factorysetting，点进去也能弹出隐藏菜单。 ADB 直接拉起 12adb shell am start -n com.twd.settings/.FactorySetting # FYT/TS10 系常见adb shell am start -n com.android.settings/.DeviceInfoFactory # 某些 XY‑Auto 若提示 Error type 3 仍找不到，说明 ROM 确实删掉了对应 Activity。 常见疑问速答 疑问 解答 密码都试完仍进不去？ 可能设备品牌归属不同，联系卖家确认密码；或在 Activity Launcher 搜索 factory 直接拉 Activity。 选项勾了保存却自动跳回未勾？ MCU 与系统包不匹配 → 刷与主板版本一致、带 wifi_bt 标识的完整 ROM + MCU。 Wi‑Fi 列表能扫，但想让车机开热点？ 默认无线芯片可能只支持 STA；需外接支持 AP 模式的 USB Wi‑Fi (RTL8188EU/RT5370) 或刷支持 hostapd 的内核。 关键提醒 操作完一定重启，否则配置不会写入 NVRAM。 切记保持 稳定供电，避免在行车或电池电压忽高忽低时操作。 建议首次进入隐藏菜单先点 Backup 或 Export Config 备份一份原始配置，方便误操作后恢复。 一句话：回桌面 → 打开「设置」→ 找到「工厂设置」→ 输入 8888／3368 等密码 → 在隐藏菜单勾选 WIFI → 保存并重启；若连入口都找不到，就用 Activity Launcher 或 ADB 命令直拉工厂设置界面，再按同样步骤操作。祝你成功点亮 Wi‑Fi！","link":"/posts/fc9b2cf2/"},{"title":"Markdown 完全指南","text":"Markdown 是一种轻量级的标记语言，广泛应用于编写文档、博客、README 文件等。由于其简单的语法和良好的可读性，Markdown 已成为技术人员和写作者常用的文档撰写工具之一。本教程将介绍 Markdown 的常用语法、进阶用法及各种扩展功能，帮助你快速掌握这项技能。 1. 标题Markdown 使用 # 符号表示标题，# 的数量决定标题的级别，从一级标题到六级标题不等。 1234567891011# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 2. 段落与换行直接输入文字即为段落，段落之间需要空行隔开。行内换行需要在行尾加两个空格。 1234这是第一段。这是第二段。这是同一段中的新行。 3. 强调Markdown 支持文本加粗、斜体及同时加粗斜体。 123_斜体_**加粗****_加粗并斜体_** 效果： 斜体加粗*加粗并斜体* 4. 引用使用 &gt; 符号可以创建引用块，并且可以嵌套。 123&gt; 这是一个引用。&gt;&gt; &gt; 这是嵌套引用。 5. 列表无序列表无序列表使用 -、+ 或 * 作为列表标记。 123- 项目一- 项目二 - 子项目 效果： 项目一 项目二 子项目 有序列表有序列表使用数字加 . 来表示。 1231. 项目一2. 项目二 1. 子项目 效果： 项目一 项目二 子项目 6. 链接与图片使用 [文本](URL &quot;文本&quot;) 语法创建超链接，使用 ![图片描述](图片地址) 插入图片。 12[Google](https://www.google.com &quot;Google&quot;)![Markdown Logo](https://markdown-here.com/img/icon256.png) 7. 代码块行内代码使用反引号 ````，多行代码使用三个反引号包围，并且可以指定代码语言以启用语法高亮。 12def hello_world(): print(&quot;Hello, World!&quot;) 8. 表格使用 | 和 - 创建表格，并通过 : 控制对齐方式。 1234| 名字 | 年龄 | 性别 || :--- | :--: | ---: || 张三 | 25 | 男 || 李四 | 30 | 女 | 效果： 名字 年龄 性别 张三 25 男 李四 30 女 9. 水平分割线使用 ---、*** 或 ___ 创建分割线。 1--- 效果： 10. 转义字符使用反斜杠 \\ 来转义 Markdown 特殊符号。 1\\*这是不被解析的星号\\* 效果： 这是不被解析的星号 11. 注脚Markdown 支持注脚功能，通过 [^注脚] 来实现，注脚内容放在文档底部。 123这是一个带注脚的例子[^1]。[^1]: 这是注脚的内容。 效果： 这是一个带注脚的例子^1。 12. 任务列表Markdown 中可以创建任务列表，常用于跟踪任务状态。 12- [ ] 未完成任务- [x] 已完成任务 13. 内部链接（锚点链接）可以通过 # 创建文档内部的跳转链接，常用于创建目录或快速导航。 1[跳转到高级用法](#高阶用法 &quot;跳转到高级用法&quot;) 14. LaTeX 公式Markdown 支持 LaTeX 数学公式，可以通过 $ 或 $$ 来包围公式内容。 1234567这是行内公式：$E=mc^2$这是块级公式：$$\\sum_{i=1}^n a_i^2$$ 效果： 这是行内公式： 这是块级公式： $$\\sum_{i=1}^n a_i^2$$ 15. Mermaid 流程图借助 Mermaid，可以在 Markdown 中创建流程图或时序图等可视化内容。 12345/Users/xu/Library/Containers/com.tencent.xinWeChat/Data/Documents/xwechat_files/wxid_neghhff72jo721_cb5c/temp/InputTemp/b699a258-8d44-4dbb-8c7c-ea70f37fa743.png&lt;pre class=&quot;mermaid&quot;&gt;graph TD; A--&gt;B; A--&gt;C; B--&gt;D; C--&gt;D;&lt;/pre&gt; 16. 折叠内容使用 &lt;details&gt; 和 &lt;summary&gt; 标签来实现可折叠的内容。 1234&lt;details&gt; &lt;summary&gt;点击展开&lt;/summary&gt; 这是隐藏的内容。&lt;/details&gt; 效果： 点击展开 这是隐藏的内容。 结语Markdown 的简洁、灵活和易读性，使其成为撰写文档的首选工具。通过本教程，你不仅能掌握 Markdown 的基本语法，还能利用其高级功能扩展文档的可读性和功能性。无论是编写博客、项目文档，还是生成结构复杂的技术手册，Markdown 都能够帮助你轻松完成任务。希望本教程对你有所帮助，助你在文档编写中更高效地应用 Markdown。 import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs'; mermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}});","link":"/posts/84c20813/"},{"title":"Typora 和Obsidian 自动使用 Github 做在线图床","text":"从前写 Markdown 使用使用相对路径，后来上了 Vuepres/Hexo 之后图床迁移一直有问题，最后采用了在线图床的办法，虽然在国内访问 Github 并不完美，但是毕竟都是都是一些折腾的记忆，如果放在不一直续费的公有云或者一些免费的小厂商，倘若有一天数据丢失那也是一个伤心的事情。 设置 Github先新建 Github 的图床目标仓库： 然后设置 Token 打开 Github –&gt; 点击头像 –&gt; Settings –&gt; Developer settings –&gt; 点击 Personal access tokens –&gt; 点击 Tokens(classic) –&gt; 选择 Generate new token –&gt; 填写 Note(token 名称)\\选择过期时间\\选择 token 权限 –&gt; 点击 Generate token 保存 token 下载 Picgo这个用来做上传图片的 Agent，实际上 Typora 和 Obsidian 都是调用了 PicGo 的 API 安装时候可能需要这个问题： 因为 PicGo 没有签名，所以会被 macOS 的安全检查所拦下。 安装后打开遇到「文件已损坏」的情况，请按如下方式操作：信任开发者，会要求输入密码: 1sudo spctl --master-disable 然后放行 PicGo : 1xattr -cr /Applications/PicGo.app 然后就能正常打开。https://github.com/Molunerfinn/PicGo/blob/dev/FAQ.md 填入仓库信息和 token： 设置 Typora 和 Obsidian在 Typora 中设置上传图片时候调用 Picgo。 Obsidian 需要安装插件，先关闭安装模式： 安装 Image upload 插件： 效果展示Github 上可以看到 commit 记录： Obsidian 也能正常渲染： 微信排版工具也能正常渲染 Github Raw 链接：https://doocs.github.io/md/","link":"/posts/1fc7f9f5/"},{"title":"多平台日程同步","text":"本来是 apple 全家桶，无奈 AWS 上的 MacOS 没办法用，于是在 windows 端使用 outlook 对 apple 的日历进行接入。 首先在 apple 日历部分添加 outlook 账户，这样就可以配置完 apple 日历和 outlook 的双向同步，在 MacOS/IOS 上安装 outlook 客户端，然后 windows 只需要使用默认的邮件客户端即可。 graph LR i(ics文件) --导入--> ia(iPhone apple 日历) ic[icloud] ma(Mac apple日历) ia io(Iphone outlook) os[outlook server] mo(Mac outlook) os wo(windows outlok) ia is(iphone sorted3) is ic ms(Mac sorted3) ms ma 从下图可以看到日历分为 outlook 和 icloud 的部分，我们把后续的日程添加到 Outlook 部分就好。另外注意的是，outlook 的默认日历就叫做“日历”，不能修改名字也不能删除。 同时我也在 apple 上安装了 sorted3，只有日程会被上边的流程同步，任务只能用软件自带的 icloud 同步（apple 设备），这样就满足了在 window 和 apple 随时查看和编辑的功能了，sorted3 中也可以选择需要同步的日历。 对于批量的日程，那么需要用到 ICS 文件，实测 iphone 的微信不能唤起 apple 的日历，所以采取了发邮件的办法，这里用到的是 apple 的邮件客户端，倒入 outlook 会有些许同步的问题，就不再继续研究了。手机的 Apple 日历倒入之后，全平台很快就可以进行同步了。 这样无论是 apple 日历，outlook 还是 sorted3，只要一个软件添加日程，剩下的平台都会同步。 import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs'; mermaid.initialize({startOnLoad: true, flowchart: {curve: 'linear'}});","link":"/posts/450f2bc0/"},{"title":"记录mokee刷机","text":"How does flash mokee as Android System?如果你的系统是稳定版的话，可能需要先降级回到开发版 0. unlock and image zip downloadYou can use SD card or OTG USB as your image zip storage. mokee MK-${version}.zip (system zip) Magisk-v21.0.zip (ROOT solution &amp; Universal Systemless Interface provided by John Wu) open_gapps (GSM services) 1. twrpfind your android device1adb device reboot into fastboot1adb reboot bootloader flash twrp into fastboot1fastboot flash recovery twrp.img after flash twrp rec 1fastboot reboot 2. use image to flash device1fastboot flash recovery twrp-x.x.x-x-x.img 2023 年 mokee 已经停更了","link":"/posts/a8322290/"},{"title":"网络维修记录","text":"房屋选择 加了宽带师傅 B 微信，几天没有结果，经得知属于联通网络，遂工信部投诉，第二天联通打电话，告知他们 IP.cn 和 speedest 都显示是联通的 IP。联通师傅 A 一直在重复不是联通的网，然后安利办理宽带。询问是不是有二级运营商或者其他方式走联通的主线缆，师傅 A 还是在重复不是联通的网，而且谈话提到师傅 B 又还是岔开话题显然知道里面的猫腻，又开始重复不是联通的网让再办一条。无奈只能赶他出去了。 接线的也是人才，一根 8 芯的线硬生生给拆成了 4 根接 WAN，4 根接 LAN，网线的一头同时接 WAN 口和 LAN 口。 交叉测试 客厅原网线 + 原路由器 = 80M 客厅新网线 + openwrt = 200M+ 客厅新网线 + 原路由器 = 80M 左右（可以说明是百兆路由器 成果从 4-80M 不等实现了全屋 200M 宽带覆盖，DHCP 看到连接成功。 traceroute 结果如下，上边还是有个交换机，好像还是给包了一层，中间商做的 PPPoe。","link":"/posts/da62ad7a/"},{"title":"酒店机场免费WIFI不弹认证？用这个方法","text":"现在免费的 Wi-FI 还可以放心用,只是需要填写认证信息,一般来说连接 WI-FI 时候会自动弹窗提示输入手机号,不过笔者遇到几次不弹窗又无法上网的尴尬情况: 解决方式如下,在浏览器输入如下网址: t.cn: 实测桔子酒店和重庆机场都能用 1.1.1.1:iphone 在重庆机场也能用 captive.apple.com:适用于 Apple 设备 上次在武汉机场也有提示, www.whairport.com","link":"/posts/c39ca3b5/"},{"title":"雷电4传输","text":"市面上的对拷线总是没有称心如意的,做的最好的应该是绿联, 于是在 ChatGPT 上询问了相关事宜,大概意思就是一个把雷电设备虚拟成一张网卡,然后设置一个单独的网络通道,两台机器使用 IP 地址进行通讯,知乎上也有成功的雷电 3 案例,只是他们 WebDav 的速度是 600MB/S 而我的是雷电 4 也是这个结果,只是在 NUC12 识别时候总是不能满速识别. 咨询客服之后也没有得到满意的结果,不久前 intel 吧 nuc 业务线给华硕了,结果售后只是给排查方向,看 BIOS 有没有打开雷电开关之类的,或者就是等待十天半个月的返厂检测. webdav: window 下显示 20G 的虚拟网卡,在 linux 下也是如此 设备管理器显示 USB4 而不是雷电 4 直连 MBP 两个雷电口: popos 和 MBP 使用 iperf3 对打: MacOS: 雷电 4 的线+40G 硬盘盒 40G 硬盘盒原装测速 win 测速","link":"/posts/6cc0c7dd/"},{"title":"北京租房心得","text":"房屋选择 刚毕业租房是 40 平米的公寓，实际也有 30 平，租金是全部的实习工资。学校蜗居够了，不想再委屈自己。来北京就只能合租了，一般中介都会虚标房间大小和朝向，还是得实际去看房。看房子的话，心理先有个预期，如果没有心仪的房子怎么样。如果是地下室或者一楼性价比再高也不要去看了，尽量租新一点和治安好的房子，北京老破小太多了。看了没相中只会浪费时间。职场人首先要活的体面一点。 不要觉得房子只是一个睡觉的地方，起码的生活设施要有：稳定的水电网，燃气和隔音(手机有很多 app 可以测试分贝，大于 60 的房子就不要选择了)。而且疫情影响居家办公已经是家常便饭了。贵点不怕，总之还是要让自己觉得舒服。 朝向： 南&gt;东&gt;西&gt;北 如果不是实在差钱的话，还是建议住在公司附近或者通勤方便的地方，很多人说单程一个半到两个小时。五环以外都是村里了，基础设施和人文设施和市里完全没有办法比，为了省心的话，还是住在繁华地带，毕竟一边工作也要一边生活，不然去市里总有村里孩子进城的感觉。二来北京可以玩的地方很多，地铁站附近去市中心也就半个小时。通勤要算往返时间，尽量减少换乘的等车时间，单程半个小时往返就是一个小时。能坐地铁不要坐公交，人多很挤，乘务员人工报站，还要维持车内秩序，没有降噪耳机的天花板建议慎选公交通勤，无听之于耳很难，很消耗精力。就算下班晚，23 点左右公交都没有座位。另外北京有共享单车，可以选择单车+地铁混合交通，单车会员每个月 15 左右。 不建议极端天气去看房，会漏调一些点。一定找不要临街的房子，五环以为打车没有管制，窗外 24H 大车通行。 租房好物第一条，选择搬家好搬且轻量的东西，买之前想好搬家怎么处理。然后才是其他，同城搬家可以无视，因为有某拉拉这些，百元以内师傅给搬(非广告，遇到的师傅可以，但是 app 做的很差，客服跟僵尸一样)。毕竟北京房租高，自己买点小玩意跟房租比根本微不足道，就任性的买买买吧，毕竟以后结婚了就不一定有机会了。(最近看中了一套设备 10W+， NUC12 飞龙峡谷和 M1 Ultra 双机双显示器，apple 官网推荐的屏幕) 工作效率物品（电脑和显示器台灯）现在基本都离不开电脑，有大桌子的买大显示器，否则就 15.6 便携屏（typec 一线通），还能带去图书馆。建议双屏或者带鱼屏，幸福指数提升很高，MacOS 用户可以用 slide bar，win 用户用 duet 都可以把 ipad 当作拓展屏。建议显示器预算 2000 左右，分辨率 4K@60HZ。现在轻薄本也性能炸裂了，没必要买大机箱，台式机的话 Macmini 和 NUC，APU 都是不错的选择。 关于机械键盘，如果你的房租隔音好，放心用青轴和茶轴，万一被听见，还能给人留下半夜认真写代码的印象。 嗯，夜深人静的时候一定要选一个暖黄色的灯光，会觉得柔和放松。 还有，多备用几个插排，自己备个路由器，防止别人在公用路由看见你的设备和智能家居。 生活用品大型洗衣机（4L 左右）：自从在学校看见有人用公共洗衣机洗鞋，再也不用这玩意了。某鱼，某宝，某东 500 以下能买到很好的。（个人觉得别人买的洗衣机最多值 200） 内衣洗衣机： 懒癌晚期，不想手洗，还有内衣洗衣液。 洗鞋机： 因人而已。 便携式烘干机： 如果不是朝南建议入手一个。 消毒酒精：家中常备，可以买个自动喷酒精的机器 降噪耳机： 2000 左右买个降噪耳机绝对值得，就当投资自己吧，开降噪听着音乐假装进入元宇宙。 厨具：单身贵族不推荐了，能清水煮就行了。毕竟打折券很多，北京很多美食羊毛可以薅。豆浆机是个 bug，大的豆浆机一个人喝不完，小的费半天劲就一杯还得浪费时间清洗。 灯具：自己可以换个好的搬家拆下带走，如果中介免费给换就更好了。 窗帘： 自己可以换个好的搬家拆下带走，没必要买自动电机。 拖布和苕帚：自己屋里备一个吧。 垃圾桶和垃圾袋： 不多说。 床上小桌子：不知道为啥不给上床下桌，床上是真舒服。 即热饮吧： 3S 出热水，适合早起时间紧张的职场人 公交卡：手机 NFC 不得不面对的人室友你的预算够了，遇到素质高的室友概率也会大大提高。当然能租开间最好，群租大家回家都是各回各屋，交流极少。 出于公共资源利用效率考虑，还是建议和室友们错开起床和睡觉时间，判断一副眼镜舒服的标准是你感觉不到它的存在。好室友的标准也是也感觉不到他的存在（eg：你上班了，他还未起，你睡觉了，他还没下班回来） 有些女室友通常不化妆不见人，所以女室友洗衣服做饭的时候就委屈一下错开空间吧。 中介一定要找个靠谱的中介，你第六感有一丝丝不舒服就不要租了（比如看起来就不厚道的人），因为不知道以后还有什么狗血的事发生，进入的社会才发现，很多的人不要脸的没有底线，无底洞。高素质的人没必要惹这个气受。如果你觉得中介不给办事但是自己可以解决的话，还是建议不要浪费这个时间，北漂人时间很宝贵，不管你是 996 还是 965。 比较靠谱的: 链家 我爱我家 暖房小程序 豆瓣租房 小红书好像也行 自如（但是房东租客两头吃，但是大家都图省心忍气了） 据说假房源很多，低价吸引的： 安居客 58 哪个中介都会有一些负面信息，房东直租也有坑，记得用法律手段保护自己，50 块开个民事诉讼之类的。 慎选小中介！！！！！！不要先交定金 （如何投诉黑中介，待补充） 房东如果是和房东手里租，查好房产证和房东身份证，留作证据。 从中介手里租的话，随便怼房东吧。（不清楚房东和中介的 py 交易是怎么样的） 不要怕麻烦别人公共区域基本都是先来先占用，不需要过于考虑其他人感受，毕竟大家都可以放东西，别太乱到过分就行。毕竟花钱租了房子，说话硬气点。记得查好水电价格。 每个人的忍耐程度不同，不要人云亦云，说你事多的直接怼回去，毕竟都是试探对方底限。别委屈自己迁就别人。 最后关于 GTD跟你说 GTD 没用的都是没做好的，靠脑子真是记不住，冥想+GTD+复盘，形成规律，别在决策上浪费时间。 北漂人很忙，但是不要慌张。","link":"/posts/cdd2a06/"},{"title":"悠乐汇看雪","text":"才吃过燃面，过午时又得出去觅食。 门前的松树又多新雪，一夜之间多了些许北国的味道，鹅毛大雪飘散着，伸出手凉凉的就化了。 北京的冬天很温和，对于东北人来说像深秋，静静的飘雪中撑一把轻伞，就能轻松制造韩剧男女主角的邂逅，北京的人是不是没体会过风刀霜剑？这的雪是留不住的，在气温回暖以及汽车尾气的破坏中，渐渐的融化成水，再蒸发成空气。不喜欢雪的人，是觉得雪堆融化之后道路泥泞，车辆难行，甚至气温来一个急转弯，把这雪水变成冰沙，甚至再光滑一些，这总会影响行人的匆匆。 每一片飘落的雪花，好似这芸芸众生，降生，飘零，陨落以及消亡。一片一片的雪花组成了洁白的雪地，雪地上留下了行人的脚印，有三两好友在讨论，有奔波的快递员外卖骑手，窗下还有小孩子在玩雪，老人在哄孩子，小男孩在团雪球，小女孩在一边看着，穿过街道，已经是光洁的柏油马路，这是雪冢。 无人的雪，踏上有吱吱的声音，光洁的雪总是能给人遐想，好似可以根据心思任意雕琢，又或者因为不是最佳路径从而无人踏足，而不远的一旁布满了行人的脚印，我却刻意绕开。夏日的大排档被闲置在这里，棚子上积满了厚厚的雪，伸出手来攒个小雪球，等着越滚越大。 等待手机升级的功夫，顶了一头的芦花。","link":"/posts/1fcc0fa5/"},{"title":"从望京吃到酒仙桥","text":"作为吃了小半个北京的人，基本上可以看到足迹留在望京和酒仙桥这里两个板块，先说一说踩的雷，不喜欢密云的鱼，分店的方砖厂，前门乱七八糟的餐馆还有簋街的小作坊，还有同样的连锁，合生汇里的品质都要和毕淘买相差甚远。 这边都是写字楼，所以工作日会针对上班的人有优惠，一般不包括周五，因为要放假了大家都 high 起来了，人多的没有位置。 郭靖烤全羊 58 抵 100（原来 38） 阿壹牛杂（美团单人餐 18 送饮料） 一井烧肉（25 单人餐，菜品半价） 掌上生活 100 减 50（羲和雅苑，烧肉 Like，小厨娘淮扬菜，上清水产，九割炸猪排，北李妈妈菜等） 阿诚市井潮汕菜（39.8 双人粥，俩小菜，打卡送豆花） 将太无二（39.9 鸡肉锅） 芦花椒麻鸡（晚间 50 抵 100，芦花脆脆茄） 刘胖妹面庄（晚间 19.9 抵 40，重庆胖妹的弟子点，跟北京胖妹没有关系，北京胖妹从来不打折） 聚点串吧 11.2 元包浆豆腐 多乐之日 5 元俩蛋挞 滋啦小路子烧烤（19.9 抵 50，不咋好吃） 隐市香·川菜·烧烤小馆（19.9 抵 50，还有午间单人餐） 中 8 楼（18.4 元黑三剁） 金掌勺锅包肉 39.9 元 煲仔皇充 528 送双倍 怒火八零市井火锅。88.8 元 赣南人家 98 双人餐（三个人也行） 功夫潮牛 138 双人餐（原来 128） 释面（9.9 素面，15.9 牛肉面，量小不推荐） ~~小湘界 98 2-3 人餐（量很小，很辣，最好两个人去吃） 管氏串吧 9.9 主食 京院涮肉 98，现在已经 158 不推荐 楠火锅 9.9 抵 100(感觉差评很多) 霸气大叔 39 抵 100 胖子龙虾（毛肚锅很不错） 米湘 九将烧肉（38 单人餐） 黄海渔村（鲅鱼水饺，很一般不好吃 蒸汽小镇（水饺 芝湖参鸡汤 松鹤楼小龙虾拌面 十八汆（砂锅秒杀很实惠 老乡鸡 9 块 9 六丁火烤肉 99 拼盘 霸碗盖饭（首开 重庆秘宗火锅 凯德 mall 椰子鸡火锅 丸福日式烤肉 望花路燃面(望京燃面天花板，很容易饿) 牛锣鼓火锅 1819 烧烤（其实还不错 荣焱 维京乐章三文鱼（意面双人餐） 小两口淄博烧烤 可以看到从望京一路吃到酒仙桥～ PS 北京吃的汇总：","link":"/posts/512ddea4/"},{"title":"2022年6月2日 北京医院拒诊（中日友好医院）","text":"凌晨 5 点 50.大概是被疼醒，流了一夜的血，床单被罩都是血，昨晚处理伤口到 1 点半，伤口有些深，于是跟领导请好假，和同事交接好今天手头的活，于是开始在各个医院打电话。 太早了没几个电话能打通，无奈只能 120 你要救护车吗，我们只管派救护车。高德上电话基本打不通，114 很不耐烦的说已经查了三个电话了，直接转了机器报号。附近药店只卖药不处理伤口。打了一个多小时电话，终于有个电话能打通了。这几天没出小区就没做核算，也防止交叉感染。中日友好医院，给了三个方案：1. 120 直接能进，显然我神志清醒，不用这个 2. 去发热门诊，等着核酸结果，核酸结果出来不能走 3. 等核酸结果出来再看病，估计我也快失血过多了，要是昏倒在路边估计也没人搭理。没办法，硬着头皮打车去医院，于是挂号，门诊发了 N95，说我万一是阳性这就得关门了，没办法只能说拿人头担保。 发热门诊要求了核算和流感抗原，好说好商量下，门诊某大夫说已经通知外科大夫过来了，等了好久，外科那边只有一个大夫，说病人多，有空过来，于是问多久能过来，有没有给个时间什么的，回答是没有，体制里的托词，懂得都懂，看来要把我一直晒这了，没办法只能继续磨门诊大夫，反正门诊这人也不多。过了半个多小时，某大夫给写个了条，告诉我直接过去门诊外科就行。一瘸一拐找了半天路，敲开外科大夫的门，礼貌说着刚才的情况，外科科室 1 里面只有一个男大夫，大概四五十岁的样子，因为刚刚发热门诊大夫已经打过招呼了，于是简单说明情况，对方一副不耐烦的样子，哪个门诊？哪个某大夫？然后把我赶出诊室，没办法只能给门诊某大夫打电话，外科大夫在电话里跟某大夫说，意思病人没有持续性出血，有纱布包扎止血，等核酸结果吧。其实纱布是我自己出门简单包扎的，给大夫看伤口时，纱布往下掉了点，很多干的血迹，裤腿有点紧，还没掀到伤口那，大夫扭头就回诊室了，扔下一句，你这没有持续性出血，俨然一副趾高气扬的样子。我的腿还流着血，我也不知道还有没有命等核酸结果出来。于是质问他是不是今天今天我死在这你也拒诊。“是，我不能违反国家规定，没有 48 小时核酸不能进手术室”说完大夫扭头就进屋了，和他确认刚才说的话，他似乎也察觉到了说错了话，转过头就不认了，就说国家规定什么的。录音我会上报有关媒体，之前这样的事已经民怨载道了。保安凑过来了，目光盯着那个医生，我的腿还流着血，我尝试跟保安解释，这个医院是不能呆了，就没想好好给治，再来个公报私仇犯不上。估计大家都看新闻了，也没人出来拦着我。后悔当时没有直接报警。或者不讲中文用日语跟他们说。 我也是第一次有底气敢和人吵架，没想竟然在三甲医院。古语讲医门多疾。现在的医生不要求有医德，不要求跟病人好好说话，能把本质工作做好就可以去了，不要求不给开太贵的药。当然不是针对所有医院，仅仅用这个医生举例子，大家结合自己经历自行脑补就好。自疫情开始，多少人因为医院的政策问题被拒在门外，本人命大两次死里逃生，上次是打疫苗之后发烧 39 度，窗外下着暴雨打着雷，我要去治疗发烧却因为发烧不能看病。否则需要做抗原四项，一共 770。再等 4-6 小时出结果，期间不能离开，发烧 39 度在急诊那个环境呆半天估计是直接去另外的世界了。一年之内就遇到两起拒诊案件，其他人呢？因此去那个世界的人呢？和变相杀人有什么区别？不作为故意杀人罪可以进局子了吧。这种没有医德乃至道德的人直接革职查办，行政拘留吧。（不作为故意杀人：处死刑、无期徒刑或者十年以上有期徒刑;情节较轻的，处三年以上十年以下有期徒刑） 中日友好医院是压死骆驼的最后一根稻草，北京又如何，上海又如何？6 月 1 日，上海刚刚解封。6 月 2 日北京就重复上演这样的事情，把国家政策当挡箭牌，把百姓的命不当回事。自古有之敢冒天下之大不韪，杀伐决断，后来的人称之为任侠。古来救死扶伤，而今一个个伪君子，在其位不谋其事。 发文可能会被网暴，键盘侠从来不会关心你过的好不好，放心我不会自杀。不想做一个忍气吞声苟活于世的人，洪流之下，很多人都活成了龙啸云。 医院不是法外之地，还轮不到地方自己立规矩。","link":"/posts/69b5547e/"},{"title":"家有吃货之自制纯肉肠","text":"淘宝买的猪小肠的肠衣，以前也使用过其他肠衣，效果不好。基本上是腌渍的肠衣，回来用料酒泡了一个多小时，然后用水冲了几遍场子内部，看看有没有坏的地方，有小孔不影响灌肉的可以忽略。 趁着清洗肠衣的时间调制肉馅，用绞肉机打碎，加上卖家的肉料（其实也可以自己调制），每斤肉加入30g淀粉，用来填补肉之间的孔位，红曲粉看颜色放入，差不多一斤肉0.5g的样子，主要为了颜色发红，多了会暗红。这个添加剂据说无害。最后加入葱姜水，六斤多肉我放了两碗。搅拌到最后越来沉，是在没力气搅拌的拉丝，直接就下一步了。 使用用灌肠神器，其实就是一个大号针管。视频里都是很顺利的灌进去了，我这个有肉堆积的现象，然后得用手一点点往下缕，不然会撑到爆开。 把肠衣完全套在神器上。灌好之后用绳子打结，分出每根的大小，最好打两层的绳子，保证切的时候不会破坏肠衣，然后用牙签戳，防止煮的时候肠衣爆开。完事之后进行风干操作，屋内低温自然2小时或者烤箱30风干30分钟。 风干之后可以继续扎眼，然后冷水下锅煮，中间可以自由翻面，有明显气泡可以直接用牙签戳破。全程小火，开锅了就加凉水，40-50分钟之后香肠都飘起来就可以了。记得扎两层绳子，防止切的时候肠衣剥开。 煮好的香肠可以冷冻上，吃多少烤多少，煎炒烹炸都可以。烤箱的话180度15分钟就可以，想吃脆皮的可以多烤一会。 基本上做出来的和网上买的火山石烤肠相差无几，不过自己家做的纯肉的，99. 99%纯肉，外边的比不了哦。","link":"/posts/75eceee6/"},{"title":"无限续面","text":"聊一聊北京那些无限续面的小吃 外面的面条不知道什么材质做的，怎么吃也感觉吃不饱，就是胀肚还觉得饿，大脑也没有能量。 刘胖妹面庄应该是望京这边最好吃的面了，能免费续面（大碗），但是不能免费加汤。首重三两半，续重二两半。单买了肉末和豌杂。 有打油诗为证： 挑战一天内只吃刘胖妹面庄刷新店内最高续面记录失败和老大哥差了二两半的白面不愧网红的小面店下次再战 和府捞面从三里屯种草之后就一发不可收拾，三十多一碗的价格不续面都觉得亏，用草本汤稀释番茄汤味道不错，最高记录6碗，可以免费加香菜，现在改了菜单，理性考虑吧。个人感觉沦为路边小吃快餐水准了。（有些店完全没有中国风的感觉。。。 ps：已经粉转黑 陈香贵号称拉面界的海底捞，其实就是普通的兰州牛肉面，觉得跟和府捞面的牛肉面也差不多。好处是无线续面，店里人一直不少。 羊肉串比较薛定谔，有次用的打折券就很难吃，串又小又苦，很难不让人觉得有什么猫腻。之前单点的还行。 方砖厂外地人慕名而来，其实还没自己家的炸酱面好吃，商业化了之徒有其表，不怎么推荐。拌面续面的结果就是吃着吃着就凉了，不给加菜，还是第一次续面吃不下去的，排队很长。酸梅汤和拌肚很不错。 蓉李记商场角落的一员。打折券13.9还能无限续面，不过每碗面很少，不过不耽误我吃6碗，最后辣子鸡很不错。","link":"/posts/45c86e6c/"},{"title":"自制味精","text":"","link":"/posts/9599d85d/"},{"title":"生活小妙招","text":"### 冰箱去霜 开水倒入不锈钢盆，放入冰箱，几分钟之后冰块就掉下来了 ### 锅去顽渍 白醋和小苏打浸泡一会就可以擦掉了，注意铁锅不能用 ### 玻璃水杯 尽量买双层的隔热杯，防止烫手，单层玻璃不管用。","link":"/posts/29d0960/"},{"title":"身份证科普","text":"身份证号码是由18位数字组成的，分别表示： 1、前1、2位数字表示：所在省份的代码。 2、前3、4位数字表示：所在城市的代码。 3、前5、6位数字表示：所在区县的代码。 4、第7～14位数字表示：出生年、月、日，7、8、9、10位是年，11、12位是月，13、14位是日。 5、第15、16位数字表示:所在地的派出所的代码。 6、第17位数字表示性别:奇数表示男性，偶数表示女性。 7、第18位数字是校检码:校检码可以是0～9的数字，有时也用X表示。 8、＊尾号X是作为尾号的校检码，是由号码编制单位。X是罗马数字的10，用X来代替10，可以保证公民身份证符合国家标准。","link":"/posts/7a47d12b/"},{"title":"上网逛逛开源项目，发现自己的文章被偷了，心慈手软给对方整改机会，结果后悔到拍大腿!","text":"本来想找点 NAS 的开源项目玩一玩，然后很巧搜到了别人”介绍”我的作品，一开始还挺高兴的，起码自己写的工具有人用了。除了我的朋友们，懒猫微服的圈子之外还有互联网上的人用。然后看到底，这个文字风格咋怎么眼熟，就好像是我的风格，打开我原来的文章，确认是洗稿无疑了。（后面有证据） 事件起因我的文章最早是发在懒猫微服的，后续也发在了亚马逊云科技的公众号上，这个稿件是商业性质了，所以足够够成侵权了。大家记住这个人，虽然他删了帖子，但是再前前后后与他沟通之后，我没有得到他良好的认错态度，所以还是决定把这个文章发出来。 记住这个 ID，这个人有很多平台，有的叫做 panda 不是猫。然后他所有的平台都洗稿了我这个文章，并且流量还不低。而且我的文章是给懒猫微服的商业供稿，就被这个人无耻的剽窃了。所以也很难不怀疑他的其他文章也是不是洗稿来的。 抄袭证据一览我列出了整个文章的四个抄袭的点，几乎涵盖了所有的项目介绍，而且介绍顺序，功能，隐藏彩蛋，话术丝毫不差。 抄袭 1: 核心功能描述被整段搬运我的原文：Containly 的核心功能是通过目录央射的 Docker 引擎读取所有容器信息，包括容器的启动、退出、停止及其他:如，当容器处于“Create“状态时它会被标记为“Other”状态，便于管理, 他的洗稿抄袭版本：界面非常清爽，是我喜欢的类型，整个容器就这么一个界面，能看到容器的启动、退出、停止及其他状态。例如，当容器处于“Create”状态时，它会被标记为“Other”状态，便于管理。 这个 other 状态其实埋下的一个彩蛋，绝对不是可以第一次使用的是能够测出来的。 抄袭 2: 容器卡片设计原封不动我的原文：默认情况下，每个容器卡片会显容器的网桥信息、端口映射和 URL。默认使用 HTTP 协议，鼠标悬停时，会在右侧显示操作按钮。通过点击这些按钮操作会被保留，再次点击会隐藏，这样子就整个比较美观。 按钮功能包括 停止/启动 重启 查看日志 SSH 进入容器 切换 HTTP/HTTPS 黑名单管理 他的洗稿抄袭版本：容器卡片会显示容器的网桥信息、端口信息以及 URL 链接地址，默认使用 HTTP 协议，可切换到 HTTPS 协议。 当鼠标悬停时，卡片右侧会显示操作按钮，这里提供了容器的启停重启、日志查看、SSH 功能以及黑名单管理功能，再次点击可以隐藏按钮，显得卡片更为美观。 抄袭 3: 域名拼接也照抄我的原文：此外，Containly 还提供了一个输入框，用户可以输入需要监控的 NAS 域名，面板会自动根据域名和端口拼接成 URI，并存储在 localStorage 中。更进一步，Containly 还支持暗黑模式，提升了用户体验。 他的洗稿抄袭版本：右上角，Containly 提供了一个地址输入框，在这里填入我们 NAS 的域名或者 IP，面板会自动根据域名和端口拼接成 URI，并存储在 localStorage 中。 抄袭 4: 一句不改的 SSH 彩蛋我的原文：利用面板的 SSH 功能能够直接从面板进去访问容器的 SHELL，不用执行再 docker exec 的命令。 他的洗稿抄袭版本：利用面板的 SSH 功能能够直接从面板进去访问容器的 SHELL，不用执行再 docker exec 的命令。 （原文一个字没改） 把两篇文章扔到 GPT 里，也判断为洗稿。 根据您提供的两篇文章内容，第二篇文章显然是Containly 项目的原创介绍，详细描述了项目的背景、功能、部署方式以及开发过程。第一篇文章则是对第二篇内容的转载，几乎没有进行实质性的修改或添加新信息。因此，第一篇文章属于抄袭行为。 如果您是第一篇文章的作者，建议您对内容进行充分的改写，或者注明原文出处，以避免版权问题。如果您是第二篇文章的作者，您有权要求删除或修改未经授权转载的内容。 沟通 &amp; 维权过程先是公众号上告诉他涉嫌抄袭洗稿，但是没有任何效果。 然后给我回复了这个，完全没有意识到自己错在哪里。 我于是贴证据给他，然后就被无视了。他用我这个文章流量也不少，看 100 多的转发应该也赚了不少的广告费。抄袭他人稿件，然后用来盈利。除了微信的平台之外，其他平台也不会有太少的广告费。 适用法律条款 &amp; 赔偿依据 根据著作权法第 10 条、第 52 条第 5 项及第 53 条第 1 项，对方未经许可复制并在信息网络向公众传播我的文章，已构成剽窃及侵权，应承担停止侵害、赔礼道歉并赔偿损失的法律责任。 第五十四条 侵犯著作权或者与著作权有关的权利的，侵权人应当按照权利人的实际损失或者侵权人的违法所得给予赔偿；权利人的实际损失或者侵权人的违法所得难以计算的，由人民法院根据侵权行为的情节，判决给予五百元以上五百万元以下的赔偿。为制止侵权行为所支付的合理开支，也可以酌情计入赔偿数额 写在最后：给创作者的提醒那再给一个机会吧，然后加微信聊聊，说不定有悔意呢（实时证明我单纯了） 然后对方一开始没理不饶人，简直认为原创。 给了他半个多周的时间来整改，然后就没有然后了，再也没回过我消息。这种无耻的人，还是把他发出来，让大家避雷吧，这种靠抄袭别人还振振有词骗流量的人，才是当代互联网的蛀虫。 免责声明本文仅陈述可核实事实，所引用截图均为证据保存；如有异议可联系作者。这个人微信号在他平台上有，不能够算恶意曝光泄漏隐私。","link":"/posts/5f056020/"},{"title":"避雷！ 百大值友熊猫不是猫公开抄袭文章理直气壮，态度恶劣，投诉、辟谣、关评全流程实录","text":"前面的文章提到了 熊猫不是熊猫/panda 不是猫，这个人抄袭我的文章，我出于礼貌跟他沟通，希望他道歉和整改结果没有任何后续，于是我发布了一开始的文章 最早在这个平台上刷到我抄袭我的文章，然后果断投诉下架，值得买和知乎也处理了他的文章。 同时他的公众号也抄袭了这个文章，阅读量有小 1W，转发就有 100 多次，也不清楚到底是赚了多少钱。 更有意思的是，他不仅不道歉而且在公众号上发辟谣。来说不是抄袭之类的。 然后评论区就是一边倒的状态，甚至有说“他就是挂出来挨打的”。 这个是我一开始评论的样子，后来他直接屏蔽我的留言。为了让大家看明白这个事情，所以我贴了我的原文链接。， 过了一天之后发现评论变成了仅作者可见，显然是心虚了，不敢让其他读者看原文。 从工信部的备案中能够查看这个人的信息，还会继续扒其他信息的，也欢迎互联网网友提供。（信息为公开） 抄袭文章，然后连一个公开的道歉都没有么？然后发过来发辟谣说我侮辱他？ 简直是素质低劣，屡教不改。我仁至义尽了。 很难不让人认为他其他文章是不是也是抄的，多次沟通让他公开道歉，但是这个态度实在在就是惯犯。 如果有商家想找他合作推广产品，慎重吧。。。 典型的死猪不怕开水烫。 很多的情况是很多原作者流量不高，抄袭的人天南海北的洗，所以流量数字也好看。等被发现或者告了。再来个下架关帐号建新号来逃避法律的追责。如此往复，抄袭者总是能无本获利。我呼吁能够维护原作的知识产权，不要让这种蛀虫危害互联网。","link":"/posts/951989c3/"},{"title":"威联通 QNAP 系列 (一) 全闪 NAS TBS-h574TX QuTS hero 初探","text":"字数 1371，阅读大约需 7 分钟 都说 2024 是全闪 NAS 的元年，各个厂商也纷纷出品的自家的 NAS，独占鳌头的还是 QNAP 的TBS-h574TX，5 盘位 NVME，支持 10G 网口以及雷电网桥，甚至还有 12 代 i5 CPU 这个配置很难不让人心动。 初始化系统安装使用 Qfinder Pro 可以查找局域网内的 QNAP NAS, 免去手动查找 IP 的麻烦,软件支持全平台。 Qfinder 寻找结果如下，可以识别出 NAS 名称，IP 地址，MAC 地址，机器型号以及系统及其版本。 除此之外，我们也可以在路由器后台寻找 IP 地址。 开始初始化流程： 进入 web 页面，开始安装系统 授权条款如下： 选择固件版本，为了快速安装，一般选择当前版本，然后进入 OS 内部再进行升级 设置 nas 名称和用户名,密码,由于系统内置了 admin 用户，所以这里不能使用 admin 设置时区以及 NTP 服务器同步时间。 设置 IP 地址，可以选择 DHCP 或者静态地址，我一般为了方便选 DHCP，这些后期都可以系统内部进行修改。 如果设置静态地址需要的参数如下：IP 地址，子网掩码，网关，DNS 服务器，不过还是建议直接在路由器上设置静态 IP 方便管理。 这个机器支持了雷电 4 的接口，原生支持了雷电网桥，所以这里多出来一个检测雷电的步骤，拔插雷电的时候机器会滴滴的响几声。 固件更新设置，建议设置通知，手动更新。 这个初始化的步骤会清除硬盘上的所有数据。 接下来就几分钟的等待，主要是等待往硬盘上安装软件，可以看到进度条。 这个机器的配置比较高，全程用了五分钟左右，这里主要启动 SMB 和系统的一些进程。 设置完毕之后，我们就可以使用 NAS 了。 使用之前设置好的用户名和密码进行登录 初始化磁盘第一步需要设置存储池，用我们安装的 NVME 硬盘组成一个 raid 存储池。 RAID 通过将多个硬盘组合在一起，形成一个更大的存储单元，以实现数据冗余备份或提升存储性能。它是一种存储虚拟化技术，可以让系统同时从多个硬盘中读取和写入数据，从而提高读写速度。 RAID 的常见级别如下： • RAID 0（条带化）：数据被分割成多个部分，分别存储在多个硬盘上，读写速度快，但没有冗余保护，任意一块硬盘损坏会导致数据丢失。（建议谨慎使用） • RAID 1（镜像）：数据在两个硬盘上存储两份，每次写操作都会写到两个硬盘上，数据安全性高，但磁盘利用率低。 • RAID 5（分布式奇偶校验）：利用条带化和奇偶校验实现数据保护，至少需要三块硬盘，能够在提高存储性能的同时保证数据的冗余性，可以容忍一块盘故障。 • RAID 6（双奇偶校验）：与 RAID 5 类似，但使用双重奇偶校验，可以容忍两块硬盘同时故障。 • RAID 10（镜像+条带化）：结合了 RAID 1 和 RAID 0 的优点，先进行镜像操作，再进行条带化，提供高性能和高可靠性。 我只有两个 NVME，所以出于测试目的，组建了 Raid0。 设置存储池预留空间，快照预留空间以及警报阈值。 可以看到我的 4T 和 2T 的 NVME 组建的 RAID0 阵列， 设置完毕，除了保留空间外，最后之后 3.6T 可以用。 同样存储池也会清除磁盘上的所有数据。 存储池磁盘位一览： ![图片](data:image/svg+xml,%3C%3Fxml version=’1.0’ encoding=’UTF-8’%3F%3E%3Csvg width=’1px’ height=’1px’ viewBox=’0 0 1 1’ version=’1.1’ xmlns=’http://www.w3.org/2000/svg‘ xmlns:xlink=’http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke=’none’ stroke-width=’1’ fill=’none’ fill-rule=’evenodd’ fill-opacity=’0’%3E%3Cg transform=’translate(-249.000000, -126.000000)’ fill=’%23FFFFFF’%3E%3Crect x=’249’ y=’126’ width=’1’ height=’1’%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E) 存储池目录结构如下： ![图片](data:image/svg+xml,%3C%3Fxml version=’1.0’ encoding=’UTF-8’%3F%3E%3Csvg width=’1px’ height=’1px’ viewBox=’0 0 1 1’ version=’1.1’ xmlns=’http://www.w3.org/2000/svg‘ xmlns:xlink=’http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke=’none’ stroke-width=’1’ fill=’none’ fill-rule=’evenodd’ fill-opacity=’0’%3E%3Cg transform=’translate(-249.000000, -126.000000)’ fill=’%23FFFFFF’%3E%3Crect x=’249’ y=’126’ width=’1’ height=’1’%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E) 简单的监控在用户管理处我们可以看到刚刚设置的用户，在这里也可以新建用户做一些额外的权限控制。 ![图片](data:image/svg+xml,%3C%3Fxml version=’1.0’ encoding=’UTF-8’%3F%3E%3Csvg width=’1px’ height=’1px’ viewBox=’0 0 1 1’ version=’1.1’ xmlns=’http://www.w3.org/2000/svg‘ xmlns:xlink=’http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke=’none’ stroke-width=’1’ fill=’none’ fill-rule=’evenodd’ fill-opacity=’0’%3E%3Cg transform=’translate(-249.000000, -126.000000)’ fill=’%23FFFFFF’%3E%3Crect x=’249’ y=’126’ width=’1’ height=’1’%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E) 同时 NAS 还自带了监控，可以看到 CPU，内存以及磁盘使用率，还有运行时间，风扇转速，访问记录等等。 ![图片](data:image/svg+xml,%3C%3Fxml version=’1.0’ encoding=’UTF-8’%3F%3E%3Csvg width=’1px’ height=’1px’ viewBox=’0 0 1 1’ version=’1.1’ xmlns=’http://www.w3.org/2000/svg‘ xmlns:xlink=’http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke=’none’ stroke-width=’1’ fill=’none’ fill-rule=’evenodd’ fill-opacity=’0’%3E%3Cg transform=’translate(-249.000000, -126.000000)’ fill=’%23FFFFFF’%3E%3Crect x=’249’ y=’126’ width=’1’ height=’1’%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E) 日志处理QuLog Center 是一款集中日志管理应用程序，可将详细的系统事件、系统访问和在线用户状态记录到您的设备。收集的信息可用于有效地诊断和理解设备系统问题，例如与用户访问相关的记录 ![图片](data:image/svg+xml,%3C%3Fxml version=’1.0’ encoding=’UTF-8’%3F%3E%3Csvg width=’1px’ height=’1px’ viewBox=’0 0 1 1’ version=’1.1’ xmlns=’http://www.w3.org/2000/svg‘ xmlns:xlink=’http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke=’none’ stroke-width=’1’ fill=’none’ fill-rule=’evenodd’ fill-opacity=’0’%3E%3Cg transform=’translate(-249.000000, -126.000000)’ fill=’%23FFFFFF’%3E%3Crect x=’249’ y=’126’ width=’1’ height=’1’%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E) QuLog 服务用于将日志传输到其他设备的 QuLog Center。您可以将其他设备的日志集中起来管理。 ![图片](data:image/svg+xml,%3C%3Fxml version=’1.0’ encoding=’UTF-8’%3F%3E%3Csvg width=’1px’ height=’1px’ viewBox=’0 0 1 1’ version=’1.1’ xmlns=’http://www.w3.org/2000/svg‘ xmlns:xlink=’http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke=’none’ stroke-width=’1’ fill=’none’ fill-rule=’evenodd’ fill-opacity=’0’%3E%3Cg transform=’translate(-249.000000, -126.000000)’ fill=’%23FFFFFF’%3E%3Crect x=’249’ y=’126’ width=’1’ height=’1’%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E) 日志也可以发送到 Syslog 服务器： ![图片](data:image/svg+xml,%3C%3Fxml version=’1.0’ encoding=’UTF-8’%3F%3E%3Csvg width=’1px’ height=’1px’ viewBox=’0 0 1 1’ version=’1.1’ xmlns=’http://www.w3.org/2000/svg‘ xmlns:xlink=’http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke=’none’ stroke-width=’1’ fill=’none’ fill-rule=’evenodd’ fill-opacity=’0’%3E%3Cg transform=’translate(-249.000000, -126.000000)’ fill=’%23FFFFFF’%3E%3Crect x=’249’ y=’126’ width=’1’ height=’1’%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E) 公网访问如果想在公网上访问这个 NAS，那么也可以在路由器上设置端口转发，使用自家的 IP 地址进行访问。 ![图片](data:image/svg+xml,%3C%3Fxml version=’1.0’ encoding=’UTF-8’%3F%3E%3Csvg width=’1px’ height=’1px’ viewBox=’0 0 1 1’ version=’1.1’ xmlns=’http://www.w3.org/2000/svg‘ xmlns:xlink=’http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke=’none’ stroke-width=’1’ fill=’none’ fill-rule=’evenodd’ fill-opacity=’0’%3E%3Cg transform=’translate(-249.000000, -126.000000)’ fill=’%23FFFFFF’%3E%3Crect x=’249’ y=’126’ width=’1’ height=’1’%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E) 写在最后全闪主要是风扇的声音比较大，用手机贴在上面测试了下，在 50 分贝左右，拿开一段距离的话在 40 分贝左右。有条件还是放在柜子里吧。 ![图片](data:image/svg+xml,%3C%3Fxml version=’1.0’ encoding=’UTF-8’%3F%3E%3Csvg width=’1px’ height=’1px’ viewBox=’0 0 1 1’ version=’1.1’ xmlns=’http://www.w3.org/2000/svg‘ xmlns:xlink=’http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke=’none’ stroke-width=’1’ fill=’none’ fill-rule=’evenodd’ fill-opacity=’0’%3E%3Cg transform=’translate(-249.000000, -126.000000)’ fill=’%23FFFFFF’%3E%3Crect x=’249’ y=’126’ width=’1’ height=’1’%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)","link":"/posts/7acb32ac/"},{"title":"DSM 外接磁盘挂载记录","text":"1. 外接磁盘识别情况将移动硬盘连接至群晖 NAS（DSM 7.2），系统右上角立即弹出外接设备提示： 可在“控制面板 - 外接设备”中查看磁盘详情： 2. exFAT 支持插件提示首次插入 exFAT 文件系统磁盘，系统提示需安装对应插件才能访问。可跳转 Package Center 安装 exFAT Access： 3. Mac 格式化分区异常在 Mac 上格式化为 exFAT 后插入群晖，系统将其识别为两个分区： 4. 在群晖中重新格式化为避免多分区问题，使用群晖内置“格式化”功能重新整理磁盘。可在外接设备列表中操作： 选择磁盘 → 点击“格式化” 文件系统建议继续使用 exFAT，以兼容 Mac/Windows 5. 结果验证格式化为 exFAT 后，无论在群晖还是 Mac 上均可正常挂载与读写：","link":"/posts/f2e07cac/"},{"title":"给群晖安装Iperf3，一键局域网测速","text":"群晖默认不带 iperf3，所以需要套件来安装： 套件中心搜索 SynoCli，然后安装 SynoCli Monitor Tools ，里面有常见的监控工具。 然后在群晖上启动服务端： 12345name@qun:~$ iperf3 -s-----------------------------------------------------------Server listening on 5201 (test #1)----------------------------------------------------------- 在 Mac 上测速，iperf3 -c 和 这两个命令的差别关键在于 数据传输方向，也就是谁是“发”谁是“收”。 ✅ iperf3 -c &lt;server_ip&gt; 含义：客户端主动发数据，服务器接收。 方向：📤 客户端 → 服务器（上传测试） 谁发数据？：客户端 谁测带宽？：客户端测发送速度，服务器测接收速度。 🧪 示例： 1iperf3 -c 192.168.5.171 表示测试从你这台机器上传数据到服务器的带宽。 ✅ iperf3 -c &lt;server_ip&gt; -R 含义：反向测试，客户端建立连接后，让服务器发数据。 方向：📥 服务器 → 客户端（下载测试） 谁发数据？：服务器 谁测带宽？：客户端测接收速度，服务器测发送速度。 🧪 示例： 1iperf3 -c 192.168.5.171 -R 表示测试从服务器下载数据到你的机器的带宽。 🔁 表格对比总结： 命令 数据方向 谁发送 谁接收 测的是什么带宽 iperf3 -c 客户端 → 服务器 客户端 服务器 上传带宽 iperf3 -c -R 服务器 → 客户端 服务器 客户端 下载带宽 🎯 提示： 二者都只能测试一个方向，不会自动“双向”测试。 如果你想做双向测试，请手动运行这两个命令各一次。","link":"/posts/e70dd7d7/"},{"title":"群晖套娃飞牛OS（FnOS）","text":"头段实在飞牛实在炒的有有点多，也安装尝试了下，同时也做了虚拟机的测评。 不过飞牛使用下来还是影音刮削的功能还是不错的，所以觉得把飞牛装在虚拟机里只使用影音的功能。 于是这个是一个使用群晖虚拟机安装飞牛 OS 的的过程。 在某个时间点的更新之后，群晖安装 debian 类虚拟机遇到问题，尽管看报错是正在加载，但是一直都没有响应。 在多次尝试之后，发现如下组合可以不卡代码，视频卡使用 vga，机器类型使用 Q35 查了下 GPT 的说法如下： 选项 说明 cirrus 非常基础的显卡，兼容性强，但仅支持 800x600 或 1024x768 的低分辨率，性能差。 vga 模拟标准 VGA，支持更多分辨率，但也比较基础。 vmvga 模拟 VMware 的显卡，适用于装有 VMware Tools 的系统，和 Chromium/FnOS 相对兼容较好。 类型 说明 PC 传统的 Intel i440FX 芯片组，兼容性强但比较老旧（类似 90 年代主板结构） Q35 模拟 Intel Q35 芯片组，支持 PCIe、AHCI、现代硬件，推荐给新系统（如 Win10+、FnOS、Linux） 飞牛要直通两个盘，一个是系统盘，一个是数据盘。当然如果你只使用 SMB 做数据盘那也没问题，只是一直会提示你要加一个盘。 我主要使用影视，就只能安装在数据盘了， 创建媒体库，选择 SMB 文件夹： 缺点是这套不能直通核显给 FnOS，所以用浏览器看的时候 CPU 是满的，但是不耽误客户端解码。 当贝桌面下载飞牛 TV，然后使用手机飞牛账户绑定。 放了一个 4K 版本的哪吒，不卡顿～","link":"/posts/1eb7a4c5/"},{"title":"群晖导入磁盘大法 - 安装img","text":"很多年之后再用群晖的虚拟机，发现越来越像云了，可能也有在云计算行业摸爬滚打了几年的原因吧，总喜欢一些比较稀奇古怪的玩法，在家里常常玩公有云那一套。 一、导入磁盘映像得到 Img 之后，点击映像，然后点击导入磁盘映像，我这里有两块盘，随便选一个就好。 选中上传的 img 文件上传到磁盘映像。 然后可以观察到群晖根据这个 img 正在创建卷文件。 这个是创建好的卷。 二、导入虚拟机并启动下面开始启动虚拟机，新增附近有一个三角箭头点击，有个导入的选项。（藏的挺深） 可以导入 OVA，也可以导入上面的磁盘映像。 同样也是选择磁盘。 唯一不同的是，在虚拟磁盘这里我们可以选择刚刚创建的硬盘映像，然后后面下一步就可以了，不再需要 ISO 啥的。 三、总结其实吧，在公有云这算基础操作，在群晖这藏的这么深。随便玩玩，差不多该有的都有了。","link":"/posts/8c366e49/"},{"title":"追忆青春 - 黑群晖.md","text":"那么现在有一个叫做 RR 的项目简化了这一切，我把这些记录下来。他们提供了 release 文件，如下： https://github.com/RROrg/rr/releases/ 用 Etcher 来写盘，需要 U 盘引导的系统不适合用 Ventoy 启动，因为没办法保存，除非把系统安装在其他的磁盘上。 从 U 盘启动页面，rr 会启动一个 web server，端口是 7681 然后就是更换语言，选择机型，系统版本，下载 PAT 文件，以及编译引导（图片来自参考链接） 选择的是 DS918+，没有额外编译任何插件 使用 web 版本的 findsnoloy 没有搜到机器，最后使用手机 app 搜到了局域网的安装好的群晖，之前安装在 ec2 上的黑群晖无法启动可能也是这个原因。 存储池信息： 手机 APP 连接的信息： 虚拟机也很好用，不输 EXSI（除了删除机器的时候强制输入密码）： 对于 VirtIO Block 控制器，官方只建议安装 Linux，实测也可以安装 Windows。 需要把官方的 guest agent 换成 VirtIO 的 ISO，对就是 fedora 那个：https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/archive-virtio/virtio-win-0.1.266-1/ 参考： https://www.wanjiachupin.com/1314.html https://www.mspace.cc/archives/1002","link":"/posts/795ed575/"}],"tags":[{"name":"HEXO","slug":"HEXO","link":"/tags/HEXO/"},{"name":"大纲","slug":"大纲","link":"/tags/%E5%A4%A7%E7%BA%B2/"},{"name":"游记","slug":"游记","link":"/tags/%E6%B8%B8%E8%AE%B0/"},{"name":"梦","slug":"梦","link":"/tags/%E6%A2%A6/"},{"name":"随笔","slug":"随笔","link":"/tags/%E9%9A%8F%E7%AC%94/"},{"name":"诗","slug":"诗","link":"/tags/%E8%AF%97/"},{"name":"读书","slug":"读书","link":"/tags/%E8%AF%BB%E4%B9%A6/"},{"name":"效率","slug":"效率","link":"/tags/%E6%95%88%E7%8E%87/"},{"name":"笔记","slug":"笔记","link":"/tags/%E7%AC%94%E8%AE%B0/"},{"name":"SEO","slug":"SEO","link":"/tags/SEO/"},{"name":"LLM","slug":"LLM","link":"/tags/LLM/"},{"name":"开发","slug":"开发","link":"/tags/%E5%BC%80%E5%8F%91/"},{"name":"向量数据库","slug":"向量数据库","link":"/tags/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"网关","slug":"网关","link":"/tags/%E7%BD%91%E5%85%B3/"},{"name":"Nginx","slug":"Nginx","link":"/tags/Nginx/"},{"name":"GIT","slug":"GIT","link":"/tags/GIT/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"外设","slug":"外设","link":"/tags/%E5%A4%96%E8%AE%BE/"},{"name":"生活","slug":"生活","link":"/tags/%E7%94%9F%E6%B4%BB/"},{"name":"租房","slug":"租房","link":"/tags/%E7%A7%9F%E6%88%BF/"},{"name":"DIY","slug":"DIY","link":"/tags/DIY/"},{"name":"消防","slug":"消防","link":"/tags/%E6%B6%88%E9%98%B2/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"懒猫微服","slug":"懒猫微服","link":"/tags/%E6%87%92%E7%8C%AB%E5%BE%AE%E6%9C%8D/"},{"name":"电脑外设","slug":"电脑外设","link":"/tags/%E7%94%B5%E8%84%91%E5%A4%96%E8%AE%BE/"},{"name":"SSH","slug":"SSH","link":"/tags/SSH/"},{"name":"网络","slug":"网络","link":"/tags/%E7%BD%91%E7%BB%9C/"},{"name":"代理","slug":"代理","link":"/tags/%E4%BB%A3%E7%90%86/"},{"name":"组网","slug":"组网","link":"/tags/%E7%BB%84%E7%BD%91/"},{"name":"samba","slug":"samba","link":"/tags/samba/"},{"name":"MFA","slug":"MFA","link":"/tags/MFA/"},{"name":"Apple","slug":"Apple","link":"/tags/Apple/"},{"name":"家庭网络","slug":"家庭网络","link":"/tags/%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C/"},{"name":"NAS","slug":"NAS","link":"/tags/NAS/"},{"name":"群晖","slug":"群晖","link":"/tags/%E7%BE%A4%E6%99%96/"},{"name":"电视盒子","slug":"电视盒子","link":"/tags/%E7%94%B5%E8%A7%86%E7%9B%92%E5%AD%90/"},{"name":"远程开发","slug":"远程开发","link":"/tags/%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91/"},{"name":"RDP","slug":"RDP","link":"/tags/RDP/"},{"name":"单点登录","slug":"单点登录","link":"/tags/%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95/"},{"name":"PWA","slug":"PWA","link":"/tags/PWA/"},{"name":"Cloudflared","slug":"Cloudflared","link":"/tags/Cloudflared/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"装机","slug":"装机","link":"/tags/%E8%A3%85%E6%9C%BA/"},{"name":"搜索引擎（ES）","slug":"搜索引擎（ES）","link":"/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%EF%BC%88ES%EF%BC%89/"},{"name":"Coco-AI","slug":"Coco-AI","link":"/tags/Coco-AI/"},{"name":"Coco AI","slug":"Coco-AI","link":"/tags/Coco-AI/"},{"name":"AWS","slug":"AWS","link":"/tags/AWS/"},{"name":"ELK","slug":"ELK","link":"/tags/ELK/"},{"name":"OpenSearch","slug":"OpenSearch","link":"/tags/OpenSearch/"},{"name":"LogAgent","slug":"LogAgent","link":"/tags/LogAgent/"},{"name":"Isaac","slug":"Isaac","link":"/tags/Isaac/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"虚拟机","slug":"虚拟机","link":"/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"打印机","slug":"打印机","link":"/tags/%E6%89%93%E5%8D%B0%E6%9C%BA/"},{"name":"路由器","slug":"路由器","link":"/tags/%E8%B7%AF%E7%94%B1%E5%99%A8/"},{"name":"车载","slug":"车载","link":"/tags/%E8%BD%A6%E8%BD%BD/"},{"name":"北漂","slug":"北漂","link":"/tags/%E5%8C%97%E6%BC%82/"},{"name":"装修日记","slug":"装修日记","link":"/tags/%E8%A3%85%E4%BF%AE%E6%97%A5%E8%AE%B0/"},{"name":"反抗","slug":"反抗","link":"/tags/%E5%8F%8D%E6%8A%97/"},{"name":"家有吃货","slug":"家有吃货","link":"/tags/%E5%AE%B6%E6%9C%89%E5%90%83%E8%B4%A7/"}],"categories":[{"name":"懒猫微服","slug":"懒猫微服","link":"/categories/%E6%87%92%E7%8C%AB%E5%BE%AE%E6%9C%8D/"},{"name":"大纲","slug":"大纲","link":"/categories/%E5%A4%A7%E7%BA%B2/"},{"name":"游记","slug":"游记","link":"/categories/%E6%B8%B8%E8%AE%B0/"},{"name":"极限科技","slug":"极限科技","link":"/categories/%E6%9E%81%E9%99%90%E7%A7%91%E6%8A%80/"},{"name":"读书笔记","slug":"读书笔记","link":"/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"效率","slug":"效率","link":"/categories/%E6%95%88%E7%8E%87/"},{"name":"SEO","slug":"SEO","link":"/categories/SEO/"},{"name":"LLM","slug":"LLM","link":"/categories/LLM/"},{"name":"开发","slug":"开发","link":"/categories/%E5%BC%80%E5%8F%91/"},{"name":"Milvus","slug":"Milvus","link":"/categories/Milvus/"},{"name":"运维","slug":"运维","link":"/categories/%E8%BF%90%E7%BB%B4/"},{"name":"GIT","slug":"GIT","link":"/categories/GIT/"},{"name":"SMTP","slug":"SMTP","link":"/categories/SMTP/"},{"name":"外设","slug":"外设","link":"/categories/%E5%A4%96%E8%AE%BE/"},{"name":"硬件","slug":"硬件","link":"/categories/%E7%A1%AC%E4%BB%B6/"},{"name":"AWS","slug":"AWS","link":"/categories/AWS/"},{"name":"Docker","slug":"Docker","link":"/categories/Docker/"},{"name":"NAS","slug":"NAS","link":"/categories/NAS/"},{"name":"电脑外设","slug":"电脑外设","link":"/categories/%E7%94%B5%E8%84%91%E5%A4%96%E8%AE%BE/"},{"name":"装机","slug":"装机","link":"/categories/%E8%A3%85%E6%9C%BA/"},{"name":"打印机","slug":"打印机","link":"/categories/%E6%89%93%E5%8D%B0%E6%9C%BA/"},{"name":"Apple","slug":"Apple","link":"/categories/Apple/"},{"name":"远程访问","slug":"远程访问","link":"/categories/%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE/"},{"name":"随笔","slug":"随笔","link":"/categories/%E9%9A%8F%E7%AC%94/"},{"name":"吃货","slug":"吃货","link":"/categories/%E5%90%83%E8%B4%A7/"},{"name":"群晖","slug":"群晖","link":"/categories/%E7%BE%A4%E6%99%96/"}],"pages":[{"title":"404","text":"好好吃饭，好好生活。网页找不到了，但是你还在。","link":"/404"},{"title":"关于我","text":"仍然在折腾路上的不断探索。人在江湖，又岂能笑傲江湖？ 亚马逊云科技（AWS） Community Builders（AI）、亚马逊云科技（AWS）中国技领云博主、极限科技技术博主、Milvus 北辰使者，懒猫微服专栏作家。 专注于 Python 后端开发与 AI 服务部署，熟练掌握亚马逊云科技（AWS）核心服务，包括 Lambda、API Gateway、SageMaker、Bedrock、OpenSearch 等，具备扎实的工程实践能力与系统架构经验。 热衷于开发效率工具与自动化脚本，常年在本地构建 Homelab 环境，部署自研工具与开源项目，深入探索大模型的本地推理、私有化部署与性能优化路径。 曾在亚马逊云科技（AWS）上海 Summit 及 User Group 活动中担任讲师，积极推动技术传播与开发者社区建设。 步入职场后，笔耕不辍，曾为 Udacity 中国、InfoQ、亚马逊云科技、Milvus 社区，极限科技、懒猫微服等多个知名平台输出高质量内容，在技术传播与行业洞察方面持续深耕。 日常斜杠：写文章拿过奖，修过电脑，家电，写过代码，玩过硬件，3D 设计，做过课程讲师，公开演讲，上架过小程序和微信表情包。 🌐 技术主页 &amp; 平台链接 🎨 拓竹社区 3D 打印模型 ✍️ CSDN 博客主页 🛠️ GitHub 项目主页 dockerhub 📚 InfoQ 技术征文主页 懒猫论坛文集 🎤 社区演讲与活动 🧑‍🤝‍🧑 AWS 用户组 Meetup 分享 🏙️ AWS Summit 技术演讲页面 🎨 设计实验《灵魂画手》：基于 Amazon Bedrock 的动图生成与风格迁移 亚麻拉松 - 12 小时极客说 🧪 极限科技专题供稿（INFINI Labs） INFINI Easysearch 尝鲜 Hands-on 使用 Elasticsearch Python SDK 查询 Easysearch Easysearch 数据可视化与管理平台：INFINI Console 使用介绍 Easysearch、Elasticsearch、Amazon OpenSearch 快照兼容对比 玩转 Easysearch 查询语法 📁 👉 CSDN 专辑汇总 懒猫微服专辑 懒猫官网专栏 文章汇总 自带内网穿透,懒猫微服治好了我的 NAS 焦虑 快速检索懒猫商店 1000+应用，微服秒变 Mac 原生 APP 轻松管理 ES 集群: 我把 Infinilabs Console 上架了懒猫微服，默认支持外网访问、TLS 加密和 OIDC 登录 深度长文：NAS 大降价的年代，我为何接受溢价来购买懒猫微服（附送回本攻略） 我用 Amazon Q 写了一个 Docker 客户端，并上架了懒猫微服商店 懒猫微服实战入门（一）：从开启 SSH 到免密登录，一步步教你搞定远程管理 懒猫微服实战入门（二）: 打造多人协作环境：权限控制、数据隔离一步到位 懒猫微服实战入门（三）: 懒猫智慧屏，我以为是地表最强电视盒子，结果竟然可以改装成闺蜜机？ 懒猫微服实战入门（四）：完全 DNS 访问，和本地代理冲突了怎么办？ 懒猫微服实战入门（五）：文件上传到懒猫网盘，电视盒子挂载 SMB 观影 懒猫微服实战入门（六）：使用 2fauth 共享你的 MFA 懒猫微服实战入门（七）：超越蒲公英 SD-WAN，用懒猫转发服务，Ipad 随时远程家里 window，没有带宽和设备限制哦~ 懒猫微服实战入门（八）：懒猫微服 × SSH Remote：打造随时随地的云端开发环境 懒猫微服实战入门（九）：给懒猫安装图形界面，使用 XRDP 实现远程桌面 懒猫微服实战入门（十）：使用 nmtui 设置静态 IP，接入旁路由实现科学上网 懒猫微服实战入门（十一）：一键换源指南：用 chsrc 开启丝滑体验 懒猫微服实战入门（十二）：用 iVentoy 打造你的 PXE 服务器 懒猫微服实战入门（十三）：懒猫穿透不只图形化，纯命令行服务器也可以 懒猫微服进阶心得（一）M 芯片移植懒猫应用构建 Docker 镜像的常见问题排查及解决方案 懒猫微服进阶心得（二）：一台机器跑三套 Docker？深入解析懒猫容器的共存机制（上） 懒猫微服进阶心得（三）：一台机器跑三套 Docker？深入解析懒猫容器的共存机制（下） 懒猫微服进阶心得（四）：每次重启都丢配置？用 systemctl –user 自动装回环境！ 懒猫微服进阶心得（五）：使用懒猫微服做 Ventoy 启动盘 懒猫微服进阶心得（六）：以纸砚双拼为例，快速移植纯前端项目到懒猫微服 懒猫微服进阶心得（七）：懒猫的镜像仓库 懒猫微服进阶心得（八）：如何在 ARM 机器上下载并运行 X86 Docker 镜像以及在 X86 上运行 ARM 架构 Docker 懒猫微服炫技篇（一）：使用懒猫微服的穿透服务，车机使用 DS music 远程听歌，黑群晖不用再洗白 懒猫微服故事篇（一）：服务器宕机之后，我和前端靠懒猫微服结对编程 懒猫微服故事篇（二）：西湖邂逅后，我手把手教她玩转 NAS 懒猫微服炫技篇（二）：使用懒猫微服倒推停电时间 📮 微信公众号文章精选📌 极限科技公众号转载 Coco AI 智能检索 Hugo Blog 集成指南 MacBook Pro 快速搭建 Easysearch 学习环境 INFINI Easysearch 尝鲜 Hands-on ｜征文系列 使用 Elasticsearch Python SDK 查询 Easysearch ｜征文系列 快照兼容对比：Easysearch vs Elasticsearch vs OpenSearch 玩转 Easysearch 查询语法｜征文系列 INFINI Console 使用介绍｜可视化管理平台 Coco AI 支持嵌入，让你的网站拥有 AI 搜索力 Coco AI 如何接入自定义数据源 MySQL 数据实时接入 Easysearch，零代码迁移全流程 从认证到透传：用 Nginx 为 Easysearch 构建一体化认证网关 Easysearch 基础运维扫盲指南：从 HTTP 到 HTTPS、认证与安全访问全解析 📌 亚马逊云科技公众号转载2024 Easysearch、Elasticsearch、OpenSearch 快照兼容性解析 超越官方：在 EC2 上部署 PopOS 新功能：Amazon OpenSearch 支持 JWT 身份验证与授权 半小时上手 Amazon Transit Gateway 基于 Lambda 获取实时天气预报推送 快速部署 WordPress 到云端 使用 es-dump 快速备份 ES 数据 2025 使用 Amazon Q 开发容器管理工具 DDNS 域名解析 使用 openlist 访问 S3 AWS DMS 把 MySQL 迁移到 ES GPUS(Nvidia) 如何在 AWS EC2 上部署 Isaac Sim Milvus Milvus workshop Contributor info 翻译 杀死谷歌搜索的那个人 用 GPT 搜索我: Easysearch 文章一栏： OpenSearch 文章一栏：","link":"/about/"},{"title":"镜湖的由来","text":"博客取名为镜湖，取自陆游的《鹊桥仙》的”镜湖元自属闲人，又何必、君恩赐与。” 墨客总会把小事写的文雅脱俗，比如辛弃疾的“听取蛙声一片”，欧阳修的”伛偻提携，往来绝者”。 从前的文人可以醉卧沙场，后来的墨客亦可科技兴邦。即使文化人看的透彻，也到底无力改变。 不会再去写歌功颂德一类的东西了，这个是留给发挥的空间，讲一些心里话，做事不愧于心： 很多东西，不必官家老爷赏赐， 很多事情，不用主流价值评看。 在别人的轻蔑中轻轻的说一句，不好意思，我不接受 PUA。 在这个时代，凡事都要冠以名誉，相比之下大多数人显得平淡如水。曾在学生时代曾讽刺当今教育与传销形式极为类似，一代传给一代人，不断重复，也无产生任何实用价值。期间按照所谓的等级阶级把人分成三六九等，并且人为的制造焦虑，信息差异，再冠以各种标签，最后按照这等级制度分发资源。大概类似《美丽新世界》中胚胎诞生之前浇灌酒精来培育畸形胚胎的做法，这样的胚胎只能奔波于最底层，无法翻身。 世人追逐名利如疯狗啃食，厮杀过后遍体鳞伤，然后得一夕安寝。 文人对此是极度敏感的，功名意识更是比他人更进一层。 从小饱读诗书，聪颖会晤，而后被世俗所累，泯然众人。 陆游说：“酒徒一半取封侯，独去作、江边渔父。” 苏轼说：“惟愿孩儿愚且鲁，无灾无难到公卿”。 几千年来如是而已。 语录主页使用hexo + icarus主题，记录生活的碎碎念，和折腾的一些电子产品。 Github 分支： Master: Hexo 源代码 gh-pages：静态文件 docs: Markdown 源文件 更新文档2025.7 更新 最近加上了 RSS，做了自定义域名（_source 目录加 CNAME，然后配置文件改域名，其实不改也没事） sitemap 申请了 Google 的，但是好像一直抓不到。会不定时整理分类和 tag。 基本成型了，后面不定时加功能吧。 博客 feature 计划（不一定修Blog 功能 目录页 markdown 高亮 友链 [x] 和 aws 页面，vuepress 连调 评论功能 打赏二维码 社交链接 改 log 404 页面 分类 搜索 草稿和发布的关系 标签 RSS 订阅 归档 最近文章 FOLLOW.IT RSS 订阅更新 文章折叠 图片的问题(Github 图床) 固定左右边栏 头像 文章 todo 我与儒释道 工作台打造计划 我的工具们 potplayer 的 aws 实时翻译插 视频字幕提取 mokee 刷机 [ ] QNAP 软路由","link":"/note/"},{"title":"感谢各位的打赏","text":"统计实际时间 2025 年 8 月 11 日 昵称 金额 备注 沈同学 80.00 支持一下 玄兴梦影 19.90 支持一下 安生 19.90 支持一下 秦峰 9.00 很实用的文章 Damo 5.00 感谢内容分享 ljh527031687 2.00 很实用的文章","link":"/reward/"},{"title":"个人语录","text":"有感 才子佳人乃是佳偶天成，世人却总会棒打鸳鸯。 我给女孩子修电脑，就真的只是修电脑，关心电脑好不好用，甚至会忘记女孩子的名字。（2020） 公开 Gitee 仓库要实名认证：离变量名有政治倾向的日子不远了。（2023） 人生四大悲剧: 戏子谈法，娼妓从良，恶人经商，老實人夢碎。（2022） 任侠多累,富贵难求。（2021） 毕竟这世界，没有人能够活着离开。 鲁迅拯救不了国人的重病，也无法唤醒沉睡的每个行尸走肉。每一个市井小民，终其一生不免于为温饱奔波，然后使自己免于周遭的迫害，对于家国天下，他们从来不敢轻易去关心。先知喊破了喉咙，不是当作疯傻，就是被冷漠雪藏。（2023.12） 在我那密不透风的学生时代，总觉得许多异乡游记是和三皇五帝一样传说的故事，而我却生在一个山高皇帝远的地方，守着些不为外人道的自然风光。甚至我在工作以后才有机会到一些不算太远的日址吊唁。比如渤海湾曾经甲午海战的地方，东鸡冠山上到处是日俄战争枪林弹雨的痕迹，就连误入的墓群主人，也分不清到底是旧时的未亡人还是几年十几年甚至几十年前疲于奔命的过劳者，甚至脚踏的这片四方黄士就是乃木宝典战死之处，还有作为标志性的建筑的弹壳，我甚至不愿想象战争年代白发人送黑发人情感被上司大如天的威严严苛所淹没，死后被历史记住已经是最大了补偿了。大连是到处都有墓碑的，在每一个所谓现代定义的景点公园，凡事对外的，总会在一不留神间瞧见墓碑或者墓群就在不远处。中日之间是有宿命的姻缘的，这点在那些发生过大规模屠杀战争的地方尤为严重。大连的每一片土地都渗着鲜血，有革命先烈的，有当代年轻人的。当地的大户说,采集百年弱冠的血，用温热的殷红把混着泥土的陈年凝块化开，喝了可以长生不老。 –《地坛游记》（2023.4） 旅大是日本的情妇，被百般虐待，所有的灵感都来源于她，荣誉则是成为一份作品，而毁灭也恰好是她。 –《佛•教化•屠杀》（2017） 世界上最大的谎言是年轻有无限的可能。几十年后回头看去，又为钱财庸碌一生。（2023） 两个人因为相爱而在一起，却又因为相处而变得普通。（2024.4.21） 原来所谓心动，只是在荷尔蒙的刺激下，新鲜感剩下的余温而已。（2024.4.24） 杀人魔踩死了一只蚂蚁，劳动模范在进行杀人比赛。（2024.4.30） 先不说生理性喜欢，但是生理性不喜欢的表现之一是，听她滔滔不绝的讲话，觉得索然无味并无营养，顿时拉肚子赶紧离开。但是讨厌一个人的表现则是，听见他说话，手里的事情都进行不下去，包括睡觉。（2024.5.20） 得不到的，往往呼天抢地，得到之后，又任凭其从指尖溜走。（2024.5.20） 跟女生聊天的时候后，对方不主动发消息绝对不要发，对方约你出来就说加班，对方要是去你工作地找你吃饭，你就半夜再回，说下班早提前回去了。然后跟介绍人说对方不会聊天，不主动，内向。然后对方再给你发消息，你就过两三天回两三个不痛不痒的字。他要是秒回你，你就再过两三天再回……还有，要是对方问你在哪工作，你就给他讲企业文化…（2025.8） 多年江湖行走，爱吃武汉莲藕。 对象一个没有，专门咒人分手。电脑一玩一天，三十不碰烟酒。（2025.8） 摘抄 要打倒邪恶就要先成为邪恶的化身。 - 《游戏王 GX》 霸王十代 在香港，任何一个凡俗的市民，毕生宏愿都置业成家安居，然后老死。 -《胭脂扣》 如梦如幻月，若即若离花。 -《胭脂扣》 不能保护我们宇宙的话，正义我就不要了！（我が宇宙を守れぬ正義など要らぬ ）《龙珠超》托破 古籍摘抄 天下多故，名士少有全者。 - 房玄龄 :《昏害·卷四十九·列傅第十九·阮籍傅》 立身之道，舆文章具，立身先须谨重，又早且识放荡。 - 南朝梁·萧纲 : 《诚凿公大心害》，收入唐·欧踢韵等《势文颊聚》 文章技术 blog：AWS 加油站生活 blog：镜湖catgpt：catgpttranslate:aws translate餐厅选择器：random-restaurant-picker awsx： 1. pypi：GitHub - Xu-Hardy/awsx pypi.org/project/awsx/ 2. npm: awsx-cli - npm","link":"/quotes/"},{"title":"博客feature 计划（不一定修","text":"Blog 功能 目录页 markdown高亮 友链 和aws页面，vuepress 连调 评论功能 打赏二维码 社交链接 改log 404页面 分类 搜索 草稿和发布的关系 标签 RSS订阅 归档 最近文章 FOLLOW.IT 订阅更新 文章折叠 图片的问题（github图床） 固定左右边栏 头像 文章todo 我与儒释道 工作台打造计划 我的工具们 chatgpt尝鲜 potplayer的aws实时翻译插 视频字幕提取 mokee刷机 QNAP 软路由","link":"/todo/"}]}