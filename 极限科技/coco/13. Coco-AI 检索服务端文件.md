---
title: Coco-AI 服务端文件系统检索
tags: Coco-AI
toc: true
categories: 极限科技
date: 2025-08-11 00:00:00
---

随着企业和个人数据量的激增，如何高效管理与搜索文件资料，已成为提升工作效率的关键。

**Coco-AI** 新增的 **本地文件连接器**，可以直接接入服务端文件系统，实现秒级搜索、即时访问，让服务器上的文件像本地文档一样触手可及。

本文将介绍如何通过 **Docker 快速部署 Coco Server**，并配置本地文件连接器，实现服务端文件的智能检索。

### 一、快速部署 Coco Server

Coco Server 是连接器功能的核心组件，部署完成后即可接入本地文件、RSS 等多种数据源。
生产环境建议使用持久化存储，避免数据丢失。

<!-- more -->

#### 1. 推荐部署方式（生产环境）

```bash
docker run -d \
  --name cocoserver \
  -p 9000:9000 \
  -v data:/app/easysearch/data \
  -v config:/app/easysearch/config \
  -v logs:/app/easysearch/logs \
  infinilabs/coco:0.7.1-2426
```

#### 2. 测试部署方式（非持久化）

```bash
docker run -d \
  --name cocoserver \
  -p 9000:9000 \
  infinilabs/coco:0.7.1-2426
```

> 建议生产环境使用持久化部署（第一种方式），测试环境可选择非持久化部署（第二种方式）。

---

### 二、配置 AI 模型

创建用户后，我选择 **Ollama** 作为模型提供商：

- **地址**：`http://localhost:11434`
- **模型**：`deepseek-r1:7b`

![设置模型](https://raw.githubusercontent.com/cloudsmithy/picgo-imh/master/35d9bf40d93482edcfd1cac26bd0f557.png)

在「模型提供商」界面可以看到默认启用的 **Coco AI**，它会直接调用已配置的 Ollama，也支持任何兼容 OpenAI API 协议的 LLM。

![模型提供商](https://raw.githubusercontent.com/cloudsmithy/picgo-imh/master/b84c85218a471729a646fc47bc899838.png)
![Coco AI 设置](https://raw.githubusercontent.com/cloudsmithy/picgo-imh/master/b86711e540165b68ad9f77f5c9f7e4c7.png)

---

### 三、数据源概览

Coco-AI 默认内置了 **官方文档** 和 **Hacker News** 数据源，并在近期新增：

![数据源连接器](https://raw.githubusercontent.com/cloudsmithy/picgo-imh/master/45419dc868e753402576504aedb4be6f.png)

- **本地文件连接器**（本文重点）
- RSS 连接器
- S3 连接器

![连接器选择](https://raw.githubusercontent.com/cloudsmithy/picgo-imh/master/8cab32aeab3b966b11d0370372982415.png)

---

### 四、配置本地文件连接器

本地连接器的配置非常简单，只需：

1. 选择文件路径
2. 设置需要索引的文件后缀
3. 等待系统从 **localFS** 中智能提取内容

![本地文件设置](https://raw.githubusercontent.com/cloudsmithy/picgo-imh/master/5415d175c5e1d5406d863adb1c8e681b.png)

### 使用 Docker 时的注意事项

如果通过 Docker 部署 Coco Server，需要将本地目录映射到容器内，因为连接器读取的是**容器内部路径**，而非主机路径。

当然，也可以像我这样直接在 **Orbstack** 等容器平台上传文件，省去目录映射的步骤。

![文件上传示例](https://raw.githubusercontent.com/cloudsmithy/picgo-imh/master/image-20250811054426758.png)

添加完成后，可以在连接器列表中看到新建的服务端本地文件连接器：

![连接器列表](https://raw.githubusercontent.com/cloudsmithy/picgo-imh/master/1d685c561ee0ea233fcf8f92846d5c99.png)

### 五、在 Coco App 中查看与检索

登录 **Coco App** 后，可以看到刚刚添加的 **本地文件** 数据源，并直接进行搜索。

![Coco App 数据源](https://raw.githubusercontent.com/cloudsmithy/picgo-imh/master/facdce6af59da887be3227b663e2eae9.png)

这是刚才添加的服务端文件的搜索结果：

![搜索结果](https://raw.githubusercontent.com/cloudsmithy/picgo-imh/master/image-20250811054929034.png)

此外，Coco-AI 还支持客户端本地文件搜索，但本文重点展示的是**服务端文件检索**功能：

![客户端本地文件](https://raw.githubusercontent.com/cloudsmithy/picgo-imh/master/image-20250811055911880.png)

### 结尾

通过本地文件连接器，Coco-AI 不仅能帮助你把服务端的文档、日志、配置文件快速接入 AI 检索，还能结合多数据源进行统一搜索，大幅减少人工查找和信息碎片化的时间成本。

未来你还可以将 本地文件检索 与 RSS、API、数据库连接器组合使用，让企业级信息管理更智能、更实时、更高效。
如果你也想让服务器里的海量资料触手可及，不妨部署一个试试——也许你的检索方式，从今天就会不一样。
